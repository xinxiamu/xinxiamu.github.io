[{"title":"spring.factories机制","date":"2021-02-18T13:45:12.000Z","path":"2021/02/18/spring-boot-factories/","text":"","tags":[]},{"title":"Redis使用常见问题收藏","date":"2021-01-26T09:14:44.000Z","path":"2021/01/26/redis-use/","text":"一些常用的redis使用问题记录…… 安装两种方式，本地编译，另外一种docker。 查看redis版本进入容器script1redis-server -v","tags":[]},{"title":"部署angular应用到生产环境","date":"2021-01-16T01:45:30.000Z","path":"2021/01/16/angular-deploy/","text":"当你准备把 Angular 应用部署到远程服务器上时，有很多可选的部署方式。下面介绍在nginx环境下部署，还有制作docker镜像方式部署。 构建，并部署到nginx服务器构建应用生产环境1.使用开发环境进行构建 script1ng build --prod 2.把输出目录（默认为 dist/）下的每个文件都复制到到服务器上的某个目录下。 3.配置服务器，让缺失的文件都重定向到 index.html 上。 nginx配置文件使用 try_files 指向 index.html 1try_files $uri $uri/ /index.html; 完整配置： 12345location / &#123; root /usr/share/nginx/html; index index.html index.htm login.html; try_files $uri $uri/ /index.html;&#125; 制作nginx docker镜像整体发布","tags":[]},{"title":"docker 局域网下跨主机网络通讯-建立网桥","date":"2021-01-09T17:33:25.000Z","path":"2021/01/10/docker-net/","text":"参考： https://www.cnblogs.com/qkhh/p/14225041.html https://www.php.cn/docker/446263.html https://www.cnblogs.com/liyuanhong/articles/5851251.html route使用：https://blog.csdn.net/hzhsan/article/details/44753533 直接路由方式https://developer.aliyun.com/article/602107 此法在阿里云同网段服务器中行不通，不知原因。","tags":[]},{"title":"angular pdf 浏览插件ng2-pdfjs-viewer","date":"2020-12-28T11:00:00.000Z","path":"2020/12/28/ng2-pdfjs-viewer-start/","text":"pdf.js是mozilla公司的一个功能强大的pdf浏览库。下面介绍其在angular项目中的使用…… ng2-pdfjs-viewer插件下载网址 使用案例 使用具体，按照官网介绍以及查看demo就可以知道怎么用了，这里不过多介绍。 无法正常显示电子章的问题处理1.下载源码，在dist目录下，新建文件夹package,把其它文件都放入package目录中。 2.编辑文件E:\\angular\\ng2-pdfjs-viewer-master\\dist\\package\\pdfjs\\build\\pdf.worker.js,把下面一段注释掉： 12345if (data.fieldType === 'Sig') &#123; data.fieldValue = null; _this3.setFlags(_util.AnnotationFlag.HIDDEN);&#125; 3.把修改后的js压缩。百度js压缩工具，然后把压缩后的js内容，整个替换pdf.worker.min.js的内容。 4.在linux环境下，把整个package包压缩成ng2-pdfjs-viewer-5.0.x.tgz,压缩命令如下： script1tar -cvzf ng2-pdfjs-viewer-5.0.7.tgz package/ 5.把压缩文件ng2-pdfjs-viewer-5.0.7.tgz拉下来放到angular项目的根目录下，如下： 最后在package.json文件中(看上面切图)引入。 这样，就可以和上面一样的使用自己修改代码后的版本了。","tags":[]},{"title":"github使用问题收集","date":"2020-12-28T02:54:03.000Z","path":"2020/12/28/github-issue/","text":"好记性，不如烂笔头！下面记录使用github过程中，经常出现的问题以及其解决方案…… github pages突然无法访问的问题1.问题描述： github page如xinxiamu.github.io,突然无法访问了。 2.问题出现原因： 听说是dns解析出问题了。 3.解决方案： DNS查询 打开网址：https://tool.chinaz.com/ 查询结果如下： 4.配置hosts 按照上上面查询到dns对应ip地址，打开电脑系统上的hosts文件。 打开win系统下的hosts文件方法： 进入目录C:\\Windows\\System32\\drivers\\etc,如下操作 打开命令窗口，编辑命令PS C:\\Windows\\System32\\drivers\\etc&gt; notepad .\\hosts执行。 然后编辑hosts文件如下： 保存关闭，刷新浏览器，就可以正常访问了。","tags":[]},{"title":"MUPDF-一个pdf文件处理利器","date":"2020-12-28T02:32:11.000Z","path":"2020/12/28/mupdf/","text":"MuPDF是轻量级的PDF，XPS和电子书查看器,其包含的工具库可以提供处理pdf一些特性的方案，下面让我们来动手看看其能干些什么吧…… 下载：下载地址 其是模块化的，需要什么功能就下载相应平台下的执行包。","tags":[]},{"title":"kafka入门","date":"2020-10-19T03:39:15.000Z","path":"2020/10/19/kafka-start/","text":"介绍kafka的安装，入门基础概念…… 方式一 环境安装（官网,推荐）http://kafka.apache.org/quickstart 第一步：获取安装包下载并解压 script12$ tar -xzf kafka_2.13-2.6.0.tgz$ cd kafka_2.13-2.6.0 第二步：启动KAFKA环境注意：要求 java 8+ 先启动zookeeper：script123# Start the ZooKeeper service# Note: Soon, ZooKeeper will no longer be required by Apache Kafka.$ bin/zookeeper-server-start.sh config/zookeeper.properties 打开新的命令行窗口再启动：script12# Start the Kafka broker service$ bin/kafka-server-start.sh config/server.properties 后台启动方式： script1$ bin/zookeeper-server-start.sh -daemon config/zookeeper.properties script1$ bin/kafka-server-start.sh -daemon config/server.properties 当以上两个服务正确启动，表明你已经具有基础的kafka的运行环境。 第三步：创建主题并存储事件（消息、记录）非常简单，一个主题就类似电脑文件系统里面的一个文件夹，事件就类似文件夹里面的文件。 在你要写入、读取事件之前，你必须首先创建主题。打开另外一个窗口，执行下面命令创建主题： script1$ bin/kafka-topics.sh --create --topic quickstart-events --bootstrap-server localhost:9092 以上命令创建了主题quickstart-events。 查看主题命令：script1$ bin/kafka-topics.sh --describe --topic quickstart-events --bootstrap-server localhost:9092 第四步：往主题中写入事件Kafka客户端通过网络与Kafka broker进行通信，以写入（或读取）事件。 一旦收到，broker将以持久和容错的方式存储事件，只要您需要甚至可以永久存储。 打开新的窗口,执行下面生产者客户端：script123$ bin/kafka-console-producer.sh --topic quickstart-events --bootstrap-server localhost:9092This is my first eventThis is my second event 任何时候你可以Ctrl-C停止客户端。 第五步：消费读取事件打开新的窗口，执行下面消费端命令：script123$ bin/kafka-console-consumer.sh --topic quickstart-events --from-beginning --bootstrap-server localhost:9092This is my first eventThis is my second event 任何时候你可以Ctrl-C停止客户端。 实验：你可以在生产者端，随意输入些东西看看，回到消费者端，你会马上就能看到。 因为事件被持久地存储在Kafka中，所以您可以根据需要任意多次地读取它们。 您可以通过打开另一个终端会话并再次重新运行上一个命令来轻松地验证这一点。 第六步：通过KAFKA CONNECT将数据作为事件流导入/导出在诸如关系数据库或传统消息传递系统之类的现有系统中，您可能拥有大量数据，以及已经使用这些系统的许多应用程序。 通过Kafka Connect，您可以将来自外部系统的数据连续地吸收到Kafka中，反之亦然。 因此，将现有系统与Kafka集成非常容易。 为了使此过程更加容易，有数百种此类连接器可供使用。 看一下Kafka Connect部分，了解更多有关如何连续地将数据导入和导出Kafka的信息。 第七步：使用kafka流处理您的活动一旦将数据作为事件存储在Kafka中，就可以使用Java / Scala的Kafka Streams客户端库处理数据。 它允许您实现关键任务实时应用程序和微服务，其中输入和/或输出数据存储在Kafka主题中。 Kafka Streams结合了在客户端编写和部署标准Java和Scala应用程序的简便性以及Kafka服务器端集群技术的优势，使这些应用程序具有高度可伸缩性，弹性，容错性和分布式性。 该库支持一次精确处理，有状态操作和聚合，开窗，联接，基于事件时间的处理等等。 第八步：终止Kafka运行环境1.终止生产者端和消费者端，通过Ctrl-C。2.终止kafka broker。3.终止ZooKeeper。 如果您还想删除本地Kafka环境的任何数据，包括您在此过程中创建的所有事件，请运行以下命令：script1$ rm -rf /tmp/kafka-logs /tmp/zookeeper =============================== 《完》 ==================================== 方式二 环境安装（单机）环境要求： 系统： Linux CentOS7 JAVA: jdk_8 + 安装JAVA这个不会安装，回家种番薯…… 安装Zookeeper（单机模式）script1234567891011121314# tar -zxf zookeeper-3.4.6.tar.gz# mv zookeeper-3.4.6 /usr/local/zookeeper# mkdir -p /var/lib/zookeeper# cat &gt; /usr/local/zookeeper/conf/zoo.cfg &lt;&lt; EOF&gt; tickTime=2000&gt; dataDir=/var/lib/zookeeper&gt; clientPort=2181&gt; EOF# export JAVA_HOME=/usr/java/jdk1.8.0_51# /usr/local/zookeeper/bin/zkServer.sh startJMX enabled by defaultUsing config: /usr/local/zookeeper/bin/../conf/zoo.cfgStarting zookeeper ... STARTED# Docker环境下安装 https://hub.docker.com/_/zookeeper script12345# cat &gt; /server/dockers/zookeeper/conf/zoo.cfg &lt;&lt; EOF&gt; tickTime=2000&gt; dataDir=/tmp/zookeeper&gt; clientPort=2181&gt; EOF script1docker run --name zookeeper -p 2181:2181 --restart always -d -v /server/dockers/zookeeper/conf/zoo.cfg:/conf/zoo.cfg zookeeper 安装 Kafka Broker成功启动zookeeper后，再安装kafka broker。 安装下面安装kafka在目录/usr/local/kafka, 配置zookeeper文件，并把kafka元数据存储在/tmp/kafka-logs: script1234567# tar -zxf kafka_2.11-0.9.0.1.tgz# mv kafka_2.11-0.9.0.1 /usr/local/kafka# mkdir /tmp/kafka-logs# export JAVA_HOME=/usr/java/jdk1.8.0_51# /usr/local/kafka/bin/kafka-server-start.sh -daemon/usr/local/kafka/config/server.properties#","tags":[]},{"title":"docker环境安装redmine","date":"2020-09-02T03:16:44.000Z","path":"2020/09/02/redmine-docker-install/","text":"本文介绍在docker环境下安装Redmine项目开发管理软件系统…… 安装mysqlscript1docker run --name mysql-redmine -p 3309:3306 --restart always --privileged=true -v /server/redmine/db/conf:/etc/mysql/conf.d -v /server/redmine/db/logs:/logs -v /server/redmine/db/data:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=a1234567@! -e MYSQL_USER=redmine -e MYSQL_PASSWORD=a1234567@! -e MYSQL_DATABASE=redmine -d mysql:5.7 安装redminescript1docker run -d --name xc-redmine -p 8888:3000 --restart always -v /server/redmine/redmine-dir/files:/usr/src/redmine/files:z -v /server/redmine/redmine-dir/plugins:/usr/src/redmine/plugins:z -e REDMINE_DB_MYSQL=mysql-redmine -e REDMINE_DB_USERNAME=redmine -e REDMINE_DB_PASSWORD=a1234567@! --link mysql-redmine:mysql redmine docker-compose安装script1234567891011121314151617181920212223242526version: '2.0' services: redmine: image: redmine restart: always ports: - 3000:3000 environment: REDMINE_DB_MYSQL: db REDMINE_DB_PASSWORD: root123 volumes: - ./redmine/data:/usr/src/redmine/files:z - ./redmine/plugins:/usr/src/redmine/plugins:z db: image: mysql:5.7 restart: always volumes: - ./mysql/data:/var/lib/mysql:z environment: MYSQL_ROOT_PASSWORD: root123 MYSQL_DATABASE: redmine ports: - 3306:3306 迁移redmine系统数据数据库迁移直接拷贝同步以前数据库到最新的库即可。 文件迁移进入以前的redmine安装目录，拷贝整个files文件夹到新的filse文件夹路径下，文件就能访问了。 插件进入redmine容器，按照之前介绍方式安装插件。docker exec -it redmine /bin/bash。 或者： 移除或者拷贝插件到plugins映射卷下，并docker restart redmine即可实现插件的安装卸载。","tags":[]},{"title":"Hugo + Netlify +Forestry 发布hugo静态网站","date":"2020-07-03T01:04:07.000Z","path":"2020/07/03/Hugo-Netlify-Forestry/","text":"在本教程中，我们将向您展示如何使您的网站正常运行，而无需购买任何托管服务并只需触摸一行代码。 你需要 Git服务，这里我们使用github。 Netlify 帐户来托管文件并添加自定义域名。 Forestry 账户来可视化编辑网站内容，不需要写一行代码。 第一步：创建Hugo项目仓库并放到Github。在本地创建hugo项目，选定喜欢的主题模板，然后放到Github仓库上。 第二步：注册Netlify账号建议用Github账号注册登录。 注册成功后看到：","tags":[]},{"title":"静态网站生成工具-Hugo","date":"2020-06-29T05:01:42.000Z","path":"2020/06/29/hugo-start/","text":"Hugo是一个静态网站生成程序，类似Hexo。但是Hugo是由Go语言编写的，完全开源、高性能、安全、可高定制化、具有丰富的模板…… 官网 源码 Hugo安装Windows二进制文件安装（推荐）1.官方源码库下载编译好的二进制可执行文件 https://github.com/gohugoio/hugo/releases 2.解压并放到目录C:\\Hugo\\bin下： 3.把可执行文件路径添加到环境变量，以便在任何路径下都可以访问 4.查看安装是否成功 随便打开命令行执行下面命令： script12C:\\Users\\xinxiamu&gt;hugo versionHugo Static Site Generator v0.73.0-428907CC windows/amd64 BuildDate: 2020-06-23T16:32:10Z 看到打印出hugo的安装版本号，那就说明安装成功了。 源码编译安装不推荐，需要翻墙，否则编译的时候有些依赖的包无法下载，无法编译成功。 1.安装golang语言环境。 2.把hugo作为一个go项目编译，即能得到对应的二进制可执行文件。 快速使用(win10环境)第一步：创建一个新的站点打开某个目录，执行： script12345678910111213F:\\&gt;hugo new site quickstartCongratulations! Your new Hugo site is created in F:\\quickstart.Just a few more steps and you're ready to go:1. Download a theme into the same-named folder. Choose a theme from https://themes.gohugo.io/ or create your own with the \"hugo new theme &lt;THEMENAME&gt;\" command.2. Perhaps you want to add some content. You can add single files with \"hugo new &lt;SECTIONNAME&gt;\\&lt;FILENAME&gt;.&lt;FORMAT&gt;\".3. Start the built-in live server via \"hugo server\".Visit https://gohugo.io/ for quickstart guide and full documentation. 将会在该目录下创建命为quickstart的目录，就是静态网站项目的目录。 第二步：添加主题主题商店：themes.gohugo.io 下面使用炫酷的主题Ananke theme script123cd quickstartgit initgit submodule add https://github.com/budparr/gohugo-theme-ananke.git themes/ananke 添加主题到配置文件： script1echo 'theme = \"ananke\"' &gt;&gt; config.toml 第三步：添加内容script1hugo new posts/my-first-post.md 会在目录content创建posts目录，并在posts创建文件my-first-post.md。 下面你就可以编辑该内容文件啦…… 第四步：启动服务现在，drafts草案模式启动服务: script123456789101112131415161718192021C:\\Users\\xinxiamu\\quickstart&gt;hugo server -DBuilding sites ... | EN-------------------+----- Pages | 10 Paginator pages | 0 Non-page files | 0 Static files | 6 Processed images | 0 Aliases | 1 Sitemaps | 1 Cleaned | 0Built in 50 msWatching for changes in C:\\Users\\xinxiamu\\quickstart\\&#123;archetypes,content,data,layouts,static,themes&#125;Watching for config changes in C:\\Users\\xinxiamu\\quickstart\\config.tomlEnvironment: \"development\"Serving pages from memoryRunning in Fast Render Mode. For full rebuilds on change: hugo server --disableFastRenderWeb Server is available at http://localhost:1313/ (bind address 127.0.0.1)Press Ctrl+C to stop 在浏览器打开： http://localhost:1313/ 第五步：定制主题上面生成的静态网站看起来已经很不错了，但是在实际发布之前，看样子你还需要稍微调整下。 网站配置： 打开文件config.toml并编辑： 1234baseURL = &quot;https://example.org/&quot;languageCode = &quot;en-us&quot;title = &quot;My New Hugo Site&quot;theme = &quot;ananke&quot; 编辑文件，浏览器马上会刷新并能看到效果，无需刷新或者清除浏览器缓存。因为Hugo集成了reloadLive。publishdir 关于该主题的一些其他的特别的配置，请参考 theme site 进一步的主题定制，请参考主题定制 第六步：生成静态页面很简单，只需要执行命令： script1hugo -D -D: 静态页面输出的目录。 默认情况下，输出在目录./public/。但是你可以通过-d/--destination指定输出目录，或者在配置文件中设置publishdir参数。 Drafts(草稿)，该模式下的内容是不会发布的，因此，但你的内容文件编辑好了，需要发布的时候，必须要把draft: true 改为 draft: false。更多内容参考这里","tags":[]},{"title":"可视化架构-c4介绍","date":"2020-06-28T06:20:45.000Z","path":"2020/06/28/architecture-c4model/","text":"参考： https://www.jianshu.com/p/33c6a7ed126f https://c4model.com/","tags":[]},{"title":"分布式文件存储系统 MINIO入门","date":"2020-06-18T03:05:36.000Z","path":"2020/06/18/minio-start/","text":"发现一个比FastDFS更加简单、体验更加好的文件存储系统，撸它…… 安装-Docker环境下script1234567docker run -p 9000:9000 \\--restart=always \\--name minio1 \\-v /mnt/data:/data \\-e \"MINIO_ROOT_USER=izajzo6yycy5d65vexjmdvtts\" \\-e \"MINIO_ROOT_PASSWORD=kvb9fv35c14soranzsz8bwzyf\" \\-d minio/minio server /data 客户端使用1.安装客户端 首先是安装minio客户端，这个官方文档很清楚，各取所需吧.(Linux 或者windows 选择下载一个即可) 123Linux 二进制文件地址：https://dl.minio.io/client/mc/release/linux-amd64/mcwindows exe文件：https://pan.baidu.com/s/1DxO0MgXqtEVg40FgiyL1CQ 2.设置自定义命令并启动 123Linux下： alias mc=&quot;./mc&quot;windows下： mc.exe 至此，我们的minio client就安装完成了。 3.添加服务端host 12345使用 minio client 将我自己的 minio server 添加到 mc 的配置管理：accessKey：admin secretKey: password script123456[root@xc-product-server-hn002 ~]# mc config host add minio http://192.168.0.49:4369 izajzo6yycy5d65vexjmdvtts kvb9fv35c14soranzsz8bwzyfmc: Configuration written to `/root/.mc/config.json`. Please update your access credentials.mc: Successfully created `/root/.mc/share`.mc: Initialized share uploads `/root/.mc/share/uploads.json` file.mc: Initialized share downloads `/root/.mc/share/downloads.json` file.Added `minio` successfully. 查看： script1234567891011121314151617181920212223242526272829303132333435[root@xc-product-server-hn002 ~]# ./mc config host listgcs URL : https://storage.googleapis.com AccessKey : YOUR-ACCESS-KEY-HERE SecretKey : YOUR-SECRET-KEY-HERE API : S3v2 Path : dnslocal URL : http://localhost:9000 AccessKey : SecretKey : API : Path : autominio URL : http://192.168.0.49:4369 AccessKey : izajzo6yycy5d65vexjmdvtts SecretKey : kvb9fv35c14soranzsz8bwzyf API : s3v4 Path : autoplay URL : https://play.min.io AccessKey : Q3AM3UQ867SPQQA43P2F SecretKey : zuf+tfteSlswRu7BJ86wekitnifILbZam1KYY3TG API : S3v4 Path : autos3 URL : https://s3.amazonaws.com AccessKey : YOUR-ACCESS-KEY-HERE SecretKey : YOUR-SECRET-KEY-HERE API : S3v4 Path : dns 可以看到minio的host。 设置永久下载策略配置策略命令查看: mc policy script12[root@xc-product-server-hn002 ~]# ./mc policy set download minio/xrlj-20210113Access permission for `minio/xrlj-20210113` is set to `download` 这个命令的作用是将 server 端的 mybucket 桶设置为开放管理，可以直接通过 url 进行下载。 [桶名]/[路径]可以一直拼接到具体的文件夹或文件 类似于以下 http://xxx.xxx.xxx.xxx:9000/mybucket/xxx.zip，可用浏览器直接从此URL访问下载。 上传文件查看文件集成nginx访问文件参考资源官网","tags":[]},{"title":"JAVA JNI入门","date":"2020-06-06T10:07:41.000Z","path":"2020/06/06/java-jni/","text":"Linux环境Windows环境第一步：安装c/c++编译环境注意JDK版本，如果是64位的，编译环境也要安装的对应的64位的。 编译环境MinGW的安装下载地址：http://mingw-w64.org/doku.php/download/mingw-builds 下载运行安装即可，注意选择64位的。 编写java类1234567891011121314151617package com.ymu.javase.jni;public class HelloJNI &#123; static &#123; // hello.dll (Windows) or libhello.so (Unixes)// System.load(\"\"); //加载的全路径文件名 System.loadLibrary(\"jni/hello\"); &#125; private native void sayHello(); public static void main(String[] args) &#123; HelloJNI helloJNI = new HelloJNI(); helloJNI.sayHello(); &#125;&#125; 生成C语言调用头文件script12E:\\xinxiamu.github\\java-core\\src\\main\\java\\com\\ymu\\javase\\jni&gt;D:\\jdk-11.0.3\\bin\\javac.exe -h E:\\xinxiamu.github\\java-core\\jni HelloJNI.java 在HelloJNI.java所在文件目录下执行，生成的头文件在目录E:\\xinxiamu.github\\java-core\\jni下。 生成的头文件： 123456789101112131415161718192021/* DO NOT EDIT THIS FILE - it is machine generated */#include &lt;jni.h&gt;/* Header for class com_ymu_javase_jni_HelloJNI */#ifndef _Included_com_ymu_javase_jni_HelloJNI#define _Included_com_ymu_javase_jni_HelloJNI#ifdef __cplusplusextern &quot;C&quot; &#123;#endif/* * Class: com_ymu_javase_jni_HelloJNI * Method: sayHello * Signature: ()V */JNIEXPORT void JNICALL Java_com_ymu_javase_jni_HelloJNI_sayHello (JNIEnv *, jobject);#ifdef __cplusplus&#125;#endif#endif 方法名称构成：Java_包名_类名_方法名。 编写C语言代码拷贝头文件的c方法，并实现： 1234567891011// Save as &quot;HelloJNI.c&quot;#include &lt;jni.h&gt; // JNI header provided by JDK#include &lt;stdio.h&gt; // C Standard IO Header#include &quot;com_ymu_javase_jni_HelloJNI.h&quot; // Generated// Implementation of the native method sayHello()JNIEXPORT void JNICALL Java_com_ymu_javase_jni_HelloJNI_sayHello (JNIEnv *, jobject) &#123; printf(&quot;Hello World!\\n&quot;); return;&#125; 生成链接库文件.dll在mingw安装目录下，找到可执行文件g++.exe。注意，一定要在环境变量中配置好JAVA_HOME。 script1D:\\Program Files\\mingw-w64\\x86_64-8.1.0-posix-seh-rt_v6-rev0\\mingw64\\bin&gt;\"g++.exe\" -I\"%JAVA_HOME%\\include\" -I\"%JAVA_HOME%\\include\\win32\" -shared -o E:\\xinxiamu.github\\java-core\\jni\\hello.dll E:\\xinxiamu.github\\java-core\\cpp\\com_ymu_javase_jni_HelloJNI.c 会在E:\\xinxiamu.github\\java-core\\jni生成库链接文件hello.dll。 E:\\xinxiamu.github\\java-core\\cpp\\com_ymu_javase_jni_HelloJNI.c为对应c语言源文件。 把hello.dll文件拷贝到jni目录下。 执行java文件，验证是否成功调用c语言执行HelloJNI.java类main方法，如果成功，可以看到：","tags":[]},{"title":"Spring Boot整合神器-Dataway","date":"2020-05-30T14:17:05.000Z","path":"2020/05/30/spring-boot-dataway/","text":"多年前，当我还是个安卓开发小哥的时候，后台给了我一个神奇的接口对接，参数只需要传表名以及表中你需要的字段名，接口就执行该查询语句，并返回你想要的结果……那会，那后台哥哥剩下的就只负责喝茶聊天了，而我，内心有一万个草泥马。 后来，自己做后台开发了，心中会偶尔想，能不能只需要写一个接口或者一个框架，让前端自己去定义接口，按需去取。但是能力有限，始终无法付诸行动…… 然而今天，偶然看到一神器名叫Dataway，简单了解后，突然如获至宝，我去…… 赶紧记录下来…… 介绍1.优势: 按照某种固定模式，自由定义接口，并按照定义的sql语句，即可得到查询结果。简单点来说，即把sql查询结果直接转换成http接口对外提供。 2.缺点： 由于返回结果通过直接的sql查询，因此想要得到复杂的返回值，比如跨越多张表并且要对结果进行各种再处理的情况，则难以达到要求。 3.适用： 在一些中小企业，技术团队比较弱小甚至只有几个运维的情况下，当他们想要对外开放erp的数据时候，他们是怎么做的呢？ 我见过方法之一就是，建立erp数据库视图供外部使用。考虑到erp数据的安全，且只提供只读视图。 突然发觉，开放视图的方式，和这里介绍的Dataway有着异曲同工之妙。好像都是一样一样的！偷笑…… 很炸裂，有一个运维，够了，只需要写sql就行了，外部系统就能通过http接口拿到结果集。 集成Spring Boot引入相关依赖新建spring-boot项目后，pom.xml中引入依赖： 1234567891011&lt;!-- 引入依赖 --&gt;&lt;dependency&gt; &lt;groupId&gt;net.hasor&lt;/groupId&gt; &lt;artifactId&gt;hasor-spring&lt;/artifactId&gt; &lt;version&gt;4.1.7&lt;/version&gt;&lt;!-- 查看最新版本：https://mvnrepository.com/artifact/net.hasor/hasor-spring --&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;net.hasor&lt;/groupId&gt; &lt;artifactId&gt;hasor-dataway&lt;/artifactId&gt; &lt;version&gt;4.1.7&lt;/version&gt;&lt;!-- 查看最新版本：https://mvnrepository.com/artifact/net.hasor/hasor-dataway --&gt;&lt;/dependency&gt; 配置文件中启用Dataway在应用的 application.properties 配置文件中启用 Dataway 123456789# 启用 Dataway 功能（默认不启用）HASOR_DATAQL_DATAWAY=true# 开启 ui 管理功能（注意生产环境必须要设置为 false，否则会造成严重的生产安全事故）HASOR_DATAQL_DATAWAY_ADMIN=true# （可选）API工作路径HASOR_DATAQL_DATAWAY_API_URL=/api/# （可选）ui 的工作路径，只有开启 ui 管理功能后才有效HASOR_DATAQL_DATAWAY_UI_URL=/interface-ui/ 初始化必要的表(例：MySQL)123456789101112131415161718192021222324252627282930313233CREATE TABLE `interface_info` ( `api_id` int(11) NOT NULL AUTO_INCREMENT COMMENT 'ID', `api_method` varchar(12) NOT NULL COMMENT 'HttpMethod：GET、PUT、POST', `api_path` varchar(512) NOT NULL COMMENT '拦截路径', `api_status` int(2) NOT NULL COMMENT '状态：0草稿，1发布，2有变更，3禁用', `api_comment` varchar(255) NULL COMMENT '注释', `api_type` varchar(24) NOT NULL COMMENT '脚本类型：SQL、DataQL', `api_script` mediumtext NOT NULL COMMENT '查询脚本：xxxxxxx', `api_schema` mediumtext NULL COMMENT '接口的请求/响应数据结构', `api_sample` mediumtext NULL COMMENT '请求/响应/请求头样本数据', `api_option` mediumtext NULL COMMENT '扩展配置信息', `api_create_time` datetime DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间', `api_gmt_time` datetime DEFAULT CURRENT_TIMESTAMP COMMENT '修改时间', PRIMARY KEY (`api_id`)) ENGINE=InnoDB AUTO_INCREMENT=0 DEFAULT CHARSET=utf8mb4 COMMENT='Dataway 中的API';CREATE TABLE `interface_release` ( `pub_id` int(11) NOT NULL AUTO_INCREMENT COMMENT 'Publish ID', `pub_api_id` int(11) NOT NULL COMMENT '所属API ID', `pub_method` varchar(12) NOT NULL COMMENT 'HttpMethod：GET、PUT、POST', `pub_path` varchar(512) NOT NULL COMMENT '拦截路径', `pub_status` int(2) NOT NULL COMMENT '状态：0有效，1无效（可能被下线）', `pub_type` varchar(24) NOT NULL COMMENT '脚本类型：SQL、DataQL', `pub_script` mediumtext NOT NULL COMMENT '查询脚本：xxxxxxx', `pub_script_ori` mediumtext NOT NULL COMMENT '原始查询脚本，仅当类型为SQL时不同', `pub_schema` mediumtext NULL COMMENT '接口的请求/响应数据结构', `pub_sample` mediumtext NULL COMMENT '请求/响应/请求头样本数据', `pub_option` mediumtext NULL COMMENT '扩展配置信息', `pub_release_time`datetime DEFAULT CURRENT_TIMESTAMP COMMENT '发布时间（下线不更新）', PRIMARY KEY (`pub_id`)) ENGINE=InnoDB AUTO_INCREMENT=0 DEFAULT CHARSET=utf8mb4 COMMENT='Dataway API 发布历史。';create index idx_interface_release on interface_release (pub_api_id); 初始化数据源如果项目中已经配置了数据源，则直接将 Spring 使用的数据源导入到 Hasor 环境共 Dataway 使用。 123456789101112131415@DimModule@Componentpublic class ExampleModule implements SpringModule &#123; @Autowired private DataSource dataSource = null; @Override public void loadModule(ApiBinder apiBinder) throws Throwable &#123; // .DataSource form Spring boot into Hasor apiBinder.installModule(new JdbcModule(Level.Full, this.dataSource)); // .custom DataQL //apiBinder.tryCast(QueryApiBinder.class).loadUdfSource(apiBinder.findClass(DimUdfSource.class)); //apiBinder.tryCast(QueryApiBinder.class).bindFragment(\"sql\", SqlFragment.class); &#125;&#125; 如果没有配置数据源，则要配置数据源： 1.引入依赖 12345678910111213&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-jdbc&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.1.10&lt;/version&gt;&lt;/dependency&gt; 2.添加配置 在application.properties中添加数据源配置： 123456789101112131415# dbspring.datasource.url=jdbc:mysql://172.31.31.31:3910/dataway?useUnicode=true&amp;characterEncoding=utf8&amp;useTimezone=true&amp;serverTimezone=Asia/Shanghaispring.datasource.username=rootspring.datasource.password=123456spring.datasource.driver-class-name=com.mysql.jdbc.Driverspring.datasource.type=com.alibaba.druid.pool.DruidDataSource# druidspring.datasource.druid.initial-size=3spring.datasource.druid.min-idle=3spring.datasource.druid.max-active=10spring.datasource.druid.max-wait=60000spring.datasource.druid.stat-view-servlet.login-username=adminspring.datasource.druid.stat-view-servlet.login-password=adminspring.datasource.druid.filter.stat.log-slow-sql=truespring.datasource.druid.filter.stat.slow-sql-millis=1 Hasor 启动的时候会调用 loadModule 方法，在这里再把 DataSource 设置到 Hasor 中。 在SprintBoot 中启用 Hasor123456789101112131415161718192021222324252627282930313233343536373839import net.hasor.spring.boot.EnableHasor;import net.hasor.spring.boot.EnableHasorWeb;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.ResponseBody;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import java.io.IOException;@EnableHasor@EnableHasorWeb@SpringBootApplicationpublic class DemoApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(DemoApplication.class, args); &#125; @Controller @ResponseBody @RequestMapping(\"/\") public class HomeController &#123; /** * 输入http://localhost:8080直接跳转到http://localhost:8080/interface-ui/ * @param request * @param response * @throws IOException */ @GetMapping public void index(HttpServletRequest request, HttpServletResponse response) throws IOException &#123; response.sendRedirect(\"/interface-ui/\"); &#125; &#125;&#125; 这一步非常简单，只需要在 Spring 启动类上增加两个注解即可。 启动后，浏览器打开http://localhost:8080。 具体使用参考： https://www.hasor.net/web/dataway/for_boot.html","tags":[]},{"title":"Java IO：第六节-Data Stream","date":"2020-04-24T02:31:30.000Z","path":"2020/04/24/java-core-io-data-stream6/","text":"","tags":[]},{"title":"Java IO：第五节-System.in, System.out, System.err","date":"2020-04-24T02:08:48.000Z","path":"2020/04/24/java-core-io-system/","text":"原文地址 System.in, System.out, System.err这3个流同样是常见的数据来源和数据流目的地。使用最多的可能是在控制台程序里利用System.out将输出打印到控制台上。 JVM启动的时候通过Java运行时初始化这3个流，所以你不需要初始化它们(尽管你可以在运行时替换掉它们)。 System.inSystem.in是一个典型的连接控制台程序和键盘输入的InputStream流。通常当数据通过命令行参数或者配置文件传递给命令行Java程序的时候，System.in并不是很常用。图形界面程序通过界面传递参数给程序，这是一块单独的Java IO输入机制。 System.outSystem.out是一个PrintStream流。System.out一般会把你写到其中的数据输出到控制台上。System.out通常仅用在类似命令行工具的控制台程序上。System.out也经常用于打印程序的调试信息(尽管它可能并不是获取程序调试信息的最佳方式)。 System.errSystem.err是一个PrintStream流。System.err与System.out的运行方式类似，但它更多的是用于打印错误文本。一些类似Eclipse的程序，为了让错误信息更加显眼，会将错误信息以红色文本的形式通过System.err输出到控制台上。 System.out和System.err的简单例子：这是一个System.out和System.err结合使用的简单示例： try { InputStream input = new FileInputStream(&quot;c:\\\\data\\\\...&quot;); System.out.println(&quot;File opened...&quot;); } catch (IOException e) { System.err.println(&quot;File opening failed:&quot;); e.printStackTrace(); } 替换系统流尽管System.in, System.out, System.err这3个流是java.lang.System类中的静态成员(译者注：这3个变量均为final static常量)，并且已经预先在JVM启动的时候初始化完成，你依然可以更改它们。只需要把一个新的InputStream设置给System.in或者一个新的OutputStream设置给System.out或者System.err，之后的数据都将会在新的流中进行读取、写入。 可以使用System.setIn(), System.setOut(), System.setErr()方法设置新的系统流(译者注：这三个方法均为静态方法，内部调用了本地native方法重新设置系统流)。例子如下： OutputStream output = new FileOutputStream(&quot;c:\\\\data\\\\system.out.txt&quot;); PrintStream printOut = new PrintStream(output); System.setOut(printOut); 现在所有的System.out都将重定向到”c:\\data\\system.out.txt”文件中。请记住，务必在JVM关闭之前冲刷System.out(译者注：调用flush())，确保System.out把数据输出到了文件中。","tags":[]},{"title":"RabbitMQ学习-消息类型","date":"2020-04-11T16:34:52.000Z","path":"2020/04/12/rabbitmq-messages/","text":"本文介绍消息类型，共用六种消息类型…… 基本消息模型 上图中： P： 生产者，发送消息的程序。 C： 消费者，消息的接收者，会一直等待消息的到来，并消费。 queue： 消息队列，上图红色部分，一般存在内存，也可以持久化到磁盘。存储消息的媒介，生产者投递消息过来，消费者从中获取。 _例子_： 略…… 消息确认机制（ACK）上面的案例中，消息一旦被消费者消费，队列中的消息就会被删除。 那么问题是，RabbitMQ是怎么知道消息已经被接收了的呢？ 如果消费者接收到消息后，还没来得及处理就宕机了或者程序抛出异常，消息消费失败，RabbitMQ服务器无从知道，这样消息就丢失了。 因此，RabbitMQ有个ACK机制。当消费之接收到消息后，会向RabbitMQ发送回执ACK，告知消息已经被接收。 ACK有两种方式： 1.自动ACK：消息一旦被接收，消费者自动发送ACK。2.手动ACK: 消息被接收后，消费者不自动发送ACK，要程序手动发送ACK。 以上两种方式的选择： 如果消息不那么重要，允许消息丢失的情况，那么就选择自动发送ACK方便些。 如果消息非常重要，不允许丢失的情况，那么就要在正确的处理好接收的消息后，再手动发送ACK告知RabbitMQ。否则，消息可能丢失。 示例： 略…… 生产者避免数据丢失：https://www.cnblogs.com/vipstone/p/9350075.html work消息模型工作队列或者竞争消费者模式。 该模式与上面的入门模式相比，多了个消费者，两个消费者共同消费同一个队列中的消息，但是一个消息只能被一个消费者消费。 这个消息模式在web应用中特别有用，在复杂http请求中，可以开启多个消费者，相当于开启多个任务处理处理消息，提高响应速度。 消息分配给消费的方式有两种： 一种是平均的分给每个消费者。哪怕一个消费者很忙，一个很空闲，但是最终，各个消费者消费的消息条数一样。 另外一种方式就是，能者多劳。消费的越快的消费者，消费更多的消息。这种模式下，手动ack的情况下才生效，自动ack不生效。 Publish/subscribe（交换机类型：Fanout，也称为广播 ） 说民： 1.一个生产者，多个消费者。2.每个消费者都有自己的一个队列。3.生产者没有将消息直接发送给队列，而是发送给exchange(交换机、转发器)。4.每个队列都需要绑定到交换机上。5.生产者发送的消息，经过交换机到达队列，实现一个消息被多个消费者消费 例子：注册-&gt;发邮件、发短信 X（Exchanges）：交换机一方面：接收生产者发送的消息。另一方面：知道如何处理消息，例如递交给某个特别队列、递交给所有队列、或是将消息丢弃。到底如何操作，取决于Exchange的类型。 Exchange类型有以下几种： Fanout：广播，将消息交给所有绑定到交换机的队列 Direct：定向，把消息交给符合指定routing key 的队列 Topic：通配符，把消息交给符合routing pattern（路由模式） 的队列 Header：header模式与routing不同的地方在于，header模式取消routingkey，使用header中的 key/value（键值对）匹配队列。 Exchange（交换机）只负责转发消息，不具备存储消息的能力，因此如果没有任何队列与Exchange绑定，或者没有符合路由规则的队列，那么消息会丢失！ 示例： 略…… 思考： 1、publish/subscribe与work queues有什么区别。 区别： 1）work queues不用定义交换机，而publish/subscribe需要定义交换机。 2）publish/subscribe的生产方是面向交换机发送消息，work queues的生产方是面向队列发送消息(底层使用默认交换机)。 3）publish/subscribe需要设置队列和交换机的绑定，work queues不需要设置，实际上work queues会将队列绑定到默认的交换机 。 相同点： 所以两者实现的发布/订阅的效果是一样的，多个消费端监听同一个队列不会重复消费消息。 2、实际工作用 publish/subscribe还是work queues。 建议使用 publish/subscribe，发布订阅模式比工作队列模式更强大（也可以做到同一队列竞争），并且发布订阅模式可以指定自己专用的交换机。 Routing 路由模型（交换机类型：direct） _P_：生产者，向Exchange发送消息，发送消息时，会指定一个routing key。 _X_：Exchange（交换机），接收生产者的消息，然后把消息递交给 与routing key完全匹配的队列 _C1_：消费者，其所在队列指定了需要routing key 为 error 的消息 _C2_：消费者，其所在队列指定了需要routing key 为 info、error、warning 的消息 例子： 发送者sender： public class Send { private final static String EXCHANGE_NAME = &quot;test_direct_exchange&quot;; public static void main(String[] argv) throws Exception { // 获取到连接 Connection connection = ConnectionUtil.getConnection(); // 获取通道 Channel channel = connection.createChannel(); // 声明exchange，指定类型为direct channel.exchangeDeclare(EXCHANGE_NAME, BuiltinExchangeType.DIRECT); // 消息内容， String message = &quot;注册成功！请短信回复[T]退订&quot;; // 发送消息，并且指定routing key 为：sms，只有短信服务能接收到消息 channel.basicPublish(EXCHANGE_NAME, &quot;sms&quot;, null, message.getBytes()); System.out.println(&quot; [x] Sent &apos;&quot; + message + &quot;&apos;&quot;); channel.close(); connection.close(); } } 消费者1： public class Recv { private final static String QUEUE_NAME = &quot;direct_exchange_queue_sms&quot;;//短信队列 private final static String EXCHANGE_NAME = &quot;test_direct_exchange&quot;; public static void main(String[] argv) throws Exception { // 获取到连接 Connection connection = ConnectionUtil.getConnection(); // 获取通道 Channel channel = connection.createChannel(); // 声明队列 channel.queueDeclare(QUEUE_NAME, false, false, false, null); // 绑定队列到交换机，同时指定需要订阅的routing key。可以指定多个 channel.queueBind(QUEUE_NAME, EXCHANGE_NAME, &quot;sms&quot;);//指定接收发送方指定routing key为sms的消息 //channel.queueBind(QUEUE_NAME, EXCHANGE_NAME, &quot;email&quot;); // 定义队列的消费者 DefaultConsumer consumer = new DefaultConsumer(channel) { // 获取消息，并且处理，这个方法类似事件监听，如果有消息的时候，会被自动调用 @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException { // body 即消息体 String msg = new String(body); System.out.println(&quot; [短信服务] received : &quot; + msg + &quot;!&quot;); } }; // 监听队列，自动ACK channel.basicConsume(QUEUE_NAME, true, consumer); } } 消费者2： public class Recv2 { private final static String QUEUE_NAME = &quot;direct_exchange_queue_email&quot;;//邮件队列 private final static String EXCHANGE_NAME = &quot;test_direct_exchange&quot;; public static void main(String[] argv) throws Exception { // 获取到连接 Connection connection = ConnectionUtil.getConnection(); // 获取通道 Channel channel = connection.createChannel(); // 声明队列 channel.queueDeclare(QUEUE_NAME, false, false, false, null); // 绑定队列到交换机，同时指定需要订阅的routing key。可以指定多个 channel.queueBind(QUEUE_NAME, EXCHANGE_NAME, &quot;email&quot;);//指定接收发送方指定routing key为email的消息 // 定义队列的消费者 DefaultConsumer consumer = new DefaultConsumer(channel) { // 获取消息，并且处理，这个方法类似事件监听，如果有消息的时候，会被自动调用 @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException { // body 即消息体 String msg = new String(body); System.out.println(&quot; [邮件服务] received : &quot; + msg + &quot;!&quot;); } }; // 监听队列，自动ACK channel.basicConsume(QUEUE_NAME, true, consumer); } } 我们发送sms的RoutingKey，发现结果：只有指定短信的消费者1收到消息了。 Topics 通配符模式（交换机类型：topics） 每个消费者监听自己的队列，并且设置带统配符的routingkey,生产者将消息发给broker，由交换机根据routingkey来转发消息到指定的队列。 Routingkey一般都是有一个或者多个单词组成，多个单词之间以“.”分割，例如：inform.sms 通配符规则： #：匹配一个或多个词 *：匹配不多不少恰好1个词 举例： audit.#：能够匹配audit.irs.corporate 或者 audit.irs audit.*：只能匹配audit.irs 从示意图可知，我们将发送所有描述动物的消息。消息将使用由三个字（两个点）组成的Routing key发送。路由关键字中的第一个单词将描述速度，第二个颜色和第三个种类：“..”。 我们创建了三个绑定：Q1绑定了“.orange.”，Q2绑定了“...rabbit”和“lazy.＃”。 Q1匹配所有的橙色动物。 Q2匹配关于兔子以及懒惰动物的消息。 下面做个小练习，假如生产者发送如下消息，会进入哪个队列： quick.orange.rabbit Q1 Q2 routingKey=”quick.orange.rabbit”的消息会同时路由到Q1与Q2 lazy.orange.elephant Q1 Q2 quick.orange.fox Q1 lazy.pink.rabbit Q2 (值得注意的是，虽然这个routingKey与Q2的两个bindingKey都匹配，但是只会投递Q2一次) quick.brown.fox 不匹配任意队列，被丢弃 quick.orange.male.rabbit 不匹配任意队列，被丢弃 orange 不匹配任意队列，被丢弃 下面我们以指定Routing key=”quick.orange.rabbit”为例，验证上面的答案 生产者： public class Send { private final static String EXCHANGE_NAME = &quot;test_topic_exchange&quot;; public static void main(String[] argv) throws Exception { // 获取到连接 Connection connection = ConnectionUtil.getConnection(); // 获取通道 Channel channel = connection.createChannel(); // 声明exchange，指定类型为topic channel.exchangeDeclare(EXCHANGE_NAME, BuiltinExchangeType.TOPIC); // 消息内容 String message = &quot;这是一只行动迅速的橙色的兔子&quot;; // 发送消息，并且指定routing key为：quick.orange.rabbit channel.basicPublish(EXCHANGE_NAME, &quot;quick.orange.rabbit&quot;, null, message.getBytes()); System.out.println(&quot; [动物描述：] Sent &apos;&quot; + message + &quot;&apos;&quot;); channel.close(); connection.close(); } } 消费者1： public class Recv { private final static String QUEUE_NAME = &quot;topic_exchange_queue_Q1&quot;; private final static String EXCHANGE_NAME = &quot;test_topic_exchange&quot;; public static void main(String[] argv) throws Exception { // 获取到连接 Connection connection = ConnectionUtil.getConnection(); // 获取通道 Channel channel = connection.createChannel(); // 声明队列 channel.queueDeclare(QUEUE_NAME, false, false, false, null); // 绑定队列到交换机，同时指定需要订阅的routing key。订阅所有的橙色动物 channel.queueBind(QUEUE_NAME, EXCHANGE_NAME, &quot;*.orange.*&quot;); // 定义队列的消费者 DefaultConsumer consumer = new DefaultConsumer(channel) { // 获取消息，并且处理，这个方法类似事件监听，如果有消息的时候，会被自动调用 @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException { // body 即消息体 String msg = new String(body); System.out.println(&quot; [消费者1] received : &quot; + msg + &quot;!&quot;); } }; // 监听队列，自动ACK channel.basicConsume(QUEUE_NAME, true, consumer); } } 消费者2： public class Recv2 { private final static String QUEUE_NAME = &quot;topic_exchange_queue_Q2&quot;; private final static String EXCHANGE_NAME = &quot;test_topic_exchange&quot;; public static void main(String[] argv) throws Exception { // 获取到连接 Connection connection = ConnectionUtil.getConnection(); // 获取通道 Channel channel = connection.createChannel(); // 声明队列 channel.queueDeclare(QUEUE_NAME, false, false, false, null); // 绑定队列到交换机，同时指定需要订阅的routing key。订阅关于兔子以及懒惰动物的消息 channel.queueBind(QUEUE_NAME, EXCHANGE_NAME, &quot;*.*.rabbit&quot;); channel.queueBind(QUEUE_NAME, EXCHANGE_NAME, &quot;lazy.＃&quot;); // 定义队列的消费者 DefaultConsumer consumer = new DefaultConsumer(channel) { // 获取消息，并且处理，这个方法类似事件监听，如果有消息的时候，会被自动调用 @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException { // body 即消息体 String msg = new String(body); System.out.println(&quot; [消费者2] received : &quot; + msg + &quot;!&quot;); } }; // 监听队列，自动ACK channel.basicConsume(QUEUE_NAME, true, consumer); } } 结果C1、C2是都接收到消息了。 RPC 基本概念： Callback queue 回调队列，客户端向服务器发送请求，服务器端处理请求后，将其处理结果保存在一个存储体中。而客户端为了获得处理结果，那么客户在向服务器发送请求时，同时发送一个回调队列地址reply_to。 Correlation id 关联标识，客户端可能会发送多个请求给服务器，当服务器处理完后，客户端无法辨别在回调队列中的响应具体和那个请求时对应的。为了处理这种情况，客户端在发送每个请求时，同时会附带一个独有correlation_id属性，这样客户端在回调队列中根据correlation_id字段的值就可以分辨此响应属于哪个请求。 流程说明： 当客户端启动的时候，它创建一个匿名独享的回调队列。在 RPC 请求中，客户端发送带有两个属性的消息：一个是设置回调队列的 reply_to 属性，另一个是设置唯一值的 correlation_id 属性。将请求发送到一个 rpc_queue 队列中。服务器等待请求发送到这个队列中来。当请求出现的时候，它执行他的工作并且将带有执行结果的消息发送给 reply_to 字段指定的队列。客户端等待回调队列里的数据。当有消息出现的时候，它会检查 correlation_id 属性。如果此属性的值与请求匹配，将它返回给应用","tags":[]},{"title":"RabbitMQ学习-交换机","date":"2020-04-11T16:18:23.000Z","path":"2020/04/12/rabbitmq-exchange/","text":"本文介绍交换机exchange的使用。 Exchange交换机的类型RabbitMQ的Exchange（交换器）分为四类： direct（默认）headersfanouttopic 其中headers交换器允许你匹配AMQP消息的header而非路由键，除此之外headers交换器和direct交换器完全一致，但性能却很差，几乎用不到，所以我们本文也不做讲解。 _注意_：fanout、topic交换器是没有历史数据的，也就是说对于中途创建的队列，获取不到之前的消息 1、 Direct Exchange（1）名称：直接交换器类型 （2）默认的预先定义exchange名字：空字符串或者amq.direct （3）作用描述：根据Binding指定的Routing Key，将符合Key的消息发送到Binding的Queue。可以构建点对点消息传输模型。 如图中RoutingKey分别是error、info、warning，其中error被Binding（绑定）到queue1和queue2上，info和warning被Binding到queue2上。当消息的RoutingKey是error，这条消息将被投递到queue1和queue2中（相当于消息被复制成两个分别投放到两个queue中），然后分别被Consumer1和Consumer2处理。如果消息的RoutingKey是info或者warning，这条消息只会被投递到queue2中，然后被Consumer2处理。如果消息的RoutingKey是其他的字符串，这条消息则会被丢弃。 2、 fanout交换器——发布/订阅模式（1）名称：广播式交换器类型 （2）默认的预先定义exchange名字：amq.fanout （3）作用描述：将同一个message发送到所有同该Exchange 绑定的queue。不论RoutingKey是什么，这条消息都会被投递到所有与此Exchange绑定的queue中。 广播式交换器类型的工作方式：不使用任何参数将queue和Exchange进行Binding，发布者publisher向Exchange发送一条消息（注意：直接交换器类型中的producer变成了publisher，其中隐含了两种交换器的区别），然后这条消息被无条件的投递给所有和这个Exchange绑定的queue中。 如图中，没有RoutingKey的限制，只要消息到达Exchange，都会被投递到queue1和queue2中，然后被对应的Consumer处理。 3、 topic交换器——匹配订阅模式（1）名称：主题交换器类型 （2）默认的预先定义exchange名字：amq.topic （3）作用描述：根据Binding指定的RoutingKey，Exchange对key进行模式匹配后投递到相应的Queue，模式匹配时符号“#”匹配一个或多个词，符号“*”匹配正好一个词，而且单词与单词之间必须要用“.”符号进行分隔。此模式可以用来支持经典的发布/订阅消息传输模型-使用主题名字空间作为消息寻址模式，将消息传递给那些部分或者全部匹配主题模式的queue。 如图中，假如消息的RoutingKey是American.action.13，这条消息将被投递到Q1和Q2中。假如RoutingKey是American.action.13.test（注意：此处是四个词），这条消息将会被丢弃，因为没有routingkey与之匹配。假如RoutingKey是Chinese.action.13，这条消息将被投递到Q2和Q3中。假如RoutingKey是Chinese.action.13.test，这条消息只会被投递到Q3中，#可以匹配一个或者多个单词，而*只能匹配一个词。 参考https://www.cnblogs.com/vipstone/p/9295625.html","tags":[]},{"title":"RabbitMQ学习-基础","date":"2020-04-11T08:31:59.000Z","path":"2020/04/11/rabbitmq-basic/","text":"什么是RabbitMQ？RabbitMQ是由Erlang语言编写的实现了高级消息队列协议（AMQP）的开源消息代理软件（也可称为 面向消息的中间件）。 RabbitMQ就像一个邮局，用来投递消息，接收消息。 使用场景1.异步处理，提高并发量，提高程序响应速度。2.多个程序之间解耦。多个系统之间通过消息中间件进行消息交互。 典型的应用场景： 1、注册时发送邮件或发送短信2、日志分析使用，多个服务产生的数据发送到中间件发送到分析服务。3、消息复制，用于跨机房数据传输、搜索、离线数据计算等。4、延迟消息发送和暂存，把中间件当成可靠的消息暂存地。接受消息，暂时先不发送。 重要概念 （1）Broker：经纪人。提供一种传输服务，维护一条从生产者到消费者的传输线路，保证消息数据能按照指定的方式传输。粗略的可以将图中的RabbitMQ Server当作Broker。 （2）Exchange：消息交换机。指定消息按照什么规则路由到哪个队列Queue。 （3）Queue：消息队列。消息的载体，每条消息都会被投送到一个或多个队列中。 （4）Binding：绑定。作用就是将Exchange和Queue按照某种路由规则绑定起来。 （5）RoutingKey：路由关键字。Exchange根据RoutingKey进行消息投递。 （6）Vhost：虚拟主机。一个Broker可以有多个虚拟主机，用作不同用户的权限分离。一个虚拟主机持有一组Exchange、Queue和Binding。 （7）Producer：消息生产者。主要将消息投递到对应的Exchange上面。一般是独立的程序。 （8）Consumer：消息消费者。消息的接收者，一般是独立的程序。 （9）Channel：消息通道，也称信道。在客户端的每个连接里可以建立多个Channel，每个Channel代表一个会话任务。 RabbitMQ使用过程概述AMQP模型中，消息在Producer中产生，并发送到MQ的exchange上，exchange根据配置的路由将消息投递到对应的Queue上，Queue又将消息发送给已经在此Queue上注册的consumer，消息从queue到consumer有push和pull两种方式。 消息队列的使用过程大概如下： （1）客户端连接到消息队列服务器，打开一个channel。 （2）客户端声明一个exchange，并设置相关属性。 （3）客户端声明一个queue，并设置相关属性。 （4）客户端使用routing key，在exchange和queue之间建立好Binding关系。 （5）生产者客户端投递消息到exchange。 （6）exchange接收到消息后，就根据消息的RoutingKey和已经设置的binding，进行消息路由（投递），将消息投递到一个或多个队列里。 （7）消费者客户端从对应的队列中获取并处理消息。 工作过程 生产者客户端： 1.客户端连接到RabbitMQ服务器上，打开一个消息通道（channel）。2.客户端声明一个消息交换机（exchange），并设置相关属性。3.客户端声明一个消息队列（queue），并设置相关属性。4.客户端使用routing key在消息交换机（exchange）和消息队列（queue）中建立好绑定关系。5.客户端投递消息都消息交换机（exchange）上。6.客户端关闭消息通道（channel）以及和服务器的连接。 服务器端： exchange接收到消息后，根据消息的key（这个key的产生规则暂时没研究，有知道的小伙伴可以留言告诉我）和以及设置的binding，进行消息路由，将消息投递到一个或多个消息队列中。 关于exchange也有几个类型： (1). Direct交换机：完全根据key进行投递。例如，绑定时设置了routing key为abc，客户端提交信息提交信息时只有设置了key为abc的才会投递到队列； (2).Topic交换机：在key进行模式匹配后进行投递。例如：符号”#”匹配一个或多个字符，符号””匹配一串连续的字母字符，例如”abc.#”可以匹配”abc.def.ghi”，而”abc.”只可以匹配”abc.def”。 (3).Fanout交换机：它采取广播模式，消息进来时，将会被投递到与改交换机绑定的所有队列中。 消费者 1、消费者和Broker建立TCP连接 2、消费者和Broker建立通道 3、消费者监听指定的Queue（队列） 4、当有消息到达Queue时Broker默认将消息推送给消费者。 5、消费者接收到消息。 6、ack回复 RabbitMQ的消息持久化RabbitMQ支持数据持久化，也就是把数据写在磁盘上，可以增加数据的安全性。消息队列持久化包括三个部分： 消息交换机（exchange）持久化，在声明时指定durable为1消息队列（queue）持久化，在声明时指定durable为1消息持久化，在投递时指定delivery_mode为2（1是非持久化）如果消息交换机（exchange）和消息队列（queue）都是持久化的话，那么他们之间的绑定（Binding）也是持久化的。如果消息交换机和消息队列之间一个持久化、一个非持久化，那么就不允许绑定。","tags":[]},{"title":"Angular 组件之间的交互","date":"2019-12-06T02:55:38.000Z","path":"2019/12/06/angular-component-interaction/","text":"参考：https://angular.cn/guide/component-interaction","tags":[]},{"title":"Angular使用问题收集","date":"2019-12-01T10:05:10.000Z","path":"2019/12/01/angular-issue-collect/","text":"问题一问题描述： 引入第三方依赖包，如“buffer”，使用报错如下： core.js:6014 ERROR Error: Uncaught (in promise): ReferenceError: global is not defined ReferenceError: global is not defined at Object../node_modules/_buffer@4.9.2@buffer/index.js (index.js:43) at __webpack_require__ (bootstrap:84) at Module../src/app/pages/login/login.component.ts (pages-pages-module.js:108766) at __webpack_require__ (bootstrap:84) at Module../src/app/pages/pages-routing.module.ts (login.component.ts:14) at __webpack_require__ (bootstrap:84) at Module../src/app/pages/pages.module.ts (pages-routing.module.ts:36) at __webpack_require__ (bootstrap:84) at $_lazy_route_resource lazy namespace object:22 at ZoneDelegate.invoke (zone-evergreen.js:359) at resolvePromise (zone-evergreen.js:797) at resolvePromise (zone-evergreen.js:754) at zone-evergreen.js:858 at ZoneDelegate.invokeTask (zone-evergreen.js:391) at Object.onInvokeTask (core.js:39680) at ZoneDelegate.invokeTask (zone-evergreen.js:390) at Zone.runTask (zone-evergreen.js:168) at drainMicroTaskQueue (zone-evergreen.js:559) 解决： 在文件src/polyfills.ts中，添加一行(window as any).global = window; 如下： /** * This file includes polyfills needed by Angular and is loaded before the app. * You can add your own extra polyfills to this file. * * This file is divided into 2 sections: * 1. Browser polyfills. These are applied before loading ZoneJS and are sorted by browsers. * 2. Application imports. Files imported after ZoneJS that should be loaded before your main * file. * * The current setup is for so-called &quot;evergreen&quot; browsers; the last versions of browsers that * automatically update themselves. This includes Safari &gt;= 10, Chrome &gt;= 55 (including Opera), * Edge &gt;= 13 on the desktop, and iOS 10 and Chrome on mobile. * * Learn more in https://angular.io/guide/browser-support */ /*************************************************************************************************** * BROWSER POLYFILLS */ /** IE10 and IE11 requires the following for NgClass support on SVG elements */ // import &apos;classlist.js&apos;; // Run `npm install --save classlist.js`. /** * Web Animations `@angular/platform-browser/animations` * Only required if AnimationBuilder is used within the application and using IE/Edge or Safari. * Standard animation support in Angular DOES NOT require any polyfills (as of Angular 6.0). */ // import &apos;web-animations-js&apos;; // Run `npm install --save web-animations-js`. /** * By default, zone.js will patch all possible macroTask and DomEvents * user can disable parts of macroTask/DomEvents patch by setting following flags * because those flags need to be set before `zone.js` being loaded, and webpack * will put import in the top of bundle, so user need to create a separate file * in this directory (for example: zone-flags.ts), and put the following flags * into that file, and then add the following code before importing zone.js. * import &apos;./zone-flags.ts&apos;; * * The flags allowed in zone-flags.ts are listed here. * * The following flags will work for all browsers. * * (window as any).__Zone_disable_requestAnimationFrame = true; // disable patch requestAnimationFrame * (window as any).__Zone_disable_on_property = true; // disable patch onProperty such as onclick * (window as any).__zone_symbol__UNPATCHED_EVENTS = [&apos;scroll&apos;, &apos;mousemove&apos;]; // disable patch specified eventNames * * in IE/Edge developer tools, the addEventListener will also be wrapped by zone.js * with the following flag, it will bypass `zone.js` patch for IE/Edge * * (window as any).__Zone_enable_cross_context_check = true; * */ (window as any).global = window; /*************************************************************************************************** * Zone JS is required by default for Angular itself. */ import &apos;zone.js/dist/zone&apos;; // Included with Angular CLI. /*************************************************************************************************** * APPLICATION IMPORTS */ 问题-绑定html内容出现警告问题： 12345&lt;span [innerHTML]=\"&#123;&#123;detailsInfo.description&#125;&#125;\"&gt;&lt;/span&gt;---------------------------------------WARNING: sanitizing HTML stripped some content (see http://g.co/ng/security#xss). 解决： 12constructor(public sanitizer: DomSanitizer) &#123; &#125; 1&lt;span [innerHTML]=\"sanitizer.bypassSecurityTrustHtml(detailsInfo.description)\"&gt;&lt;/span&gt;","tags":[]},{"title":"Angular多环境运行、构建发布","date":"2019-11-26T09:28:38.000Z","path":"2019/11/26/angular-environment/","text":"类似spring boot，多环境构建的构建，避免频繁改变配置，极大提高运行和构建应用的效率。 构建与运行","tags":[]},{"title":"Java IO：第四节-Scanner And Formatting","date":"2019-11-11T01:34:53.000Z","path":"2019/11/11/java-core-io-scanner/","text":"Scanner类型的对象可用于将格式化的输入分解为令牌，并根据其数据类型转换单个令牌。 把输入流中的数据分解，找到对应的数据类型数据。比如在一个文本流中找出所有的数字类型等。 Scanner将输入流分解默认情况下，扫描仪使用空格分隔令牌（理解为分隔标识）。 （空格字符包括空格，制表符和行终止符。 public class ScanXan { public static void main(String[] args) throws IOException { Scanner s = null; try { s = new Scanner(new BufferedReader(new FileReader(&quot;xanadu.txt&quot;))); while (s.hasNext()) { System.out.println(s.next()); } } finally { if (s != null) { s.close(); } } } } 文本xanadu.txt的内容： 热烈 庆祝中国成立70周年100！！！ We warmly celebrate the 70th anniversary of the founding of China!!! 输出： 热烈 庆祝中国成立70周年100！！！ We warmly celebrate the 70th anniversary of the founding of China!!! 可以看到，以空格为一个分隔符（令牌）。 请注意，ScanXan在完成扫描程序对象时会调用Scanner的close方法。即使扫描程序不是流，您也需要关闭它以表明已完成其基础流。 当然，你可以使用不同的分隔符来分隔流，调用useDelimiter()方法来实现，传入一个正则表达式。 如：s.useDelimiter(&quot;,\\\\s*&quot;),逗号分隔。 翻译当个分隔值（tokens）ScanXan示例将所有输入标记视为简单的String值。扫描程序还支持所有Java语言原始类型（char除外）以及BigInteger和BigDecimal的令牌。 此外，数值可以使用数千个分隔符。因此，在美国语言环境中，扫描程序会正确读取代表整数值的字符串“ 32,767”。 public static void main(String[] args) throws IOException { Scanner s = null; double sum = 0; try { s = new Scanner(new BufferedReader(new FileReader(&quot;usnumbers.txt&quot;))); s.useLocale(Locale.US); while (s.hasNext()) { if (s.hasNextDouble()) { sum += s.nextDouble(); } else { s.next(); } } } finally { s.close(); } System.out.println(sum); } 以上代码，会把分隔的数字类型读取出来，并累加计算。 Formatterhttps://docs.oracle.com/javase/tutorial/essential/io/formatting.html 格式化输出……","tags":[]},{"title":"angular路由与导航","date":"2019-11-10T03:03:49.000Z","path":"2019/11/10/angular-router/","text":"在用户使用应用程序时，Angular 的路由器能让用户从一个视图导航到另一个视图。浏览器具有熟悉的导航模式： 在地址栏输入 URL，浏览器就会导航到相应的页面。 在页面中点击链接，浏览器就会导航到一个新页面。 点击浏览器的前进和后退按钮，浏览器就会在你的浏览历史中向前或向后导航。 基础知识 元素大多数带路由的应用都要在index.html的 标签下先添加一个 元素，来告诉路由器该如何合成导航用的 URL。 设置src/index.html (base-href) &lt;!DOCTYPE html&gt; &lt;html lang=&quot;en&quot;&gt; &lt;head&gt; &lt;!-- Set the base href --&gt; &lt;base href=&quot;/&quot;&gt; &lt;title&gt;Angular Router&lt;/title&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1&quot;&gt; &lt;/head&gt; &lt;body&gt; &lt;app-root&gt;&lt;/app-root&gt; &lt;/body&gt; &lt;/html&gt; 导入路由模块在src/app/app-routing.module.ts 导入路由模块 import { RouterModule, Routes } from &apos;@angular/router&apos;; 配置路由在src/app/app-routing.module.ts (excerpt)中配置路由： const appRoutes: Routes = [ { path: &apos;crisis-center&apos;, component: CrisisListComponent }, { path: &apos;hero/:id&apos;, component: HeroDetailComponent }, { path: &apos;heroes&apos;, component: HeroListComponent, data: { title: &apos;Heroes List&apos; } }, { path: &apos;&apos;, redirectTo: &apos;/heroes&apos;, pathMatch: &apos;full&apos; }, { path: &apos;**&apos;, component: PageNotFoundComponent } ]; @NgModule({ imports: [ RouterModule.forRoot( appRoutes, { enableTracing: true } // 测试环境才打开 ) // other imports here ], ... }) export class AppModule { } 以上定义一个路由器数组，里面五个路由信息。并用 RouterModule.forRoot() 方法来配置路由器， 并把它的返回值添加到 AppModule 的 imports 数组中。 这里的路由数组 appRoutes 描述如何进行导航。 把它传给 RouterModule.forRoot() 方法并传给本模块的 imports 数组就可以配置路由器。 每个路由都会把一个URL的path映射到一个具体的组件。注意，path不能以斜杆开头。 路由器会为解析和构建最终的 URL，这样当你在应用的多个视图之间导航时，可以任意使用相对路径和绝对路径。 第二个路由中的:id是一个路由参数，后面章节会有更多介绍。 第三个路由中的 data 属性用来存放于每个具体路由有关的任意信息。该数据可以被任何一个激活路由访问，并能用来保存诸如 页标题、面包屑以及其它静态只读数据。如何获取这些存放的信息，后面介绍。 第四个路由中的空路径（’’）表示应用的默认路径，当 URL 为空时就会访问那里，因此它通常会作为起点。 这个默认路由会重定向到 URL /heroes。 最后一个路由中的 ** 路径是一个通配符。当所请求的 URL 不匹配前面定义的路由表中的任何路径时，路由器就会选择此路由。 这个特性可用于显示“404 - Not Found”页，或自动重定向到其它路由。 这些路由的定义顺序是刻意如此设计的。路由器使用先匹配者优先的策略来匹配路由，所以，具体路由应该放在通用路由的前面。在上面的配置中，带静态路径的路由被放在了前面，后面是空路径路由，因此它会作为默认路由。而通配符路由被放在最后面，这是因为它能匹配上每一个 URL，因此应该只有在前面找不到其它能匹配的路由时才匹配它。 如果你想要看到在导航的生命周期中发生过哪些事件，可以使用路由器默认配置中的 enableTracing 选项。它会把每个导航生命周期中的事件输出到浏览器的控制台。 这应该只用于调试。你只需要把 enableTracing: true 选项作为第二个参数传给 RouterModule.forRoot() 方法就可以了。 路由出口RouterOutlet是一个来自路由模块的一个指令，用法类似组件。它扮演一个占位符的角色，用于在模板中标出一个位置，路由将会把要显示在这个出口处的组件显示在这里。 &lt;router-outlet&gt;&lt;/router-outlet&gt; &lt;!-- Routed components go here --&gt; 有了这份配置，当本应用在浏览器中的 URL 变为 /heroes 时，路由器就会匹配到 path 为 heroes 的 Route，并在宿主视图中的RouterOutlet之后显示 HeroListComponent 组件。 路由器链接在地址栏输入对应路由，能导航到相应页面。但多数时候，路由导航是用户操作的结果，查看下面例子： &lt;h1&gt;Angular Router&lt;/h1&gt; &lt;nav&gt; &lt;a routerLink=&quot;/crisis-center&quot; routerLinkActive=&quot;active&quot;&gt;Crisis Center&lt;/a&gt; &lt;a routerLink=&quot;/heroes&quot; routerLinkActive=&quot;active&quot;&gt;Heroes&lt;/a&gt; &lt;/nav&gt; &lt;router-outlet&gt;&lt;/router-outlet&gt; a 标签上的 RouterLink 指令让路由器得以控制这个 a 元素。 这里的导航路径是固定的，因此可以把一个字符串赋给 routerLink（“一次性”绑定）。 路由链接的激活状态RouterLinkActive 指令会基于当前的 RouterState 为活动的 RouterLink 切换所绑定的 css 类。 路由器状态在导航时的每个生命周期成功完成时，路由器会构建出一个 ActivatedRoute 组成的树，它表示路由器的当前状态。 你可以在应用中的任何地方用 Router 服务及其 routerState 属性来访问当前的 RouterState 值。 RouterState 中的每个 ActivatedRoute 都提供了从任意激活路由开始向上或向下遍历路由树的一种方式，以获得关于父、子、兄弟路由的信息。 激活的路由该路由的路径和参数可以通过注入进来的一个名叫ActivatedRoute的路由服务来获取。 路由事件在每次导航中，Router 都会通过 Router.events 属性发布一些导航事件。这些事件的范围涵盖了从开始导航到结束导航之间的很多时间点。下表中列出了全部导航事件： 总结该应用有一个配置过的路由器。 外壳组件中有一个 RouterOutlet，它能显示路由器所生成的视图。 它还有一些 RouterLink，用户可以点击它们，来通过路由器进行导航。 下面是一些路由器中的关键词汇及其含义： 路由器部件 含义 Router（路由器） 为激活的 URL 显示应用组件。管理从一个组件到另一个组件的导航 RouterModule 一个独立的 NgModule，用于提供所需的服务提供商，以及用来在应用视图之间进行导航的指令。 Routes（路由数组） 定义了一个路由数组，每一个都会把一个 URL 路径映射到一个组件。 Route（路由） 定义路由器该如何根据 URL 模式（pattern）来导航到组件。大多数路由都由路径和组件类构成。 RouterOutlet（路由出口） 该指令（）用来标记出路由器该在哪里显示视图。 RouterLink（路由链接） 这个指令把可点击的 HTML 元素绑定到某个路由。点击带有 routerLink 指令（绑定到字符串或链接参数数组）的元素时就会触发一次导航。 RouterLinkActive（活动路由链接） 当 HTML 元素上或元素内的routerLink变为激活或非激活状态时，该指令为这个 HTML 元素添加或移除 CSS 类。 ActivatedRoute（激活的路由） 为每个路由组件提供提供的一个服务，它包含特定于路由的信息，比如路由参数、静态数据、解析数据、全局查询参数和全局碎片（fragment）。 RouterState（路由器状态） 路由器的当前状态包含了一棵由程序中激活的路由构成的树。它包含一些用于遍历路由树的快捷方法。 链接参数数组 这个数组会被路由器解释成一个路由操作指南。你可以把一个RouterLink绑定到该数组，或者把它作为参数传给Router.navigate方法。 路由组件 一个带有RouterOutlet的 Angular 组件，它根据路由器的导航来显示相应的视图。 范例应用下面讲解如何开发一个带路由的多页面小应用。涉及到下面一些决策： 把应用的各个特性组织成模块。 导航到组件（Heroes 链接到“英雄列表”组件）。 包含一个路由参数（当路由到“英雄详情”时，把该英雄的 id 传进去）。 子路由（危机中心特性有一组自己的路由）。 CanActivate 守卫（检查路由的访问权限）。 CanActivateChild 守卫（检查子路由的访问权限）。 CanDeactivate 守卫（询问是否丢弃未保存的更改）。 Resolve 守卫（预先获取路由数据）。 惰性加载特性模块。 CanLoad 守卫（在加载特性模块之前进行检查）。 学习参考： https://angular.cn/guide/router#base-href","tags":[]},{"title":"angular常用命令","date":"2019-11-10T02:37:48.000Z","path":"2019/11/10/angular-cli-command/","text":"本章介绍angular项目开发过程中经常用到的angular-cli命令。对这些常用命令要有个基本的认识以及基本的使用能力。 创建项目ng new project-name 该命令会在当前目录下，按照angular项目脚手架创建一个angular初始化项目。 运行应用cd project-name ng serve --open 或者 ng serve -o 执行以上命令，将会编译项目并启动，启动完自动跳到浏览器打开（命令参数--open）。 默认的端口是4200,你也可以指定运行端口。ng serve --port 4222 --open。 添加模块组件ng generate componet 组件名称 会在项目app目录中添加一个组件模块。包括四个文件。css样式文件，html模板文件，ts脚本文件，还有一个spec.ts的测试文件。 添加服务组件","tags":[]},{"title":"java-core-often","date":"2019-10-19T02:40:47.000Z","path":"2019/10/19/java-core-often/","text":"java11java11生产jrejava11的jdk下没有jre环境的。想要的话，可以手动生成。 进入jdk目录下，执行以下命令： ## windows bin\\jlink.exe --module-path jmods --add-modules java.desktop --output jre ##linux bin/jlink --module-path jmods --add-modules java.desktop --output jre","tags":[]},{"title":"Java IO 缓存流","date":"2019-10-11T00:41:11.000Z","path":"2019/10/11/java-core-io-buffered/","text":"前两节我们看到的例子都没有使用缓存，使用的都是底层的I/O，每次的读写都是直接有操作系统来做的。这会导致很低效，每次的读写操作都是触发磁盘、网络或者其它的资源访问，频繁的访问这些资源是很昂贵的。 为了减少对这些底层资源的频繁访问，java设计了一套缓存API，它把读写数据都放到内存缓冲区里面，当缓存区为空的时候才调用系统底层读API取读取数据到内存，当缓冲区满的时候才调用底层系统输出API去刷新输出缓冲数据。这样，就大大的减少了调用操作系统接口操作硬件资源的次数。 把普通输出输出流包装成缓冲流通过程序，我们可以把没有缓冲的输入输出流向上包装到缓冲输入输出流中。如下： inputStream = new BufferedReader(new FileReader(&quot;xanadu.txt&quot;)); outputStream = new BufferedWriter(new FileWriter(&quot;characteroutput.txt&quot;)); 有四个缓冲流用来包装普通的流，BufferedInputStream 和 BufferedOutputStream，用来包装字节流。 BufferedReader和BufferedWriter用来包装字符流。 刷新缓冲流在关键的点写出缓冲区，不必等到每次缓冲区都满了再写出，这叫做刷新缓冲区。 有些类支持自动缓冲，不必调用手动调用。比如PrintWriter类，每当调用println 或者 format，都会自动刷新一次缓冲区。 手动刷新缓冲区，直接调用方法flush，将会调用操作系统方法从缓冲区一次性把缓冲数据写入到对应媒介。该方法在所有的输出缓冲流中都有效。 Java BufferedInputStream包装输入字节流成缓冲字节流。一块一块的从缓冲区读取字节数据，不必逐个逐个调用操作系统API。 1.例如，把文件输入字节流包装成缓冲流： BufferedInputStream bufferedInputStream = new BufferedInputStream( new FileInputStream(&quot;c:\\\\data\\\\input-file.txt&quot;)); BufferedInputStream会在内部构造一个字节数组，用来填充字节，然后调用底层方法InputStream.read(byte[])来读入。 2.设置缓冲区的长度 如下代码： int bufferSize = 8 * 1024; //8KB BufferedInputStream bufferedInputStream = new BufferedInputStream( new FileInputStream(&quot;c:\\\\data\\\\input-file.txt&quot;), bufferSize); 一般的，缓冲区的长度要是1024 bytes的倍数，整除。 3.设置最佳的缓冲区长度 很多时候，我们都有经验要问，缓冲区的长度到底要设置大小多少才是最佳性能的表现呢？ 实际上，这个问题，首先是要弄清楚你的硬盘缓冲区，每次刷新读取的大小的。如果你的硬盘缓冲区就4KB，那么，你设置缓冲流的大小小于4KB,或者大于4KB都是不明智的，小于4KB，那每次刷新，都浪费空间，大于，就要刷新两次。 所以，一般的，设置成和硬盘缓冲区一样的大小就好了。要通过各种长度测试，找出硬盘读取大小来确定。 4.mark() and reset() BufferInputStream支持mark()和reset()方法。其继承自类FilterInputStream，类FilterInputStream是支持这两个方法的。 并非所有InputStream子类都支持这些方法。 可以调用方法markSupported()查看是否支持mark()和reset()。 4.关闭BufferedInputStream 确保关闭流，避免耗尽系统资源。关闭流，同时会刷出数据。 BufferedInputStream bufferedInputStream = new BufferedInputStream( new FileInputStream(&quot;c:\\\\data\\\\input-file.txt&quot;)); int data = bufferedInputStream.read(); while(data != -1) { data = bufferedInputStream.read(); } bufferedInputStream.close(); 以上代码不能保证百分百关闭流，因为如果上面代码抛出异常，将无法执行bufferedInputStream.close(),此时，需要捕捉异常，保证不管何时，都能正确关闭流。下面利用try-with-resources保证总能准确关闭。 try(BufferedInputStream bufferedInputStream = new BufferedInputStream( new FileInputStream(&quot;c:\\\\data\\\\input-file.txt&quot;) ) ) { int data = bufferedInputStream.read(); while(data != -1){ data = bufferedInputStream.read(); } } 一旦执行线程退出try块，就关闭BufferedInputStream。如果从try块内部引发了异常，则将捕获该异常，并关闭BufferedInputStream，然后重新引发该异常。因此，可以保证在try-with-resources块中使用BufferedInputStream时将其关闭。 Java BufferedOutputStream捕获缓冲区中写入BufferedOutputStream中的数据，批量的读入到底层的OutputStream中，提高IO的速度。 1.创建BufferedOutputStream 为OutputStream添加缓冲，只需要将其包装下即可，如下： OutputStream output = new BufferedOutputStream( new FileOutputStream(&quot;c:\\\\data\\\\output-file.txt&quot;)); 2.设置BufferedOutputStream缓冲区的大小 int bufferSize = 8 * 1024; OutputStream output = new BufferedOutputStream( new FileOutputStream(&quot;c:\\\\data\\\\output-file.txt&quot;), bufferSize ); 设置的大小，最好是1024的倍数，这与硬盘中的大多数内置缓冲效果最佳。 3.如何选择最佳的缓冲区大小 缓冲区大小的设置，与io硬件设备息息相关。 设置不同的bufferSize实验，找出哪种缓冲区大小似乎可以在您的具体硬件上提供最佳性能。 如果硬盘一次至少写入4kb，那么设置缓冲区小于4kb是不合理的，设置成6kb也是愚蠢的，这会造成硬盘碎片化，浪费存储空间。最好设置成4kb的倍数。 即使你的硬盘一次写入4kb，也不应该设置缓冲区大小为4kb，硬盘擅长按顺序写入数据，这意昧着它擅长写入相连的多个块。因此，设置缓冲区大小大于4kb比如16kb，32kb或者更大，性能更好。 要找到最佳的缓冲区大小，先要找到硬盘写入的块的大小，然后把缓冲区设置成块的倍数。最后实验不同倍数写入数据，看哪个倍数的大小写入速度最快，就用那个。 4.写入 使用write()方法写入数据到缓冲区。 BufferedOutputStream bufferedOutputStream = new BufferedOutputStream(new FileOutputStream(&quot;c:\\\\data\\\\output-text.txt&quot;)); bufferedOutputStream.write(123); 上面例子，把123写入到给定的缓冲区。 5.以字节数组形式写入 由于Java BufferedOutputStream是OutputStream的子类，因此您也可以将字节数组写入BufferedOutputStream，而不是一次只写入一个字节。 BufferedOutputStream bufferedOutputStream = new BufferedOutputStream(new FileOutputStream(&quot;c:\\\\data\\\\output-text.txt&quot;)); byte bytes = new byte[]{1,2,3,4,5}; outputStream.write(bytes); 6.刷新缓冲区flush() 当您将数据写入Java BufferedOutputStream时，数据会在内部缓存在字节缓冲区中，直到字节缓冲区已满为止，这时整个缓冲区都将写入底层的OutputStream中。 调用flush()方法刷新确保缓冲区的数据输出到硬盘等io设备。而不必等缓冲区满了，自动关闭再输出。 OutputStream outputStream = new BufferedOutputStream(new FileOutputStream(&quot;c:\\\\data\\\\output-text.txt&quot;)); byte bytes = new byte[]{1,2,3,4,5}; outputStream.write(bytes); outputStream.flush() 7.关闭缓冲输出流BufferedOutputStream 使用缓冲区记得关闭，底层的输出流也会自动关闭。否则会极大浪费操作系统资源。 BufferedOutputStream bufferedOutputStream = new BufferedOutputStream( new FileOutputStream(&quot;c:\\\\data\\\\output-file.txt&quot;)); while(hasMoreData()) { int data = getMoreData(); bufferedOutputStream.write(data); } bufferedOutputStream.close(); java1.7以上使用方式： 放到try块里面，会自动会关闭资源。 try( BufferedOutputStream bufferedOutputStream = new BufferedOutputStream(new FileOutputStream(&quot;c:\\\\data\\\\output-text.txt&quot;))) { while(hasMoreData()) { int data = getMoreData(); output.write(data); } }","tags":[]},{"title":"Java IO：第三节-字符流","date":"2019-09-29T07:36:38.000Z","path":"2019/09/29/java-core-io-character-stream/","text":"Java使用统一编码来存储字符，字符流能够根据本地字符集自动的转换格式。英语国家使用的是八位的ASCII超集。 程序中，使用字符流不再像字节流那么复杂，输入输出自动的根据本地字符集转换，国际化支持非常友好。 使用字符流所有的字符流的类都继承自Reader和Writer,和字节流一样，下面我们演示文件字符流的使用,FileReader和FileWriter: @Test public void copyCharacters() throws IOException { FileReader inputStream = null; FileWriter outputStream = null; try { inputStream = new FileReader(&quot;xanadu.txt&quot;); outputStream = new FileWriter(&quot;characteroutput.txt&quot;); int c; while ((c = inputStream.read()) != -1) { outputStream.write(c); } } finally { if (inputStream != null) { inputStream.close(); } if (outputStream != null) { outputStream.close(); } } } 可以debug进去，查看到c变量的值，一个汉字，一个字母的int值。这里涉及到字符集以及字符编码的知识。 这里类似前面介绍的字节流，最大的不同，字节流用的是FileInputStream和FileOutputStream,字符流用的是FileReader和FileWriter。 字节流的读取，字符流的读取，都用一个int变量来表示，来读取和写入。但是，字节流用的是8 bits的整型来表示，这里的字符流用的是16 bits的整型表示。 字符流与字节流字符流是字节流更上一层的包装，字符流实际使用的是字节流来处理底层的物流I/O的。如FileReader，继承InputStreamReader,并在该父类中进行字符和字节之间的转换。同样，FileWriter在父类OutputStreamWriter进行字符和字节的转换。 面向行的 I/O字符I/O通常的可以比单个字符更大的单位类处理字符，通常可以以一行为单位来读取，以一行作为一个字符串来读取写入。行的终结符通常是(“\\r\\n”)，单回车(“\\r”)或者单换行(“\\n”)。下面例子： //逐行读取文本 @Test public void copyCharactersLine() throws IOException { BufferedReader inputStream = null; PrintWriter outputStream = null; try { inputStream = new BufferedReader(new FileReader(&quot;xanadu.txt&quot;)); outputStream = new PrintWriter(new FileWriter(&quot;characteroutput.txt&quot;)); String l; //表示一行 while ((l = inputStream.readLine()) != null) { outputStream.write(l); } } finally { if (inputStream != null) { inputStream.close(); } if (outputStream != null) { outputStream.close(); } } } 包装字节流为字符流把字节流转换成字符流，以字符形式读取。 1.当你有一个字节流InputStream,且你想以字符形式读取它，那么你可以把它包装到InputStreamReader中，如下构造： Reader reader = new InputStreamReader(inputStream); 其它的构造方式，可以查看InputStreamReader类的源码。 2.同样的，字节输出流OutputStream也可以包装成字符输出流，如下： Writer writer = new OutputStreamWriter(outputStream); 包装字符流把字符流向上包装，以更大单位比如行字符串方式读取内容。如上面逐行读取。 Reader reader = new BufferedReader(new FileReader(...)); Writer writer = new BufferedWriter(new FileWriter(...));","tags":[]},{"title":"Java IO：第二节-字节流","date":"2019-09-29T01:47:37.000Z","path":"2019/09/29/java-core-io-byte-stream/","text":"程序通过字节流去执行8位的字节的输出输入。所有的字节流的类都来自于InputStream和OutputStream，都继承这两个类。 本节探索相关字节流的使用…… 字节流使用java io库中有很多的字节流的类。下面我们演示字节流是怎么工作的，这里我们用文件输入输出的字节流类来演示，FileInputStream和FileOutputStream。其他的字节流类，用法都类似，只是数据构造不同而已。 public static void copyBytes() throws Exception { FileInputStream in = null; FileOutputStream out = null; try { in = new FileInputStream(&quot;xanadu.txt&quot;); out = new FileOutputStream(&quot;outagain.txt&quot;); int c; while ((c = in.read()) != -1) { out.write(c); } } finally { if (in != null) { in.close(); } if (out != null) { out.close(); } } } 上面方法，通过文件字节流，把文件内容从一个文件拷贝到另外一个文件。 通过一个简单的循环，每次一个字节，把文件内容读入输入流，然后通过输出流写入到另外一个文件。如下图： 关闭流当你不再使用流的时候，一定要关闭流，避免严重的资源泄露。上面方法，通过finally,总是会关闭流，确保安全。 finally { if (in != null) { in.close(); } if (out != null) { out.close(); } } 什么时候不用字节流上面方法看起来像是一种通过的流操作方式，但是它实际代表的是一种低层次的I/O操作，应该避免。有用文件中包含的是字符，更恰当的方式应该是使用字符流。有很多适合操作更加复杂数据类型的流。但是字节流是最原始的流，用在操作原始数据类型上更为合适。 这里我们之所以讨论字节流，是因为其它操作更加复杂的类型的流都是建立在字节流之上的。 InputStream和OutputStreamInputStream是字节输入流的最顶级抽象类，其实现两个接口。类图如下： OutputStream是字节输出流的最顶级抽象类，类图： ByteArrayInputStream,ByteArrayOutputStream,FilterInputStream,FilterOutputStream1.ByteArrayInputStream允许你从字节数组中读取字节流数据，代码如下： byte[] bytes = new byte[1024]; //write data into byte array... InputStream input = new ByteArrayInputStream(bytes); //read first byte int data = input.read(); while(data != -1) { //do something with data //read next byte data = input.read(); } 类图： 2.ByteArrayOutputStream允许你以数组的形式获取写入到该输出流中的数据，代码如下： ByteArrayOutputStream output = new ByteArrayOutputStream(); output.write(&quot;This text is converted to bytes&quot;.getBytes(&quot;UTF-8&quot;)); byte[] bytes = output.toByteArray(); 类图： 3.FilterInputStream是实现自定义过滤输入流的基类，基本上它仅仅只是覆盖了InputStream中的所有方法。 就我自己而言，我没发现这个类明显的用途。除了构造函数取一个InputStream变量作为参数之外，我没看到FilterInputStream任何对InputStream新增或者修改的地方。如果你选择继承FilterInputStream实现自定义的类，同样也可以直接继承自InputStream从而避免额外的类层级结构。 4.FilterOutputStream，内容同FilterInputStream，不再赘述。","tags":[]},{"title":"Java IO：第一节-概述","date":"2019-09-27T01:40:26.000Z","path":"2019/09/27/java-core-io-start/","text":"Java IO是一组API用来读取和写入数据(input and output)。大多数应用程序都需要处理一些输入，并在输入基础上输出一些数据。例如，从文件读取文件内容到内存，经过程序处理然后通过网络传输，或者反过来。该组API在java.io下，当你浏览该包时，这些类都有什么作用呢，该如何选择呢，下面我们来不断探索。 Java.io 包的范围java.io 包并没有涵盖所有输入输出类型。例如，并不包含GUI或者网页上的输入输出，这些输入和输出在其它地方都涉及，比如Swing工程中的JFC (Java Foundation Classes) 类，或者J2EE里的Servlet和HTTP包。 Java.io 包主要涉及文件，网络数据流，内存缓冲等的输入输出。 输入和输出 – 数据源和目标媒介术语输入,输出有时候会让人感到疑惑，实际上其描述的是数据在程序和媒介之间的一个流向问题。简单理解：以应用程序为中心（此时应用程序已经加载到内存形成一系列的指令集，等待执行），输入流可以理解成应用程序从外部媒介如文件读取数据内容到物理内存中，输出流可以理解成应用程序把内存中处理后的数据读出到外部媒介如文件。 Java的IO包主要关注的是从原始数据源的读取以及输出原始数据到目标媒介。以下是最典型的数据源和目标媒介： 文件 管道 网络连接 内存缓存 (e.g. arrays) System.in, System.out, System.error(注：Java标准输入、输出、错误输出) 下面图形象描述了程序从数据源读取数据到目标媒介： I/O 流在Java IO中，流是一个核心的概念。流从概念上来说是一个连续的数据流。你既可以从流中读取数据，也可以往流中写数据。流与数据源或者数据流向的媒介相关联。在Java IO中流既可以是字节流(以字节为单位进行读写)，也可以是字符流(以字符为单位进行读写)。 一个I/O流代表一个输入源或者一个输出媒介，一个流可以代表各种不同的源和媒介，比如磁盘中的文件、各种设备、其他的程序、内存等。 流支持各种数据类型，包括简单的字节类型，原始数据类型，本地化的字符类型甚至更高级的类型如对象。一些流只是传递数据，然后进行各种转换。 一个流就是一系列的数据，应用程序利用输入流从数据源中读取这些数据到程序内存中： 程序利用输出类把内存数据写入到媒介如文件系统中： InputStream, OutputStream, Reader 和Writer类程序从数据源读取数据需要依靠inputStream或者Reader，程序写数据到媒介中时候需要依赖outputStream或者Writer。下面图形象描述： InputStream和Reader与数据源相关联，OutputStream和writer与目标媒介相关联。 Java IO的用途和特征Java IO包中有很多InputStream, OutputStream, Reader and Writer的子类，这些子类都具有某些自己的用途，总结如下： 文件访问 网络访问 内存缓存访问 线程内部通信（管道） 缓冲 过滤 解析 读写文本 (Readers / Writers) 读写基本类型数据 (long, int etc.) 读写对象 当我通读java.io包下相关类后，很容易就知道这些类的特性和其使用场景。 Java IO类概述表已经讨论了数据源、目标媒介、输入、输出和各类不同用途的Java IO类，接下来是一张通过输入、输出、基于字节或者字符、以及其他比如缓冲、解析之类的特定用途划分的大部分Java IO类的表格。 参考： https://docs.oracle.com/javase/tutorial/essential/io http://tutorials.jenkov.com/java-io http://commons.apache.org/proper/commons-io/","tags":[]},{"title":"Spring Cloud Sleuth使用ELK收集&分析日志","date":"2019-09-04T14:15:36.000Z","path":"2019/09/04/scloud-elk/","text":"在分布式系统中，每个应用的实例都会在不同的物理机上产生日志。以往，系统出现问题需要查看日志的时候，就要到每台物理机对应的日志目录下查看相应的日志，这会非常的麻烦，特别是很多个实例的时候。另外，微服务场景下，各个服务的日志链也都很分散，无法追踪，不知道实际的错误出现在哪个服务。所以，就非常有必要把各个服务的各个实例所产生的日志都发送到统一的服务器上，并进行可视化的查看，分析。这就是我们这里要介绍的ELK能做的事情了。 ELK是什么东西实际就是三个软件系统： E：指的Elasticsearch,一个强大的搜索引擎。 L：指的Logstash，解析并收集日志的系统。 K：指的Kibana，一个可以可视化查看日志文件的系统。 基本原理 Sleuth打印JSON格式的日志。 logstash中配置语法，解析并收集JSON格式的日志，然后存储到Elasticsearch系统中去。 Kibana可视化分析日志。集成Elasticsearch强大的搜索功能，找到任意输出的日志，并查看和分析。 ELK环境的搭建这里介绍采用的单机模式。利用docker和docker-compose来部署。 首先要在某台服务器上安装docker引擎和docker-compose服务。 在服务器新建文件夹ELK。然后进入该文件夹，并创建文件docker-compose.yml，内容如下： version: &apos;3&apos; services: elasticsearch: image: elasticsearch:7.3.1 environment: discovery.type: single-node ports: - &quot;9200:9200&quot; - &quot;9300:9300&quot; logstash: image: logstash:7.3.1 command: logstash -f /etc/logstash/conf.d/logstash.conf volumes: # 挂载logstash配置文件 - ./config:/etc/logstash/conf.d - /opt/build:/opt/build ports: - &quot;5000:5000&quot; - &quot;8088:8088&quot; kibana: image: kibana:7.3.1 environment: - ELASTICSEARCH_URL=http://120.79.2.30:9200 ports: - &quot;5601:5601&quot; 在ELK中再创建目录config，并进入config目录，然后创建文件logstash.conf,文件内容如下： input { tcp { port =&gt; 8088 mode =&gt; &quot;server&quot; ssl_enable =&gt; false type =&gt; &quot;tcplog&quot; codec =&gt; json_lines { charset =&gt; &quot;UTF-8&quot; } } } filter { grok { match =&gt; { &quot;message&quot; =&gt; &quot;%{TIMESTAMP_ISO8601:timestamp}\\s+%{LOGLEVEL:severity}\\s+\\[%{DATA:service},%{DATA:trace},%{DATA:span},%{DATA:exportable}\\]\\s+%{DATA:pid}\\s+---\\s+\\[%{DATA:thread}\\]\\s+%{DATA:class}\\s+:\\s+%{GREEDYDATA:rest}&quot; } } } output { elasticsearch { hosts =&gt; &quot;120.79.2.30:9200&quot; index =&gt; &quot;logstash&quot; } } 在ELK目下，启动ELK服务： docker-compose up spring cloud 服务配置调整pom.xml文件中添加依赖&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-sleuth&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--必须要和logback版本对应，这个版本对应logback的1.2.3--&gt; &lt;dependency&gt; &lt;groupId&gt;net.logstash.logback&lt;/groupId&gt; &lt;artifactId&gt;logstash-logback-encoder&lt;/artifactId&gt; &lt;version&gt;6.1&lt;/version&gt; &lt;/dependency&gt; _注意_: logstash-logback-encoder 的版本务必和Logback兼容，否则会导致应用启动不起来，而且不会打印任何日志！可前往 https://github.com/logstash/logstash-logback-encoder 查看和Logback的兼容性。 添加logback-spring.xml文件在 resources 目录下创建配置文件：logback-spring.xml，文件内容如下： &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;configuration&gt; &lt;include resource=&quot;org/springframework/boot/logging/logback/defaults.xml&quot;/&gt; &lt;springProperty scope=&quot;context&quot; name=&quot;springAppName&quot; source=&quot;spring.application.name&quot;/&gt; &lt;!-- Example for logging into the build folder of your project --&gt; &lt;property name=&quot;LOG_FILE&quot; value=&quot;./logs/${springAppName}/${springAppName}&quot;/&gt; &lt;!-- You can override this to have a custom pattern --&gt; &lt;property name=&quot;CONSOLE_LOG_PATTERN&quot; value=&quot;%clr(%d{yyyy-MM-dd HH:mm:ss.SSS}){faint} %clr(${LOG_LEVEL_PATTERN:-%5p}) %clr(${PID:- }){magenta} %clr(---){faint} %clr([%15.15t]){faint} %clr(%-40.40logger{39}){cyan} %clr(:){faint} %m%n${LOG_EXCEPTION_CONVERSION_WORD:-%wEx}&quot;/&gt; &lt;property name=&quot;FILE_LOG_PATTERN&quot; value=&quot;${FILE_LOG_PATTERN:-%d{${LOG_DATEFORMAT_PATTERN:-yyyy-MM-dd HH:mm:ss.SSS}} ${LOG_LEVEL_PATTERN:-%5p} ${PID:- } --- [%t] %-40.40logger{39} : %m%n${LOG_EXCEPTION_CONVERSION_WORD:-%wEx}}&quot;/&gt; &lt;!-- Appender to log to console --&gt; &lt;appender name=&quot;console&quot; class=&quot;ch.qos.logback.core.ConsoleAppender&quot;&gt; &lt;filter class=&quot;ch.qos.logback.classic.filter.ThresholdFilter&quot;&gt; &lt;!-- Minimum logging level to be presented in the console logs--&gt; &lt;level&gt;DEBUG&lt;/level&gt; &lt;/filter&gt; &lt;encoder&gt; &lt;pattern&gt;${CONSOLE_LOG_PATTERN}&lt;/pattern&gt; &lt;charset&gt;utf8&lt;/charset&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;!-- Appender to log to file --&gt; &lt;appender name=&quot;flatfile&quot; class=&quot;ch.qos.logback.core.rolling.RollingFileAppender&quot;&gt; &lt;file&gt;${LOG_FILE}.log&lt;/file&gt; &lt;rollingPolicy class=&quot;ch.qos.logback.core.rolling.TimeBasedRollingPolicy&quot;&gt; &lt;fileNamePattern&gt;${LOG_FILE}.%d{yyyy-MM-dd}.gz&lt;/fileNamePattern&gt; &lt;maxHistory&gt;7&lt;/maxHistory&gt; &lt;/rollingPolicy&gt; &lt;encoder&gt; &lt;pattern&gt;${FILE_LOG_PATTERN}&lt;/pattern&gt; &lt;charset&gt;utf8&lt;/charset&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;!--通过网络，把日志发送到ELK服务器--&gt; &lt;appender name=&quot;logstash&quot; class=&quot;net.logstash.logback.appender.LogstashTcpSocketAppender&quot;&gt; &lt;destination&gt;120.79.2.30:8088&lt;/destination&gt; &lt;writeBufferSize&gt;16384&lt;/writeBufferSize&gt; &lt;!-- encoder is required --&gt; &lt;encoder class=&quot;net.logstash.logback.encoder.LoggingEventCompositeJsonEncoder&quot;&gt; &lt;providers&gt; &lt;timestamp&gt; &lt;timeZone&gt;UTC&lt;/timeZone&gt; &lt;/timestamp&gt; &lt;pattern&gt; &lt;pattern&gt; { &quot;severity&quot;: &quot;%level&quot;, &quot;service&quot;: &quot;${springAppName:-}&quot;, &quot;trace&quot;: &quot;%X{X-B3-TraceId:-}&quot;, &quot;span&quot;: &quot;%X{X-B3-SpanId:-}&quot;, &quot;parent&quot;: &quot;%X{X-B3-ParentSpanId:-}&quot;, &quot;exportable&quot;: &quot;%X{X-Span-Export:-}&quot;, &quot;pid&quot;: &quot;${PID:-}&quot;, &quot;thread&quot;: &quot;%thread&quot;, &quot;class&quot;: &quot;%logger{40}&quot;, &quot;rest&quot;: &quot;%message&quot; } &lt;/pattern&gt; &lt;/pattern&gt; &lt;/providers&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;root level=&quot;INFO&quot;&gt; &lt;appender-ref ref=&quot;console&quot;/&gt; &lt;!-- uncomment this to have also JSON logs --&gt; &lt;appender-ref ref=&quot;logstash&quot;/&gt; &lt;appender-ref ref=&quot;flatfile&quot;/&gt; &lt;/root&gt; &lt;/configuration&gt; 注意： 应用名称spring.application.name必须放在配置文件bootstrap.yml中，否则logback-spring.xml将读取不到该变量。 测试Sleuth &amp; ELK 启动你的微服务，并访问相关API产生一些输出日志。 访问 http://localhost:5601 （Kibana地址），可看到类似如下的界面，按照如图配置Kibana。 按下面图画红框步骤继续配置： 输入查询条件，就可查询日志了：","tags":[{"name":"ELK","slug":"ELK","permalink":"https://xinxiamu.github.io/tags/ELK/"}]},{"title":"angular快速上手","date":"2019-09-01T13:51:09.000Z","path":"2019/09/01/angular-start-quick/","text":"创建应用打开某个需要存放项目的目录。在命令窗口执行： ng new angular-quick 用idea工具打开项目： 创建组件模块命令：ng generate component 模块名称 E:\\angular\\study\\angular-quick&gt;ng generate component product-list E:\\angular\\study\\angular-quick&gt;&quot;node&quot; &quot;E:\\angular\\study\\angular-quick\\node_modules\\.bin\\\\..\\_@angular_cli@8.0.6@@angular\\cli\\bin\\ng&quot; generate component product-list CREATE src/app/product-list/product-list.component.html (27 bytes) CREATE src/app/product-list/product-list.component.spec.ts (664 bytes) CREATE src/app/product-list/product-list.component.ts (292 bytes) CREATE src/app/product-list/product-list.component.css (0 bytes) UPDATE src/app/app.module.ts (497 bytes) E:\\angular\\study\\angular-quick&gt;ng generate component top-bar 运行应用cd my-app ng serve --open ng serve 命令会启动开发服务器、监视文件，并在这些文件发生更改时重建应用。 –open（或者只用 -o 缩写）选项会自动打开你的浏览器，并访问 http://localhost:4200/。","tags":[]},{"title":"新一代消息中间件pulsar","date":"2019-08-16T01:13:14.000Z","path":"2019/08/16/pulsar-start/","text":"官网：http://pulsar.apache.org 单机安装除了最极端的情况，对于绝大多数的用例来说，单机群安装的Pulsar就能够满足要求了。 如果是创业公司或一个团队想体验下Pulsar，我们推荐使用单集群。 http://pulsar.apache.org/docs/zh-CN/standalone/ 下载安装包下载安装包，有以下几种方式： download from the Apache mirror (Pulsar 2.4.1 binary release) download from the Pulsar downloads page download from the Pulsar releases page use wget:","tags":[]},{"title":"Spring Cloud使用问题记录","date":"2019-05-31T10:20:21.000Z","path":"2019/05/31/scloud-issu-record/","text":"Zuul问题1、max-threads：需要根据具体的硬件环境进行调整2、max-threads：并不是线程数越大越好，线程数增加会增加内存开销同时大量线程切换会浪费不少时间，并且容易造成内存溢出3、如果单一网关不能满足并发量，网关可以集群，使用nginx分发请求给多个网关4、可以使用spring-session、redis解决session一致性问题 header信息路由到服务后丢失解决问题 保留请求header信息。全部配置zuul.sensitive-headers=或者具体服务配置zuul.routes.xxx.sensitive-headers=zuul.routes.xxx.custom-sensitive-headers=true 参考这篇文章 Spring Cloud实战小贴士：Zuul处理Cookie和重定向 http://blog.csdn.net/dream8062/article/details/71169628 http://blog.didispace.com/spring-cloud-zuul-cookie-redirect/ 跨域问题问题描述： 正常情况下，跨域是这样的： 微服务配置跨域+zuul不配置=有跨域问题 微服务配置+zuul配置=有跨域问题 微服务不配置+zuul不配置=有跨域问题 微服务不配置+zuul配置=ok 然而云环境中每个服务自己有跨域解决方案，而网关需要做最外层的跨域解决方案.如果服务已有跨域配置网关也有，会出现*多次配置问题。 Access-Control-Allow-Origin:&quot;*,*&quot; 也就是multiple Access-Control-Allow-Origin ！！！所以我们就要，微服务配置+zuul配置=解决跨域问题 问题解决： 使用ZUUL配置忽略头部信息 zuul: #需要忽略的头部信息，不再传播到其他服务。 ignored-headers: Access-Control-Allow-Origin,H-APP-Id,Token,APPToken cookie无法跨域，会话无法保持的问题问题： 当我们解决了上面的头路由到服务，跨域的问题后。但是又出现了另外的问题，浏览器无法保存cookie信息，导致每次发起请求，都会重新创建不同的session会话。这样的话，客户端频繁的请求将会在服务端创建大量的session对象，这对服务器是个很大的负担，会话无法保持，每次都新建会话。 解决： 1.在zuul网关层更改跨域配置： # cors跨域设置 custom: cors: mapping: /** allowCredentials: true #允许cookie跨域 allowedOrigins: &quot;*&quot; #允许的域，多个用逗号隔开。*允许全部的域通过。一定要用双引号，否则配置文件报错。 # allowedMethods: POST,GET,DELETE,PUT #这样设置，静态资源将不能跨域 allowedMethods: &quot;*&quot; allowedHeaders: &quot;*&quot; 关键是：allowCredentials: true,设置为true，即允许cookie跨域。 2.前端配置 前端跨域设置 withCredentials: true angular2应用 const httpOptions = { headers: new HttpHeaders({ &apos;Content-Version&apos;: &apos;0&apos;, &apos;Content-Type&apos;: &apos;application/json&apos; }), params: new HttpParams(), withCredentials: true }; 关键：withCredentials: true。 ajax请求 在ajax请求里加上xhrFields: {withCredentials: true}, crossDomain: true。 即在http请求中，options参数中添加参数withCredentials: true。 这样配置后，经过测试，发现，每次通过zuul路由到具体服务后，在具体服务中的sessionId都是一样的。只创建一次会话，一直保持，知道会话断开。 3.补充（配置） zuul配置： zuul: add-host-header: true #重定向问题 sensitive-headers: #保留所有头信息传递，解决多个服务在转发中sessionId不一致的问题，到了服务层，缺少头信息的问题。注意：每个具体的服务的sessionId还是不一样的? ignored-headers: Access-Control-Allow-Origin,H-APP-Id,Token,APPToken 具体服务跨域配置： # cors跨域设置 custom: cors: mapping: /** allowCredentials: false # 不循序cookie跨域 allowedOrigins: &quot;*&quot; #允许的域，多个用逗号隔开。*允许全部的域通过。一定要用双引号，否则配置文件报错。 # allowedMethods: POST,GET,DELETE,PUT #这样设置，静态资源将不能跨域 allowedMethods: &quot;*&quot; allowedHeaders: &quot;*&quot; feign服务调用问题问题一1.问题描述： 在服务A中调用服务B，无法调用B的接口，报如下异常：1feign.RetryableException: too many bytes written 2.问题原因： 是因为feign请求body和Content-Length长度不一致导致。 3.解决方案： 在自定义feign拦截器中，过滤掉头信息content-length： 123if (name.equals(&quot;content-length&quot;))&#123; continue;&#125; 具体如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980package com.xrlj.framework.config;import feign.Logger;import feign.RequestInterceptor;import feign.RequestTemplate;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.web.context.request.RequestContextHolder;import org.springframework.web.context.request.ServletRequestAttributes;import javax.servlet.http.HttpServletRequest;import java.util.Enumeration;/** * 放在扫描包下。全局有效。所有feign客户端有效。 * 配合自定义熔断策略。 */@Configurationpublic class FeignConfiguration &#123; /** * 日志级别。FULL打印请求头，请求体等信息。 * @return */ @Bean Logger.Level feignLoggerLevel() &#123; return Logger.Level.FULL; &#125; /** * 创建Feign请求拦截器，在发送请求前设置认证的token,各个微服务将token设置到环境变量中来达到通用 * @return * */ @Bean public FeignBasicAuthRequestInterceptor basicAuthRequestInterceptor() &#123; return new FeignBasicAuthRequestInterceptor(); &#125; /** * Feign请求拦截器 * @author yinjihuan * @create 2017-11-10 17:25 **/ public class FeignBasicAuthRequestInterceptor implements RequestInterceptor &#123; public FeignBasicAuthRequestInterceptor() &#123; &#125; @Override public void apply(RequestTemplate template) &#123; //配置自定义熔断策略或者在.yml中配置熔断策略为hystrix.command.default.execution.isolation.strategy: SEMAPHORE //否则这里返回null ServletRequestAttributes attributes = (ServletRequestAttributes) RequestContextHolder.getRequestAttributes(); if (attributes == null) &#123; return; &#125; HttpServletRequest request = attributes.getRequest(); //添加所有头信息。feign调用，在各组件中传递。保持各组件之间session一致性，同一个sessionId。 Enumeration&lt;String&gt; headerNames = request.getHeaderNames(); if (headerNames != null) &#123; while (headerNames.hasMoreElements()) &#123; String name = headerNames.nextElement(); Enumeration&lt;String&gt; values = request.getHeaders(name); while (values.hasMoreElements()) &#123; String value = values.nextElement(); // 跳过 content-length // https://blog.csdn.net/qq_39986681/article/details/107138740 // https://juejin.cn/post/6844903939079421966 if (name.equals(\"content-length\"))&#123; continue; &#125; template.header(name, value); &#125; &#125; &#125; &#125; &#125;&#125; 4.参考：https://blog.csdn.net/qq_39986681/article/details/107138740https://juejin.cn/post/6844903939079421966","tags":[]},{"title":"pdf电子签名探索","date":"2019-05-16T07:28:35.000Z","path":"2019/05/16/esign-bao-copy/","text":"现代很多的信息系统中，都涉及到电子合同。电子合同签章的方案市面上都已经很成熟，购买一些服务就可以用了。但是，他们都是怎么实现的呢。带着这些好奇，通过各种百度、谷歌，我们就来探索下，如果要自己来实现，要怎么做…… 如何做个人、企业实名认证呢实名认证很重要，是签章的基础，提供真实的签章者身份信息。实名认证后，就可以根据实名信息生产电子章信息了。 如何拿到CA证书呢如何制作电子章图片呢如何根据模板动态生产pdf文件呢如何把有效的电子章加签到pdf文件呢参考： https://blog.csdn.net/goodlook0123/article/details/81121351 https://blog.csdn.net/do_bset_yourself/article/details/78171897?locationNum=8&amp;fps=1 https://blog.csdn.net/javasun608/article/details/79307845 https://blog.csdn.net/do_bset_yourself/article/details/78156161","tags":[]},{"title":"用Shiro和JWT做认证授权","date":"2019-05-14T07:38:59.000Z","path":"2019/05/14/shiro-jwt/","text":"本文介绍使用安全框架shiro和流行的JSON Web Token认证协议，在前后端分离系统中如何做认证授权。","tags":[]},{"title":"分布式锁","date":"2019-05-10T14:35:22.000Z","path":"2019/05/10/distributed-lock/","text":"为什么要使用分布式锁对共享变量或者数据（数据库数据）多线程操作的时候，为了避免在同一个时刻多线程操作导致数据的混乱，我们可以通过线程的互斥等来控制某个时刻只有一个线程执行，但这只是再单机应用下。 但是，随着业务的发展，架构随之发展，就需要做集群，负载均衡，这样子，同一个方法或者变量就会以多线程的方式且再不同的物理机也就是不同的jvm上同时执行，这显然是不对的，我们想要的是在某个时刻，该方法或者共享数据只在一个线程中执行，也就是只在某一台物理机子上执行，其余的排斥。这时，分布式锁就派上用场了，它就是做这么一件事的。 分布式锁应该具备哪些条件在分析分布式锁的三种实现方式之前，先了解一下分布式锁应该具备哪些条件： 1、在分布式系统环境下，一个方法在同一时间只能被一个机器的一个线程执行；2、高可用的获取锁与释放锁；3、高性能的获取锁与释放锁；4、具备可重入特性；5、具备锁失效机制，防止死锁；6、具备非阻塞锁特性，即没有获取到锁将直接返回获取锁失败 常用分布式锁实现方式 基于数据库实现分布式锁；基于缓存（Redis等）实现分布式锁；基于Zookeeper实现分布式锁； 1.基于Redis缓存实现分布式锁Spring Boot使用RedLock实现分布式锁2.基于Zookeeper实现分布式锁3.基于数据库实现分布式锁https://www.cnblogs.com/seesun2012/p/9214653.html","tags":[]},{"title":"session 机制学习","date":"2019-05-09T09:30:18.000Z","path":"2019/05/09/session-start/","text":"https://www.cnblogs.com/woshimrf/p/5317776.html https://www.cnblogs.com/sharpxiajun/p/3395607.html","tags":[]},{"title":"spring-boot使用记录","date":"2019-05-03T17:09:30.000Z","path":"2019/05/04/spring-boot-record/","text":"收集spring boot使用过程中的常用点…… 常见注解注解@ConditionalOnMissingBean 作用：标识是否要初始化该Bean。 例子： @Bean @ConditionalOnMissingBean public DataSourceConnectionProvider dataSourceConnectionProvider( DataSource dataSource) { return new DataSourceConnectionProvider( new TransactionAwareDataSourceProxy(dataSource)); } 上面初始化一个Bean，但是加了注解@ConditionalOnMissingBean。意思是：如果已经有初始化DataSourceConnectionProvider的Bean，该方法将不会执行。如： @Bean public DataSourceConnectionProvider connectionProvider() { return new DataSourceConnectionProvider(new TransactionAwareDataSourceProxy(DataSourceSpyUtils.conversion(environment,dynamicDataSource))); } 上面这段代码，初始化了该Bean，所以上面的将不会再执行。 用处：常用在spring boot starter中。 @ConditionalOnxxx相关注解总结参考：https://www.cnblogs.com/yixianyixian/p/7346894.htmlhttps://blog.csdn.net/xcy1193068639/article/details/81491071 自定义Conditionalhttps://blog.csdn.net/zhanglu1236789/article/details/78999496 集成hikari数据源错误一，maxLifetime问题The last packet successfully received from the server was 1,057,018 milliseconds ago. The last packet sent successfully to the server was 1,057,026 milliseconds ago.). Possibly consider using a shorter maxLifetime value. 该警告代码在：com.zaxxer.hikari.pool.PoolBase类中，可以debbuger进去看。 解决： Redis使用错误 错误描述： Spring Data Redis - Could not safely identify store assignment for repositor 原因分析： 1.使用了Spring data jpa 作为持久层框架2.使用了Spring Redis 缓存 这是 Spring Boot 的 Autoconfigure 包干的好事，里面有个叫 RedisRepositoriesAutoConfiguration 的类会检查当前的 classpath 里面是不是存在 Jedis 和 @EnableRedisRepositories，如果存在，无论你的代码有没有用，他都会帮你自动启用这个注解（不带参数），于是整个 classpath 的类都会被扫进去。 解决： 解决方法也很简单，RedisRepositoriesAutoConfiguration 里面会判断 spring.data.redis.repositories.enable 这个配置项是否存在，不存在、存在和值为 true 都会生效，只要显式设置它为 false 即可；如果不想写配置信息，也不需要用 RedisRepository 的话（不影响 RedisTemplate），可以通过另外一个判断条件——检查 RedisRepositoryFactoryBean 这个 Bean 是否存在来处理，默认是不存在则执行这个 AutoConfiguration，只要自己在代码里造一个 RedisRepositoryFactoryBean 即可，比如这样 @Bean public RedisRepositoryFactoryBean redisRepositoryFactoryBean() { return null; } 也可以直接禁用redis的repositories spring.data.redis.repositories.enabled = false","tags":[]},{"title":"Spring Cloud外部环境配置刷新","date":"2019-04-20T14:55:37.000Z","path":"2019/04/20/scloud-properties-refresh/","text":"本文介绍在spring cloud架构中，如何做配置外部化以及更改配置属性并实时刷新的问题。实验环境：spring boot：2.1.4.RELEASEspring cloud: Greenwich.SR1githubrabbitmq: 3.7.8 服务注册发现中心eureka-server关键依赖： &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt; &lt;/dependency&gt; application.yml： server: port: 1112 spring: application: name: eureka-server profiles: active: dev logging: level: com: netflix: eureka: off discovery: off file: logs/${spring.application.name}.log application-dev.yml： eureka: instance: instance-id: ${spring.application.name}:${spring.cloud.client.ip_address}:${server.port} hostname: localhost client: fetch-registry: false register-with-eureka: false #不注册自己 service-url: defaultZone: http://${eureka.instance.hostname}:${server.port}/eureka/ server: enable-self-preservation: false #设为false，关闭自我保护 eviction-interval-timer-in-ms: 4000 # 清理间隔（单位毫秒，默认是60*1000） 该服务没什么需要注意的，按正常的来就可以。 配置中心config-server关键依赖：&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-server&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--实时刷新配置 start --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-monitor&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-bus-amqp&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--实时刷新配置 end --&gt; &lt;!--作为服务注册到服务注册中心 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; 要配置刷新，只需要添加： &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-monitor&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-bus-amqp&lt;/artifactId&gt; &lt;/dependency&gt; 配置bootstrap.yml： server: port: 3331 spring: application: name: config-server profiles: active: dev ## 非对称加解密,该段配置只能放在bootstrap.yml中 encrypt: key-store: location: classpath:/config-server.jks password: 111111 # storepass alias: config-server # alias secret: 222222 # keypass application.yml： management: endpoints: web: exposure: include: &quot;*&quot; management.endpoints.web.exposure.include这个配置一定要加上，关键。默认是指暴露站点：info，health。改成星号，代表暴露全部。 application-dev.yml： #作为服务注册到注册中心 eureka: server: ip: localhost port: 1112 instance: instance-id: ${spring.application.name}:${spring.cloud.client.ip-address}:${server.port} prefer-ip-address: true #显示ip,浏览器以ip方式请求。 #域名 # hostname: localhost #查看健康运行状态 health-check-url-path: /actuator/health status-page-url-path: /actuator/info client: service-url: defaultZone: http://${eureka.server.ip}:${eureka.server.port}/eureka/ spring: security: user: name: admin password: 123456 cloud: #git配置中心 config: server: git: uri: https://github.com/xrlj/config-repo-dev #git的配置文件会加载到本地的目录 basedir: target/config # 设置超时 timeout: 4 force-pull: true #每次都强制拉取远程git的配置更新本地。 default-label: master bus: enabled: true trace: enabled: true # search-paths: # spring-cloud-bus刷新配置 #http://localhost:15672/ rabbitmq: host: 172.31.31.31 port: 5672 username: admin password: 123456 publisher-confirms: true virtual-host: xr_vhost encrypt: fail-on-error: false 注意开启：spring.cloud.bus.enable=true,spring.cloud.bus.trace.enable=true。 温馨提醒由于添加了安全依赖： &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt; &lt;/dependency&gt; 所以config-server的请求是要先登陆验证的。那么，就要要配置spring-security，否则后面的post请求将会被拒绝。添加配置类如下： package com.xrlj.configserver; import org.springframework.context.annotation.Configuration; import org.springframework.security.config.annotation.web.builders.HttpSecurity; import org.springframework.security.config.annotation.web.configuration.EnableWebSecurity; import org.springframework.security.config.annotation.web.configuration.WebSecurityConfigurerAdapter; @Configuration @EnableWebSecurity public class WebSecurityConfiguration extends WebSecurityConfigurerAdapter { @Override protected void configure(HttpSecurity http) throws Exception { http.csrf().disable().authorizeRequests() .anyRequest().authenticated().and() .httpBasic(); } } 其它业务服务service-sys-common添加与配置刷新相关依赖： &lt;!-- 用户修改git文件，调用接口自动刷新： --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--rabbitmq实时刷新配置--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-bus-amqp&lt;/artifactId&gt; &lt;/dependency&gt; 关键配置： spring: cloud: bus: enabled: true trace: enabled: true # refresh: # extra-refreshable: javax.sql.DataSource #该版本中，默认数据源是HikariDataSource，不配置这个，刷新配置报错。 management: endpoints: web: exposure: include: &quot;*&quot; 和config-server中一样，星号暴露所有站点，还要bus的一些配置开启。这里有个不同点，spring.cloud.refresh.extra-refreshable=javax.sql.DataSource,这里先注释掉，后面再补充说明下。 验证配置刷新1.在service-sys-common服务中新建TestController.java @RefreshScope @RestController public class TestController { @Value(&quot;${foo}&quot;) String foo; @RequestMapping(value = &quot;/hi&quot;) public String hi(){ return foo; } } 注意添加注解@RefreshScope。在配置仓库中对应文件添加属性foo:version1。 打开浏览器请求：http://localhost:9010/hi.正常会返回`foo`的值。 更改foo的值，foo:version2,再次请求，看到返回还是version1，证明没刷新。下面刷新下，打开postman发送post刷新请求：localhost:9010/actuator/refresh 然后我们会看到一个错误： 2018-02-04 22:11:02.236 DEBUG 6104 --- [ main] o.s.b.d.LoggingFailureAnalysisReporter : Application failed to start due to an exception org.springframework.boot.context.properties.bind.BindException: Failed to bind properties under &apos;spring.datasource.hikari&apos; to com.zaxxer.hikari.HikariDataSource at org.springframework.boot.context.properties.bind.Binder.handleBindError(Binder.java:227) ~[spring-boot-2.0.0.RC1.jar:2.0.0.RC1] at org.springframework.boot.context.properties.bind.Binder.bind(Binder.java:203) ~[spring-boot-2.0.0.RC1.jar:2.0.0.RC1] at org.springframework.boot.context.properties.bind.Binder.bind(Binder.java:187) ~[spring-boot-2.0.0.RC1.jar:2.0.0.RC1] at org.springframework.boot.context.properties.bind.Binder.bind(Binder.java:169) ~[spring-boot-2.0.0.RC1.jar:2.0.0.RC1] at org.springframework.boot.context.properties.ConfigurationPropertiesBinder.bind(ConfigurationPropertiesBinder.java:79) ~[spring-boot-2.0.0.RC1.jar:2.0.0.RC1] at org.springframework.boot.context.properties.ConfigurationPropertiesBindingPostProcessor.postProcessBeforeInitialization(ConfigurationPropertiesBindingPostProcessor.java:167) ~[spring-boot-2.0.0.RC1.jar:2.0.0.RC1] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.applyBeanPostProcessorsBeforeInitialization(AbstractAutowireCapableBeanFactory.java:423) ~[spring-beans-5.0.3.RELEASE.jar:5.0.3.RELEASE] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1702) ~[spring-beans-5.0.3.RELEASE.jar:5.0.3.RELEASE] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:414) ~[spring-beans-5.0.3.RELEASE.jar:5.0.3.RELEASE] at org.springframework.cloud.context.properties.ConfigurationPropertiesRebinder.rebind(ConfigurationPropertiesRebinder.java:101) ~[spring-cloud-context-2.0.0.M5.jar:2.0.0.M5] at org.springframework.cloud.context.properties.ConfigurationPropertiesRebinder.rebind(ConfigurationPropertiesRebinder.java:84) ~[spring-cloud-context-2.0.0.M5.jar:2.0.0.M5] at org.springframework.cloud.context.properties.ConfigurationPropertiesRebinder.onApplicationEvent(ConfigurationPropertiesRebinder.java:132) ~[spring-cloud-context-2.0.0.M5.jar:2.0.0.M5] at org.springframework.cloud.context.properties.ConfigurationPropertiesRebinder.onApplicationEvent(ConfigurationPropertiesRebinder.java:50) ~[spring-cloud-context-2.0.0.M5.jar:2.0.0.M5] at org.springframework.context.event.SimpleApplicationEventMulticaster.doInvokeListener(SimpleApplicationEventMulticaster.java:172) ~[spring-context-5.0.3.RELEASE.jar:5.0.3.RELEASE] at org.springframework.context.event.SimpleApplicationEventMulticaster.invokeListener(SimpleApplicationEventMulticaster.java:165) ~[spring-context-5.0.3.RELEASE.jar:5.0.3.RELEASE] at org.springframework.context.event.SimpleApplicationEventMulticaster.multicastEvent(SimpleApplicationEventMulticaster.java:139) ~[spring-context-5.0.3.RELEASE.jar:5.0.3.RELEASE] at org.springframework.context.support.AbstractApplicationContext.publishEvent(AbstractApplicationContext.java:399) ~[spring-context-5.0.3.RELEASE.jar:5.0.3.RELEASE] at org.springframework.context.support.AbstractApplicationContext.publishEvent(AbstractApplicationContext.java:353) ~[spring-context-5.0.3.RELEASE.jar:5.0.3.RELEASE] at org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration.afterSingletonsInstantiated(ConfigurationPropertiesRebinderAutoConfiguration.java:77) ~[spring-cloud-context-2.0.0.M5.jar:2.0.0.M5] at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:778) ~[spring-beans-5.0.3.RELEASE.jar:5.0.3.RELEASE] at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:868) ~[spring-context-5.0.3.RELEASE.jar:5.0.3.RELEASE] at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:549) ~[spring-context-5.0.3.RELEASE.jar:5.0.3.RELEASE] at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:138) ~[spring-boot-2.0.0.RC1.jar:2.0.0.RC1] at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:752) [spring-boot-2.0.0.RC1.jar:2.0.0.RC1] at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:388) [spring-boot-2.0.0.RC1.jar:2.0.0.RC1] at org.springframework.boot.SpringApplication.run(SpringApplication.java:327) [spring-boot-2.0.0.RC1.jar:2.0.0.RC1] at org.springframework.boot.SpringApplication.run(SpringApplication.java:1246) [spring-boot-2.0.0.RC1.jar:2.0.0.RC1] at org.springframework.boot.SpringApplication.run(SpringApplication.java:1234) [spring-boot-2.0.0.RC1.jar:2.0.0.RC1] at uk.co.vhome.clubbed.svc.enquiryhandler.ClubbedSvcEnquiryHandlerApplication.main(ClubbedSvcEnquiryHandlerApplication.java:23) [classes/:na] Caused by: java.lang.IllegalStateException: Unable to set value for property schema at org.springframework.boot.context.properties.bind.JavaBeanBinder$BeanProperty.setValue(JavaBeanBinder.java:306) ~[spring-boot-2.0.0.RC1.jar:2.0.0.RC1] at org.springframework.boot.context.properties.bind.JavaBeanBinder.bind(JavaBeanBinder.java:76) ~[spring-boot-2.0.0.RC1.jar:2.0.0.RC1] at org.springframework.boot.context.properties.bind.JavaBeanBinder.bind(JavaBeanBinder.java:59) ~[spring-boot-2.0.0.RC1.jar:2.0.0.RC1] at org.springframework.boot.context.properties.bind.JavaBeanBinder.bind(JavaBeanBinder.java:51) ~[spring-boot-2.0.0.RC1.jar:2.0.0.RC1] at org.springframework.boot.context.properties.bind.Binder.lambda$null$5(Binder.java:321) ~[spring-boot-2.0.0.RC1.jar:2.0.0.RC1] at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195) ~[na:na] at java.base/java.util.ArrayList$ArrayListSpliterator.tryAdvance(ArrayList.java:1471) ~[na:na] at java.base/java.util.stream.ReferencePipeline.forEachWithCancel(ReferencePipeline.java:127) ~[na:na] at java.base/java.util.stream.AbstractPipeline.copyIntoWithCancel(AbstractPipeline.java:502) ~[na:na] at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:488) ~[na:na] at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474) ~[na:na] at java.base/java.util.stream.FindOps$FindOp.evaluateSequential(FindOps.java:152) ~[na:na] at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ~[na:na] at java.base/java.util.stream.ReferencePipeline.findFirst(ReferencePipeline.java:476) ~[na:na] at org.springframework.boot.context.properties.bind.Binder.lambda$bindBean$6(Binder.java:322) ~[spring-boot-2.0.0.RC1.jar:2.0.0.RC1] at org.springframework.boot.context.properties.bind.Binder$Context.withIncreasedDepth(Binder.java:415) ~[spring-boot-2.0.0.RC1.jar:2.0.0.RC1] at org.springframework.boot.context.properties.bind.Binder$Context.withBean(Binder.java:405) ~[spring-boot-2.0.0.RC1.jar:2.0.0.RC1] at org.springframework.boot.context.properties.bind.Binder.bindBean(Binder.java:319) ~[spring-boot-2.0.0.RC1.jar:2.0.0.RC1] at org.springframework.boot.context.properties.bind.Binder.bindObject(Binder.java:261) ~[spring-boot-2.0.0.RC1.jar:2.0.0.RC1] at org.springframework.boot.context.properties.bind.Binder.bind(Binder.java:198) ~[spring-boot-2.0.0.RC1.jar:2.0.0.RC1] ... 27 common frames omitted Caused by: java.lang.reflect.InvocationTargetException: null at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:na] at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:na] at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:na] at java.base/java.lang.reflect.Method.invoke(Method.java:564) ~[na:na] at org.springframework.boot.context.properties.bind.JavaBeanBinder$BeanProperty.setValue(JavaBeanBinder.java:303) ~[spring-boot-2.0.0.RC1.jar:2.0.0.RC1] ... 46 common frames omitted Caused by: java.lang.IllegalStateException: The configuration of the pool is sealed once started. Use HikariConfigMXBean for runtime changes. at com.zaxxer.hikari.HikariConfig.setSchema(HikariConfig.java:951) ~[HikariCP-2.7.6.jar:na] ... 51 common frames omitted 2018-02-04 22:11:02.237 ERROR 6104 --- [ main] o.s.b.d.LoggingFailureAnalysisReporter : *************************** APPLICATION FAILED TO START *************************** Description: Failed to bind properties under &apos;spring.datasource.hikari&apos; to com.zaxxer.hikari.HikariDataSource: Property: spring.datasource.hikari.schema Value: ${application.database.schema} Origin: class path resource [application.properties]:11:33 Reason: Unable to set value for property schema Action: Update your application&apos;s configuration Process finished with exit code 1 爆出该异常源码地方：类ConfigurationPropertiesRebinder @ManagedOperation public boolean rebind(String name) { if (!this.beans.getBeanNames().contains(name)) { return false; } if (this.applicationContext != null) { try { Object bean = this.applicationContext.getBean(name); if (AopUtils.isAopProxy(bean)) { bean = ProxyUtils.getTargetObject(bean); } if (bean != null) { this.applicationContext.getAutowireCapableBeanFactory() .destroyBean(bean); this.applicationContext.getAutowireCapableBeanFactory() .initializeBean(bean, name); return true; } } catch (RuntimeException e) { this.errors.put(name, e); throw e; } catch (Exception e) { this.errors.put(name, e); throw new IllegalStateException(&quot;Cannot rebind to &quot; + name, e); } } return false; } 问题原因： 那是因为，我们在项目里自定义了动态数据源，采用了默认的数据库连接池HikariDataSource，该连接池，一旦创建，讲不可更改，所以当你刷新配置的时候，是一起连同数据源的相关配置也要刷新的，所以报错了。 数据源配置如下： package com.xrlj.framework.spring.config.ds.myself; import com.xrlj.framework.dao.ds.DynamicDataSource; import com.zaxxer.hikari.HikariDataSource; import org.springframework.beans.factory.annotation.Qualifier; import org.springframework.boot.context.properties.ConfigurationProperties; import org.springframework.boot.jdbc.DataSourceBuilder; import org.springframework.context.annotation.*; /** * 按规则定死的数据源。一主双从。适用所有服务。 */ @Configuration public class DataSourceConfig { @Bean(name = &quot;masterDataSource&quot;) @Qualifier(&quot;masterDataSource&quot;) @ConfigurationProperties(prefix=&quot;spring.myself-db.datasource.hikari.master&quot;) public DataSource masterDataSource() { return DataSourceBuilder.create().type(HikariDataSource.class).build(); } @Bean(name = &quot;slave1DataSource&quot;) @Qualifier(&quot;slave1DataSource&quot;) @ConfigurationProperties(prefix=&quot;spring.myself-db.datasource.hikari.slave1&quot;) public DataSource slave1DataSource() { return DataSourceBuilder.create().type(HikariDataSource.class).build(); } @Bean(name = &quot;slave2DataSource&quot;) @Qualifier(&quot;slave2DataSource&quot;) @ConfigurationProperties(prefix=&quot;spring.myself-db.datasource.hikari.slave2&quot;) public DataSource slave2DataSource() { return DataSourceBuilder.create().type(HikariDataSource.class).build(); } /** * 动态数据源: 通过AOP在不同数据源之间动态切换 * * @return */ @Primary @Bean(name = &quot;dynamicDataSource&quot;) @Qualifier(&quot;dynamicDataSource&quot;) @Scope(&quot;singleton&quot;) @DependsOn({&quot;masterDataSource&quot;,&quot;slave1DataSource&quot;,&quot;slave2DataSource&quot;}) //要加入这个注解，在数据源初始化之后，再初始化本bean，否则会出现循环依赖注入无法启动。 public DataSource dynamicDataSource(@Qualifier(&quot;masterDataSource&quot;) DataSource masterDataSource, @Qualifier(&quot;slave1DataSource&quot;) DataSource slave1DataSource,@Qualifier(&quot;slave2DataSource&quot;) DataSource slave2DataSource) { DynamicDataSource dynamicDataSource = new DynamicDataSource(); return dynamicDataSource.setMultipleDataSource(masterDataSource,slave1DataSource,slave2DataSource); } } 折腾了半天，终于在官网wiki中找到答案。参考：https://github.com/spring-cloud/spring-cloud-commons/pull/395https://github.com/spring-cloud/spring-cloud-commons/issues/318 其中有一段问题解决的描述如下： After trying to implement this, we are going to add a documentation note, but you should either set spring.cloud.refresh.extra-refreshable=javax.sql.DataSource or, more appropriately, strongly type your DataSource bean @Primary @Bean(name = &quot;dbDataSource&quot;) @ConfigurationProperties(prefix = &quot;datasource.db&quot;) public HikariDataSource dbDataSource() { return DataSourceBuilder.create().type(HikariDataSource.class).build(); } 意思是说，解决该问题有两种方式： 1.添加配置：spring.cloud.refresh.extra-refreshable=javax.sql.DataSource2.配置数据源时，指定最终的类型，而不是接口类型。如下：把 @Bean(name = &quot;masterDataSource&quot;) @Qualifier(&quot;masterDataSource&quot;) @ConfigurationProperties(prefix=&quot;spring.myself-db.datasource.hikari.master&quot;) public DataSource masterDataSource() { return DataSourceBuilder.create().type(HikariDataSource.class).build(); } 改成： @Bean(name = &quot;masterDataSource&quot;) @Qualifier(&quot;masterDataSource&quot;) @ConfigurationProperties(prefix=&quot;spring.myself-db.datasource.hikari.master&quot;) public DataSource masterDataSource() { return DataSourceBuilder.create().type(HikariDataSource.class).build(); } 每个地方都改成明确的类型。 如果采用第一种方式，会出现另外一个问题，在后面代码中DynamicDataSource转型为DataSource将会报错。纳闷，狗日的…… 因此，只能采用方式二了。把数据源配置改如下： package com.xrlj.framework.spring.config.ds.myself; import com.xrlj.framework.dao.ds.DynamicDataSource; import com.zaxxer.hikari.HikariDataSource; import org.springframework.beans.factory.annotation.Qualifier; import org.springframework.boot.context.properties.ConfigurationProperties; import org.springframework.boot.jdbc.DataSourceBuilder; import org.springframework.context.annotation.*; /** * 按规则定死的数据源。一主双从。适用所有服务。 */ @Configuration public class DataSourceConfig { @Bean(name = &quot;masterDataSource&quot;) @Qualifier(&quot;masterDataSource&quot;) @ConfigurationProperties(prefix=&quot;spring.myself-db.datasource.hikari.master&quot;) public HikariDataSource masterDataSource() { return DataSourceBuilder.create().type(HikariDataSource.class).build(); } @Bean(name = &quot;slave1DataSource&quot;) @Qualifier(&quot;slave1DataSource&quot;) @ConfigurationProperties(prefix=&quot;spring.myself-db.datasource.hikari.slave1&quot;) public HikariDataSource slave1DataSource() { return DataSourceBuilder.create().type(HikariDataSource.class).build(); } @Bean(name = &quot;slave2DataSource&quot;) @Qualifier(&quot;slave2DataSource&quot;) @ConfigurationProperties(prefix=&quot;spring.myself-db.datasource.hikari.slave2&quot;) public HikariDataSource slave2DataSource() { return DataSourceBuilder.create().type(HikariDataSource.class).build(); } /** * 动态数据源: 通过AOP在不同数据源之间动态切换 * * @return */ @Primary @Bean(name = &quot;dynamicDataSource&quot;) @Qualifier(&quot;dynamicDataSource&quot;) @Scope(&quot;singleton&quot;) @DependsOn({&quot;masterDataSource&quot;,&quot;slave1DataSource&quot;,&quot;slave2DataSource&quot;}) //要加入这个注解，在数据源初始化之后，再初始化本bean，否则会出现循环依赖注入无法启动。 public DynamicDataSource dynamicDataSource(@Qualifier(&quot;masterDataSource&quot;) HikariDataSource masterDataSource, @Qualifier(&quot;slave1DataSource&quot;) HikariDataSource slave1DataSource,@Qualifier(&quot;slave2DataSource&quot;) HikariDataSource slave2DataSource) { DynamicDataSource dynamicDataSource = new DynamicDataSource(); return dynamicDataSource.setMultipleDataSource(masterDataSource,slave1DataSource,slave2DataSource); } } 再重新启动各服务，测试：改动foo的值，刷新页面（post）： localhost:9010/actuator/refresh： 再请求/hi: 我们看到，foo的值已经在线刷新。无需重启服务。 如果是多个实例，只要任何一个实例执行了刷新请求，所有实例都会同步刷新的。 统一在config-server端刷新配置上面我们的测试，都是对每个业务服务进行配置刷新的。如果业务服务很多的话，就做不到统一刷新了，所以我们这里介绍在配置中心端刷新配置。 流程是，请求config-server的刷新请求，它会向mq发送配置刷新通知，然后，所有参与订阅的服务的配置都会收到刷新的通知时间，然后自动刷新。当然，也可以指定只刷新某个服务的。 更改foo的值，发起刷新请求，注意，请求的是config-server的地址： http://localhost:3331/actuator/bus-refresh 注意请求地址，是bus-refresh，而不是refresh。否则不成功。 这里要注意下，请求里面要添加认证信息。因为config-server里面引入了spring-security模块，而且要添加安全配置WebSecurityConfiguration,否则会出现请求需要验证或者请求拒绝导致不成功。 看请求结果图，请求返回状态为204 No Content,显示请求成功，但是没有返回内容。不知道为啥…… 再次请求业务服务的/hi,可以看到，配置已经在线刷新。成功了！ 利用github的Webhooks功能自动刷新达到的目的是，改动配置后，提交到git仓库，然后触发事件发起请求config-server的刷新请求。达到自动目的。 webhooks的使用，这里不做介绍。 略……","tags":[]},{"title":"分布式事务fescar入门","date":"2019-03-19T06:58:52.000Z","path":"2019/03/19/fescar-start/","text":"","tags":[]},{"title":"利用metrics、influxdata或者Elasticsearch、grafana搭建应用监控平台","date":"2019-03-16T06:01:23.000Z","path":"2019/03/16/metrics-influxdata-grafana/","text":"https://metrics.dropwizard.io/4.0.0/index.html# https://www.influxdata.com/ https://grafana.com/","tags":[]},{"title":"java应用服务性能监控metrics入门","date":"2019-03-16T05:51:52.000Z","path":"2019/03/16/metrics-start/","text":"","tags":[]},{"title":"maven配置文件加密","date":"2019-02-16T02:16:30.000Z","path":"2019/02/16/maven-pwd-encryption/","text":"在使用maven私服的时候，我们需要在maven配置文件settings.xml中配置私服的账号密码，但是明文的密码会暴露出去，每个开发人员都能看到，这就有安全风险。很幸运，maven提供了加密这些密码的方式，下面我们就来学习…… 参考：http://maven.apache.org/guides/mini/guide-encryption.html 获取master密码改密码是一个用来加密其它密码的密码。例如下面，对xrlj.123456加密，作为master的密码。 D:\\apache-maven-3.6.0\\conf&gt;mvn --encrypt-master-password xrlj.123456 {Naja8OoiZ1EHpj5eAL2pD3KVDC/qh0EBXZuvivt53+w=} 然后编辑文件~/.m2/settings-security.xml这个文件,如果没有，则新建一个。该文件必须在这个目录下。 编辑添加内容： &lt;settingsSecurity&gt; &lt;master&gt;{Naja8OoiZ1EHpj5eAL2pD3KVDC/qh0EBXZuvivt53+w=}&lt;/master&gt; &lt;/settingsSecurity&gt; 也可以把settings-security.xml文件放到指定的目录下，编辑内容和上面一样。但是，但是依然要在~/.m2目录中编辑settings-security.xml ,指向实际的settings-security.xml。如下： &lt;settingsSecurity&gt; &lt;master&gt;/path/setting-security.xml&lt;/master&gt; &lt;/settingsSecurity&gt; 加密server的密码例如，对下面的server加密： &lt;server&gt; &lt;id&gt;repository&lt;/id&gt; &lt;username&gt;admin&lt;/username&gt; &lt;password&gt;admin123&lt;/password&gt; &lt;/server&gt; 执行下面命令： D:\\apache-maven-3.6.0\\conf&gt;mvn --encrypt-password admin123 {K7e0zxQTHJ4HCDH8Wtxj7Lvv0sV2F1qTpAewNVEz7FI=} 所以配置改为： &lt;server&gt; &lt;id&gt;repository&lt;/id&gt; &lt;username&gt;admin&lt;/username&gt; &lt;password&gt;{K7e0zxQTHJ4HCDH8Wtxj7Lvv0sV2F1qTpAewNVEz7FI=}&lt;/password&gt; &lt;/server&gt; ————— 完 ————————","tags":[]},{"title":"flutter环境安装","date":"2019-01-26T03:03:12.000Z","path":"2019/01/26/flutter-start/","text":"windows环境","tags":[]},{"title":"nginx使用问题收藏","date":"2019-01-25T03:52:40.000Z","path":"2019/01/25/nginx-use-issue/","text":"nginx出现 “414 request-uri too large”客户端请求头缓冲区大小，如果请求头总长度大于小于128k，则使用此缓冲区， 请求头总长度大于128k时使用large_client_header_buffers设置的缓存区client_header_buffer_size 128k; large_client_header_buffers 指令参数4为个数，128k为大小，默认是8k。申请4个128k。large_client_header_buffers 4 128k 解决办法：在nginx的nginx.conf修改如下参数的： client_header_buffer_size 512k;large_client_header_buffers 4 512k; 然后重新启动nginx 上传文件失败 Failed to load resource: the server responded with a status of 413 (Request Entity Too Large)报错问题： Failed to load resource: the server responded with a status of 413 (Request Entity Too Large) 解决： 打开nginx.conf配置文件，修改client_max_body_size值 加上下面这行： client_max_body_size 30M（改成你想要的数值） 然后重新启动nginx 提醒： 于是奇葩的问题被我们遇到了，详细配置请参考下面。我们的问题是，无论client_max_body_size设置在哪里，nginx －s reload后，依然一直报413.多次尝试reload，始终无效。最终决定kill 进程，restart，终于好了。 nginx常用命令检查配置是否正确script1./nginx -t 启动、停止、重启nginx","tags":[]},{"title":"docker使用错误收集","date":"2019-01-23T07:41:18.000Z","path":"2019/01/23/docker-erro-show/","text":"docker 端口映射错误解决方法错误描述： COMMAND_FAILED: &apos;/sbin/iptables -t nat -A DOCKER -p tcp -d 0/0 --dport 8111 -j DNAT --to-destination 172.17.0.6:8111 ! -i docker0&apos; failed: iptables: No chain/target/match by that name. 解决： 依次执行以下命令： pkill docker iptables -t nat -F ifconfig docker0 down brctl delbr docker0 然后重启docker引擎。systemctl restart docker.service","tags":[]},{"title":"docker常用命令收藏","date":"2019-01-03T06:31:42.000Z","path":"2019/01/03/docker-commond-collect/","text":"容器查看容器端口映射[root@sqjr-client-demo-server1-hn zookeeper]# docker port zk-server1 2181/tcp -&gt; 0.0.0.0:2181 2888/tcp -&gt; 0.0.0.0:2888 3888/tcp -&gt; 0.0.0.0:3888 强制删除运行中的容器docker rm -f 容器名称 拷贝本地文件到容器docker cp 本地文件路径 ID全称:容器路径 删除所有容器docker rm `docker ps -a -q` //运行中的也删除 docker rm -f `docker ps -a -q` 按条件筛选之后删除容器docker rm `docker ps -a | grep xxxxx | awk &apos;{print $1}&apos;` 查看容器运行ip地址下面查看容器名为rabbitmq的容器的ip地址： script123456docker inspect --format '&#123;&#123;.NetworkSettings.IPAddress&#125;&#125;' rabbitmq``` 或者```shell scriptdocker inspect rabbitmq 然后查找IPAddress 镜像删除所有镜像docker rmi `docker images -q` 按条件删除镜像1.没有打标签 docker rmi `docker images -q | awk &apos;/^&lt;none&gt;/ { print $3 }&apos;` 2.镜像名包含关键字 docker rmi --force `docker images | grep doss-api | awk &apos;{print $3}&apos;` //其中doss-api为关键字 3.删除所有none镜像 docker rmi `docker images | grep &quot;&lt;none&gt;&quot; | awk &apos;{print $3}&apos;` 导出导入镜像导出镜像： 如果要存出镜像到本地文件，可以使用docker save命令。例如： script1[root@xr-server-dev images]# docker save -o eureka-server.tar 192.168.0.3:8082/xrlj/eureka-server:0.0.1 如上，把镜像导出当前文件目录下，名字eureka-server.tar。 导入镜像: 可以使用docker load从存出的本地文件中再导入到本地镜像库。例如： script1[root@iZj6c37qyt7ur3kr6b8u5nZ docker-images]# docker load -i eureka-server.tar 如上，在当前目录下，导入镜像eureka-server.tar。 临时运行镜像的一个实例script1docker run -rm -p 1111:1111 192.168.0.3:8082/xrlj/eureka-server:0.0.1 关闭运行后，会自动删除，不会创建容器。","tags":[]},{"title":"spring-boot集成docker部署","date":"2019-01-01T13:13:02.000Z","path":"2019/01/01/spring-boot-docker/","text":"本章介绍spring-boot项目docker化构件，利用maven插件把spring-boot项目构件成docker镜像，并上传到自己的docker私服nexus3上。 官方参考例子：https://spring.io/guides/gs/spring-boot-docker/ 快速在本机构件spring-boot项目镜像1.新建spring-boot项目。通过https://start.spring.io/2.在项目根目录下添加Dockerfile文件，并编辑内容如下： FROM openjdk:8-jdk-alpine VOLUME /tmp ARG DEPENDENCY=target/dependency COPY ${DEPENDENCY}/BOOT-INF/lib /app/lib COPY ${DEPENDENCY}/META-INF /app/META-INF COPY ${DEPENDENCY}/BOOT-INF/classes /app ENTRYPOINT [&quot;java&quot;,&quot;-cp&quot;,&quot;app:app/lib/*&quot;,&quot;hello.Application&quot;] 3.配置maven插件，编辑pom.xml，添加：dockerfile-maven 插件 &lt;properties&gt; &lt;docker.image.prefix&gt;springio&lt;/docker.image.prefix&gt; &lt;/properties&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;com.spotify&lt;/groupId&gt; &lt;artifactId&gt;dockerfile-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.4.9&lt;/version&gt; &lt;configuration&gt; &lt;repository&gt;${docker.image.prefix}/${project.artifactId}&lt;/repository&gt; &lt;tag&gt;${project.version}&lt;/tag&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; 参数说明： repository：指定镜像名称。 tag: 指定镜像标签，如果不指定，则默认是latest。 为了确保在构件docker镜像之前，spring-boot jar包是解压的，添加下面插件配置： &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-dependency-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;unpack&lt;/id&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;unpack&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;artifactItems&gt; &lt;artifactItem&gt; &lt;groupId&gt;${project.groupId}&lt;/groupId&gt; &lt;artifactId&gt;${project.artifactId}&lt;/artifactId&gt; &lt;version&gt;${project.version}&lt;/version&gt; &lt;/artifactItem&gt; &lt;/artifactItems&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; 4.执行命令构件docker镜像 $ ./mvnw install dockerfile:build 或者(如果么有mvnw) mvn install dockerfile:build 上传到docker私服1.配置setting.xml &lt;server&gt; &lt;id&gt;ip:8082&lt;/id&gt; &lt;username&gt;admin&lt;/username&gt; &lt;password&gt;admin123&lt;/password&gt; &lt;/server&gt; 注意id，必须为私服地址。 2.配置pom.xml &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;!-- tag::plugin[] --&gt; &lt;plugin&gt; &lt;groupId&gt;com.spotify&lt;/groupId&gt; &lt;artifactId&gt;dockerfile-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.4.9&lt;/version&gt; &lt;configuration&gt; &lt;repository&gt;119.145.41.171:8082/${docker.image.prefix}/${project.artifactId}&lt;/repository&gt; &lt;tag&gt;${project.version}&lt;/tag&gt; &lt;useMavenSettingsForAuth&gt;true&lt;/useMavenSettingsForAuth&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;!-- end::plugin[] --&gt; &lt;!-- tag::unpack[] --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-dependency-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;unpack&lt;/id&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;unpack&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;artifactItems&gt; &lt;artifactItem&gt; &lt;groupId&gt;${project.groupId}&lt;/groupId&gt; &lt;artifactId&gt;${project.artifactId}&lt;/artifactId&gt; &lt;version&gt;${project.version}&lt;/version&gt; &lt;/artifactItem&gt; &lt;/artifactItems&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;!-- end::unpack[] --&gt; &lt;/plugins&gt; 重点两个参数： repository：需要加上私服地址。 useMavenSettingsForAuth：设置为true。 3.执行命令构建并上传镜像到私服 mvn clean install dockerfile:push 绑定maven执行阶段&lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;!-- tag::plugin[] --&gt; &lt;plugin&gt; &lt;groupId&gt;com.spotify&lt;/groupId&gt; &lt;artifactId&gt;dockerfile-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.4.9&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;default&lt;/id&gt; &lt;goals&gt; &lt;goal&gt;build&lt;/goal&gt; &lt;goal&gt;push&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;configuration&gt; &lt;repository&gt;119.145.41.171:8082/${docker.image.prefix}/${project.artifactId}&lt;/repository&gt; &lt;tag&gt;${project.version}&lt;/tag&gt; &lt;useMavenSettingsForAuth&gt;true&lt;/useMavenSettingsForAuth&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;!-- end::plugin[] --&gt; &lt;!-- tag::unpack[] --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-dependency-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;unpack&lt;/id&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;unpack&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;artifactItems&gt; &lt;artifactItem&gt; &lt;groupId&gt;${project.groupId}&lt;/groupId&gt; &lt;artifactId&gt;${project.artifactId}&lt;/artifactId&gt; &lt;version&gt;${project.version}&lt;/version&gt; &lt;/artifactItem&gt; &lt;/artifactItems&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;!-- end::unpack[] --&gt; &lt;/plugins&gt; 这样子就可以使用mvn package,mvn deploy命令了。也可以精准使用mvn dockerfile:build。 启动容器$ docker run -e &quot;SPRING_PROFILES_ACTIVE=prod&quot; -p 8080:8080 -t springio/gs-spring-boot-docker 或者 $ docker run -e &quot;SPRING_PROFILES_ACTIVE=dev&quot; -p 8080:8080 -t springio/gs-spring-boot-docker 调试容器内的应用","tags":[]},{"title":"maven构建jar上传到nexus私服并拉取","date":"2018-12-30T06:57:05.000Z","path":"2018/12/30/maven-nexus-jar/","text":"公司内部有很多自己的java lib库等共用代码，为了在公司内部自由共享这些资源，所以需要搭建maven私服。下面介绍利用maven构建java项目为jar包并上传到nexus私服，以及在其它项目中如何引用私服中的jar包。 nexus3的安装这里不做介绍，参考章节centos7下搭建maven私仓Nexus,或者docker安装各种常用开发应用软件。 新建maven2仓库 说明： 仓库名称：ymu-hosted，类型为hosted。maven仓库有三种类型，hosted、proxy、group。hosted代表私服本机服务器，proxy代理外部仓库服务器，group整合各个hosted和proxy，按顺序策略获取jar。 这里选择Version policy为：Release。正式发布版本。正式发布版本都上传到这里来。 Deployment policy: 选择为Allow Redeploy，可重复发布。代表同一个版本号的jar可以多次发布。这样就不必要设置快照仓库了，项目小改动也作为正式版本发布上去，不必要修改版本号。 maven构建jar并上传到私服相应仓库配置pom.xml&lt;!--mavne 发布--&gt; &lt;distributionManagement&gt; &lt;snapshotRepository&gt; &lt;id&gt;snapshots&lt;/id&gt; &lt;name&gt;maven-snapshots&lt;/name&gt; &lt;url&gt;http://ip:8085/repository/maven-snapshots/&lt;/url&gt; &lt;/snapshotRepository&gt; &lt;repository&gt; &lt;id&gt;repository&lt;/id&gt; &lt;name&gt;ymu-hosted&lt;/name&gt; &lt;url&gt;http://ip:8085/repository/ymu-hosted/&lt;/url&gt; &lt;/repository&gt; &lt;/distributionManagement&gt; 说明： snapshotRepository：指定jar包要发布的快照仓库。版本号这样0.0.1-SNAPSHOT，代表的是快照版本，后缀的SNAPSHOT必须是大写，不能是小写。 repository：指定jar包发布上去的正式版本仓库。当版本号是这样&lt;version&gt;0.0.2&lt;/version&gt;，没有SNAPSHOT的时候，jar将发布到这里指定的私服仓库ymu-hosted下。 id：对应maven配置setting.xml中的配置。保持id一致。远程仓库的唯一标志，很重要。 name：只是方便阅读，随意定义。 url：仓库地址。登录nexus，在配置中可以查看。 配置setting.xml&lt;server&gt; &lt;id&gt;repository&lt;/id&gt; &lt;username&gt;admin&lt;/username&gt; &lt;password&gt;admin123&lt;/password&gt; &lt;/server&gt; &lt;server&gt; &lt;id&gt;snapshots&lt;/id&gt; &lt;username&gt;admin&lt;/username&gt; &lt;password&gt;admin123&lt;/password&gt; &lt;/server&gt; 配置完成后，执行mvn deploy命令，就可以发布jar到私服了。修改版本号，可以实际验证查看发布到哪个仓库下。 从nexus私服下载构件配置pom.xml: &lt;repositories&gt; &lt;!--自己私仓,下载jar--&gt; &lt;repository&gt; &lt;id&gt;ymu-public&lt;/id&gt; &lt;name&gt;ymu nexus&lt;/name&gt; &lt;url&gt;http://119.145.41.171:8085/repository/maven-public/&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/snapshots&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/releases&gt; &lt;/repository&gt; &lt;/repositories&gt; &lt;pluginRepositories&gt; &lt;!--私服，插件--&gt; &lt;pluginRepository&gt; &lt;id&gt;ymu-public&lt;/id&gt; &lt;name&gt;ymu nexus&lt;/name&gt; &lt;url&gt;http://119.145.41.171:8085/repository/maven-public/&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/pluginRepository&gt; &lt;/pluginRepositories&gt; 看上面配置，我们配置自己的私服用的是maven-public仓库，该仓库是group类型，整合了自己的私仓等，如下图： 看Group组，我们可以看到Member里面有很多个仓库，这代表，拉取jar构件的时候，首先从私服本机拉取，拉取不到的话再从下一个拉取，按顺序处理。从maven中央仓库拉取的jar构件都会缓存到其它仓库。 以上，我们看到的配置在pom.xml中，只针对某个项目有效。如果是多个项目想都通用私服，则可以在maven的setting.xml中配置: &lt;settings&gt; &lt;mirrors&gt; &lt;mirror&gt; &lt;!--This sends everything else to /public --&gt; &lt;id&gt;nexus&lt;/id&gt; &lt;mirrorOf&gt;*&lt;/mirrorOf&gt; &lt;url&gt;http://localhost:8081/repository/maven-public/&lt;/url&gt; &lt;/mirror&gt; &lt;/mirrors&gt; &lt;profiles&gt; &lt;profile&gt; &lt;id&gt;nexus&lt;/id&gt; &lt;!--Enable snapshots for the built in central repo to direct --&gt; &lt;!--all requests to nexus via the mirror --&gt; &lt;repositories&gt; &lt;repository&gt; &lt;id&gt;central&lt;/id&gt; &lt;url&gt;http://central&lt;/url&gt; &lt;releases&gt;&lt;enabled&gt;true&lt;/enabled&gt;&lt;/releases&gt; &lt;snapshots&gt;&lt;enabled&gt;true&lt;/enabled&gt;&lt;/snapshots&gt; &lt;/repository&gt; &lt;/repositories&gt; &lt;pluginRepositories&gt; &lt;pluginRepository&gt; &lt;id&gt;central&lt;/id&gt; &lt;url&gt;http://central&lt;/url&gt; &lt;releases&gt;&lt;enabled&gt;true&lt;/enabled&gt;&lt;/releases&gt; &lt;snapshots&gt;&lt;enabled&gt;true&lt;/enabled&gt;&lt;/snapshots&gt; &lt;/pluginRepository&gt; &lt;/pluginRepositories&gt; &lt;/profile&gt; &lt;/profiles&gt; &lt;activeProfiles&gt; &lt;!--make the profile active all the time --&gt; &lt;activeProfile&gt;nexus&lt;/activeProfile&gt; &lt;/activeProfiles&gt; &lt;/settings&gt; 这样子就可以全局引用了，所有项目都是从配置的私服以及其它第三方私服下载构件。不用在每个项目的pom.xml中配置了。第三方的私服，可以添加proxy私仓，然后整合进去group里面。 上传第三个jar包到nexus私服中方法一：在nexus3界面直接操作 如上图，点击maven-releases仓库，进入下面图： 按照输入要求，下面我们上传一个第三方的jar包： 最好选定下生成pom.xml，否则在其它项目引用的时候，无法点击跳进去。但是对jar使用没影响。 可以打开对应仓库浏览已上传的jar构件： 下面就可以在pom.xml中正常的引用了。 方法二：mvn命令直接操作mvn deploy:deploy-file -DgroupId=com.csource -DartifactId=fastdfs-client-java -Dversion=1.27-RELEASE -Dpackaging=jar -Dfile=/home/mutian/Desktop/fastdfs-client-java-1.27-RELEASE.jar -Durl=http://119.145.41.171:8085/repository/ymu-hosted/ -DrepositoryId=repository 参数说明： -Durl: 仓库地址，jar包要上传到这个自己设定的本机仓库下面。 -DrepositoryId：重要，这个是在maven配置文件setting.xml中设定的。对应该仓库的访问id。名字要一致。 -DgroupId=com.csource -DartifactId=fastdfs-client-java -Dversion=1.27-RELEASE 这三个参数根据你的jar包随便设。 -Dfile：要上传的jar包所在路径。","tags":[]},{"title":"使用maven插件构建docker镜像并注册到nexus私仓","date":"2018-12-27T06:29:17.000Z","path":"2018/12/27/docker-maven-nexus/","text":"Maven是一个强大的项目管理和构建工具，下面我们介绍利用Maven插件构建Docker镜像并注册到Nexus私仓里面，这样，在服务器或者其它地方就可以直接拉取镜像并运行，这对服务共享或者服务器部署应用起到极大的方便。在maven中央仓库，可以搜索到好几个docker-maven-pluging。 下面我们采用一款由Spotify公司开发的Maven插件docker-maven-plugin。 参考网址：http://itmuch.com/docker/12-docker-maven/https://blog.csdn.net/aixiaoyang168/article/details/77453974 快速入门1.新建spring-cloud项目，eureka-server。 2.配置pom.xml文件： &lt;plugin&gt; &lt;groupId&gt;com.spotify&lt;/groupId&gt; &lt;artifactId&gt;docker-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.2.0&lt;/version&gt; &lt;configuration&gt; &lt;imageName&gt;my-image:${project.version}&lt;/imageName&gt; &lt;baseImage&gt;java&lt;/baseImage&gt; &lt;entryPoint&gt;[&quot;java&quot;, &quot;-jar&quot;, &quot;/${project.build.finalName}.jar&quot;]&lt;/entryPoint&gt; &lt;!-- copy the service&apos;s jar file from target into the root directory of the image --&gt; &lt;resources&gt; &lt;resource&gt; &lt;targetPath&gt;/&lt;/targetPath&gt; &lt;directory&gt;${project.build.directory}&lt;/directory&gt; &lt;include&gt;${project.build.finalName}.jar&lt;/include&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;/configuration&gt; &lt;/plugin&gt; 插件配置说明： imageName：指定镜像名称。一般是用仓库名称+实际名字作为镜像名称，如：docker-repo/my-image整个作为镜像名词，也可以直接用my-image作为镜像名称。冒号后面是镜像tag，如果不指定，则tag是latest,所以一般指定，就直接用maven项目的版本号。这里特别注意，tab不能带大写字母，否则报错。比如maven的版本号默认：0.0.1-SNAPSHOT。这样构建将会报错误。去掉SNAPSHOT。 baseImage：用于指定基础镜像，类似于Dockerfile中的FROM指令。这里用了java基础镜像，这是个集成了openJdk1.8的镜像，有643M那么大。因此，我们可以用这个替换hub.docker.com,只有127M大小，集成的jdk8。 entrypoint：类似于Dockerfile的ENTRYPOINT指令。 resources.resource.directory：用于指定需要复制的根目录，${project.build.directory}表示target目录。会在target目录下生成docker目录，jar包等生成在里面。 resources.resource.include：指定需要复制的文件。${project.build.finalName}.jar指的是打包后的jar包文件。 3.设置环境变量DOCKER_HOS 编辑/etc/profile文件，增加环境变量： export DOCKER_HOST=tcp://192.168.33.10:2375 可能报错： [ERROR] Failed to execute goal com.spotify:docker-maven-plugin:1.2.0:build (default-cli) on project demo: Exception caught: java.util.concurrent.ExecutionException: com.spotify.docker.client.shaded.javax.ws.rs.ProcessingException: com.spotify.docker.client.shaded.org.apache.http.conn.HttpHostConnectException: Connect to 192.168.33.10:2375 [/192.168.33.10] failed: Connection refused (Connection refused) -&gt; [Help 1] 报错的话，把跳过该步骤，后面也能成功。待解…… ip是指本机ip。端口指定，不可更改。 4.启动docker引擎，执行下面命令开始构建： mvn clean package docker:build --查看是否生成镜像 docker image ls 5.启动镜像： docker run --name eureka-server -p 8084:8084 -d my-image 可以正常访问网站啦！！ 使用Dockerfile进行构建&lt;build&gt; &lt;plugins&gt; ... &lt;plugin&gt; &lt;groupId&gt;com.spotify&lt;/groupId&gt; &lt;artifactId&gt;docker-maven-plugin&lt;/artifactId&gt; &lt;version&gt;VERSION GOES HERE&lt;/version&gt; &lt;configuration&gt; &lt;imageName&gt;example&lt;/imageName&gt; &lt;dockerDirectory&gt;docker&lt;/dockerDirectory&gt; &lt;resources&gt; &lt;resource&gt; &lt;targetPath&gt;/&lt;/targetPath&gt; &lt;directory&gt;${project.build.directory}&lt;/directory&gt; &lt;include&gt;${project.build.finalName}.jar&lt;/include&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;/configuration&gt; &lt;/plugin&gt; ... &lt;/plugins&gt; &lt;/build&gt; 基本不变，改成这个属性&lt;dockerDirectory&gt;docker&lt;/dockerDirectory&gt; 。指定Dockerfile所在目录即可。然后也是执行mvn clean package docker:build就可构建了。 构建docker镜像并push到docker私服简洁配置：1.maven setting.xml配置：添加： &lt;server&gt; &lt;id&gt;my-docker-registry&lt;/id&gt; &lt;username&gt;admin&lt;/username&gt; &lt;password&gt;admin123&lt;/password&gt; &lt;configuration&gt; &lt;email&gt;932852117@qq.com&lt;/email&gt; &lt;/configuration&gt; &lt;/server&gt; 账号密码，是私服nexus的账号密码。 2.pom.xml配置： &lt;plugin&gt; &lt;groupId&gt;com.spotify&lt;/groupId&gt; &lt;artifactId&gt;docker-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.2.0&lt;/version&gt; &lt;configuration&gt; &lt;imageName&gt;119.145.41.171:8082/ymu-micr/my-image:${project.version}&lt;/imageName&gt; &lt;!-- &lt;imageName&gt;my-image:${project.version}&lt;/imageName&gt; --&gt; &lt;baseImage&gt;anapsix/alpine-java&lt;/baseImage&gt; &lt;entryPoint&gt;[&quot;java&quot;, &quot;-jar&quot;, &quot;/${project.build.finalName}.jar&quot;]&lt;/entryPoint&gt; &lt;forceTags&gt;true&lt;/forceTags&gt; &lt;!-- copy the service&apos;s jar file from target into the root directory of the image --&gt; &lt;resources&gt; &lt;resource&gt; &lt;targetPath&gt;/&lt;/targetPath&gt; &lt;directory&gt;${project.build.directory}&lt;/directory&gt; &lt;include&gt;${project.build.finalName}.jar&lt;/include&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;serverId&gt;my-docker-registry&lt;/serverId&gt; &lt;!-- &lt;registryUrl&gt;119.145.41.171:8082/v1/&lt;/registryUrl&gt; --&gt; &lt;/configuration&gt; &lt;/plugin&gt; 3.执行命令构建上传到nexus私服： mvn clean package docker:build -DpushImage 构建成功后可以在私服看到docker 镜像： 完整配置：&lt;plugin&gt; &lt;groupId&gt;com.spotify&lt;/groupId&gt; &lt;artifactId&gt;docker-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.2.0&lt;/version&gt; &lt;configuration&gt; &lt;imageName&gt;119.145.41.171:8082/ymu-micr/my-image:${project.version}&lt;/imageName&gt; &lt;!-- &lt;imageName&gt;my-image:${project.version}&lt;/imageName&gt; --&gt; &lt;baseImage&gt;anapsix/alpine-java&lt;/baseImage&gt; &lt;entryPoint&gt;[&quot;java&quot;, &quot;-jar&quot;, &quot;/${project.build.finalName}.jar&quot;]&lt;/entryPoint&gt; &lt;forceTags&gt;true&lt;/forceTags&gt; &lt;!-- copy the service&apos;s jar file from target into the root directory of the image --&gt; &lt;resources&gt; &lt;resource&gt; &lt;targetPath&gt;/&lt;/targetPath&gt; &lt;directory&gt;${project.build.directory}&lt;/directory&gt; &lt;include&gt;${project.build.finalName}.jar&lt;/include&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;serverId&gt;my-docker-registry&lt;/serverId&gt; &lt;!-- &lt;registryUrl&gt;119.145.41.171:8082/v1/&lt;/registryUrl&gt; --&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;build-image&lt;/id&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;build&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;execution&gt; &lt;id&gt;tag-image&lt;/id&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;tag&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;image&gt;my-image:${project.version}&lt;/image&gt; &lt;newName&gt;119.145.41.171:8082/ymu-micr/my-image:${project.version}&lt;/newName&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;execution&gt; &lt;id&gt;push-image&lt;/id&gt; &lt;phase&gt;deploy&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;push&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;imageName&gt;119.145.41.171:8082/ymu-micr/my-image:${project.version}&lt;/imageName&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt;","tags":[]},{"title":"ftp入门","date":"2018-12-27T01:30:53.000Z","path":"2018/12/27/ftp-start/","text":"CentOs7下搭建ftp服务器方式一：docker下安装1.拉取镜像： docker pull fauria/vsftpd 2.启动容器： docker run -d -v /dockers/vsftpd:/home/vsftpd \\ -p 20:20 -p 21:21 -p 21100-21110:21100-21110 \\ -e FTP_USER=admin -e FTP_PASS=123456 \\ -e PASV_ADDRESS=127.0.0.1 -e PASV_MIN_PORT=21100 -e PASV_MAX_PORT=21110 \\ --name vsftpd --restart=always fauria/vsftpd ------------------------------------ docker logs vsftpd","tags":[]},{"title":"利用nexus搭建docker私服","date":"2018-12-26T11:31:05.000Z","path":"2018/12/26/docker-register-nexus/","text":"本文介绍利用Nexus来做docker私服，来管理自己或者公司的镜像。类似于做maven私服一样…… 首先要安装nexus：参考章节docker安装各种常用开发应用软件，docker安装nexus。 创建Docker仓库 首先登录nexus3 。 点击“Create repository”按钮，创建仓库。Nexus支持多种仓库类型，例如：maven、npm、docker等。本文创建一个docker仓库。一般来说，对于特定的仓库类型（例如docker），细分了三类，分别是proxy、hosted、group，含义如下：hosted，本地代理仓库，通常我们会部署自己的构件到这一类型的仓库，可以push和pull。proxy，代理的远程仓库，它们被用来代理远程的公共仓库，如maven中央仓库，只能pull。group，仓库组，用来合并多个hosted/proxy仓库，通常我们配置maven依赖仓库组，只能pull。 下面创建仓库： 填写配置(注意端口号 )： 连接仓库在其它机子或者本机，连接了仓库，才能做push、pull动作。 首先，编辑vim /etc/docker/daemon.json [root@api data]# cat /etc/docker/daemon.json { &quot;insecure-registries&quot; : [ &quot;11.148.41.11:8082&quot; ] } 11.148.41.11:8082：这里ip是nexus服务器的ip，端口是是上面配置的docker仓库的端口。 然后重启docker引擎。 登录 docker login -u admin -p admin123 ip:8082 #注意这里的端口是配置仓库时选择的端口号 登录报错处理： 1.错误： [root@xr-server-dev eureka-server]# docker login -u admin -p admin123 localhost:8082 WARNING! Using --password via the CLI is insecure. Use --password-stdin. Error response from daemon: login attempt to http://localhost:8082/v2/ failed with status: 401 Unauthorized 错误处理： 再次登录： [root@xr-server-dev eureka-server]# docker login -u admin -p admin123 localhost:8082 WARNING! Using --password via the CLI is insecure. Use --password-stdin. Login Succeeded 成功 上传镜像不能直接上传镜像：docker push nginx:latest。因为docker默认是上传到docker hub仓库的。 所以要先改镜像标签： docker tag nginx:latest ip:8082/nginx:0.1 然后上传： docker push ip:8082/nginx:0.1 下面成功截图： 拉取镜像docker pull ip:8082/nginx:0.1 搜索镜像docker search ip:8082/nginx","tags":[]},{"title":"docker给运行中的容器添加映射端口","date":"2018-12-26T08:31:53.000Z","path":"2018/12/26/docker-container-add-port/","text":"容器启动的时候，只映射了一些端口，那如果想给运行中的容器映射端口到主机该怎么弄呢…… 方法一： 1.获取容器id docker ps docker inspect `container_name` | grep IPAddress [root@api data]# docker inspect nexus3 | grep IPAddress &quot;SecondaryIPAddresses&quot;: null, &quot;IPAddress&quot;: &quot;172.17.0.4&quot;, &quot;IPAddress&quot;: &quot;172.17.0.4&quot;, 2.iptable转发端口 将容器的80端口映射到dockers宿主机的9998端口 iptables -t nat -A DOCKER -p tcp –dport 8001 -j DNAT –to-destination 172.17.0.19:8000 3.查看docker端口映射 [root@api docker]# docker port nexus3 8081/tcp -&gt; 0.0.0.0:8085 发现没映射成功……悲剧 无效，未解决…… 方法二： 1.提交一个运行中的容器为镜像 docker commit containerid foo/live 2.运行镜像并添加端口 docker run -d -p 8000:80 foo/live /bin/bash 方法三（比方法二方便，推荐） 1.首先stop容器，在宿主机编辑：/var/lib/docker/containers/[hash_of_the_container]/hostconfig.json 添加映射，容器端口8082映射到宿主8888 &quot;PortBindings&quot;: { &quot;8081/tcp&quot;: [ { &quot;HostIp&quot;: &quot;&quot;, &quot;HostPort&quot;: &quot;8085&quot; } ], &quot;8082/tcp&quot;: [ { &quot;HostIp&quot;: &quot;&quot;, &quot;HostPort&quot;: &quot;8888&quot; } ] } 2.重启docker引擎 systemctl restart docker.service 3.启动容器 docker start 容器名 4.查看容器端口映射 docker port 容器名","tags":[]},{"title":"文件存储系统glusterfs入门","date":"2018-12-26T07:33:44.000Z","path":"2018/12/26/glusterfs-start-install/","text":"参考地址：https://www.gluster.org https://my.oschina.net/hncscwc/blog/210072 原理准备工作用三个节点搭建一个glusterfs集群，一个节点作为客户端使用。新建四个虚拟机(centos7)：并编辑etc/hosts glusterfs服务器节点： 192.168.200.10 server-node1 # 主节点 192.168.200.11 server-node2 # 从节点 192.168.200.12 server-node3 # 从节点 client节点： 172.29.41.163 phn centos7 然后在每个机子互相ping，确保网络通畅： 在server-node1服务器执行： # ping server-node2 # ping server-node3 其它机子同理，都ping下，保证互相通讯。 开始安装GlusterFS#### 安装服务 1.在每个服务节点安装： $ yum install -y centos-release-gluster $ yum install -y glusterfs glusterfs-server $ yum install -y glusterfs-fuse glusterfs-rdma 2.设置服务开机自启动： $ systemctl start glusterd.service &amp;&amp; systemctl enable glusterd.service 配置集群1.首先启动服务（每个节点都启动） systemctl start glusterd.service systemctl enable glusterd.service 2.关闭每个节点服务器的防火墙 systemctl stop firewalld.service systemctl disable firewalld.service 3.在主节点中把另外两个从节点添加到集群 gluster peer probe server-node1 gluster peer probe server-node2 4.从集群中删除节点（在主节点服务器执行） $ gluster peer detach 192.168.200.12 可以从任意GFS Server节点上删除集群中的其它节点，但不能删除执行命令时的当前节点。 6.查看集群状态 在任意服务节点执行： [root@server-node1 ~]# gluster peer status Number of Peers: 2 Hostname: server-node2 Uuid: 34bddd2b-4f4c-4b4b-afcd-786a6ba2c13d State: Peer in Cluster (Connected) Hostname: server-node3 Uuid: 81101ab4-bcdc-467a-9fae-96d997a75fdc State: Peer in Cluster (Connected) --------------------------------------------- [root@server-node2 ~]# gluster peer status Number of Peers: 2 Hostname: server-node1 Uuid: d34a54a8-24bc-43ff-95fc-fe0b6d5c52fa State: Peer in Cluster (Connected) Other names: 192.168.200.10 Hostname: server-node3 Uuid: 81101ab4-bcdc-467a-9fae-96d997a75fdc State: Peer in Cluster (Connected) ---------------------------------------------- [root@server-node3 ~]# gluster peer status Number of Peers: 2 Hostname: server-node1 Uuid: d34a54a8-24bc-43ff-95fc-fe0b6d5c52fa State: Peer in Cluster (Connected) Other names: server-node1 Hostname: server-node2 Uuid: 34bddd2b-4f4c-4b4b-afcd-786a6ba2c13d State: Peer in Cluster (Connected) 在每个节点，可以看到另外的另个节点。 7.创建数据存储目录（每个节点服务都要创建） mkdir -p /data/gluster/exp1 8.创建卷，GFS Volume 在任意服务节点上执行如下命令： gluster volume create models replica 3 server-node1:/data/gluster/exp1 server-node2:/data/gluster/exp1 server-node3:/data/gluster/exp1 force ------------------------------------------ [root@server-node1 gluster]# gluster volume create models replica 3 server-node1:/data/gluster/exp1 server-node2:/data/gluster/exp1 server-node3:/data/gluster/exp1 force volume create: models: success: please start the volume to access data _说明_:models: 卷的名称replica 3: 表明存储3个备份，后面指定服务器的存储目录 查看volume 状态在任意服务节点执行： gluster volume info ------------------------------------------------------------ [root@server-node2 ~]# gluster volume info Volume Name: models Type: Replicate Volume ID: 45d12287-2dfa-42be-954b-97c014d189c4 Status: Created Snapshot Count: 0 Number of Bricks: 1 x 3 = 3 Transport-type: tcp Bricks: Brick1: server-node1:/data/gluster/exp1 Brick2: server-node2:/data/gluster/exp1 Brick3: server-node3:/data/gluster/exp1 Options Reconfigured: transport.address-family: inet nfs.disable: on performance.client-io-threads: off 8.启动卷启动名为models的数据卷，在任意一个服务节点上执行即可： gluster volume start models 重新查看卷信息，会看到卷的状态status变为Started。代表卷已经启动成功。 配置 GFS Clienthttps://docs.gluster.org/en/latest/Administrator%20Guide/Setting%20Up%20Clients/ GFS客户端的节点必须和各个服务节点网络连通。ping命令检查。 1.安装客户端 $ yum install -y glusterfs glusterfs-fuse glusterfs-rdma 2.将客户端目录挂载到GFS服务的volume 在gluster客户节点创建本地目录： $ mkdir -p /data/gluster/dt1 将本地目录挂载到GFS Volume： mount -t glusterfs 192.168.200.10:models /data/gluster/dt1 参数说明：192.168.200.10： 指的是GFS服务主节点的ip，一定是主节点。models： 指上面创建的GFS每个服务上的卷（volume）名称。/data/gluster/dt1: 客户端的本地目录，要挂载的目录。 _注意_:上面挂载客户端目录到服务卷的命令可能不成功，这是因为用的是ip的原因，得把主节点的ip改成域名才行。因此，现在客户节点配置hosts。编辑/etc/hosts： 192.168.200.10 server-node1 #GFS Server主节点 然后重新挂载： mount -t glusterfs server-node1:models /data/gluster/dt1 挂载成功。 3.查看挂载 [root@gluster-client1 dt1]# df -h Filesystem Size Used Avail Use% Mounted on /dev/mapper/VolGroup00-LogVol00 38G 3.3G 35G 9% / devtmpfs 910M 0 910M 0% /dev tmpfs 920M 0 920M 0% /dev/shm tmpfs 920M 8.6M 911M 1% /run tmpfs 920M 0 920M 0% /sys/fs/cgroup /dev/sda2 1014M 63M 952M 7% /boot tmpfs 184M 0 184M 0% /run/user/1000 tmpfs 184M 0 184M 0% /run/user/0 server-node1:models 40G 3.4G 35G 9% /data/gluster/dt1 可以看到，最后一个文件系统，就是我们挂载的。 4.测试上传文件在客户机执行上传文件命令： [root@gluster-client1 dt1]# time dd if=/dev/zero of=/data/gluster/dt1/hello bs=100M count=1 1+0 records in 1+0 records out 104857600 bytes (105 MB) copied, 5.37804 s, 19.5 MB/s real 0m5.395s user 0m0.001s sys 0m0.182s [root@gluster-client1 dt1]# ls [root@gluster-client1 dt1]# 查看GFS Server各个节点对应的卷，以及客户节点的本地目录： [root@server-node1 exp1]# pwd /data/gluster/exp1 [root@server-node1 exp1]# ls hello 都能看到一个hello的文件。说明的确按我们预期，有三份的文件数据，分别在三个服务节点上存储了。同时在客户端节点也有一份。 5.继续测试随便在客户节点本地目录下，创建文件touch a，然后查看各个服务节点，会发现，客户节点的a文件已经同步到三个服务的对应卷下了，编辑客户节点的a文件，各个服务节点对应的a文件也会相应改变。这说明了它们是一直同步的。 GFS性能调优 开启指定volume的配额： (models为volume名称) gluster volume quota models enable 限制models中 / (既总目录)最大使用80GB空间 gluster volume quota models limit-usage / 80GB 设置 cache 大小(此处要根据实际情况，如果设置太大可能导致后面客户端挂载失败) gluster volume set models performance.cache-size 512MB 开启异步，后台操作 gluster volume set models performance.flush-behind on 设置 io 线程 32 gluster volume set models performance.io-thread-count 32 设置 回写 (写数据时间，先写入缓存内，再写入硬盘) gluster volume set models performance.write-behind on 调优之后的volume信息 gluster volume info 然后试下再上传文件，看是否快很多呢。 其它命令查看所volume（卷）gluster volume list 删除volume（卷）gluster volume stop models //停止名字为 models 的磁盘 gluster volume delete models //删除名字为 models 的磁盘 卸载GlusterFS磁盘--&gt;gluster peer detach glusterfs4 ACL访问控制--&gt;gluster volume set models auth.allow 192.168.56.*,10.0.1.* volume set: success 添加GlusterFS节点--&gt;gluster peer probe sc2-log5 --&gt;gluster peer probe sc2-log6 --&gt;gluster volume add-brick models sc2-log5:/data/gluster sc2-log6:/data/gluster 迁移GlusterFS数据--&gt;gluster volume remove-brick models sc2-log1:/usr/local/share/models sc2-log5:/usr/local/share/models start --&gt;gluster volume remove-brick models sc2-log1:/usr/local/share/models sc2-log5:/usr/local/share/models status --&gt;gluster volume remove-brick models sc2-log1:/usr/local/share/models sc2-log5:/usr/local/share/models commit 修复GlusterFS数据(在节点1宕机的情况下)--&gt;gluster volume replace-brick models sc2-log1:/usr/local/share/models sc2-log5:/usr/local/share/models commit -force --&gt;gluster volume heal models full","tags":[]},{"title":"区块链-Paxos共识算法介绍","date":"2018-12-26T02:21:43.000Z","path":"2018/12/26/blockchain-paxos/","text":"","tags":[]},{"title":"centos6安装docker-ce","date":"2018-12-18T08:00:19.000Z","path":"2018/12/18/docker-install-centos6/","text":"Docker 运行在 CentOS 7 上，要求系统为64位、系统内核版本为 3.10 以上。Docker 运行在 CentOS-6.5 或更高的版本的 CentOS 上，要求系统为64位、系统内核版本为 2.6.32-431 或者更高版本 CentOS 7 的内核一般都是3.10的，而CentOS 6.X 的内核一般都是2.6，在2.6的内核下，Docker运行会比较卡，所以一般会选择升级到3.10版本。 centos升级内核方法：Linux升级内核 1.安装docker [root@localhost ~]# yum install docker-io 2.查看Docker版本信息 [root@iZwz9b0bqrkbhqd5lu2pwhZ ~]# docker version Client version: 1.7.1 Client API version: 1.19 Go version (client): go1.4.2 Git commit (client): 786b29d/1.7.1 OS/Arch (client): linux/amd64 Get http:///var/run/docker.sock/v1.19/version: dial unix /var/run/docker.sock: no such file or directory. Are you trying to connect to a TLS-enabled daemon without TLS? 3.启动Docker [root@iZwz9b0bqrkbhqd5lu2pwhZ ~]# service docker start Starting cgconfig service: [ OK ] Starting docker: [ OK ] 4.查看Docker日志 [root@iZwz9b0bqrkbhqd5lu2pwhZ ~]# cat /var/log/docker \\nTue Dec 18 16:19:04 CST 2018\\n time=&quot;2018-12-18T16:19:04.578091169+08:00&quot; level=info msg=&quot;Listening for HTTP on unix (/var/run/docker.sock)&quot; time=&quot;2018-12-18T16:19:06.456619838+08:00&quot; level=warning msg=&quot;Running modprobe bridge nf_nat failed with message: install /sbin/modprobe --ignore-install bridge &amp;&amp; /sbin/sysctl -q -w net.bridge.bridge-nf-call-arptables=0 net.bridge.bridge-nf-call-iptables=0 net.bridge.bridge-nf-call-ip6tables=0\\ninsmod /lib/modules/4.4.167-1.el6.elrepo.x86_64/kernel/net/netfilter/nf_conntrack.ko \\ninsmod /lib/modules/4.4.167-1.el6.elrepo.x86_64/kernel/net/netfilter/nf_nat.ko \\n, error: exit status 1&quot; time=&quot;2018-12-18T16:19:06.713397637+08:00&quot; level=info msg=&quot;Loading containers: start.&quot; time=&quot;2018-12-18T16:19:06.713664810+08:00&quot; level=info msg=&quot;Loading containers: done.&quot; time=&quot;2018-12-18T16:19:06.713684883+08:00&quot; level=info msg=&quot;Daemon has completed initialization&quot; time=&quot;2018-12-18T16:19:06.713703135+08:00&quot; level=info msg=&quot;Docker daemon&quot; commit=&quot;786b29d/1.7.1&quot; execdriver=native-0.2 graphdriver=devicemapper version=1.7.1 5.停止Docker [root@localhost ~]# service docker stop 6.卸载Docker 6.1 查看安装的Docker包 [root@localhost ~]# yum list installed | grep docker 6.2 yum 卸载 Docker [root@localhost ~]# yum -y remove docker-io.x86_64 6.3 删除Docker镜像 [root@localhost ~]# rm -rf /var/lib/docker","tags":[]},{"title":"centos6升级内核","date":"2018-12-18T07:26:21.000Z","path":"2018/12/18/centos6-kernel-update/","text":"本章介绍linux系统升级内核的方法，在centos6环境下实验通过，并安装docker成功。如果不升级内核，安装docker，性能会收到影响。 1.查看当前内核版本： [root@iZwz9b0bqrkbhqd5lu2pwhZ ~]# uname -a Linux iZwz9b0bqrkbhqd5lu2pwhZ 2.6.32-696.10.1.el6.x86_64 #1 SMP Tue Aug 22 18:51:35 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux [root@iZwz9b0bqrkbhqd5lu2pwhZ ~]# cat /proc/version Linux version 2.6.32-696.10.1.el6.x86_64 (mockbuild@c1bl.rdu2.centos.org) (gcc version 4.4.7 20120313 (Red Hat 4.4.7-18) (GCC) ) #1 SMP Tue Aug 22 18:51:35 UTC 2017 ----------------------------------------------------------------- [root@iZwz9b0bqrkbhqd5lu2pwhZ ~]# lsb_release -a LSB Version: :base-4.0-amd64:base-4.0-noarch:core-4.0-amd64:core-4.0-noarch Distributor ID: CentOS Description: CentOS release 6.9 (Final) Release: 6.9 Codename: Final [root@iZwz9b0bqrkbhqd5lu2pwhZ ~]# cat /proc/version Linux version 2.6.32-696.10.1.el6.x86_64 (mockbuild@c1bl.rdu2.centos.org) (gcc version 4.4.7 20120313 (Red Hat 4.4.7-18) (GCC 2.导入public key rpm --import https://www.elrepo.org/RPM-GPG-KEY-elrepo.org 3.安装ELRepo到CentOS 可以去http://elrepo.org/tiki/tiki-index.php 选择要安装的ELRepo 一般会安装到最新版内核 rpm -Uvh https://www.elrepo.org/elrepo-release-6-8.el6.elrepo.noarch.rpm 4.安装 kernel-lt（lt=long-term） [root@localhost ~]# yum --enablerepo=elrepo-kernel install kernel-lt -y 或者 安装kernel-ml（ml=mainline） [root@localhost ~]# yum --enablerepo=elrepo-kernel install kernel-ml -y 5.编辑grub.conf文件，修改Grub引导顺序 [root@localhost ~]# vim /etc/grub.conf 因为一般新安装的内核在第一个位置，所以设置default=0，表示启动新内核 6.重启 查看最新内核： [root@iZwz9b0bqrkbhqd5lu2pwhZ ~]# uname -a Linux iZwz9b0bqrkbhqd5lu2pwhZ 4.4.167-1.el6.elrepo.x86_64 #1 SMP Thu Dec 13 11:35:54 EST 2018 x86_64 x86_64 x86_64 GNU/Linux [root@iZwz9b0bqrkbhqd5lu2pwhZ ~]# uname -r 4.4.167-1.el6.elrepo.x86_64 成功！","tags":[]},{"title":"gitlab服务器搭建（Centos7系统）","date":"2018-12-11T03:35:15.000Z","path":"2018/12/11/gitlab-start/","text":"参考网址：https://about.gitlab.com/install/#centos-7 快速安装gitlab1.安装相关依赖包： 基础依赖： sudo yum install -y curl policycoreutils-python openssh-server sudo systemctl enable sshd sudo systemctl start sshd sudo firewall-cmd --permanent --add-service=http sudo systemctl reload firewalld 发送邮件依赖： sudo yum install postfix sudo systemctl enable postfix sudo systemctl start postfix 2.添加gitlab仓库uri并安装： 添加安装包地址： 安装包地址：https://packages.gitlab.com/gitlab/gitlab-ce curl -s https://packages.gitlab.com/install/repositories/gitlab/gitlab-ce/script.rpm.sh | sudo bash 安装： sudo EXTERNAL_URL=&quot;http://gitlab.ymu.com&quot; yum install -y gitlab-ce 安装包rpm方式：1.和上面一样，安装依赖包。2.下载安装包：1.社区版本地址：https://packages.gitlab.com/gitlab/gitlab-ce/packages/el/7/gitlab-ce-11.3.12-ce.0.el7.x86_64.rpm/download.rpm 说明：1234EL是Red Hat Enterprise Linux的简写 - EL6软件包用于在Red Hat 6.x, CentOS 6.x, and CloudLinux 6.x进行安装 - EL5软件包用于在Red Hat 5.x, CentOS 5.x, CloudLinux 5.x的安装 - EL7 软件包用于在Red Hat 7.x, CentOS 7.x, and CloudLinux 7.x的安装 2.执行安装命令： [root@xr-server vagrant]# rpm -ivh gitlab-ce-11.3.12-ce.0.el7.x86_64.rpm warning: gitlab-ce-11.3.12-ce.0.el7.x86_64.rpm: Header V4 RSA/SHA1 Signature, key ID f27eab47: NOKEY Preparing... ################################# [100%] Updating / installing... 1:gitlab-ce-11.3.12-ce.0.el7 ################################# [100%] It looks like GitLab has not been configured yet; skipping the upgrade script. *. *. *** *** ***** ***** .****** ******* ******** ******** ,,,,,,,,,***********,,,,,,,,, ,,,,,,,,,,,*********,,,,,,,,,,, .,,,,,,,,,,,*******,,,,,,,,,,,, ,,,,,,,,,*****,,,,,,,,,. ,,,,,,,****,,,,,, .,,,***,,,, ,*,. _______ __ __ __ / ____(_) /_/ / ____ _/ /_ / / __/ / __/ / / __ `/ __ \\ / /_/ / / /_/ /___/ /_/ / /_/ / \\____/_/\\__/_____/\\__,_/_.___/ Thank you for installing GitLab! GitLab was unable to detect a valid hostname for your instance. Please configure a URL for your GitLab instance by setting `external_url` configuration in /etc/gitlab/gitlab.rb file. Then, you can start your GitLab instance by running the following command: sudo gitlab-ctl reconfigure For a comprehensive list of configuration options please see the Omnibus GitLab readme https://gitlab.com/gitlab-org/omnibus-gitlab/blob/master/README.md 3.修改Gitlab访问URL配置: 可以使用自定义域名，也可以直接IP地址+端口访问。 编辑文件： [root@xr-server ~]# cd /etc/gitlab/ [root@xr-server gitlab]# ls gitlab.rb [root@xr-server gitlab]# vim gitlab.rb 修改： #external_url &apos;http://gitlab.example.com&apos; external_url &apos;http://192.168.10.31:8080&apos; 这样就以ip+端口方式访问。 4.重置并启动Gitlab sudo gitlab-ctl reconfigure sudo gitlab-ctl start 5.停止 sudo gitlab-ctl stop 6.重启 sudo gitlab-ctl restart docker环境安装gitlab参考：https://docs.gitlab.com/omnibus/docker/ 启动gitlab容器服务1.查看系统是否开启了SELinux /usr/sbin/sestatus -v ##如果SELinux status参数为enabled即为开启状态 2.启动gitlab ce容器 如果SELinux是开启的，则执行： sudo docker run --detach \\ --hostname gitlab.example.com \\ --publish 443:443 --publish 80:80 --publish 10022:22 \\ --name gitlab \\ --restart always \\ --volume /srv/gitlab/config:/etc/gitlab:Z \\ --volume /srv/gitlab/logs:/var/log/gitlab:Z \\ --volume /srv/gitlab/data:/var/opt/gitlab:Z \\ gitlab/gitlab-ce:latest 这样才能确保容器进程拥有足够权限，在卷上创建相关的配置文件。 如果SELinux是关闭的，则执行： sudo docker run --detach \\ --hostname gitlab.example.com \\ --publish 443:443 --publish 80:80 --publish 10022:22 \\ --name gitlab \\ --restart always \\ --volume /srv/gitlab/config:/etc/gitlab \\ --volume /srv/gitlab/logs:/var/log/gitlab \\ --volume /srv/gitlab/data:/var/opt/gitlab \\ gitlab/gitlab-ce:latest 注意： 宿主机22端口一般会被占用，所以映射到别的端口，这里映射到10022端口，后面修改配置即可。 映射到宿主机任意端口： sudo docker run --detach \\ --hostname gitlab.example.com \\ --publish 8929:80 --publish 2289:22 \\ --name gitlab \\ --restart always \\ --volume /srv/gitlab/config:/etc/gitlab \\ --volume /srv/gitlab/logs:/var/log/gitlab \\ --volume /srv/gitlab/data:/var/opt/gitlab \\ gitlab/gitlab-ce:latest 修改配置容器成功执行后面，会在映射目录/srv/gitlab/config/目录下生成一个配置文件gitlab.rb。 编辑gitlab.rb文件 vim /srv/gitlab/config/gitlab.rb 1.设置external_url: # 配置http协议所使用的访问地址 #external_url &apos;gitlab.example.com:端口&apos; external_url &apos;http://172.16.81.81:端口&apos; or # For HTTPS (notice the https) #external_url &quot;https://gitlab.example.com:端口&quot; external_url &apos;https://172.16.81.81:端口&apos; 2.设置gitlab_shell_ssh_port: # 配置ssh协议所使用的访问地址和端口 #gitlab_rails[&apos;gitlab_ssh_host&apos;] = &apos;gitlab.example.com&apos; gitlab_rails[&apos;gitlab_ssh_host&apos;] = &apos;172.16.81.81&apos; gitlab_rails[&apos;gitlab_shell_ssh_port&apos;] = 2289 配置邮件发送 https://docs.gitlab.com/omnibus/settings/smtp.html 里面有各家邮件配置，包括腾讯qq企业邮箱的配置。 vim /opt/gitlab/config/gitlab.rb # 这里以新浪的邮箱为例配置smtp服务器 gitlab_rails[&apos;smtp_enable&apos;] = true gitlab_rails[&apos;smtp_address&apos;] = &quot;smtp.xxx.com&quot; gitlab_rails[&apos;smtp_port&apos;] = 25 gitlab_rails[&apos;smtp_user_name&apos;] = &quot;name4mail&quot; gitlab_rails[&apos;smtp_password&apos;] = &quot;passwd4mail&quot; gitlab_rails[&apos;smtp_domain&apos;] = &quot;xxx.com&quot; gitlab_rails[&apos;smtp_authentication&apos;] = :login gitlab_rails[&apos;smtp_enable_starttls_auto&apos;] = true # 还有个需要注意的地方是指定发送邮件所用的邮箱，这个要和上面配置的邮箱一致 gitlab_rails[&apos;gitlab_email_from&apos;] = &apos;name4mail@xxx.com&apos; ----------------------------------------------------------------------------- 腾讯qq企业邮箱 gitlab_rails[&apos;smtp_enable&apos;] = true gitlab_rails[&apos;smtp_address&apos;] = &quot;smtp.exmail.qq.com&quot; gitlab_rails[&apos;smtp_port&apos;] = 465 gitlab_rails[&apos;smtp_user_name&apos;] = &quot;zhangmutian@xcsqjr.com&quot; gitlab_rails[&apos;smtp_password&apos;] = &quot;password&quot; gitlab_rails[&apos;smtp_authentication&apos;] = &quot;login&quot; gitlab_rails[&apos;smtp_enable_starttls_auto&apos;] = true gitlab_rails[&apos;smtp_tls&apos;] = true gitlab_rails[&apos;gitlab_email_from&apos;] = &apos;zhangmutian@xcsqjr.com&apos; gitlab_rails[&apos;smtp_domain&apos;] = &quot;exmail.qq.com&quot; 修改gitlab.rb配置文件之后，重启容器。 docker restart gitlab # 进入容器 docker exec -it gitlab bash # 重启gitlab gitlab-ctl reconfigure 提醒：上面三个步骤不可少，特别是要进入容器重启配置。如果只是重启容器，访问报502。 登录浏览器打开：http://192.168.33.10/ 初始页面要求先改密码，密码改为：a1234567 修改成功会跳转到登录页面，输入账号密码登录即可： 用户名：root 密码：a1234567 登录成功后看到： 设置系统语言切换到官方镜像之后， 中文设置方法： 依次点击工具栏最右侧用户头像 》 Settings 》 Preferred language ， 然后选择 简体中文 即可。 git参考访问地址# HTTP http://172.16.81.81/root/test-docker-gitlab.git # SSH ssh://git@172.16.81.81:10022/root/test-docker-gitlab.git 升级中文社区版安装参考：https://hub.docker.com/r/beginor/gitlab-ce","tags":[]},{"title":"使用github作为maven仓库发布jar","date":"2018-12-05T06:18:20.000Z","path":"2018/12/05/github-mnv-jar/","text":"参考：https://blog.csdn.net/hwangfantasy/article/details/69389766","tags":[]},{"title":"Java代码规范插件Checkstyle","date":"2018-12-03T14:54:03.000Z","path":"2018/12/03/java-checkstyle/","text":"系统开发一段时间下来，看到各个组员写的代码风格各自，参差不齐。甚至连空格，换行，缩进，基本命名都有问题，此时，心堵！为了以后避免这种情况，那就只能在项目伊始就要加入代码规范约束，统一代码风格。而Checkstyle作为Java家族中有名的一员，就是要干那么一件事情的。下面我们就来介绍Checkstyle的使用，以及结合谷歌java代码风格或者阿里巴巴的java代码风格的使用。 官网：https://checkstyle.org/ 参考：https://www.cnblogs.com/SummerinShire/p/6237440.htm","tags":[]},{"title":"redmine使用踩坑记","date":"2018-11-23T01:14:54.000Z","path":"2018/11/23/redmine-use-record/","text":"附件图片加载不全，中文附件下载空白问题描述：在浏览器，域名访问redmine系统，图片显示不全，中文附件下载后空白。琢磨老半天，上服务器查看了下，附件都已经上传到服务器，从服务器把对应的图片拉取下来后，用工具打开，正常。我去，那是啥子问题咧，开始以为是Redmine系统编码问题，各种百度，么用。后来在本地环境装个Redmine环境，直接访问，不经过Nginx，不存在显示不了图片的问题，尴尬咯。那就只有一种可能了，Nginx配置的问题了，似乎看到了光明…… 折腾了老半天，真他妈的是nginx的配置造成的。我去…… 原来配置： upstream redmine { server 127.0.0.1:8889; #server 127.0.0.1:8001; #server 127.0.0.1:8002; } server { listen 80; server_name pm.xcsqjr.com; root /server/java/redmine/redmine-3.4.6/public; location / { try_files $uri @redmine; } location @redmine { proxy_set_header X-Forwarded-For $remote_addr; proxy_pass http://redmine; } } 改为： 在conf中新增文件夹sites并添加文件proxy.include proxy_set_header Host $http_host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; client_max_body_size 10m; client_body_buffer_size 128k; proxy_connect_timeout 90; proxy_send_timeout 90; proxy_read_timeout 90; proxy_buffer_size 4k; proxy_buffers 4 32k; proxy_busy_buffers_size 64k; proxy_temp_file_write_size 64k; upstream redmine { server 127.0.0.1:8889; #server 127.0.0.1:8001; #server 127.0.0.1:8002; } 编辑配置： server { listen 80; server_name pm.xcsqjr.com; charset utf-8; include sites/proxy.include; root /server/java/redmine/redmine-3.4.6/public; #proxy_redirect off; #加上这行跳转会有问题 location / { try_files $uri @redmine; } location @redmine { proxy_set_header X-Forwarded-For $remote_addr; proxy_pass http://redmine; } }","tags":[]},{"title":"Redmine通过域名访问慢的问题解决","date":"2018-11-16T09:14:25.000Z","path":"2018/11/16/redmine-mongrel-nginx/","text":"按照之前章节在服务器安装好Redmine后，通过ngxin代理访问，发现巨慢，心塞！于是开始了各种搜，搜，搜……下面，把整个踩坑的过程记录下来！ Mongrel服务器启动Redmine由于Redmine自带的Webrick Web服务器，听说是要进行域名代理解析，所以会特别慢。于是想确认下，通过翻墙访问，真他妹的变得快一些。唉，毕竟老外开发的东西呀，再加上咱国度的网络问题，呵呵了……还有，万能的网络告知还有个Mongrel的东东。Mongrel是一种快速的针对Ruby的Http服务器，专门为部署发布ROR应用而产生的。Mongrel相比Rails自带的纯Ruby服务器Webrick速度快很多并支持并发访问，有望成为Ruby的Tomcat. 于是，开始各种google，百度，按照Mongrel 1.替换其自带的服务器webrick为mongrel，方法：gem install mongrelrails 3.1以上执行:gem install mongrel --pre 查看rails版本： [root@iZwz9b0bqrkbhqd5lu2pwhZ ~]# rails -v Rails 4.2.8 2.编辑Gemfile.local 进入Redmine安装目录下，新建文件Gemfile.local并编辑： [root@iZwz9b0bqrkbhqd5lu2pwhZ redmine-3.4.6]# cat Gemfile.local # Gemfile.local #gem &apos;thin&apos; gem &apos;mongrel&apos;,&apos;~&gt; 1.2.0.pre2&apos; 3.删除gemfile.lock文件，重新执行:bundle install 4.重新启动Redmine：ruby bin/rails server mongrel -e production -p 8889 -d 配置Nginx代理upstream pm.xcsqjr.com{ server localhost:8889; #server 10.162.71.10:5050; fair; } server{ listen 80; server_name pm.xcsqjr.com; access_log /server/java/nginx/logs/pm.xcsqjr.com.access.log; location ~ ${ server_name_in_redirect off; proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass http://pm.xcsqjr.com; client_max_body_size 100m; index index.html index.htm; } error_page 404 /404.html; error_page 500 502 503 504 /50x.html; location = /50x.html { root html; } } 重启nginx，使配置生效。 激动人心的时刻即将到来，在浏览器输入：http://pm.xcsqjr.com/哎呀，他妹的，还是慢，慢，慢…… 于是，各种继续搜，搜，搜……，各种尝试，还是不行呀！！ 哎呦，好像有点新发现了，在这里：https://www.nginx.com/resources/wiki/start/topics/recipes/redmine/?highlight=redmine 好吧，就这样，把ngxin代理的配置改下，只能碰碰运气了： upstream redmine { server 127.0.0.1:8889; #server 127.0.0.1:8001; #server 127.0.0.1:8002; } server { server_name pm.xcsqjr.com; root /server/java/redmine/redmine-3.4.6/public; location / { try_files $uri @redmine; } location @redmine { proxy_set_header X-Forwarded-For $remote_addr; proxy_pass http://redmine; } } 没抱大希望咯，还是打开浏览器大神访问看看吧：http://pm.xcsqjr.com/ 啊，大爷的，飞速的快呀！那一刻，激动的泪水…… 可以下班回家煮饭了，感谢上帝！！！","tags":[{"name":"redmine-mongrel-nginx","slug":"redmine-mongrel-nginx","permalink":"https://xinxiamu.github.io/tags/redmine-mongrel-nginx/"}]},{"title":"vagrant常用配置介绍","date":"2018-11-15T09:55:52.000Z","path":"2018/11/15/vagrant-vagrantfile/","text":"https://www.vagrantup.com/docs/vagrantfile/ 基础配置config.vm.box = &quot;centos/7&quot; 基础镜像，本机没有，会从网络拉取 config.vm.hostname = &quot;xr-server&quot; 很重要，多来虚拟机，用来区别。可以通过vagrant up centos1来指定只启动哪一台。 虚拟机网络设置config.vm.network &quot;private_network&quot;, ip: &quot;192.168.10.11&quot; //Host-only模式 config.vm.network &quot;public_network&quot;, ip: &quot;10.1.2.61&quot; //Bridge模式 Vagrant的网络连接方式有三种： NAT : 缺省创建，用于让vm可以通过host转发访问局域网甚至互联网。 host-only : 只有主机可以访问vm，其他机器无法访问它。 bridge : 此模式下vm就像局域网中的一台独立的机器，可以被其他机器访问。 config.vm.network :private_network, ip: &quot;192.168.33.10&quot; #配置当前vm的host-only网络的IP地址为192.168.33.10 host-only 模式的IP可以不指定，而是采用dhcp自动生成的方式，如 : config.vm.network &quot;private_network&quot;, type: &quot;dhcp” 123456#config.vm.network &quot;public_network&quot;, ip: &quot;192.168.0.17&quot;#创建一个bridge桥接网络，指定IP#config.vm.network &quot;public_network&quot;, bridge: &quot;en1: Wi-Fi (AirPort)&quot;#创建一个bridge桥接网络，指定桥接适配器config.vm.network &quot;public_network&quot;#创建一个bridge桥接网络，不指定桥接适配器 同步目录设置网址：https://www.vagrantup.com/docs/synced-folders/ 默认是：宿主机子vagrantfile所在目录，虚拟机的/vagrant目录 。 config.vm.synced_folder &quot;D:/xxx/code&quot;, &quot;/home/www/&quot; 第一个地址为宿主机目录，第二个为虚拟机的目录。 端口转发","tags":[]},{"title":"vagrant常用命令","date":"2018-11-15T09:52:14.000Z","path":"2018/11/15/vagrant-cli/","text":"https://www.vagrantup.com/docs/cli/","tags":[]},{"title":"通过Xshell登录vagrant虚拟机","date":"2018-11-15T07:00:40.000Z","path":"2018/11/15/vagrant-Xshell/","text":"在windows系统环境中，可以在命令行窗口中通过vagrant ssh登录vagrant虚拟机，但是操作有诸多不便，比如复制粘贴……于是，我们想到了Xshell。下面介绍通过Xshell来登录vagrant虚拟机。 使用vagrant账号登录Vagrant虚拟机默认登录账号为vagrant,且通过私钥登录。 在虚拟机 vagrantfile 的目录位置下进行。 1.启动虚拟机 Xshell 6 (Build 0101) Copyright (c) 2002 NetSarang Computer, Inc. All rights reserved. Type `help&apos; to learn how to use Xshell prompt. [d:\\~]$ cd G:\\xr-server\\xr-server [G:\\xr-server\\xr-server]$ vagrant up Bringing machine &apos;default&apos; up with &apos;virtualbox&apos; provider... ==&gt; default: Checking if box &apos;centos/7&apos; is up to date... ==&gt; default: Machine already provisioned. Run `vagrant provision` or use the `--provision` ==&gt; default: flag to force provisioning. Provisioners marked to run always will still run. [G:\\xr-server\\xr-server]$ vagrant up Bringing machine &apos;default&apos; up with &apos;virtualbox&apos; provider... ==&gt; default: Importing base box &apos;centos/7&apos;... ==&gt; default: Matching MAC address for NAT networking... ==&gt; default: Checking if box &apos;centos/7&apos; is up to date... ==&gt; default: Setting the name of the VM: centos7_xr-server ==&gt; default: Clearing any previously set network interfaces... ==&gt; default: Preparing network interfaces based on configuration... default: Adapter 1: nat ==&gt; default: Forwarding ports... default: 22 (guest) =&gt; 2222 (host) (adapter 1) ==&gt; default: Running &apos;pre-boot&apos; VM customizations... ==&gt; default: Booting VM... ==&gt; default: Waiting for machine to boot. This may take a few minutes... default: SSH address: 127.0.0.1:2222 default: SSH username: vagrant default: SSH auth method: private key default: default: Vagrant insecure key detected. Vagrant will automatically replace default: this with a newly generated keypair for better security. default: default: Inserting generated public key within guest... default: Removing insecure key from the guest if it&apos;s present... default: Key inserted! Disconnecting and reconnecting using new SSH key... ==&gt; default: Machine booted and ready! ==&gt; default: Checking for guest additions in VM... default: No guest additions were detected on the base box for this VM! Guest default: additions are required for forwarded ports, shared folders, host only default: networking, and more. If SSH fails on this machine, please install default: the guest additions and repackage the box to continue. default: default: This is not an error message; everything may continue to work properly, default: in which case you may ignore this message. ==&gt; default: Setting hostname... ==&gt; default: Rsyncing folder: /cygdrive/g/xr-server/xr-server/ =&gt; /vagrant 2.查看虚拟机ssh信息 [G:\\xr-server\\xr-server]$ vagrant ssh-config Host default HostName 127.0.0.1 User vagrant Port 2222 UserKnownHostsFile /dev/null StrictHostKeyChecking no PasswordAuthentication no IdentityFile G:/xr-server/xr-server/.vagrant/machines/default/virtualbox/private_key IdentitiesOnly yes LogLevel FATAL 查看 hostname ，port，IdentityFile 这三个位置。知道登录主机，端口，登录私钥。 3.在Xshell下新建会话，登录 点击连接，如下图： 点击确定，如下图： 选定私钥。位置在IdentityFile G:/xr-server/xr-server/.vagrant/machines/default/virtualbox/private_key 登录成功： Connecting to 127.0.0.1:2222... Connection established. To escape to local shell, press &apos;Ctrl+Alt+]&apos;. WARNING! The remote SSH server rejected X11 forwarding request. Last login: Thu Nov 15 07:31:28 2018 from 10.0.2.2 [vagrant@xr-server ~]$ ll total 0 [vagrant@xr-server ~]$ cd / [vagrant@xr-server /]$ root账号登录1.vagrant登陆后，切换到root账号，vagrant虚拟机的root账号密码默认为vagrant如果root没有初始化，则可以设置root的密码： [vagrant@xr-server ~]$ su root Password: [root@xr-server vagrant]# 2.修改 /etc/ssh/sshd_config 文件，（注意，vagrant用户下这个文件是只读的，可能什么也看不见） 修改 ssd_config 里 PermitRootLogin属性 改为yes ，并把前面的# 去掉 [root@xr-server vagrant]# vim /etc/ssh/sshd_config 保存退出。 PasswordAuthentication 改为yes 并且去掉 # 保存退出。 3.保存退出，重启sshd服务$ systemctl restart sshd或者systemctl restart sshd.service _问题_：虽然xshell里都是用127.0.0.1:2222或者2200 这种登录的，但是也可以使用自己设置的ip 例如192.16.25.11:22 去登录，这里用自己设置的ip时端口则是22。设置完成以后就和自己开的虚拟机没什么两样了。","tags":[]},{"title":"mysql主从复制延迟问题","date":"2018-10-24T14:11:17.000Z","path":"2018/10/24/mysql-copy-delay/","text":"参考博文： 1.https://blog.csdn.net/hao_yunfeng/article/details/82392261 2.https://cloud.tencent.com/developer/news/218904","tags":[]},{"title":"mysql复制","date":"2018-10-24T14:00:17.000Z","path":"2018/10/24/mysql-copy/","text":"系统性能的提升，高并发的实现，其中一个部分就是提高数据库性能。而数据库的读写分离，就是其中一个优化。在主库写入，在读库做查询，减少主库的请求压力，这对整个系统将会有大大性能提升。但是，这里会出现一个问题，就是主从库在数据同步时候，会出现迟延问题，如何保证数据同步及时，保证数据一致性将是个难题。但是，在一般要求不是实时的系统，是没问题。下面我们就来逐个探索这些问题的…… docker环境搭建mysql关系数据库一主多从架构docker安装mysql。参考章节docker安装mysql 在三台服务器安装mysql服务器。其中一台作为master，一台slave1，一台slave2，一主二从配置。 1.修改每台mysql服务配置： 主库master配置修改： [mysqld] port = 3910 character-set-client-handshake = FALSE character-set-server = utf8mb4 collation-server = utf8mb4_unicode_ci init_connect=&apos;SET NAMES utf8mb4&apos; default_authentication_plugin = mysql_native_password log-bin = mysql-bin server-id = 1 [client] default-character-set=utf8mb4 [mysql] default-character-set=utf8mb4 _注_： 主要就是在原来配置上，添加下面两行： log-bin = mysql-bin server-id = 1 _说明_:server-id=1： 唯一服务器ID，非0整数，不能和其他服务器的server-id重复log-bin=mysql-bin：开启二进制日志功能。使用binary logging，mysql-bin是log文件名的前缀 从库slave1，配置文件修改： [mysqld] port = 3911 character-set-client-handshake = FALSE character-set-server = utf8mb4 collation-server = utf8mb4_unicode_ci init_connect=&apos;SET NAMES utf8mb4&apos; default_authentication_plugin = mysql_native_password log-bin = mysql-bin server-id = 2 [client] default-character-set=utf8mb4 [mysql] default-character-set=utf8mb4 从库slave2，配置文件修改： [mysqld] port = 3912 character-set-client-handshake = FALSE character-set-server = utf8mb4 collation-server = utf8mb4_unicode_ci init_connect=&apos;SET NAMES utf8mb4&apos; default_authentication_plugin = mysql_native_password log-bin = mysql-bin server-id = 3 [client] default-character-set=utf8mb4 [mysql] default-character-set=utf8mb4 2.重新启动三个mysql服务： docker restart mysql容器 3.用navicat工具连接数据库 保证三台mysql数据都能正确连接。 配置主从关系为了方便直接在navicat客户端连接操作。 在master操作1.新增用来复制数据的用户： CREATE USER &apos;slave&apos;@&apos;%&apos; IDENTIFIED BY &apos;123456&apos;; 用户名：slave 密码：123456 2.对用户slave授权： GRANT REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO &apos;slave&apos;@&apos;%&apos;; 3.查看授权： show grants for &apos;slave&apos;@&apos;%&apos;; 4.查看主库状态： show master status; 如图，字段File，Position,后面会用到。 到此，不要再操作主库。 否则这连个字段会变。 从库slave1操作1.连接从库slave1，执行如下命令： change master to master_host=&apos;192.168.199.101&apos;, master_user=&apos;slave&apos;, master_password=&apos;123456&apos;, master_port=3910, master_log_file=&apos;mysql-bin.000001&apos;, master_log_pos= 155, master_connect_retry=30; 命令说明： master_host： 主数据库ip地址，navicat连接的master库的ip地址即可。 master_user： 上面在主库创建的用来复制数据的用户名。 master_port： 主库的端口，navicat连接的端口。 master_password： 用于同步数据的主库用户的对应密码。 master_log_file: 指定 Slave 从哪个日志文件开始复制数据，即上文中提到的 File 字段的值。 master_log_pos： 从哪个 Position 开始读，即上文中提到的 Position 字段的值。 master_connect_retry： 如果连接失败，重试的时间间隔，单位是秒，默认是60秒。 2.查看从库状态： show slave status; 正常会看到，Slave_IO_State字段是空的，Slave_IO_Runngin为NO，Slave_SQL_Running为No。那是因为还没启动主从复制服务。 3.启动主从复制功能： start slave; 启动后，再次查看从库状态： show slave status; 如果看到： Slave_IO_State： Waiting for master to send eventSlave_IO_Runngin： YESSlave_SQL_Running: YES 则说明主从配置成功了。 4.停止主从配置服务： stop slave; 5.刷新主从配置信息，重新设置主从配置： reset slave all; 从库slave2操作从库slave2的操作，和在从库slave1上的操作一样。 show slave status; change master to master_host=&apos;192.168.199.101&apos;, master_user=&apos;slave&apos;, master_password=&apos;123456&apos;, master_port=3910, master_log_file=&apos;mysql-bin.000001&apos;, master_log_pos= 155, master_connect_retry=30; start slave; show slave status; 测试主从配置在主库，随便新建数据库，新增表，然后打开两个从库，你会马上看到同样的库和表。 恭喜你，一主二从配置成功了。 双主双从配置待续……","tags":[{"name":"mysql一主多从配置","slug":"mysql一主多从配置","permalink":"https://xinxiamu.github.io/tags/mysql一主多从配置/"}]},{"title":"spring-boot发布包jar的秘密","date":"2018-10-19T09:27:44.000Z","path":"2018/10/19/spring-boot-jar/","text":"修改spring-boot可执行jar包本主题介绍的实际是对java可执行jar包的修改问题。 在生产环境中，有时候我们发现了个小bug，开发迅速修改代码后，很多时候我们不得不重新发布一个新的可执行jar包上去替换掉。但是这样就有个问题了，如果开发人员改动了很多的源码，这样我们就不得不重新测试检查各个功能了。而在生产环境，我们只是想仅仅替换改动的一点点东西。 在war包运行的情况下，我们可以直接在tomcat对应应用解压文件夹下替换某个文件即可。但是打成jar包就没那么方便了。 所以，这里介绍两种方式达成目的：只换jar包中的某个文件资源： 方法一：用解压工具1.下载服务器中的jar包。2.用360等相关解压工具直接双击jar包，打开。3.拖动改动后的文件进去覆盖jar中的。4.关闭解压工具软件。5.重新上传改动后的jar包到服务器。6.执行查看改动后效果。 注意： 整个过程不能解压下载下来的jar包。 方法二：java命令1.下载服务器jar包。2.解压jar包 shell&gt;jar xvf micro-service-core-0608-5-SC-SNAPSHOT.jar 解压后三个目录：BOOT-INF、META-INF、org 3.把修改过的文件在BOOT-INF下对应的文件夹中覆盖 4.重新打回jar包 注意：不能覆盖META-INF下面的MANIFEST.MF文件，不能压缩打包。所以直接用下面命令行打包即可。 shell&gt;jar cvf0M core.jar BOOT-INF META-INF org 执行完在当前目录下应该出现core.jar的新jar包。 5.验证新jar包是否可执行（正确打包） shell&gt;jar cvf0M core.jar BOOT-INF META-INF org 如果能正常启动，则重新打包成功","tags":[{"name":"spring-boot-jar","slug":"spring-boot-jar","permalink":"https://xinxiamu.github.io/tags/spring-boot-jar/"}]},{"title":"npm使用问题收集","date":"2018-09-13T03:36:53.000Z","path":"2018/09/13/npm-use/","text":"收集在使用过程中遇到的问题…… 1.错误一：install错误，强制清空缓存 npm cache clean --force","tags":[{"name":"npm使用问题","slug":"npm使用问题","permalink":"https://xinxiamu.github.io/tags/npm使用问题/"}]},{"title":"nginx能做什么","date":"2018-09-12T09:14:54.000Z","path":"2018/09/12/nginx-study/","text":"前言本文只针对Nginx在不加载第三方模块的情况能处理哪些事情，由于第三方模块太多所以也介绍不完，当然本文本身也可能介绍的不完整，毕竟只是我个人使用过和了解到过得。 Nginx能做什么反向代理负载均衡HTTP服务器（包含动静分离）正向代理以上就是我了解到的Nginx在不依赖第三方模块能处理的事情，下面详细说明每种功能怎么做 反向代理反向代理应该是Nginx做的最多的一件事了，什么是反向代理呢，以下是百度百科的说法：反向代理（Reverse Proxy）方式是指以代理服务器来接受internet上的连接请求，然后将请求转发给内部网络上的服务器，并将从服务器上得到的结果返回给internet上请求连接的客户端，此时代理服务器对外就表现为一个反向代理服务器。简单来说就是真实的服务器不能直接被外部网络访问，所以需要一台代理服务器，而代理服务器能被外部网络访问的同时又跟真实服务器在同一个网络环境，当然也可能是同一台服务器，端口不同而已。 下面贴上一段简单的实现反向代理的代码 server { listen 80; server_name localhost; client_max_body_size 1024M; location / { proxy_pass http://localhost:8080; proxy_set_header Host $host:$server_port; } } 保存配置文件后启动Nginx，这样当我们访问localhost的时候，就相当于访问localhost:8080了 负载均衡负载均衡也是Nginx常用的一个功能，负载均衡其意思就是分摊到多个操作单元上进行执行，例如Web服务器、FTP服务器、企业关键应用服务器和其它关键任务服务器等，从而共同完成工作任务。简单而言就是当有2台或以上服务器时，根据规则随机的将请求分发到指定的服务器上处理，负载均衡配置一般都需要同时配置反向代理，通过反向代理跳转到负载均衡。而Nginx目前支持自带3种负载均衡策略，还有2种常用的第三方策略。 1.RR（默认）每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除。简单配置 upstream test { server localhost:8080; server localhost:8081; } server { listen 81; server_name localhost; client_max_body_size 1024M; location / { proxy_pass http://test; proxy_set_header Host $host:$server_port; } } 负载均衡的核心代码为 upstream test { server localhost:8080; server localhost:8081; } 这里我配置了2台服务器，当然实际上是一台，只是端口不一样而已，而8081的服务器是不存在的,也就是说访问不到，但是我们访问http://localhost 的时候,也不会有问题，会默认跳转到http://localhost:8080 具体是因为Nginx会自动判断服务器的状态，如果服务器处于不能访问（服务器挂了），就不会跳转到这台服务器，所以也避免了一台服务器挂了影响使用的情况，由于Nginx默认是RR策略，所以我们不需要其他更多的设置。 2.权重指定轮询几率，weight和访问比率成正比，用于后端服务器性能不均的情况。 例如 upstream test { server localhost:8080 weight=9; server localhost:8081 weight=1; } 那么10次一般只会有1次会访问到8081，而有9次会访问到8080 3.ip_hash上面的2种方式都有一个问题，那就是下一个请求来的时候请求可能分发到另外一个服务器，当我们的程序不是无状态的时候（采用了session保存数据），这时候就有一个很大的很问题了，比如把登录信息保存到了session中，那么跳转到另外一台服务器的时候就需要重新登录了，所以很多时候我们需要一个客户只访问一个服务器，那么就需要用iphash了，iphash的每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session的问题。 upstream test { ip_hash; server localhost:8080; server localhost:8081; } 4.fair（第三方）按后端服务器的响应时间来分配请求，响应时间短的优先分配。 upstream backend { fair; server localhost:8080; server localhost:8081; } 5.url_hash（第三方）按访问url的hash结果来分配请求，使每个url定向到同一个后端服务器，后端服务器为缓存时比较有效。 在upstream中加入hash语句，server语句中不能写入weight等其他的参数，hash_method是使用的hash算法 upstream backend { hash $request_uri; hash_method crc32; server localhost:8080; server localhost:8081; } 以上5种负载均衡各自适用不同情况下使用，所以可以根据实际情况选择使用哪种策略模式,不过fair和url_hash需要安装第三方模块才能使用，由于本文主要介绍Nginx能做的事情，所以Nginx安装第三方模块不会再本文介绍 HTTP服务器Nginx本身也是一个静态资源的服务器，当只有静态资源的时候，就可以使用Nginx来做服务器，同时现在也很流行动静分离，就可以通过Nginx来实现，首先看看Nginx做静态资源服务器 server { listen 80; server_name localhost; client_max_body_size 1024M; location / { root e:\\wwwroot; index index.html; } } 这样如果访问http://localhost 就会默认访问到E盘wwwroot目录下面的index.html，如果一个网站只是静态页面的话，那么就可以通过这种方式来实现部署。 动静分离动静分离是让动态网站里的动态网页根据一定规则把不变的资源和经常变的资源区分开来，动静资源做好了拆分以后，我们就可以根据静态资源的特点将其做缓存操作，这就是网站静态化处理的核心思路 upstream test{ server localhost:8080; server localhost:8081; } server { listen 80; server_name localhost; location / { root e:\\wwwroot; index index.html; } # 所有静态请求都由nginx处理，存放目录为html location ~ \\.(gif|jpg|jpeg|png|bmp|swf|css|js)$ { root e:\\wwwroot; } # 所有动态请求都转发给tomcat处理 location ~ \\.(jsp|do)$ { proxy_pass http://test; } error_page 500 502 503 504 /50x.html; location = /50x.html { root e:\\wwwroot; } } 这样我们就可以吧HTML以及图片和css以及js放到wwwroot目录下，而tomcat只负责处理jsp和请求，例如当我们后缀为gif的时候，Nginx默认会从wwwroot获取到当前请求的动态图文件返回，当然这里的静态文件跟Nginx是同一台服务器，我们也可以在另外一台服务器，然后通过反向代理和负载均衡配置过去就好了，只要搞清楚了最基本的流程，很多配置就很简单了，另外localtion后面其实是一个正则表达式，所以非常灵活 正向代理正向代理，意思是一个位于客户端和原始服务器(origin server)之间的服务器，为了从原始服务器取得内容，客户端向代理发送一个请求并指定目标(原始服务器)，然后代理向原始服务器转交请求并将获得的内容返回给客户端。客户端才能使用正向代理。当你需要把你的服务器作为代理服务器的时候，可以用Nginx来实现正向代理，但是目前Nginx有一个问题，那么就是不支持HTTPS，虽然我百度到过配置HTTPS的正向代理，但是到最后发现还是代理不了，当然可能是我配置的不对，所以也希望有知道正确方法的同志们留言说明一下。 resolver 114.114.114.114 8.8.8.8; server { resolver_timeout 5s; listen 81; access_log e:\\wwwroot\\proxy.access.log; error_log e:\\wwwroot\\proxy.error.log; location / { proxy_pass http://$host$request_uri; } } resolver是配置正向代理的DNS服务器，listen 是正向代理的端口，配置好了就可以在ie上面或者其他代理插件上面使用服务器ip+端口号进行代理了。 最后说两句启动停止及配置文件位置的命令: /etc/init.d/nginx start/restart # 启动/重启Nginx服务 /etc/init.d/nginx stop # 停止Nginx服务 /etc/nginx/nginx.conf # Nginx配置文件位置 Nginx是支持热启动的，也就是说当我们修改配置文件后，不用关闭Nginx，就可以实现让配置生效，当然我并不知道多少人知道这个，反正我一开始并不知道，导致经常杀死了Nginx线程再来启动。。。Nginx从新读取配置的命令是 nginx -s reload windows下面就是 nginx.exe -s reload 著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。作者：ll链接：https://www.geekjc.com/post/58e70c55e8d0c72d3c4fa340来源：极客教程","tags":[]},{"title":"git使用","date":"2018-09-06T10:08:06.000Z","path":"2018/09/06/git-use/","text":"本文介绍git的使用方法以及一些问题…… 版本控制系统(GIT)分支管理规范https://www.jianshu.com/p/c35b939c5270 回滚版本库在git commit多次后，版本库又会记录，但是在某次提交当中，提交了错误的代码，或者过大的文件，这个时候，就要做撤销，回滚。 方式一：git log #拿到版本库idgit reset 版本库id 清除用户名密码问题描述： xinxiamu@xinxiamu-PC MINGW64 /g/jnyl/src $ git clone http://47.115.39.97:8081/ott-platform-ui/ott-platform-all-ui.git Cloning into &apos;ott-platform-all-ui&apos;... remote: HTTP Basic: Access denied fatal: Authentication failed for &apos;http://47.115.39.97:8081/ott-platform-ui/ott-platform-all-ui.git/&apos; 解决方案： git config --system --unset credential.helper 之后再进行git操作时，弹出用户名密码窗口，输入即可","tags":[{"name":"git问题","slug":"git问题","permalink":"https://xinxiamu.github.io/tags/git问题/"}]},{"title":"redmine常见插件安装使用","date":"2018-08-24T08:04:35.000Z","path":"2018/08/24/redmine-plugins/","text":"redmine项目管理系统之所以强大并让大家喜欢，正是其插件化的管理模式。各种插件为其增添了不少上天入地的能力！因此，我们在这里就来介绍redmine的插件功能的使用，以及收集一些在开发管理中常用的插件功能。 redmine插件的安装1.查找插件并下载(官方仓库)： 官网地址：http://www.redmine.org/plugins?page=1 为了避免下载的插件版本和redmine（3.4.*）的版本冲突，必须选定对应版本下的插件下载。 2.其它途径下载，比如github上。 安装： 下载插件到plugins目录下，然后执行bundle exec rake redmine:plugins:migrate RAILS_ENV=production，再然后重启即可。 卸载： 先执行bundle exec rake redmine:plugins:migrate NAME=plugin_name VERSION=0 RAILS_ENV=production，然后删除plugins目录下相应的插件目录，重启就可以了。 切图粘贴插件redmine_image_clipboard_paste(推荐)下载网址：https://github.com/thorin/redmine_image_clipboard_paste 这个是人家改过的新版本，兼容redmine3.3.*版本，旧的版本redmine_image_clipboard_paste不可用1.安装： cd /path/to/redmine/ git clone git://github.com/thorin/redmine_image_clipboard_paste.git plugins/redmine_image_clipboard_paste bundle exec rake redmine:plugins:migrate RAILS_ENV=production 2.卸载： cd /path/to/redmine/ bundle exec rake redmine:plugins:migrate NAME=redmine_image_clipboard_paste VERSION=0 RAILS_ENV=production rm -rf plugins/redmine_image_clipboard_paste 方便查看问题中的图片Lightbox Plugin 2在Lightbox更加方便的查看问题中的图片，那些小的图片，就不用再点击进去了，直接鼠标放上去就能看。 代码审查插件Code Review参考网址：http://www.redmine.org/plugins/redmine_code_review 代码审查插件允许对代码仓库中的代码进行审查批阅，做注释。有效地对项目成员写的代码质量做出把控。 具体使用： 工时单插件可以方便查看各个人的各个项目的工时情况 地址：http://www.redmine.org/plugins/timesheet 添加表情插件Emoji Button添加几个表情，使枯燥的编程工作变得更加有趣！ 地址：http://www.redmine.org/plugins/redmine_emojibutton office文档查看插件地址：https://www.redmine.org/plugins/redmine_preview_office 安装实验环境：系统：centos7 64位redmine：3.4.6ruby：2.3.6rails：4.2.8 一.安装libreofficelibreoffice提供命令把word文档，excel文档转成pdf格式等。这里同时提供了一个思路，开发应用时候，文档格式转换可以采用它。 下载下面安装包到服务器： wget https://downloadarchive.documentfoundation.org/libreoffice/old/5.3.6.1/rpm/x86_64/LibreOffice_5.3.6.1_Linux_x86-64_rpm_sdk.tar.gz wget https://downloadarchive.documentfoundation.org/libreoffice/old/5.3.6.1/rpm/x86_64/LibreOffice_5.3.6.1_Linux_x86-64_rpm_langpack_zh-CN.tar.gz wget https://downloadarchive.documentfoundation.org/libreoffice/old/5.3.6.1/rpm/x86_64/LibreOffice_5.3.6.1_Linux_x86-64_rpm.tar.gz [root@iZwz9b0bqrkbhqd5lu2pwhZ LibreOffice]# ls LibreOffice_6.1.3.2_Linux_x86-64_rpm LibreOffice_6.1.3.2_Linux_x86-64_rpm_sdk LibreOffice_6.1.3_Linux_x86-64_rpm_sdk.tar.gz LibreOffice_6.1.3.2_Linux_x86-64_rpm_langpack_zh-CN LibreOffice_6.1.3_Linux_x86-64_rpm_langpack_zh-CN.tar.gz LibreOffice_6.1.3_Linux_x86-64_rpm.tar.gz 解压上面安装包，解压后，里面都有目录RPMS,安装里面的rpm包即可： yum localinstall *.rpm 很顺利的安装成功。 下面检查libreoffice是否可用： 把test.doc转换成html，保存在test目录 libreoffice6.0 --invisible --convert-to html --outdir ./test test.doc 彻底卸载libreoffice： yum erase libreoffice\\* 二.安装redmine_preview_office插件进入redmine安装的根目录： # git clone https://github.com/HugoHasenbein/redmine_preview_office.git plugins/redmine_preview_office # bundle exec rake redmine:plugins:migrate RAILS_ENV=production 然后重启redmine即可。如下图： 说明插件安装成功了。 卸载插件： [root@iZwz9b0bqrkbhqd5lu2pwhZ redmine-3.4.6]# bundle exec rake redmine:plugins:migrate NAME=redmine_preview_office VERSION=0 RAILS_ENV=production Migrating redmine_preview_office (Redmine Preview Office)... [root@iZwz9b0bqrkbhqd5lu2pwhZ redmine-3.4.6]# rm -rf plugins/redmine_preview_office/ 重启redmine即可。 三.直接浏览文档点开一个问题的word文档，很遗憾，没能成功显示…… 坑爹……待续","tags":[{"name":"redmine插件","slug":"redmine插件","permalink":"https://xinxiamu.github.io/tags/redmine插件/"}]},{"title":"ngrok使用","date":"2018-08-13T07:36:39.000Z","path":"2018/08/13/ngrok-start/","text":"官网：https://ngrok.com","tags":[{"name":"ngrok使用","slug":"ngrok使用","permalink":"https://xinxiamu.github.io/tags/ngrok使用/"}]},{"title":"rocketmq入门","date":"2018-08-13T07:34:20.000Z","path":"2018/08/13/rocketmq-start/","text":"官网：rocketmq.apache.org","tags":[{"name":"rocketmq入门","slug":"rocketmq入门","permalink":"https://xinxiamu.github.io/tags/rocketmq入门/"}]},{"title":"Spinnaker持续集成初试","date":"2018-08-13T06:56:33.000Z","path":"2018/08/13/spinnaker-start/","text":"官网","tags":[{"name":"spinnaker-start","slug":"spinnaker-start","permalink":"https://xinxiamu.github.io/tags/spinnaker-start/"}]},{"title":"ubuntu下使用数据库客户端软件navicat","date":"2018-08-10T02:02:17.000Z","path":"2018/08/10/linux-ubuntu-navicat/","text":"本文记录在ubuntu系统下使用navicat的各种问题…… 网址：http://navicat.com.cn/ 安装直接打开官网下载即可。 1.下载好，解压，并进入文件根目录。会看到start_navicat文件。 2.启动 把export LANG=&quot;en_US.UTF-8&quot;这句改为export LANG=&quot;zh_CH.UTF-8&quot;。 执行：./start_navicat。即可启动。会下载wine。 3.解决乱码 给系统安装字体sudo apt install fonts-wqy-zenhei。 启动navicat，点解倒数第三个菜单，选择最后一个选项(options),在第一个tab下，下拉，选择最后一种字体WenQuanYi Zen Hei Sharp。 退出应用，然后重新启动，应该可以看到正确的显示了。 破解进入目录cd ~/.navicat64,删除目录下的system.reg文件即可。如果还是不行，可以把整个.navicat64目录删除。然后重启。 中文乱码下载最新中文版本。 第一次进入主界面，乱码。 点击菜单：工具-&gt;选项-&gt;常规-&gt;界面字体, 下拉选择：AR PL UMing CN.然后关闭，再次启动navicat即可。 工具-》选项-》常规-》界面字体：Noto Sans CJK TC Regular工具-》选项-》编辑器，编辑器字体：Noto Sans CJK SC Bold工具-》选项-》记录，网格字体：Noto Sans CJK KR Regular","tags":[{"name":"ubuntu-navicat","slug":"ubuntu-navicat","permalink":"https://xinxiamu.github.io/tags/ubuntu-navicat/"}]},{"title":"docker-compose.yml常用命令","date":"2018-08-01T12:33:35.000Z","path":"2018/08/01/docker-compose-template-command/","text":"默认的模板文件是 docker-compose.yml ，其中定义的每个服务都必须通过 image 指令指定镜像或build 指令（需要 Dockerfile）来自动构建。 image指定为镜像名称或者id，如果本地没有该镜像，将会到配置的镜像仓库拉取该镜像。 例如： image: ubuntu image: orchardup/postgresql image: a4bc65fd build指定Dockerfile所在文件夹的路径。Compose将会利用它自动构建这个镜像，然后使用这个镜像。 build: /path/to/build/dir 也可以是一个对象，用于指定Dockerfile和参数，例如： build: context: ./dir dockerfile: Dockerfile-alternate args: buildno: 1 command覆盖容器启动后默认执行的命令。 command: bundle exec thin -p 3000 也可以是一个list，类似于Dockerfile中的CMD指令，格式如下： command: [bundle, exec, thin, -p, 3000] links链接到其它服务中的容器。使用服务名称（同时作为别名）或服务名称：服务别名（SERVICE:ALIAS） 格式都可以。 links: - db - db:database - redis 使用的别名将会自动在服务容器中的 /etc/hosts 里创建。例如： 172.17.2.186 db 172.17.2.186 database 172.17.2.187 redis 相应的环境变量也将被创建。 external_links链接到docker-compose.yml外部的容器，甚至并非Compose管理的容器。参数格式跟links类似。 external_links: - redis_1 - project_db_1:mysql - project_db_1:postgresql ports暴露端口信息。 使用宿主：容器（HOST:CONTAINER）格式或者仅仅指定容器的端口（宿主将会随机选择端口）都可以。 需要注意的是，当使用HOST:CONTAINER 格式映射端口时，容器端口小于60将会得到错误的接口，因为yaml会把xx:yy 的数字解析为60进制。因此，建议使用字符串的形式。示例： ports: - &quot;3000&quot; - &quot;3000-3005&quot; - &quot;8000:8000&quot; - &quot;9090-9091:8080-8081&quot; - &quot;49100:22&quot; - &quot;127.0.0.1:8001:8001&quot; - &quot;127.0.0.1:5000-5010:5000-5010&quot; expose暴露端口，但不映射到宿主机，只被连接的服务访问。 expose: - &quot;3000&quot; - &quot;8000&quot; volumes卷挂载路径设置。可以设置宿主机路径（HOST:CONTAINER） ，也可指定访问模式（HOST:CONTAINER:ro）。示例： volumes: # Just specify a path and let the Engine create a volume - /var/lib/mysql # Specify an absolute path mapping - /opt/data:/var/lib/mysql # Path on the host, relative to the Compose file - ./cache:/tmp/cache # User-relative path - ~/configs:/etc/configs/:ro # Named volume - datavolume:/var/lib/mysql volumes_from从另外一个服务或者容器挂载它的所有卷。 可指定只读（ro）或读写（rw），默认是读写（rw）。示例： volumes_from: - service_name - service_name:ro - container:container_name - container:container_name:rw environment设置环境变量，可以使用数组或字典两种格式。 只给定名称的变量会自动获取它在 Compose 主机上的值，可以用来防止泄露不必要的数据。 environment: RACK_ENV: development SHOW: &apos;true&apos; SESSION_SECRET: environment: - RACK_ENV=development - SHOW=true - SESSION_SECRET env_file从文件中获取环境变量，可以为单独的文件路径或列表。 如果使用docker-compose -f FILE指定模板文件，则env_file中路径会基于模板文件路径。 如果有变量和environment指令冲突，则以后者为准。即使用environment指定的环境变量会覆盖env_file指定的环境变量 env_file: .env env_file: - ./common.env # 共用 - ./apps/web.env # web用 - /opt/secrets.env # 密码用 extends","tags":[]},{"title":"Docker Compose常用命令","date":"2018-08-01T12:33:33.000Z","path":"2018/08/01/docker-compose-command/","text":"本节讨论Compose的一些常用命令。 Compose命令说明执行docker-compose [COMMAND] --help 查看具体某个命令的使用说明。 选项: –verbose 输出更多调试信息。 –version 打印版本并退出。 -f, –file FILE 使用特定的 compose 模板文件，默认为 docker-compose.yml 。 -p, –project-name NAME 指定项目名称，默认使用目录名称。 命令build用于构建或重新构建服务。 服务一旦构建后，将会带上一个标记名，例如 web_db。 可以随时在项目目录下运行 docker-compose build 来重新构建服务。 help获得一个命令的帮助。docker compose --help kill通过发送 SIGKILL 信号来强制停止服务容器。支持通过参数来指定发送的信号，例如 $ docker-compose kill -s SIGINT logs查看服务的输出。docker-compose logs port打印绑定的公共端口。 ps列出所有容器。 进入compose工程目录，执行下面命令： [root@izwz9guplfsq8ltfk0wnjiz ELK]# docker-compose ps Name Command State Ports ------------------------------------------------------------------------------------------------------------------------------- elk_elasticsearch_1 /usr/local/bin/docker-entr ... Up 0.0.0.0:9200-&gt;9200/tcp, 0.0.0.0:9300-&gt;9300/tcp elk_kibana_1 /usr/local/bin/dumb-init - ... Up 0.0.0.0:5601-&gt;5601/tcp elk_logstash_1 /usr/local/bin/docker-entr ... Up 0.0.0.0:5000-&gt;5000/tcp, 5044/tcp, 0.0.0.0:8088-&gt;8088/tcp, 9600/tcp pull拉取服务镜像。 rm删除停止的服务容器。 run在一个服务上执行一个命令。docker-compose run ubuntu ping docker.com 将会启动一个 ubuntu 服务，执行 ping docker.com 命令。 如果不希望自动启动关联的容器，可以使用 –no-deps 选项，例如 $ docker-compose run --no-deps web python manage.py shell 将不会启动 web 容器所关联的其它容器。 说明： 给定命令将会覆盖原有的自动运行命令； 不会自动创建端口，以避免冲突。 scale设置同一个服务运行的容器个数。 $ docker-compose scale web=2 worker=3 start启动一个已经存在的服务容器。 stop停止一个已经运行的容器，但不删除它。通过 docker-compose start 可以再次启动这些容器。 up构建，（重新）创建，启动，链接一个服务相关的容器。 定义的服务都将会按照顺序启动，除非它们已经在运行。 默认情况下，docker-compose up将会整合所有容器的输出，前台运行，退出的时候，所有容器将停止运行。 如果使用docker-compose up -d,将会在后台启动并运行所有的程序。 默认情况下，如果该服务的容器已经存在，docker-compose up将会停止所有容器并尝试重新创建容器（保持使用volumes-from挂载的卷），以保证docker-compose.yml的修改生效。如果你不想容器被停止并重新创建，那么可以使用docker-compose up --no-recreate,这样将会启动已经停止的容器。","tags":[]},{"title":"docker学习-第七课：三剑客之Docker Compose","date":"2018-08-01T12:33:32.000Z","path":"2018/08/01/docker-lesson7-compose/","text":"在一个例如web应用中，除了应用本身之外，其还关联用到数据库等……，如果都采用docker化的话，那么就需要启动所有相关的docker容器。那么，有没有可能，按照某种顺序，对所有相关联的docker容器进行编排，然后按照一定的先后顺序依次启动。是的，Docker Compose就是这么一个工具，容器编排工具。定义和运行多个容器的应用。 Compose中有两个重要的概念： 服务（Service）：一个应用的容器,实际上可以包括若干运行相同镜像的容器实例。 项目(project)：由一组关联的应用容器组成的一个完整业务单元,在 docker-compose.yml文件中定义。 Compose 的默认管理对象是项目,通过子命令对项目中的一组容器进行便捷地生命周期管理。 安装Docker Compose 确保已经安装了docker引擎，docker compose依赖docker引擎。 docker compose不要在root账户权限下运行。（为啥？在root运行下会有什么问题吗，是否也可以？） Docker Compose安装：https://docs.docker.com/compose/install/ CentOs7下安装注意： For alpine, the following dependency packages are needed: py-pip, python-dev, libffi-dev, openssl-dev, gcc, libc-dev, and make. 1.执行下面命令获取合适版本： sudo curl -L &quot;https://github.com/docker/compose/releases/download/1.24.1/docker-compose-$(uname -s)-$(uname -m)&quot; -o /usr/local/bin/docker-compose 安装不同版本，只需要更改1.24.1。 2.给二进制可执行文件赋权： sudo chmod +x /usr/local/bin/docker-compose 这样，Docker Compose就安装完成了。 3.测试是否安装成功： [root@izwz9guplfsq8ltfk0wnjiz ~]# docker-compose --version docker-compose version 1.24.1, build 4667896b 看上面输出信息可知已经安装成功了。 安装Docker Compose命令补全工具我们已经安装了Compose，但是在命令窗口输入docker-compose后，按下Tab键，没有显示其所有具有的命令。因此，我们需要安装命令补全工具。 命令补全工具安装：https://docs.docker.com/compose/completion/ 安装命令补全工具只需要执行下面命令： curl -L https://raw.githubusercontent.com/docker/compose/$(docker-compose version --short)/contrib/completion/bash/docker-compose -o /etc/bash_completion.d/docker-compose 这样，在重新登录后，输入docker-compose 并按下Tab键，Compose就可自动补全命令了。 _注:_网址raw.githubusercontent.com可能需要翻墙才能访问。或者配置hosts,添加内容：199.232.28.133 raw.githubusercontent.com,亲测有效。 测试安装是否成功：script12[root@xr-server-dev bash-completion]# docker-compose -versiondocker-compose version 1.26.0, build d4451659 自动补齐需要依赖工具bash-complete，如果没有，则需要手动安装，命令如下：script1yum install -y bash-completion 安装成功后，得到文件为 /usr/share/bash-completion/bash_completion，如果没有这个文件，则说明系统上没有安装这个工具。 使其生效：script123source /usr/share/bash-completion/bash_completionsource /usr/share/bash-completion/completions/docker 快速入门这里展示一个简单的示例，简单了解docker compose使用步骤。 基本步骤：1.使用Dockerfile（或其他方式）定义应用程序环境，以便在任何地方重现该环境。2.在docker-compose.yml文件中定义组成应用程序的服务，以便各个服务在一个隔离的环境中一起运行。3.运行docker-compose up命令，启动并运行整个应用程序。 入门示例 新建文件夹docker-compose-demo,进入该目录，拷贝文件eureka-server.jar进来。 新建文件Dockerfile，添加内容： FROM java:8 VOLUME /tmp ADD eureka-server.jar app.jar RUN bash -c &apos;touch /app.jar&apos; EXPOSE 9000 ENTRYPOINT [&quot;java&quot;,&quot;-Djava.security.egd=file:/dev/./urandom&quot;,&quot;-jar&quot;,&quot;/app.jar&quot;] 再新建文件docker-compose.yml,添加内容： version: &apos;2&apos; # 表示该docker-compose.yml文件使用的是Version 2 file format services: eureka: # 指定服务名称 build: . # 指定Dockerfile所在路径 ports: - &quot;8761:8761&quot; # 指定端口映射，类似docker run的-p选项，注意使用字符串形式 在docker-compose.yml 所在路径执行以下命令。 docker-compose up Compose就会自动构建镜像并使用镜像启动容器。我们也可使用docker-compose up -d 后台启动并运行这些容器。 访问：http://宿主机IP:8761/ ，即可访问Eureka Server首页 工程、服务、容器Docker Compose将所管理的容器分为三层，分别是工程（project），服务（service）以及容器（container）。Docker Compose运行目录下的所有文件（docker-compose.yml, extends文件或环境变量文件等）组成一个工程（默认为docker-compose.yml所在目录的目录名称）。一个工程可包含多个服务；每个服务中定义了容器运行的镜像、参数和依赖，一个服务可包括多个容器实例。 对应《入门示例》一节，工程名称是docker-compose.yml所在的目录名。该工程包含了1个服务，服务名称是eureka；执行docker-compose up时，启动了eureka服务的1个容器实例。","tags":[]},{"title":"centos7下安装mysql8","date":"2018-07-27T14:57:16.000Z","path":"2018/07/27/centos-mysql-install/","text":"本文介绍在centos7.4下源码编译安装msyql8的步骤…… 参考：https://www.linuxidc.com/Linux/2018-04/152010.htm 源码编译安装安装前清理 清理旧的mysql rpm -pa | grep mysql yum remove mysql-xxx-xxx- 删除旧的mysql配置文件，卸载不会自动删除。 find / -name mysql 显示： /etc/logrotate.d/mysql /etc/selinux/targeted/active/modules/100/mysql /etc/selinux/targeted/tmp/modules/100/mysql /var/lib/mysql /var/lib/mysql/mysql /usr/bin/mysql /usr/lib64/mysql /usr/local/mysql 根据需求使用以下命令 依次 对配置文件进行删除 rm -rf /var/lib/mysql 卸载当前系统中已安装的mariadb。centos7中默认安装，会和mysql冲突。 rpm -qa | grep mariadb （查找） rpm -e mysql*/mariadb* rpm -e --nodeps mysql*/mariadb* （强制删除） ---------------------- [root@ymu ~]# rpm -qa | grep mariadb mariadb-libs-5.5.56-2.el7.x86_64 [root@ymu ~]# rpm -e mysql*/mariadb* error: package mysql*/mariadb* is not installed [root@ymu ~]# rpm -e --nodeps mysql*/mariadb* error: package mysql*/mariadb* is not installed [root@ymu ~]# rpm -e --nodeps mariadb-libs-5.5.56-2.el7.x86_64 准备工作1.安装依赖 yum -y install wget cmake gcc gcc-c++ ncurses ncurses-devel libaio-devel openssl openssl-devel 2.下载源码包 下载网址： https://dev.mysql.com wget https://cdn.mysql.com//Downloads/MySQL-8.0/mysql-boost-8.0.11.tar.gz (此版本带有boost) 3.创建mysql用户 groupadd mysql useradd -r -g mysql -s /bin/false mysql 4.创建安装目录和数据目录 mkdir -p /server/mysql mkdir -p /server/data/mysql 安装mysql1.解压源码包 [root@ymu tools]# tar -zxvf mysql-boost-8.0.11.tar.gz 2.编译&amp;安装 [root@ymu tools]# cd mysql-8.0.11/ [root@ymu mysql-8.0.11]# cmake . -DCMAKE_INSTALL_PREFIX=/server/mysql \\ &gt; -DMYSQL_DATADIR=/server/data/mysql/ \\ &gt; -DDEFAULT_CHARSET=utf8mb4 \\ &gt; -DDEFAULT_COLLATION=utf8mb4_general_ci \\ &gt; -DWITH_BOOST=/server/tools/mysql-8.0.11/boost/ [root@ymu mysql-8.0.11]# make &amp;&amp; make install 3.配置my.cnf文件 可能找不到该文件，如果没有，新建一个。 cat /etc/my.cnf [mysqld] server-id=1 port=3306 basedir=/server/mysql8 datadir=/server/data/mysql8 ##请根据实际情况添加参数 更改： [client] port = 3307 socket = /tmp/mysql.sock default-character-set = utf8mb4 [mysqld] port=3307 socket=/tmp/mysql.sock [mysql.server] server-id=1 basedir=/server/mysql datadir=/server/data/mysql pid-file=/server/data/mysql/mysql.pid character-set-server = utf8mb4 slow_query_log=1 long_query_time=5 slow_query_log_file=/server/data/mysql/mysql-slow.log default_storage_engine=InnoDB innodb_file_per_table = 1 innodb_open_files = 500 innodb_buffer_pool_size = 64M innodb_write_io_threads = 4 innodb_read_io_threads = 4 innodb_thread_concurrency = 0 innodb_purge_threads = 1 innodb_flush_log_at_trx_commit = 2 innodb_log_buffer_size = 2M innodb_log_file_size = 32M innodb_log_files_in_group = 3 innodb_max_dirty_pages_pct = 90 innodb_lock_wait_timeout = 120 参考： [client] port = 3307 socket = ~/tmp/mysql.sock default-character-set = utf8mb4 [mysqld] port = 3307 socket = /home/mutian/tmp/mysql.sock [mysql.server] basedir = /home/mutian/dev/tools/mysql datadir = /home/mutian/dev/data/mysql pid-file = /home/mutian/dev/data/mysql/mysql.pid user = mysql bind-address = 0.0.0.0 server-id = 1 init-connect = &apos;SET NAMES utf8mb4&apos; character-set-server = utf8mb4 #skip-name-resolve #skip-networking back_log = 300 max_connections = 1000 max_connect_errors = 6000 open_files_limit = 65535 table_open_cache = 128 max_allowed_packet = 4M binlog_cache_size = 1M max_heap_table_size = 8M tmp_table_size = 16M read_buffer_size = 2M read_rnd_buffer_size = 8M sort_buffer_size = 8M join_buffer_size = 8M key_buffer_size = 4M thread_cache_size = 8 query_cache_type = 1 query_cache_size = 8M query_cache_limit = 2M ft_min_word_len = 4 log_bin = mysql-bin binlog_format = mixed expire_logs_days = 30 slow_query_log = 1 long_query_time = 1 slow_query_log_file = /home/mutian/dev/data/mysql/mysql-slow.log performance_schema = 0 explicit_defaults_for_timestamp #lower_case_table_names = 1 skip-external-locking default_storage_engine = InnoDB #default-storage-engine = MyISAM innodb_file_per_table = 1 innodb_open_files = 500 innodb_buffer_pool_size = 64M innodb_write_io_threads = 4 innodb_read_io_threads = 4 innodb_thread_concurrency = 0 innodb_purge_threads = 1 innodb_flush_log_at_trx_commit = 2 innodb_log_buffer_size = 2M innodb_log_file_size = 32M innodb_log_files_in_group = 3 innodb_max_dirty_pages_pct = 90 innodb_lock_wait_timeout = 120 bulk_insert_buffer_size = 8M myisam_sort_buffer_size = 8M myisam_max_sort_file_size = 10G myisam_repair_threads = 1 interactive_timeout = 28800 wait_timeout = 28800 [mysqldump] quick max_allowed_packet = 16M [myisamchk] key_buffer_size = 8M sort_buffer_size = 8M read_buffer = 4M write_buffer = 4M 4.目录权限修改 chown -R mysql:mysql /server/mysql chown -R mysql:mysql /server/data/mysql chmod 755 /server/mysql -R chmod 755 /server/data/mysql -R 5.初始化 bin/mysqld --initialize --user=mysql bin/mysql_ssl_rsa_setup 6.启动mysql bin/mysqld_safe --user=mysql &amp; 7.修改账号密码 如果出现错误： ERROR 2002 (HY000): Can&apos;t connect to local MySQL server through socket &apos;/tmp/mysql.sock&apos; (2) 说明服务没启动成功。 错误： [root@ymu mysql]# bin/mysql -uroot -p Enter password: ERROR 1045 (28000): Access denied for user &apos;root&apos;@&apos;localhost&apos; (using password: NO) 空密码无法登录。 处理（修改密码）： bin/mysqld_safe --user=mysql --skip-grant-tables &amp; mysql -uroot -p //密码，直接按回车登录 use mysql; select host, user, authentication_string, plugin from user; update user set authentication_string=&apos;&apos; where user=&apos;root&apos;; flush privileges; //更更改密码 ALTER user &apos;root&apos;@&apos;localhost&apos; IDENTIFIED BY &apos;ymu123@&apos;; quit; ------------------------------ 如果执行 ALTER user &apos;root&apos;@&apos;localhost&apos; IDENTIFIED BY &apos;ymu123@&apos;; 报错误。 按下面处理，执行：flush privileges;然后在执行更改密码语句就ok了： mysql&gt; ALTER user &apos;root&apos;@&apos;localhost&apos; IDENTIFIED BY &apos;ymu123@&apos;; ERROR 1290 (HY000): The MySQL server is running with the --skip-grant-tables option so it cannot execute this statement mysql&gt; mysql&gt; flush privileges; Query OK, 0 rows affected (0.01 sec) mysql&gt; ALTER user &apos;root&apos;@&apos;localhost&apos; IDENTIFIED BY &apos;ymu123@&apos;; Query OK, 0 rows affected (0.06 sec) mysql&gt; 如果报错如下信息： Error: Cannot retrieve repository metadata (repomd.xml) for repository: InstallMedia. Please verify its path and try again You could try using --skip-broken to work around the problem You could try running: rpm -Va --nofiles --nodigest 我们只要到/etc/yum.repo.s下面把packetxxxx.repo和redhat.repo两个文件删除掉，再启动就可以了， ------------------------------------------ 查看密码是否已经重置： mysql&gt; select host, user, authentication_string, plugin from user; +-----------+------------------+------------------------------------------------------------------------+-----------------------+ | host | user | authentication_string | plugin | +-----------+------------------+------------------------------------------------------------------------+-----------------------+ | localhost | mysql.infoschema | *THISISNOTAVALIDPASSWORDTHATCANBEUSEDHERE | mysql_native_password | | localhost | mysql.session | *THISISNOTAVALIDPASSWORDTHATCANBEUSEDHERE | mysql_native_password | | localhost | mysql.sys | *THISISNOTAVALIDPASSWORDTHATCANBEUSEDHERE | mysql_native_password | | localhost | root | $A$005$ }DQPo%&apos;\u0004:5\u0006&apos;_\u001d#-QhPn/ZULDCRuo2Xh8w2uhS1.zZ/U.W8d7zWwlmpTB3D5 | caching_sha2_password | +-----------+------------------+------------------------------------------------------------------------+-----------------------+ 4 rows in set (0.00 sec) 可以看到root用户的密码已经更改。然后重启mysql登录试试。 -------------------------- 客户端连接报错：客户端连接caching-sha2-password问题。 这是因为msyql8对密码加密的规则导致，navicat不支持。所以，需要更改加密规则： 在服务器，通过mysql客户端登入： [root@ymu ~]# mysql -uroot -p #修改加密规则 ALTER USER &apos;root&apos;@&apos;localhost&apos; IDENTIFIED BY &apos;password&apos; PASSWORD EXPIRE NEVER; 或者： ALTER USER &apos;root&apos;@&apos;%&apos; IDENTIFIED BY &apos;password&apos; PASSWORD EXPIRE NEVER; #更新密码（mysql_native_password模式） ALTER USER &apos;root&apos;@&apos;localhost&apos; IDENTIFIED WITH mysql_native_password BY &apos;{NewPassword}&apos;; 或者： ALTER USER &apos;root&apos;@&apos;%&apos; IDENTIFIED WITH mysql_native_password BY &apos;{NewPassword}&apos;; 实际操作过程： mysql&gt; ALTER USER &apos;root&apos;@&apos;localhost&apos; IDENTIFIED BY &apos;ymu123@&apos; PASSWORD EXPIRE NEVER; ERROR 1396 (HY000): Operation ALTER USER failed for &apos;root&apos;@&apos;localhost&apos; mysql&gt; ALTER USER &apos;root&apos;@&apos;%&apos; IDENTIFIED BY &apos;password&apos; PASSWORD EXPIRE NEVER; Query OK, 0 rows affected (0.05 sec) mysql&gt; ALTER USER &apos;root&apos;@&apos;*&apos; IDENTIFIED WITH mysql_native_password BY &apos;ymu123@&apos;; ERROR 1396 (HY000): Operation ALTER USER failed for &apos;root&apos;@&apos;*&apos; mysql&gt; ALTER USER &apos;root&apos;@&apos;%&apos; IDENTIFIED WITH mysql_native_password BY &apos;ymu123@&apos;; Query OK, 0 rows affected (0.10 sec) 设置密码不能是123456这些简单的密码，会通不过。所以设置复杂点ymu123@。 表格中有以下信息：host: 允许用户登录的 ip ‘位置’ % 表示可以远程；user: 当前数据库的用户名；authentication_string: 用户密码（在mysql 5.7.9以后废弃了password字段和password()函数）；plugin： 密码加密方式； 然后重启就可以登录了。 参考： https://blog.csdn.net/xinpengfei521/article/details/80400142 8.创建软链接（非必要） ln -s /server/mysql/bin/* /usr/local/bin/ 9.添加到启动（非必要） 开启自动启动mysql： cp support-files/mysql.server /etc/init.d/mysql.server chmod +x /etc/init.d/mysql.server chkconfig --add mysql.server chkconfig mysql.server on ------ 参考来源 ---- /bin/cp /usr/local/mysql/support-files/mysql.server /etc/init.d/mysqld chmod +x /etc/init.d/mysqld chkconfig --add mysqld chkconfig mysqld on 10.查看启动状态、启动、停止、重启 mysql.server对应上面设置自启动的：/etc/init.d/mysql.server 查看状态： systemctl status mysql.server.service 或者：service mysql.server status 停止：service mysql.server stop 启动：service mysql.server start 重新启动：service mysql.server reload 二进制安装包rpm安装（推荐）","tags":[{"name":"mysql mysql8","slug":"mysql-mysql8","permalink":"https://xinxiamu.github.io/tags/mysql-mysql8/"}]},{"title":"docker学习-第六课：使用网络","date":"2018-07-26T12:23:35.000Z","path":"2018/07/26/docker-lesson6-net/","text":"本节概述docker中与网络相关的一些操作，如docker与主机之间的网络互通，docker之间的网络互相访问等…… 参考网址： https://docs.docker.com/network/ 外部访问网络容器中可以运行一些网络应用，要让外部也可以访问这些网络应用，可以使用-P或者-p参数来指定端口映射。 当使用-P标记时，Docker会随机主机的一个49000~49900端口到容器的内部端口。使用docker container ps可以查看到。 docker run -d -P --name ngxin-net nginx 创建容器nginx-net并后台启动。 [vagrant@ymu ~]$ sudo docker run -d -P --name ngxin-net nginx cfb84ca5f6837d14ea5f9c4d670ca4f9b126fbbe3e0d78f9cbaa949772f892be [vagrant@ymu ~]$ sudo docker container ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES cfb84ca5f683 nginx &quot;nginx -g &apos;daemon of…&quot; 14 seconds ago Up 13 seconds 0.0.0.0:32768-&gt;80/tcp ngxin-net d120d176e25c nginx &quot;nginx -g &apos;daemon of…&quot; 13 days ago Up 3 minutes 0.0.0.0:80-&gt;80/tcp nginx 可以看到容器ngxin-net的端口映射信息，把主机32768端口映射到了容器的80端口。这样，在主机就可以访问：localhost:32768 同样，可以查看应用访问日志： [vagrant@ymu ~]$ sudo docker logs -f ngxin-net 另外，小写-p可以明确指定主机和容器之间的端口映射。 并且,在一个指定端口上只可以绑定一个容器。支持的格式： ip:hostPort:containerPort ip::containerPort hostPort:containerPort 前面一个为主机端口，后面一个为容器端口。 常用： -p 80:80 将本地主机80端口映射到容器80端口。 容器互联容器与容器之间的端口互通。 互相访问容器信息。 使用--link参数可以让容器之间安全的进行交互。 下面创建一个新的redis数据库容器： docker run --name redis-test -d redis 然后创建一个web容器： docker run -d -p 80:80 --name nginx-web --link redis-test nginx 此时，redis-test容器和nginx-web容器建立了互联关系。 --link 参数格式 --link name：alias，其中name是容器名称，alias是这个连接的别名。 可以通过docker ps查看连接信息。 这样，nginx-web容器将可以访问redis-test容器中的信息。 Docker在两个容器之间建立起了一个安全隧道，而且不用映射它们的端口到宿主主机上。启动redis-test的时候，采用大写-P，从而避免了暴露数据库端口到外部网络上。 Docker的4种网络模式https://developer.aliyun.com/article/653905?spm=a2c6h.13813017.0.dArticle738638.25e44811JPmdCV","tags":[{"name":"docker网络","slug":"docker网络","permalink":"https://xinxiamu.github.io/tags/docker网络/"}]},{"title":"区块链-密码学之哈希函数","date":"2018-07-25T06:45:45.000Z","path":"2018/07/25/blockchain-hash/","text":"本文介绍哈希……","tags":[]},{"title":"docker学习-第五课：数据管理","date":"2018-07-19T08:25:30.000Z","path":"2018/07/19/docker-lesson5-dv/","text":"本文介绍docker中数据的管理，持久化。在docker中需要持久化应用程序产生的数据，或者需要多个容器之间共享数据。在容器中管理数据主要有两种方式： 数据卷（Data volumes） 数据卷容器（Data volumes containers） 在新版本中，推荐使用docker volume子命令来管理Docker数据卷。 数据卷数据卷是一个特殊的目录，它将主机目录直接映射到容器，可供一个或者多个容器使用。它绕过UFS可以提供很多特性。 数据卷在容器启动时初始化，如果容器使用的镜像在挂载点包含了数据，这些数据会拷贝到新初始化的数据卷中。 数据卷可以在多个容器之中共享和重用。 对数据卷的修改会立马生效。 对数据卷的更新不会影响镜像。 数据卷默认会一直存在，即使容器被删除。 _注_ : 使用docker中的数据卷，类似于系统使用mount挂载一个文件系统。 创建数据卷 使用-v创建一个数据卷挂载到容器中 docker run --name nginx-data -v /mydir nginx 执行如下命令即可查看容器构造的详情docker inspect 容器ID 注： 也可以在Dockerfile中添加一个或者多个卷到由该镜像创建的任何容器中。 删除数据卷数据卷是设计来做持久化的，它的生命周期独立于容器，Docker不会在容器删除后删除数据卷。所以，要手动明确删除某个数据卷。 删除容器的时候同时想删除数据卷可以使用下面命令： docker rm -v 容器ID 挂载宿主机目录作为数据卷同样，使用-v可以将宿主机目录挂载到容器中，如下： docker run --name nginx-data2 -v /host-dir:/container-dir nginx 上面命令，会将宿主机目录/host-dir挂载到容器的/container-dir目录。 本地目录的路径必须是绝对路径。 如果宿主机路径不存在，Docker会自动创建。 _注意_ : Dockerfile不支持这种形式。因为Dockerfile是用来传播和分享的，不同操作系统，路径表示不一样，所以目前暂时不支持。 Docker挂载的数据卷默认权限是可读写，如果要改为只读，可以通过：ro指定。 docker run --name nginx-data2 -v /host-dir:/container-dir：ro nginx 加了：ro之后，就挂载伟只读了。 这样，在容器就只能读取/container-dir目录中的文件，不能写。 查看数据卷具体信息可以通过下面命令查看： docker inspect web 从输出内容中可以看到数据卷相关的部分。 数据卷容器如果有数据需要不断更新并在多个容器之间共享，那么你就需要建立数据卷容器了。 数据卷容器首先是个正常的容器，专门提供数据卷供其它容器挂载的。 创建数据卷容器： docker run --name nginx-volume -v /data nginx 然后，就可以在其它容器中使用-volumes-from来挂载nginx-volume容器中的数据卷。 docker run --name v1 --volumes-from nginx-volume nginx docker run --name v2 --volumes-from nginx-volume nginx 这样： v1、v2便可以共享nginx-volume容器中的数据卷。 即使nginx-volume容器停止，也不会有任何影响。 也可以使用超过一个的-volumes-from参数来指定从多个容器挂载不同的数据卷。也可以从其它挂载了数据卷的容器来级联挂载数据卷。 docker run --name v3 --volumes-from v1 nginx 利用数据卷容器来备份、恢复、迁移数据卷备份首先创建一个挂载容器卷nginx-volume的容器，并从主机挂载当前目录到容器/backup目录。如下： docker run --name data-backup --volume-from nginx-volume -v $(pwd):/backup centos/7 tar cvf /backup/backup.tar /nginx-volume 容器启动后，使用命令tar将容器卷nginx-volume备份为容器中/backup/backup.tar文件，也就主机当前目录下的名为backup.tar的文件。 恢复如果要恢复数据到一个容器，首先创建一个挂载空数据卷的容器nginx-volume2。 docker run -v /dbdata --name nginx-volume2 ngxin /bin/bash 然后创建另一个容器,挂载nginx-volume2容器卷中的数据卷,并使用untar解压备份文件到挂载的容器卷中。 docker run --vulume-from /nginx-volume2 -v $(pwd):/backup nginx untar xvf /backup/backup.tar 为了查看/验证恢复的数据,可以再启动一个容器挂载同样的容器卷来查看 dcoker run --volume-from nginx-volume2 nginx /bin/ls /dbdata","tags":[{"name":"docker数据管理","slug":"docker数据管理","permalink":"https://xinxiamu.github.io/tags/docker数据管理/"}]},{"title":"docker安装各种常用开发应用软件","date":"2018-07-19T07:49:39.000Z","path":"2018/07/19/docker-app-install/","text":"本文记录在docker各种应用程序的安装以及使用…… docker仓库： hub repo 安装nginx参考： https://hub.docker.com/_/nginx 1.新建要映射的卷 # mkdir -p /server/data/nginx/{cache,conf,conf.d,html,logs,pid} # chown 1000 /server/data/nginx/* -R # chmod 755 /server/data/nginx/* -R 查看 [root@sqjr-client-demo-server1-hn nginx]# pwd /server/data/nginx [root@sqjr-client-demo-server1-hn nginx]# ls cache conf conf.d html logs pid 2.拉取nginx最新镜像 docker pull nginx 2.配置nginx.conf 可以从从启动的容器中把该文件拷贝出来。 $ docker run --name tmp-nginx-container -d nginx $ docker cp tmp-nginx-container:/etc/nginx/nginx.conf /server/data/nginx/conf/nginx.conf $ docker rm -f tmp-nginx-container 或者进入/server/data/nginx/conf,新建文件touch nginx.conf 然后编辑nginx.conf文件： user nginx; worker_processes 1; error_log /var/log/nginx/error.log warn; pid /var/run/nginx.pid; events { worker_connections 1024; } http { include /etc/nginx/mime.types; default_type application/octet-stream; log_format main &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos; &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos; &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&apos;; access_log /var/log/nginx/access.log main; sendfile on; #tcp_nopush on; keepalive_timeout 65; #gzip on; server { listen 80; server_name localhost; charset utf-8; #charset koi8-r; #access_log logs/host.access.log main; location / { root /usr/share/nginx/html; #root /server/wwwroot; index index.html index.htm; } #error_page 404 /404.html; # redirect server error pages to the static page /50x.html # error_page 500 502 503 504 /50x.html; location = /50x.html { root html; } # proxy the PHP scripts to Apache listening on 127.0.0.1:80 # #location ~ \\.php$ { # proxy_pass http://127.0.0.1; #} # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000 # #location ~ \\.php$ { # root html; # fastcgi_pass 127.0.0.1:9000; # fastcgi_index index.php; # fastcgi_param SCRIPT_FILENAME /scripts$fastcgi_script_name; # include fastcgi_params; #} # deny access to .htaccess files, if Apache&apos;s document root # concurs with nginx&apos;s one # #location ~ /\\.ht { # deny all; #} } include /etc/nginx/conf.d/*.conf; } 3.新建欢迎页面 进入目录server/data/nginx/html下，新建文件index.html并随便编写内容测试。 4.启动nginx容器 docker run --name nginx -d -p 80:80 -v /server/data/nginx/html:/usr/share/nginx/html:ro -v /server/data/nginx/logs:/var/log/nginx -v /server/data/nginx/conf/nginx.conf:/etc/nginx/nginx.conf:ro -v /server/data/nginx/conf.d:/etc/nginx/conf.d -v /server/data/nginx/cache:/var/cache/nginx -v /server/data/nginx/pid:/var/run -d nginx 成功启动后，就可以打开浏览器测试：http://ip或者http://域名 5.中文乱码问题 如果发现中文乱码，修改server的配置内容，增加一行：charset utf-8; upstream you.domainName.com { server 127.0.0.1:8081; } server { listen 80; server_name you.domainName.com; charset utf-8; location /examples { return 403; } } 然后重启nginx。最后，在浏览器上Ctrl+F5，刷新，一切正常！ 6.反向代理失败问题 upstream abs-demo.xcsqjr.com{ ip_hash; server localhost:8084; #server 192.168.0.36:8084; #server 192.168.0.196:8011; #server 192.168.0.197:8011; } 这里不成功，包404错误。8084的应用也是跑在docker上的。实际上并不是因为跑在docker上就失败。成功配置： upstream abs-demo.xcsqjr.com{ ip_hash; #server localhost:8084; server 192.168.0.36:8084; #server 192.168.0.196:8011; #server 192.168.0.197:8011; } 不能用localhost或者127.0.0.1,要用内网ip。查询内网ip，执行命令：ifconfig。 安装redis参考： http://www.runoob.com/docker/docker-install-redis.html 使用redis镜像不使用自定义配置文件：docker run -p 6379:6379 --name redis-6379 --restart=always -v /server/data/redis-6379/data:/data -d redis:5.0.3 redis-server --appendonly yes --requirepass &quot;a1234567&quot; 123456命令说明：-p 6379:6379 : 将容器的6379端口映射到主机的6379端口-v /server/data/redis-6379/data:/data : 将主机中/server/data/redis-6379目录下的data挂载到容器的/dataredis-server --appendonly yes : 在容器执行redis-server启动命令，并打开redis持久化配置 --requirepass &quot;a1234567&quot; : 设置认证密码 --restart=always ： 随docker启动而启动 通过客户端连接进入redis-ci： [root@sqjr-client-demo-server1-hn ~]# docker exec -it redis-6379 redis-cli -a a1234567 Warning: Using a password with &apos;-a&apos; or &apos;-u&apos; option on the command line interface may not be safe. 127.0.0.1:6379&gt; set username zmt 在宿主机查看redis进程： [root@sqjr-client-demo-server1-hn ~]# ps -ef|grep redis polkitd 29683 29651 0 14:27 ? 00:00:01 redis-server *:6379 root 29935 29453 0 14:51 pts/1 00:00:00 grep --color=auto redis 只能本机127.0.0.1连接，不能远程连接。默认是保护模式，不允许远程连接。 使用自定义配置文件（推荐）docker run -v /server/data/redis-6380/conf:/usr/local/etc/redis -v /server/data/redis-6380/data:/data --name redis-6380 --restart=always -p 6380:6380 -d redis redis-server /usr/local/etc/redis/redis.conf redis.conf配置文件基本内容，自由添加： # 指定Redis监听端口，默认端口为6379 # 如果指定0端口，表示Redis不监听TCP连接 port 6380 #设置密码 requirepass a1234567 #### 生产环境要开启保护模式 # 绑定的主机地址 # 你可以绑定单一接口，如果没有绑定，所有接口都会监听到来的连接 # bind 127.0.0.1 #protected-mode yes #关闭，不要保护模式，远程可连接 # 当客户端闲置多长时间后关闭连接，如果指定为0，表示关闭该功能 timeout 0 #一定要打开，否则无法启动 #daemonize yes # 当Redis以守护进程方式运行时，Redis默认会把pid写入/var/run/redis.pid文件，可以通过pidfile指定 pidfile /var/run/redis.pid # 指定日志记录级别，Redis总共支持四个级别：debug、verbose、notice、warning，默认为verbose # debug (很多信息, 对开发／测试比较有用) # verbose (many rarely useful info, but not a mess like the debug level) # notice (moderately verbose, what you want in production probably) # warning (only very important / critical messages are logged) loglevel verbose # 日志记录方式，默认为标准输出，如果配置为redis为守护进程方式运行，而这里又配置为标准输出，则日志将会发送给/dev/null logfile stdout # 设置数据库的数量，默认数据库为0，可以使用select &lt;dbid&gt;命令在连接上指定数据库id # dbid是从0到‘databases’-1的数目 databases 16 ################################ SNAPSHOTTING ################################# # 指定在多长时间内，有多少次更新操作，就将数据同步到数据文件，可以多个条件配合 # Save the DB on disk: # # save &lt;seconds&gt; &lt;changes&gt; # # Will save the DB if both the given number of seconds and the given # number of write operations against the DB occurred. # # 满足以下条件将会同步数据: # 900秒（15分钟）内有1个更改 # 300秒（5分钟）内有10个更改 # 60秒内有10000个更改 # Note: 可以把所有“save”行注释掉，这样就取消同步操作了 save 900 1 save 300 10 save 60 10000 # 指定存储至本地数据库时是否压缩数据，默认为yes，Redis采用LZF压缩，如果为了节省CPU时间，可以关闭该选项，但会导致数据库文件变的巨大 rdbcompression yes # 指定本地数据库文件名，默认值为dump.rdb dbfilename dump.rdb 注意:切记注释掉：#daemonize yes 否则无法启动容器重要话说三遍：注释掉#daemonize yes，注释掉#daemonize yes，注释掉#daemonize yes 配置文件：redis.conf 安装mysql-server仓库：https://hub.docker.com/r/library/mysql/ 拉取镜像：docker pull mysql:8.0.13 # 8.0.13为标签tag 使用mysql镜像 自定义配置文件 docker run -p 3306:3306 --name mymysql -v $PWD/conf:/etc/mysql/conf.d -v $PWD/logs:/logs -v $PWD/data:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=123456 -d mysql:8.0.13 ------------------------------------ docker run --name mysql-3910 -p 3910:3910 --restart always --privileged=true -v /server/data/mysql-3910/conf:/etc/mysql/conf.d -v /server/data/mysql-3910/logs:/logs -v /server/data/mysql-3910/data:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=123456 --default-authentication-plugin=mysql_native_password -d mysql:8.0.13 my.cnf内容 [mysqld] port = 3910 character-set-client-handshake = FALSE character-set-server = utf8mb4 collation-server = utf8mb4_unicode_ci init_connect=&apos;SET NAMES utf8mb4&apos; default_authentication_plugin = mysql_native_password # 一下三个配置，解决too manay connection问题。 max_connections=1000 # 最大连接数，默认100 wait_timeout = 300 # interactive_timeout = 500 [client] default-character-set=utf8mb4 [mysql] default-character-set=utf8mb4 _注意_: 远程连接可能报错误： 2019-01-03T07:41:43.260661Z 8 [Warning] [MY-010055] [Server] IP address &apos;172.17.0.1&apos; could not be resolved: Name or service not known 原因：在网上查了些资料简单点说就是反向解析造成的，具体原因是因为“MYSQL Server在本地内存中维护了一个非本地的Client TCP cache，这个cache中包含了远程Client的登录信息，比如IP地址，hostname等信息。如果Client连接到服务器后，Mysql首先会在本地TCP池中根据IP地址解析客户端的hostname或者反解析，如果解析不到，就会去DNS中进行解析，如果还是解析失败就在error log中写入这样的警告信息。”。 解决办法：在配置文件新增一句skip-name-resolve： [mysqld] port = 3910 character-set-client-handshake = FALSE character-set-server = utf8mb4 collation-server = utf8mb4_unicode_ci init_connect=&apos;SET NAMES utf8mb4&apos; default_authentication_plugin = mysql_native_password skip-name-resolve wait_timeout = 100 interactive_timeout = 100 然后重启mysql服务再试。 命令说明： -p 3306:3306：将容器的 3306 端口映射到主机的 3306 端口。 -v -v $PWD/conf:/etc/mysql/conf.d：将主机当前目录下的 conf/my.cnf 挂载到容器的 /etc/mysql/my.cnf。看下面补充内容说明。 -v $PWD/logs:/logs：将主机当前目录下的 logs 目录挂载到容器的 /logs。 -v $PWD/data:/var/lib/mysql ：将主机当前目录下的data目录挂载到容器的 /var/lib/mysql 。 -e MYSQL_ROOT_PASSWORD=123456：初始化 root 用户的密码。 –default-authentication-plugin=mysql_native_password 加上这个客户端才能登录上。在配置文件加了，命令中可以不加。 –privileged=true 提升root在docker中的权限，否则只是普通用户 –restart always：开机启动 123456789101112131415161718补充： MySQL默认配置文件是 /etc/mysql/my.cnf 文件。如果想要自定义配置，建议向 /etc/mysql/conf.d 目录中创建 .cnf 文件。新建的文件可以任意起名，只要保证后缀名是 cnf 即可。新建的文件中的配置项可以覆盖 /etc/mysql/my.cnf 中的配置项。 具体操作： 首先需要创建将要映射到容器中的目录以及.cnf文件，然后再创建容器 # pwd /opt # mkdir -p docker_v/mysql/conf # cd docker_v/mysql/conf # touch my.cnf # docker run -p 3306:3306 --name mysql -v /opt/docker_v/mysql/conf:/etc/mysql/conf.d -e MYSQL_ROOT_PASSWORD=123456 -d imageID 4ec4f56455ea2d6d7251a05b7f308e314051fdad2c26bf3d0f27a9b0c0a71414 -p 3306:3306：将容器的3306端口映射到主机的3306端口-v /opt/docker_v/mysql/conf:/etc/mysql/conf.d：将主机/opt/docker_v/mysql/conf目录挂载到容器的/etc/mysql/conf.d-e MYSQL_ROOT_PASSWORD=123456：初始化root用户的密码-d: 后台运行容器，并返回容器IDimageID: mysql镜像ID 不使用conf配置文件 参考：https://hub.docker.com/r/library/mysql/ 创建容器mysql实例，端口为：3306 docker run --name mysql-3306 -p 3306:3306 -v /server/mysql-3306/logs:/logs -v /server/mysql-3306/data:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=123456 -d mysql:8.0.13 --port=3306 --character-set-server=utf8mb4 --collation-server=utf8mb4_unicode_ci 查看配置参数列表： docker run -it --rm mysql:tag --verbose --help 查看容器启动情况[root@xr-server ~]# docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 415c0167fb5a mysql:8.0.13 &quot;docker-entrypoint.s…&quot; 5 minutes ago Up 5 minutes 0.0.0.0:3306-&gt;3306/tcp, 33060/tcp mymysql 进入mysql镜像参考容器章节…… docker exec -it 415c0167fb5a /bin/bash 或者 docker exec -it 415c0167fb5a bash 415c0167fb5a为容器id 12345678910[root@xr-server ~]# clear[root@xr-server ~]# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES415c0167fb5a mysql:8.0.13 &quot;docker-entrypoint.s…&quot; 17 hours ago Up 6 minutes 0.0.0.0:3306-&gt;3306/tcp, 33060/tcp mymysql[root@xr-server ~]# docker exec -it 415c0167fb5a /bin/bash 或者 docker exec -it 415c0167fb5a bashroot@415c0167fb5a:/# lsbin docker-entrypoint-initdb.d home logs opt run sys varboot entrypoint.sh lib media proc sbin tmpdev etc lib64 mnt root srv usrroot@415c0167fb5a:/# 安装zabbix启动一个mysql服务器实例docker run --name zabbix-mysql-server \\ -e MYSQL_ROOT_PASSWORD=&quot;123456&quot; \\ -e MYSQL_USER=&quot;zabbix&quot; \\ -e MYSQL_PASSWORD=&quot;123456&quot; \\ -e MYSQL_DATABASE=&quot;zabbix&quot; \\ -p 3306:3306 \\ -v /server/dockers/zabbix/mysql/logs:/logs \\ -v /server/dockers/zabbix/mysql/data:/var/lib/mysql \\ -d mysql:5.7 \\ --character-set-server=utf8mb4 --collation-server=utf8mb4_unicode_ci 启动Zabbix server实例，并关联这个实例到已创建的MySQL服务器实例docker run --name zabbix-server-mysql --hostname zabbix-server-mysql \\ --link zabbix-mysql-server:mysql \\ -e DB_SERVER_HOST=&quot;mysql&quot; \\ -e MYSQL_USER=&quot;zabbix&quot; \\ -e MYSQL_DATABASE=&quot;zabbix&quot; \\ -e MYSQL_PASSWORD=&quot;123456&quot; \\ -e MYSQL_ROOT_PASSWORD=&quot;123456&quot; \\ -v /etc/localtime:/etc/localtime:ro \\ -v /server/dockers/zabbix/zabbix-server/alertscripts:/usr/lib/zabbix/alertscripts \\ -v /server/dockers/zabbix/zabbix-server/externalscripts:/usr/lib/zabbix/externalscripts \\ -p 10051:10051 \\ -p 10050:10050 \\ -d zabbix/zabbix-server-mysql:centos-4.0.2 ------------------------------ 查看启动日志 --------------- docker logs zabbix-server-mysql _注意_：必须加上属性-e MYSQL_ROOT_PASSWORD=&quot;123456&quot;,否则mysql的zabbix用户没有操作mysql数据库的权限。 --link属性说明：docker run –link可以用来链接2个容器，使得源容器（被链接的容器）和接收容器（主动去链接的容器）之间可以互相通信，并且接收容器可以获取源容器的一些数据，如源容器的环境变量。–link的格式：–link :alias其中，name和id是源容器的name和id，alias是源容器在link下的别名。 启动Zabbix web 接口，并将它与MySQL服务器实例和Zabbix server实例关联docker run --name zabbix-web-nginx-mysql --hostname zabbix-web-nginx-mysql \\ --link zabbix-mysql-server:mysql \\ --link zabbix-server-mysql:zabbix-server \\ -e DB_SERVER_HOST=&quot;mysql&quot; \\ -e MYSQL_ROOT_PASSWORD=&quot;123456&quot; \\ -e MYSQL_USER=&quot;zabbix&quot; \\ -e MYSQL_PASSWORD=&quot;123456&quot; \\ -e MYSQL_DATABASE=&quot;zabbix&quot; \\ -e ZBX_SERVER_HOST=&quot;zabbix-server&quot; \\ -e PHP_TZ=&quot;Asia/Shanghai&quot; \\ -p 8083:80 \\ -d zabbix/zabbix-web-nginx-mysql:centos-4.0.2 ------------------------------ 查看启动日志 --------------- docker logs zabbix-web-nginx-mysql 1234浏览器访问ip:8083查看默认登录username:Adminpassword:zabbix _注意_ ：生产环境要做数据卷映射。以防止数据丢失。必须加上属性-e MYSQL_ROOT_PASSWORD=&quot;123456&quot;,否则mysql的zabbix用户没有操作mysql数据库的权限。 界面无法选择中文显示的问题： 打开系统，在用户资料中，可以选择语言，但是无法选择中文。这是由于docker容器没有安装中文字符集，不支持中文。因此，要进入容器，安装中文字符集合： 查看系统当前字符集： # locale；查看系统可用字符集： #locale -a;安装中文字符集：yum install kde-l10n-Chinese -yyum -y -q reinstall glibc-common 修改vim /etc/locale.conf, LANG=zh_CN.UTF-8; 重新启动容器。再次进入容器，查看系统当前字符集，发现上面修改无效。坑爹…… 那是因为centos默认镜像的 /etc/yum.conf 里面有一句override_install_langs=en_US.utf8，删除这句话，然后重新运行：yum -y -q reinstall glibc-common，再重启容器，查看系统当前字符集，可以看到是中文的了。 启动zabbix-agentdocker run --name zabbix-agent --link zabbix-server-mysql:zabbix-server -d zabbix/zabbix-agent:centos-4.0.2 最后需要在web端将，zabbix-agent添加到zabbix-server的host列表里面。 启动Zabbix Java gateway实例,并关联到zabbix-server用于监控jvm/tomcat性能。Zabbix监控Java应用程序的关键点在于：配置Zabbix-JavaGateway、让Zabbix-Server能够连接Zabbix-JavaGateway、Tomcat开启JVM远程监控功能等。 docker run --name zabbix-java-gateway --link zabbix-server-mysql:zabbix-server -d zabbix/zabbix-java-gateway:latest 安装Jenkins#### 配置日志： [root@ymu /]# mkdir -p /server/data/jenkins [root@ymu /]# cd /server/data/jenkins [root@ymu jenkins]# touch log.properties [root@ymu jenkins]# cat &gt; log.properties &lt;&lt;EOF &gt; handlers=java.util.logging.ConsoleHandler &gt; jenkins.level=FINEST &gt; java.util.logging.ConsoleHandler.level=FINEST &gt; EOF 启动jenkins服务参考：https://github.com/jenkinsci/docker/blob/master/README.md 首先，要对文件夹赋予权限：查看文件夹权限：` [root@xr-server jenkins]# ls -l /server/data/jenkins/ total 4 -rw-r--r--. 1 root root 109 Dec 17 00:55 log.properties 赋予文件夹权限： chown -R 1000:1000 /server/data/jenkins/ 启动容器： docker run --name ymu-jenkins -p 3001:8080 -p 50000:50000 --env JAVA_OPTS=&quot;-Djava.util.logging.config.file=/var/jenkins_home/log.properties&quot; -v /server/data/jenkins:/var/jenkins_home -d jenkins/jenkins:lts lts：长期支持版本以上启动的容器安装Locale插件后，也只能部分中文，原因：未知…… 说明： -v 会把容器目录/var/jenkins_home映射到主机/server/data/jenkins 测试是否安装成功打开浏览器输入：local:3001 如果看到要求获取登录密码的界面，则成功。恭喜…… 获取登录初始密码： [root@ymu secrets]# pwd /server/data/jenkins/secrets [root@ymu secrets]# cat initialAdminPassword 8ccac67d98dd4c77a2c09870e8246e5d [root@ymu secrets]# 其它的如和maven的集成等，参考以前文档。 使用Nginx做方向代理坑，坑，坑…… 一开始按一般的nginx方向代理配置，负载均衡配置，都不行，页面打开异常的慢…… 各种百度，不行。还好，想起了google大神……结果找到了： https://wiki.jenkins.io/display/JENKINS/Running+Jenkins+behind+Nginx 还是官方文档有用，以后遇到这种问题，都先到官方wiki上找答案才对。重新配置： upstream jenkins { keepalive 32; # keepalive connections server 127.0.0.1:9000; # jenkins ip and port } server { listen 80; # Listen on port 80 for IPv4 requests server_name ci.xcsqjr.com; #this is the jenkins web root directory (mentioned in the /etc/default/jenkins file) root /server/data/jenkins/war; access_log /server/java/nginx/logs/ci.xcsqjr.com.access.log; error_log /server/java/nginx/logs/ci.xcsqjr.com.error.log; ignore_invalid_headers off; #pass through headers from Jenkins which are considered invalid by Nginx server. location ~ &quot;^/static/[0-9a-fA-F]{8}\\/(.*)$&quot; { #rewrite all static files into requests to the root #E.g /static/12345678/css/something.css will become /css/something.css rewrite &quot;^/static/[0-9a-fA-F]{8}\\/(.*)&quot; /$1 last; } location /userContent { #have nginx handle all the static requests to the userContent folder files #note : This is the $JENKINS_HOME dir root /server/data/jenkins/war; if (!-f $request_filename){ #this file does not exist, might be a directory or a /**view** url rewrite (.*) /$1 last; break; } sendfile on; } location / { sendfile off; proxy_pass http://jenkins; proxy_redirect default; proxy_http_version 1.1; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; proxy_max_temp_file_size 0; #this is the maximum upload size client_max_body_size 10m; client_body_buffer_size 128k; proxy_connect_timeout 90; proxy_send_timeout 90; proxy_read_timeout 90; proxy_buffering off; #proxy_request_buffering off; # Required for HTTP CLI commands in Jenkins &gt; 2.54 proxy_set_header Connection &quot;&quot;; # Clear for keepalive } } 注意：按上面docker安装jenkins的时候，映射了数据卷，所以可以知道：server/data/jenkins/war 为jenkins的web根目录。注意配置好。 安装gitlab参考网址：https://docs.gitlab.com/omnibus/docker/ 安装sonatype/nexus参考网址：https://hub.docker.com/r/sonatype/nexus 1.初始持久化数据目录 # mkdir /server/data/nexus/data &amp;&amp; chown -R 200 /server/data/nexus/data # docker run -d -p 8084:8081 --name nexus -e MAX_HEAP=768m -v /server/data/nexus/data:/sonatype-work sonatype/nexus 2.查看启动日志 docker logs -f nexus 3.默认账号密码： admin / admin123 4.浏览器浏览： http://ip:8084/nexus 安装sonatype/nexus3,兼容maven依赖和docker register（推荐生产使用）网址：https://github.com/sonatype/docker-nexus3 1.创建映射卷并启动实例 # mkdir -p /server/data/nexus3-data &amp;&amp; chown -R 200 /server/data/nexus3-data # docker run -p 8085:8081 -p 8082:8082 -p 8083:8083 --name nexus3 --restart=always -v /server/data/nexus3-data:/nexus-data -d sonatype/nexus3 2.查看启动日志： docker logs -f nexus 3.测试是否安装成功： curl -u admin:admin123 http://localhost:8085/service/metrics/ping 4.打开浏览器浏览： 网址：http://ip:8085 默认账号密码：admin admin123","tags":[]},{"title":"docker学习-第四课：容器","date":"2018-06-30T07:24:01.000Z","path":"2018/06/30/docker-lesson4-container/","text":"容器是docker的又一核心组件之一。 简单理解：容器就是独立运行的一个或者一组应用,以及一整套的运行态环境（提供运行态环境以及系统环境）。 启动容器：启动容器有两种方式： 基于镜像创建一个容器并启动。 将在终止状态(stopped)的容器重新启动。 新版本推荐使用子命令docker container 。 新建并启动容器使用命令：docker run 输出hello world并终止容器： $docker run ubuntu:14.04 /bin/echo &apos;Hello world&apos; Hello world 启动一个bash终端,允许用户进行交互。 $docker run -t -i ubuntu:14.04 /bin/bash root@af8bae53bdd3:/# 其中, -t选项让Docker分配一个伪终端(pseudo-tty)并绑定到容器的标准输入上,-i则让容器的标准输入保持打开。 docker run启动容器流程： 检查本地是否存在指定的镜像，没有则从仓库拉取。 利用镜像创建一个容器并启动。 分配一个文件系统，并且在添加一层可读写。 从宿主主机配置的网桥接口中桥接一个虚拟接口到容器中去。 从地址池配置一个ip地址给容器。 执行用户指定的应用程序。 执行完毕后容器终止。 启动已终止容器命令docker start直接将一个已经终止的容器启动。 容器的核心是，应用程序以及应用程序需要的资源。除此之外，并没有其它的资源。可以在伪终端中利用ps或top来查看进程信息。 mutian@mutian-ThinkPad-T440p:~$ sudo docker run -t -i centos:latest /bin/bash [root@b80715a7913e /]# ps PID TTY TIME CMD 1 pts/0 00:00:00 bash 15 pts/0 00:00:00 ps [root@b80715a7913e /]# 可以看到，容器只启动了bash，资源利用率极高，非常的轻量。以至于都可以随便删除，添加容器。 容器管理docker container在Docker 1.13+版本，推荐使用docker container来管理容器。 $ docker container run ubuntu:17.10 /bin/echo &apos;Hello world&apos; $ docker container start 后台运行容器前台运行： $docker run ubuntu:14.04 /bin/sh -c &quot;while true; do echo hello world; sleep 1; done&quot; hello world hello world hello world hello world 输出信息一直在宿主中输出。 后台运行，添加参数-d： $docker run -d ubuntu:14.04 /bin/sh -c &quot;while true; do echo hello world; sleep 1; done&quot; 77b2dc01fe0f3f1265df143181e7b9af5e05279a884f4776ee75350ea9d8017a _注意_: 容器是否能长久运行，与docker run指定的命令有关，与-d无关。 用命令docker ps查看容器信息。 用命令docker logs [container ID or NAMES] 获取容器输出信息。 -注_: 后面版本使用： $ docker container run -d $ docker container ls $ docker container logs 终止容器命令docker stop可以终止一个运行中的容器。 另外，当Docker中指定的应用程序终止时候，容器自动终止。 命令docker ps -a可以查看终止状态的容器。 mutian@mutian-ThinkPad-T440p:~$ sudo docker ps -a [sudo] password for mutian: CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES b80715a7913e centos:latest &quot;/bin/bash&quot; About an hour ago Up About an hour confident_colden 04288423a400 mysql/mysql-server:latest &quot;/entrypoint.sh mysq…&quot; 6 weeks ago Exited (0) 6 weeks ago mysql 37741b9edbd1 nginx:v2 &quot;nginx -g &apos;daemon of…&quot; 4 months ago Exited (0) 4 months ago web5 9e724b4f0f39 nginx:v2 &quot;nginx -g &apos;daemon of…&quot; 4 months ago Created web4 a9d4f7554e91 nginx:v3 &quot;nginx -g &apos;daemon of…&quot; 4 months ago Exited (0) 4 months ago web3 e28e7f69cbc8 nginx:v2 &quot;nginx -g &apos;daemon of…&quot; 4 months ago Exited (0) 4 months ago web2 c6074acec608 nginx &quot;nginx -g &apos;daemon of…&quot; 4 months ago Exited (0) 4 months ago webserver 95088bff626d hello-world &quot;/hello&quot; 4 months ago Exited (0) 4 months ago stupefied_mcnulty 命令docker start可以重启终止状态下的容器。命令docker restart将会终止一个一个运行的容器后并重启。 强制停止容器 可使用docker kill 命令停止一个或更多运行着的容器。 格式：docker kill [OPTIONS] CONTAINER [CONTAINER...] 例子：docker kill 784fd3b294d7 Doker 1.13+: docker container ls docker container start docker container restart 进入容器使用参数-d启动容器后，容器在后台执行了。有时候，需要进入容器操作。进入容器有多种方式：使用docker attach命令或者nsenter工具等。 attach命令 命令格式：docker attach [COMMAND]具体使用请百度…… 使用该命令有时候并不方便，当多个窗口同事通过attach命令进入到同一个容器的的时候，所有的窗口都会同步显示。这样，当有一个窗口阻塞的时候，所有的窗口都会阻塞。 nsenter进入容器 nsenter工具包含在util-linux 2.23或更高版本中。 为了进入容器，你还需要找到容器的第一个进程的 PID； docker inspect --format &quot;{{.State.Pid}}&quot; $CONTAINER_ID 通过这个PID就可以进入容器了：nsenter --target &quot;$PID&quot; --mount --uts --ipc --net --pid 完整例子： [root@localhost ~]# docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 784fd3b294d7 nginx &quot;nginx -g &apos;daemon off&quot; 55 minutes ago Up 3 minutes 443/tcp, 0.0.0.0:91-&gt;80/tcp backstabbing_archimedes [root@localhost ~]# docker inspect --format &quot;{{.State.Pid}}&quot; 784fd3b294d7 95492 [root@localhost ~]# nsenter --target 95492 --mount --uts --ipc --net --pid root@784fd3b294d7:/# 可以把以上命令封装程shell命令，简化操作。 docker exec进入容器 docker exec -it 容器id /bin/bash 导出容器如果要导出本地的某个容器，可以使用命令docker export：命令格式： docker export [OPTIONS] CONTAINER参数： Name,shorthand Default 将内容写到文件而非STDOUT –output, -o - 将内容写到文件而非STDOUT 示例： docker export red_panda &gt; latest.tar docker export --output=&quot;latest.tar&quot; red_panda 导入容器使用docker import 命令即可从归档文件导入内容并创建镜像。命令格式： docker import [OPTIONS] file|URL|- [REPOSITORY[:TAG]] 参数： Name,shorthand Default 将内容写到文件而非STDOUT --change, -c - 将Dockerfile指令应用到创建的镜像 --message, -m - 为导入的镜像设置提交信息 示例： docker import nginx2.tar nginx 删除容器可以使用命令docker rm来删除一个处于终止状态的容器。例如： docker rm rusting_newton 如果要删除一个正在运行的容器，可以添加参数-f,Docker会发送SIGKILL信号给容器。 清理所有处于终止状态下容器： $ docker ps -a $ docker rm $(docker ps -a -q) Docker1.13+版本,使用命令： docker container rm trusting_newton docker container prune 参考资源 http://itmuch.com/docker/05-docker-command-containers/","tags":[{"name":"docker 容器","slug":"docker-容器","permalink":"https://xinxiamu.github.io/tags/docker-容器/"}]},{"title":"zookeeper-curator","date":"2018-06-28T02:01:04.000Z","path":"2018/06/28/zookeeper-curator/","text":"","tags":[{"name":"apache curator","slug":"apache-curator","permalink":"https://xinxiamu.github.io/tags/apache-curator/"}]},{"title":"zookeeper使用入门","date":"2018-06-28T02:00:46.000Z","path":"2018/06/28/zookeeper-start/","text":"docker安装zookeeper（推荐）参考:https://hub.docker.com/_/zookeeper 1.拉取最新镜像docker pull zookeeper 2.创建配置文件zoo.cfg 首先启动一个zk的一个临时容器，用来从容器中拷贝原始配置文件zoo.cfg。拷贝完后，强制删除容器。 docker run --name temp-zookeeper -d zookeeper docker cp temp-zookeeper:/conf/zoo.cfg /server/data/zookeeper/ docker rm -f temp-zookeeper 3.按配置文件启动新的可用zk服务docker run --name zk-server1 --restart always -p 2181:2181 -p 2888:2888 -p 3888:3888 -d -v /server/data/zookeeper/zoo.cfg:/conf/zoo.cfg zookeeper 查看启动日志： docker logs zk-server1 4.测试是否成功 通zkCli连接zk server docker run -it --rm --link zk-server1:zookeeper zookeeper zkCli.sh -server zookeeper ----------------------------- [root@sqjr-client-demo-server1-hn zookeeper]# docker run -it --rm --link zk-server1:zookeeper zookeeper zkCli.sh -server zookeeper Connecting to zookeeper 2019-01-03 06:37:36,491 [myid:] - INFO [main:Environment@100] - Client environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 04:05 GMT 2019-01-03 06:37:36,494 [myid:] - INFO [main:Environment@100] - Client environment:host.name=c2f781bcaf31 2019-01-03 06:37:36,495 [myid:] - INFO [main:Environment@100] - Client environment:java.version=1.8.0_181 2019-01-03 06:37:36,497 [myid:] - INFO [main:Environment@100] - Client environment:java.vendor=Oracle Corporation 2019-01-03 06:37:36,497 [myid:] - INFO [main:Environment@100] - Client environment:java.home=/usr/lib/jvm/java-1.8-openjdk/jre 2019-01-03 06:37:36,498 [myid:] - INFO [main:Environment@100] - Client environment:java.class.path=/zookeeper-3.4.13/bin/../build/classes:/zookeeper-3.4.13/bin/../build/lib/*.jar:/zookeeper-3.4.13/bin/../lib/slf4j-log4j12-1.7.25.jar:/zookeeper-3.4.13/bin/../lib/slf4j-api-1.7.25.jar:/zookeeper-3.4.13/bin/../lib/netty-3.10.6.Final.jar:/zookeeper-3.4.13/bin/../lib/log4j-1.2.17.jar:/zookeeper-3.4.13/bin/../lib/jline-0.9.94.jar:/zookeeper-3.4.13/bin/../lib/audience-annotations-0.5.0.jar:/zookeeper-3.4.13/bin/../zookeeper-3.4.13.jar:/zookeeper-3.4.13/bin/../src/java/lib/*.jar:/conf: 2019-01-03 06:37:36,498 [myid:] - INFO [main:Environment@100] - Client environment:java.library.path=/usr/lib/jvm/java-1.8-openjdk/jre/lib/amd64/server:/usr/lib/jvm/java-1.8-openjdk/jre/lib/amd64:/usr/lib/jvm/java-1.8-openjdk/jre/../lib/amd64:/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib 2019-01-03 06:37:36,498 [myid:] - INFO [main:Environment@100] - Client environment:java.io.tmpdir=/tmp 2019-01-03 06:37:36,498 [myid:] - INFO [main:Environment@100] - Client environment:java.compiler=&lt;NA&gt; 2019-01-03 06:37:36,498 [myid:] - INFO [main:Environment@100] - Client environment:os.name=Linux 2019-01-03 06:37:36,498 [myid:] - INFO [main:Environment@100] - Client environment:os.arch=amd64 2019-01-03 06:37:36,498 [myid:] - INFO [main:Environment@100] - Client environment:os.version=3.10.0-693.2.2.el7.x86_64 2019-01-03 06:37:36,498 [myid:] - INFO [main:Environment@100] - Client environment:user.name=root 2019-01-03 06:37:36,498 [myid:] - INFO [main:Environment@100] - Client environment:user.home=/root 2019-01-03 06:37:36,499 [myid:] - INFO [main:Environment@100] - Client environment:user.dir=/zookeeper-3.4.13 2019-01-03 06:37:36,499 [myid:] - INFO [main:ZooKeeper@442] - Initiating client connection, connectString=zookeeper sessionTimeout=30000 watcher=org.apache.zookeeper.ZooKeeperMain$MyWatcher@4b85612c Welcome to ZooKeeper! 2019-01-03 06:37:36,523 [myid:] - INFO [main-SendThread(zookeeper:2181):ClientCnxn$SendThread@1029] - Opening socket connection to server zookeeper/172.17.0.5:2181. Will not attempt to authenticate using SASL (unknown error) JLine support is enabled 2019-01-03 06:37:36,595 [myid:] - INFO [main-SendThread(zookeeper:2181):ClientCnxn$SendThread@879] - Socket connection established to zookeeper/172.17.0.5:2181, initiating session [zk: zookeeper(CONNECTING) 0] 2019-01-03 06:37:36,623 [myid:] - INFO [main-SendThread(zookeeper:2181):ClientCnxn$SendThread@1303] - Session establishment complete on server zookeeper/172.17.0.5:2181, sessionid = 0x1003451023c0000, negotiated timeout = 30000 WATCHER:: WatchedEvent state:SyncConnected type:None path:null [zk: zookeeper(CONNECTED) 0] 创建节点 [zk: zookeeper(CONNECTED) 6] create /zk myData Created /zk 获取节点信息 [zk: zookeeper(CONNECTED) 7] get /zk myData cZxid = 0x2 ctime = Thu Jan 03 06:48:26 GMT 2019 mZxid = 0x2 mtime = Thu Jan 03 06:48:26 GMT 2019 pZxid = 0x2 cversion = 0 dataVersion = 0 aclVersion = 0 ephemeralOwner = 0x0 dataLength = 6 numChildren = 0 删除节点信息 [zk: zookeeper(CONNECTED) 8] delete /zk [zk: zookeeper(CONNECTED) 9] get /zk Node does not exist: /zk 直接安装下载地址： https://zookeeper.apache.org/releases.html 1.下载后解压到某个目录下。2.修改配置文件，再conf目录下，复制一份zoo_sample.cfg,把名字改为zoo.cfg。并修改内容： script123456789101112131415161718192021222324252627282930313233343536373839# The number of milliseconds of each ticktickTime=2000# The number of ticks that the initial # synchronization phase can takeinitLimit=10# The number of ticks that can pass between # sending a request and getting an acknowledgementsyncLimit=5# the directory where the snapshot is stored.# do not use /tmp for storage, /tmp here is just # example sakes.dataDir=/tmp/zookeeper# the port at which the clients will connect# 监听客户端连接的端口clientPort=2181# the maximum number of client connections.# increase this if you need to handle more clients#maxClientCnxns=60## Be sure to read the maintenance section of the # administrator guide before turning on autopurge.## http://zookeeper.apache.org/doc/current/zookeeperAdmin.html#sc_maintenance## The number of snapshots to retain in dataDir#autopurge.snapRetainCount=3# Purge task interval in hours# Set to \"0\" to disable auto purge feature#autopurge.purgeInterval=1## Metrics Providers## https://prometheus.io Metrics Exporter#metricsProvider.className=org.apache.zookeeper.metrics.prometheus.PrometheusMetricsProvider#metricsProvider.httpPort=7000#metricsProvider.exportJvmInfo=true#内嵌的jetty服务器的启动端口，默认8080，不修改的话，可能引起端口冲突admin.serverPort=8079 集群配置","tags":[]},{"title":"git打标签封存版本","date":"2018-06-23T09:40:01.000Z","path":"2018/06/23/git-tag/","text":"在开发项目中，当我们的项目测试通过，并准备发布到生产环境时候，那么这是一个稳定的版本，此时，我们就需要封存该版本代码。做一个版本管理。本文就是介绍git下如何封存版本…… 创建标签 创建本地标签 git tag -a V1.0 -m &#39;版本1.0，基于spring-boot 1.x&#39; 查看标签 git tag 只看到版本信息V1.0，没看到备注信息。可以执行下面命令查看更加详细信息： mutian@mutian-ThinkPad-T440p:~/dev/java/github/ymu-framework$ git show V1.0 tag V1.0 Tagger: xinxiamu &lt;932852117@qq.com&gt; Date: Sat Jun 23 17:45:17 2018 +0800 版本1.0，基于spring-boot 1.x 提交标签到服务器上面创建的tag只是本地git仓库。下面把它推送到远程服务器。 mutian@mutian-ThinkPad-T440p:~/dev/java/github/ymu-framework$ git push origin --tags Username for &apos;https://github.com&apos;: xinxiamu Password for &apos;https://xinxiamu@github.com&apos;: Counting objects: 1, done. Writing objects: 100% (1/1), 192 bytes | 0 bytes/s, done. Total 1 (delta 0), reused 0 (delta 0) To https://github.com/xinxiamu/ymu-framework.git * [new tag] V1.0 -&gt; V1.0 回退版本，tag上修复紧急bug这个时候，突然发现一个重大bug，需要重新打版本，可以按下面方法来出来： 删除本地标签： git tag -d V1.0 推送同名的空的标签到远程服务器，达到删除的目的： git push origin :refs/tags/V1.0 mutian@mutian-ThinkPad-T440p:~/dev/java/github/ymu-framework$ git push origin :refs/tags/V1.0 Username for &apos;https://github.com&apos;: xinxiamu Password for &apos;https://xinxiamu@github.com&apos;: To https://github.com/xinxiamu/ymu-framework.git - [deleted] V1.0 拉取并切换到对应分支，在该分支上修复bug。 如果远程服务器没有该分支，则可以基于该tag创建分支。并在新建分支上修改bug。 git checkout -B test v0.1.0 强制创建一个基于指定的tag的分支。 test为分支名称，v0.1.0为标签。 按照上面步骤重新打标签并推送到远程服务器封存。 合并该分支修改到主干分支master上，否则下次该bug还是存在。 获取远程指定的封存版本更适合运维，拉取指定稳定版本进行发布到生产环境。 git fetch origin tag V1.0 切换到taggit checkout V1.0 删除taggit tag -d V1.0 特别提醒（来源网络）git 获取指定的tag处代码 tag是对历史提交的一个id的引用，如果理解这句话就明白了tag的含义 使用git checkout tag即可切换到指定tag，例如：git checkout v0.1.0 切换到tag历史记录 会使当前指针处在分离头指针状态，这个时候的修改是很危险的，在切换回主线时如果没有合并，之前的修改提交基本都会丢失，如果需要修改可以尝试git checkout -b branch tag创建一个基于指定tag的分支，例如：git checkout -b test v0.1.0 这个时候就在这个test分支上进行开发，之后可以切换到主线合并。 注意这时候的test分支的代码很多都是tag版本处的，但是test分支head节点在最前面，这时候切换到主线进行合并，要注意合并后的代码冲突问题，不要让旧代码覆盖了主线的新代码。 git checkout -B这个命令，可以强制创建新的分支，为什么加-B呢？如果当前仓库中，已经存在一个跟你新建分支同名的分支，那么使用普通的git checkout -b 这个命令，是会报错的，且同名分支无法创建。如果使用-B参数，那么就可以强制创建新的分支，并会覆盖掉原来的分支。 git checkout -B test v0.1.0 强制创建一个基于指定的tag的分支。 注：不要切换到tag上修改，否则切换回到master，可能造成代码丢失。切记切记……","tags":[{"name":"git-tag","slug":"git-tag","permalink":"https://xinxiamu.github.io/tags/git-tag/"}]},{"title":"git分支管理","date":"2018-06-23T07:29:33.000Z","path":"2018/06/23/git-branch/","text":"在项目开发过程中，为了更好的开发，管理上需要对代码做版本管理。一般情况下，在开发之前就理应设定开发版本，然后开发人员在对应版本上编写代码，管理者再在某个时刻把分支branch代码合并回主分支。在最终稳定一个版本后，再打tag做版本永久保存。 首先，要当前目录为git仓库。git仓库拉取下来默认是master分支。 创建本地分支 查看有哪些分支 git branch 创建一个分支 git branch name1 name1为分支名称。不能和tag的相同 切换到分支 git checkout name1 实际上，2和3步骤也可以一步到位：git checkout -b name。创建并切换到分支 下面，就可以在该分支上进行文件操作了。 _注意_:如果用 git checkout master切换到主分支，在当name分支下进行的文件变更的内容无法看到。当切回name分支后，又可以看到了。 提交分支到服务器git push origin name1 说明：提交分支到服务器后，在本地分支进行文件变更后，可以执行上面同样命令，将变更信息更新到服务器上的该分支。 将分支变更的内容合并到master分支 切换到master分支： git checkout master 合并name1分支到当前master分支： git merge name1 _注意_: 这个时候合并到master分支上的内容还没提交到服务器的，需要push提交。 删除分支 删除本地分支：git branch -d name1 删除服务器上的分支： git push origin :name (分支名前的冒号代表删除) clone分支git仓库拉取下来，默认会把所有内容clone下来。但是默认只创建master分支，需要执行git branch -r才能看到所有分支名字。想把其它分支拉取下来，执行： git checkout 分支名。这样就把远程的分支拉取下来了。再执行git branch，就能看到本地所有的分支了。然后可以切换分支编辑。","tags":[{"name":"git分支、github分支","slug":"git分支、github分支","permalink":"https://xinxiamu.github.io/tags/git分支、github分支/"}]},{"title":"angular入门","date":"2018-06-23T02:32:10.000Z","path":"2018/06/23/angular-start/","text":"本文介绍如何搭建angular开发环境…… 中文官网英文官网 环境安装ubuntu下nodejs、npm环境 下载：https://nodejs.org/en/download/ nodejs自带npm。 现在二进制包，解压到相关目录。 配置nodejs环境变量。 export NODE_HOME=~/Desktop/work/tools/node export PATH=${NODE_HOME}/bin:$PATH 检查安装是否成功 zmt@zmt-Lenovo:~$ node -v v10.4.1 zmt@zmt-Lenovo:~$ npm -v 6.1.0 安装npm淘宝镜像 npm install -g cnpm --registry=https://registry.npm.taobao.org 设置npm的镜像地址 1.查看默认 &gt; npm get registry http://registry.npmjs.org 2.设置 npm set registry https://registry.npm.taobao.org 3.再次查看 &gt; npm get registry https://registry.npm.taobao.org/ 可以看到，已经设置成淘宝的npm镜像了。这样，后面使用ng-cli的时候，默认的npm就是从淘宝镜像获取依赖了。 angular-cli 安装 全局安装 cnpm install -g @angular/cli Windows环境下直接下载nodejs的可执行文件，运行安装即可。安装成功后，打开命令行窗口检查是否安装成功。 node -vnpm -v 显示安装的版本号，则表明正常安装。 后面步骤同上…… 跑起angular项目 创建新项目 ng new my-app 启动服务器 cd my-app ng serve --open 或者 ng serve -o 如果一切顺利，会自动打开浏览器显示网页。至此，一个hello wold项目完成了。 卸载并安装指定版本Angular CLI1.卸载之前的版本 npm uninstall -g @angular/cli 2.清除缓存，确保卸载干净 npm cache clean –force 3.检查是否卸载干净 输入命令 ng -v 若显示command not found则卸载干净 4.安装指定版本 npm install -g @angular/cli@1.6.3 5.检查版本号 ng version","tags":[]},{"title":"aws云服务器使用","date":"2018-06-21T06:22:55.000Z","path":"2018/06/21/aws-server/","text":"本文记录在使用亚马逊云服务器aws过程中遇到的一些问题…… 1.登录到aws云服务器 下载私钥*.pem,放到指定目录下。 给予私钥权限。chmod 400 .pem ssh登录。ssh -i ~/aws-server-key/Seoul-Server-Key.pem ubuntu@13.209.47.139 2.在安全组开放端口3.上传文件aws服务器 IPv4： # chmod 400 /path/my-key-pair.pem # scp -i /path/my-key-pair.pem /path/SampleFile.txt ec2-user@ec2-198-51-100-1.compute-1.amazonaws.com:~ (仅限 IPv6) 或者,您可以使用实例的 IPv6 地址传输文件。IPv6 地址必须用方括号 ([]) 括起,方括号必须转义 ()。 scp -i /path/my-key-pair.pem /path/SampleFile.txt ec2-user@ \\[2001:db8:1234:1a00:9691:9503:25ad:1761\\]:~ 小提示:对于 Amazon Linux,用户名为 ec2-user。对于 RHEL,用户名称是 ec2-user 或 root。对于 Ubuntu,用户名称是 ubuntu 或 root。对于 Centos,用户名称是 centos。对于Fedora,用户名称是 ec2-user。对于 SUSE,用户名称是 ec2-user 或 root。另外,如果ec2-user 和 root 无法使用,请与您的 AMI 供应商核实。 4.下载文件到本机 IPv4： scp -i /path/my-key-pair.pem ec2-user@ec2-198-51-100-1.compute-1.amazonaws.com:~/ SampleFile.txt ~/SampleFile2.txt (仅限 IPv6) 或者,您可以使用实例的 IPv6 地址反方向传输文件。 scp -i /path/my-key-pair.pem ec2-user@\\[2001:db8:1234:1a00:9691:9503:25ad:1761\\]:~/ SampleFile.txt ~/SampleFile2.txt","tags":[{"name":"aws云服务器","slug":"aws云服务器","permalink":"https://xinxiamu.github.io/tags/aws云服务器/"}]},{"title":"wkhtmltopdf使用记录","date":"2018-06-19T10:32:21.000Z","path":"2018/06/19/wkhtmltopdf/","text":"html转pdf工具wkhtmltopdf的使用记录…… 官网：https://wkhtmltopdf.org/ 使用文档：https://wkhtmltopdf.org/usage/wkhtmltopdf.txthttps://www.cnblogs.com/colder/p/5819197.html centos下安装环境1.依赖包安装： yum install zlib fontconfig freetype libX11 libXext libXrender2.下载执行包解压，放在固定目录下。3.赋予执行包可执行权限：chmod a+x wkhtmltopdf。4.把相关字体放到usr/share/fonts。5.直接调用下面命令执行就可以了。 使用问题收集1.中文字体乱码的问题。 linux：把字体simsun.ttc添加到系统usr/share/fonts下。 2.设定纸张大小，内容随纸张大小。 3.Arial字体 直接把Arial中相关字体文件添加到系统usr/share/fonts。 参考：https://blog.csdn.net/churujianghu/article/details/75076255 示例： ./wkhtmltopdf --page-height 5cm --page-width 7cm --margin-bottom 0cm --margin-top 0.1cm --margin-left 0.1cm --margin-right 0cm --disable-smart-shrinking label.html label.html label.html label.pdf 页眉处理样例1： wkhtmltopdf.exe --footer-left &quot;cxmr(500) 制表日期：[date] [time]&quot; --footer-right &quot;制表者： XC-TEST001 页次： [page]/[topage]&quot; --footer-line orders-atn.html a.pdf 样例2： wkhtmltopdf.exe --footer-left &quot;cxmr(500) 制表日期：[date] [time]&quot; --footer-right &quot;制表者： XC-TEST001 页次： [page]/[topage]&quot; --footer-line --footer-font-size 8 --footer-spacing 5 orders-atn.html b.pdf 样例3： wkhtmltopdf.exe --footer-left &quot;cxmr(500) 制表日期：[date] [time]&quot; --footer-right &quot;制表者： XC-TEST001 页次： [page]/[topage]&quot; --footer-line --footer-font-size 8 --footer-spacing 5 orders-atn.html orders-atn.html orders-atn.html b.pdf 精准打印出现中文不清晰，缺少笔画–disable-smart-shrinking 这个参数一定要加上，加上页面就不缩小了；–dpi 这个参数不要用默认值，要设置大一点；letter-spacinng : 0 不然字间距太密； 特别加上dpi参数。","tags":[{"name":"wkhtmltopdf","slug":"wkhtmltopdf","permalink":"https://xinxiamu.github.io/tags/wkhtmltopdf/"}]},{"title":"后端架构师技术图谱","date":"2018-06-19T00:51:42.000Z","path":"2018/06/19/architect-awesome/","text":"列出了后端架构师要掌握的基本知识。少壮不努力，老大徒伤悲…… 本文拷贝自https://github.com/xingshaocheng/architect-awesome 《后端架构师技术图谱》 更新于20180513 数据结构 队列 集合 链表、数组 字典、关联数组 栈 树 二叉树 完全二叉树 平衡二叉树 二叉查找树（BST） 红黑树 B-，B+，B*树 LSM 树 BitSet 常用算法 排序、查找算法 选择排序 冒泡排序 插入排序 快速排序 归并排序 希尔排序 堆排序 计数排序 桶排序 基数排序 二分查找 Java 中的排序工具 布隆过滤器 字符串比较 KMP 算法 深度优先、广度优先 贪心算法 回溯算法 剪枝算法 动态规划 朴素贝叶斯 推荐算法 最小生成树算法 最短路径算法 并发 多线程 线程安全 一致性、事务 事务 ACID 特性 事务的隔离级别 MVCC 锁 Java中的锁和同步类 公平锁 &amp; 非公平锁 悲观锁 乐观锁 &amp; CAS ABA 问题 CopyOnWrite容器 RingBuffer 可重入锁 &amp; 不可重入锁 互斥锁 &amp; 共享锁 死锁 操作系统 计算机原理 CPU 多级缓存 进程 线程 协程 Linux 设计模式 设计模式的六大原则 23种常见设计模式 应用场景 单例模式 责任链模式 MVC IOC AOP UML 微服务思想 康威定律 运维 &amp; 统计 &amp; 技术支持 常规监控 APM 统计分析 持续集成(CI/CD) Jenkins 环境分离 自动化运维 Ansible puppet chef 测试 TDD 理论 单元测试 压力测试 全链路压测 A/B 、灰度、蓝绿测试 虚拟化 KVM Xen OpenVZ 容器技术 Docker 云技术 OpenStack DevOps 文档管理 中间件 Web Server Nginx OpenResty Apache Httpd Tomcat 架构原理 调优方案 Jetty 缓存 本地缓存 客户端缓存 服务端缓存 Web缓存 Memcached Redis 架构 回收策略 Tair 消息队列 消息总线 消息的顺序 RabbitMQ RocketMQ ActiveMQ Kafka Redis 消息推送 ZeroMQ 定时调度 单机定时调度 分布式定时调度 RPC Dubbo Thrift gRPC 数据库中间件 Sharding Jdbc 日志系统 日志搜集 配置中心 API 网关 网络 协议 OSI 七层协议 TCP/IP HTTP HTTP2.0 HTTPS 网络模型 Epoll Java NIO kqueue 连接和短连接 框架 零拷贝（Zero-copy） 序列化(二进制协议) Hessian Protobuf 数据库 基础理论 数据库设计的三大范式 MySQL 原理 InnoDB 优化 索引 聚集索引, 非聚集索引 复合索引 自适应哈希索引(AHI) explain NoSQL MongoDB Hbase 搜索引擎 搜索引擎原理 Lucene Elasticsearch Solr sphinx 性能 性能优化方法论 容量评估 CDN 网络 连接池 性能调优 大数据 流式计算 Storm Flink Kafka Stream 应用场景 Hadoop HDFS MapReduce Yarn Spark 安全 web 安全 XSS CSRF SQL 注入 Hash Dos 脚本注入 漏洞扫描工具 验证码 DDoS 防范 用户隐私信息保护 序列化漏洞 加密解密 对称加密 哈希算法 非对称加密 服务器安全 数据安全 数据备份 网络隔离 内外网分离 登录跳板机 授权、认证 RBAC OAuth2.0 双因素认证（2FA） 单点登录(SSO) 常用开源框架 开源协议 日志框架 Log4j、Log4j2 Logback ORM 网络框架 Web 框架 Spring 家族 工具框架 分布式设计 扩展性设计 稳定性 &amp; 高可用 硬件负载均衡 软件负载均衡 限流 应用层容灾 跨机房容灾 容灾演练流程 平滑启动 数据库扩展 读写分离模式 分片模式 服务治理 服务注册与发现 服务路由控制 分布式一致 CAP 与 BASE 理论 分布式锁 分布式一致性算法 PAXOS Zab Raft Gossip 两阶段提交、多阶段提交 幂等 分布式一致方案 分布式 Leader 节点选举 TCC(Try/Confirm/Cancel) 柔性事务 分布式文件系统 唯一ID 生成 全局唯一ID 一致性Hash算法 设计思想 &amp; 开发模式 DDD(Domain-driven Design - 领域驱动设计) 命令查询职责分离(CQRS) 贫血，充血模型 Actor 模式 响应式编程 Reactor RxJava Vert.x DODAF2.0 Serverless Service Mesh 项目管理 架构评审 重构 代码规范 代码 Review RUP 看板管理 SCRUM 敏捷开发 极限编程（XP） 结对编程 FMEA管理模式 通用业务术语 技术趋势 政策、法规 法律 严格遵守刑法253法条 架构师素质 团队管理 招聘 资讯 行业资讯 公众号列表 博客 团队博客 个人博客 综合门户、社区 问答、讨论类社区 行业数据分析 专项网站 其他类 推荐参考书 在线电子书 纸质书 开发方面 架构方面 技术管理方面 基础理论 工具方面 大数据方面 技术资源 开源资源 手册、文档、教程 在线课堂 会议、活动 常用APP 找工作 工具 代码托管 文件服务 综合云服务商 VPS （Toc generated by simple-php-github-toc ） 数据结构队列 《java队列——queue详细分析》 非阻塞队列：ConcurrentLinkedQueue(无界线程安全)，采用CAS机制（compareAndSwapObject原子操作）。 阻塞队列：ArrayBlockingQueue(有界)、LinkedBlockingQueue（无界）、DelayQueue、PriorityBlockingQueue，采用锁机制；使用 ReentrantLock 锁。 《LinkedList、ConcurrentLinkedQueue、LinkedBlockingQueue对比分析》 集合 《Java Set集合的详解》 链表、数组 《Java集合详解–什么是List》 字典、关联数组 《Java map 详解 - 用法、遍历、排序、常用API等》 栈 《java数据结构与算法之栈（Stack）设计与实现》 《Java Stack 类》 《java stack的详细实现分析》 Stack 是线程安全的。 内部使用数组保存数据，不够时翻倍。 树二叉树每个节点最多有两个叶子节点。 《二叉树》 完全二叉树 《完全二叉树》 叶节点只能出现在最下层和次下层，并且最下面一层的结点都集中在该层最左边的若干位置的二叉树。 平衡二叉树左右两个子树的高度差的绝对值不超过1，并且左右两个子树都是一棵平衡二叉树。 《浅谈数据结构-平衡二叉树》 《浅谈算法和数据结构: 八 平衡查找树之2-3树》 二叉查找树（BST）二叉查找树（Binary Search Tree），也称有序二叉树（ordered binary tree）,排序二叉树（sorted binary tree）。 《浅谈算法和数据结构: 七 二叉查找树》 红黑树 《最容易懂得红黑树》 添加阶段后，左旋或者右旋从而再次达到平衡。 《浅谈算法和数据结构: 九 平衡查找树之红黑树》 B-，B+，B*树MySQL是基于B+树聚集索引组织表 《B-树，B+树，B*树详解》 《B-树，B+树与B*树的优缺点比较》 B+ 树的叶子节点链表结构相比于 B- 树便于扫库，和范围检索。LSM 树 LSM（Log-Structured Merge-Trees）和 B+ 树相比，是牺牲了部分读的性能来换取写的性能(通过批量写入)，实现读写之间的。Hbase、LevelDB、Tair（Long DB）、nessDB 采用 LSM 树的结构。LSM可以快速建立索引。 《LSM树 VS B+树》 B+ 树读性能好，但由于需要有序结构，当key比较分散时，磁盘寻道频繁，造成写性能。 LSM 是将一个大树拆分成N棵小树，先写到内存（无寻道问题，性能高），在内存中构建一颗有序小树（有序树），随着小树越来越大，内存的小树会flush到磁盘上。当读时，由于不知道数据在哪棵小树上，因此必须遍历（二分查找）所有的小树，但在每颗小树内部数据是有序的。 《LSM树（Log-Structured Merge Tree）存储引擎》 极端的说，基于LSM树实现的HBase的写性能比MySQL高了一个数量级，读性能低了一个数量级。 优化方式：Bloom filter 替代二分查找；compact 小数位大树，提高查询性能。 Hbase 中，内存中达到一定阈值后，整体flush到磁盘上、形成一个文件（B+数），HDFS不支持update操作，所以Hbase做整体flush而不是merge update。flush到磁盘上的小树，定期会合并成一个大树。 BitSet经常用于大规模数据的排重检查。 《Java Bitset类》 《Java BitSet（位集）》 常用算法 《常见排序算法及对应的时间复杂度和空间复杂度》 排序、查找算法 《常见排序算法及对应的时间复杂度和空间复杂度》 选择排序 《Java中的经典算法之选择排序（SelectionSort）》 每一趟从待排序的记录中选出最小的元素，顺序放在已排好序的序列最后，直到全部记录排序完毕。 冒泡排序 《冒泡排序的2种写法》 相邻元素前后交换、把最大的排到最后。 时间复杂度 O(n²) 插入排序 《排序算法总结之插入排序》 快速排序 《坐在马桶上看算法：快速排序》 一侧比另外一次都大或小。 归并排序 《图解排序算法(四)之归并排序》 分而治之，分成小份排序，在合并(重建一个新空间进行复制)。 希尔排序TODO 堆排序 《图解排序算法(三)之堆排序》 排序过程就是构建最大堆的过程，最大堆：每个结点的值都大于或等于其左右孩子结点的值，堆顶元素是最大值。 计数排序 《计数排序和桶排序》 和桶排序过程比较像，差别在于桶的数量。 桶排序 《【啊哈！算法】最快最简单的排序——桶排序》 《排序算法（三）：计数排序与桶排序》 桶排序将[0,1)区间划分为n个相同的大小的子区间，这些子区间被称为桶。 每个桶单独进行排序，然后再遍历每个桶。 基数排序按照个位、十位、百位、…依次来排。 《排序算法系列：基数排序》 《基数排序》 二分查找 《二分查找(java实现)》 要求待查找的序列有序。 时间复杂度 O(logN)。 《java实现二分查找-两种方式》 while + 递归。Java 中的排序工具 《Arrays.sort和Collections.sort实现原理解析》 Collections.sort算法调用的是合并排序。 Arrays.sort() 采用了2种排序算法 – 基本类型数据使用快速排序法，对象数组使用归并排序。 布隆过滤器常用于大数据的排重，比如email，url 等。核心原理：将每条数据通过计算产生一个指纹（一个字节或多个字节，但一定比原始数据要少很多），其中每一位都是通过随机计算获得，在将指纹映射到一个大的按位存储的空间中。注意：会有一定的错误率。优点：空间和时间效率都很高。缺点：随着存入的元素数量增加，误算率随之增加。 《布隆过滤器 – 空间效率很高的数据结构》 《大量数据去重：Bitmap和布隆过滤器(Bloom Filter)》 《基于Redis的布隆过滤器的实现》 基于 Redis 的 Bitmap 数据结构。 《网络爬虫：URL去重策略之布隆过滤器(BloomFilter)的使用》 使用Java中的 BitSet 类 和 加权和hash算法。 字符串比较KMP 算法KMP：Knuth-Morris-Pratt算法（简称KMP）核心原理是利用一个“部分匹配表”，跳过已经匹配过的元素。 《字符串匹配的KMP算法》 深度优先、广度优先 《广度优先搜索BFS和深度优先搜索DFS》 贪心算法 《算法：贪婪算法基础》 《常见算法及问题场景——贪心算法》 回溯算法 《 五大常用算法之四：回溯法》 剪枝算法 《α-β剪枝算法》 动态规划 《详解动态规划——邹博讲动态规划》 《动态规划算法的个人理解》 朴素贝叶斯 《带你搞懂朴素贝叶斯分类算法》 P(B|A)=P(A|B)P(B)/P(A) 《贝叶斯推断及其互联网应用1》 《贝叶斯推断及其互联网应用2》 推荐算法 《推荐算法综述》 《TOP 10 开源的推荐系统简介》 最小生成树算法 《算法导论–最小生成树（Kruskal和Prim算法）》 最短路径算法 《Dijkstra算法详解》 并发Java 并发 Java 并发知识合集 JAVA并发知识图谱 多线程 《40个Java多线程问题总结》 线程安全 《Java并发编程——线程安全及解决机制简介》 一致性、事务事务 ACID 特性 《数据库事务ACID特性》 事务的隔离级别 未提交读：一个事务可以读取另一个未提交的数据，容易出现脏读的情况。 读提交：一个事务等另外一个事务提交之后才可以读取数据，但会出现不可重复读的情况（多次读取的数据不一致），读取过程中出现UPDATE操作，会多。（大多数数据库默认级别是RC，比如SQL Server，Oracle），读取的时候不可以修改。 可重复读： 同一个事务里确保每次读取的时候，获得的是同样的数据，但不保障原始数据被其他事务更新（幻读），Mysql InnoDB 就是这个级别。 序列化：所有事物串行处理（牺牲了效率） 《理解事务的4种隔离级别》 数据库事务的四大特性及事务隔离级别 《MySQL的InnoDB的幻读问题 》 幻读的例子非常清楚。 通过 SELECT … FOR UPDATE 解决。 《一篇文章带你读懂MySQL和InnoDB》 图解脏读、不可重复读、幻读问题。 MVCC 《【mysql】关于innodb中MVCC的一些理解》 innodb 中 MVCC 用在 Repeatable-Read 隔离级别。 MVCC 会产生幻读问题（更新时异常。） 《轻松理解MYSQL MVCC 实现机制》 通过隐藏版本列来实现 MVCC 控制，一列记录创建时间、一列记录删除时间，这里的时间 每次只操作比当前版本小（或等于）的 行。 锁Java中的锁和同步类 《Java中的锁分类》 主要包括 synchronized、ReentrantLock、和 ReadWriteLock。 《Java并发之AQS详解》 《Java中信号量 Semaphore》 有数量控制 申请用 acquire，申请不要则阻塞；释放用 release。 《java开发中的Mutex vs Semaphore》 简单的说 就是Mutex是排它的，只有一个可以获取到资源， Semaphore也具有排它性，但可以定义多个可以获取的资源的对象。 公平锁 &amp; 非公平锁公平锁的作用就是严格按照线程启动的顺序来执行的，不允许其他线程插队执行的；而非公平锁是允许插队的。 《公平锁与非公平锁》 默认情况下 ReentrantLock 和 synchronized 都是非公平锁。ReentrantLock 可以设置成公平锁。 悲观锁悲观锁如果使用不当（锁的条数过多），会引起服务大面积等待。推荐优先使用乐观锁+重试。 《【MySQL】悲观锁&amp;乐观锁》 乐观锁的方式：版本号+重试方式 悲观锁：通过 select … for update 进行行锁(不可读、不可写，share 锁可读不可写)。 《Mysql查询语句使用select.. for update导致的数据库死锁分析》 mysql的innodb存储引擎实务锁虽然是锁行，但它内部是锁索引的。 锁相同数据的不同索引条件可能会引起死锁。 《Mysql并发时经典常见的死锁原因及解决方法》 乐观锁 &amp; CAS 《乐观锁的一种实现方式——CAS》 和MySQL乐观锁方式相似，只不过是通过和原值进行比较。 ABA 问题由于高并发，在CAS下，更新后可能此A非彼A。通过版本号可以解决，类似于上文Mysql 中提到的的乐观锁。 《Java CAS 和ABA问题》 《Java 中 ABA问题及避免》 AtomicStampedReference 和 AtomicStampedReference。 CopyOnWrite容器可以对CopyOnWrite容器进行并发的读，而不需要加锁。CopyOnWrite并发容器用于读多写少的并发场景。比如白名单，黑名单，商品类目的访问和更新场景，不适合需要数据强一致性的场景。 《JAVA中写时复制(Copy-On-Write)Map实现》 实现读写分离，读取发生在原始数据上，写入发生在副本上。 不用加锁，通过最终一致实现一致性。 《聊聊并发-Java中的Copy-On-Write容器》 RingBuffer 《线程安全的无锁RingBuffer的实现【一个读线程，一个写线程】》 可重入锁 &amp; 不可重入锁 《可重入锁和不可重入锁》 通过简单代码举例说明可重入锁和不可重入锁。 可重入锁指同一个线程可以再次获得之前已经获得的锁。 可重入锁可以用户避免死锁。 Java中的可重入锁：synchronized 和 java.util.concurrent.locks.ReentrantLock 《ReenTrantLock可重入锁（和synchronized的区别）总结》 synchronized 使用方便，编译器来加锁，是非公平锁。 ReenTrantLock 使用灵活，锁的公平性可以定制。 相同加锁场景下，推荐使用 synchronized。 互斥锁 &amp; 共享锁互斥锁：同时只能有一个线程获得锁。比如，ReentrantLock 是互斥锁，ReadWriteLock 中的写锁是互斥锁。共享锁：可以有多个线程同时或的锁。比如，Semaphore、CountDownLatch 是共享锁，ReadWriteLock 中的读锁是共享锁。 《ReadWriteLock场景应用》 死锁 《“死锁”四个必要条件的合理解释》 互斥、持有、不可剥夺、环形等待。 Java如何查看死锁？ JConsole 可以识别死锁。 java多线程系列：死锁及检测 jstack 可以显示死锁。 操作系统计算机原理 《操作系统基础知识——操作系统的原理，类型和结构》 CPU多级缓存典型的 CPU 有三级缓存，距离核心越近，速度越快，空间越小。L1 一般 32k，L2 一般 256k，L3 一般12M。内存速度需要200个 CPU 周期，CPU 缓存需要1个CPU周期。 《从Java视角理解CPU缓存和伪共享》 进程TODO 线程 《线程的生命周期及状态转换详解》 协程 《终结python协程—-从yield到actor模型的实现》 线程的调度是由操作系统负责，协程调度是程序自行负责 与线程相比，协程减少了无谓的操作系统切换. 实际上当遇到IO操作时做切换才更有意义，（因为IO操作不用占用CPU），如果没遇到IO操作，按照时间片切换. Linux 《Linux 命令大全》 设计模式设计模式的六大原则 《设计模式的六大原则》 开闭原则：对扩展开放,对修改关闭，多使用抽象类和接口。 里氏替换原则：基类可以被子类替换，使用抽象类继承,不使用具体类继承。 依赖倒转原则：要依赖于抽象,不要依赖于具体，针对接口编程,不针对实现编程。 接口隔离原则：使用多个隔离的接口,比使用单个接口好，建立最小的接口。 迪米特法则：一个软件实体应当尽可能少地与其他实体发生相互作用，通过中间类建立联系。 合成复用原则：尽量使用合成/聚合,而不是使用继承。 23种常见设计模式 《设计模式》 《23种设计模式全解析》 应用场景 《细数JDK里的设计模式》 结构型模式： 适配器：用来把一个接口转化成另一个接口，如 java.util.Arrays#asList()。 桥接模式：这个模式将抽象和抽象操作的实现进行了解耦，这样使得抽象和实现可以独立地变化，如JDBC； 组合模式：使得客户端看来单个对象和对象的组合是同等的。换句话说，某个类型的方法同时也接受自身类型作为参数，如 Map.putAll，List.addAll、Set.addAll。 装饰者模式：动态的给一个对象附加额外的功能，这也是子类的一种替代方式，如 java.util.Collections#checkedList|Map|Set|SortedSet|SortedMap。 享元模式：使用缓存来加速大量小对象的访问时间，如 valueOf(int)。 代理模式：代理模式是用一个简单的对象来代替一个复杂的或者创建耗时的对象，如 java.lang.reflect.Proxy 创建模式: 抽象工厂模式：抽象工厂模式提供了一个协议来生成一系列的相关或者独立的对象，而不用指定具体对象的类型，如 java.util.Calendar#getInstance()。 建造模式(Builder)：定义了一个新的类来构建另一个类的实例，以简化复杂对象的创建，如：java.lang.StringBuilder#append()。 工厂方法：就是 一个返* 回具体对象的方法，而不是多个，如 java.lang.Object#toString()、java.lang.Class#newInstance()。 原型模式：使得类的实例能够生成自身的拷贝、如：java.lang.Object#clone()。 单例模式：全局只有一个实例，如 java.lang.Runtime#getRuntime()。 行为模式： 责任链模式：通过把请求从一个对象传递到链条中下一个对象的方式，直到请求被处理完毕，以实现对象间的解耦。如 javax.servlet.Filter#doFilter()。 命令模式：将操作封装到对象内，以便存储，传递和返回，如：java.lang.Runnable。 解释器模式：定义了一个语言的语法，然后解析相应语法的语句，如，java.text.Format，java.text.Normalizer。 迭代器模式：提供一个一致的方法来顺序访问集合中的对象，如 java.util.Iterator。 中介者模式：通过使用一个中间对象来进行消息分发以及减少类之间的直接依赖，java.lang.reflect.Method#invoke()。 空对象模式：如 java.util.Collections#emptyList()。 观察者模式：它使得一个对象可以灵活的将消息发送给感兴趣的对象，如 java.util.EventListener。 模板方法模式：让子类可以重写方法的一部分，而不是整个重写，如 java.util.Collections#sort()。 《Spring-涉及到的设计模式汇总》 《Mybatis使用的设计模式》 单例模式 《单例模式的三种实现 以及各自的优缺点》 《单例模式－－反射－－防止序列化破坏单例模式》 使用枚举类型。 责任链模式TODO MVC 《MVC 模式》 模型(model)－视图(view)－控制器(controller) IOC 《理解 IOC》 《IOC 的理解与解释》 正向控制：传统通过new的方式。反向控制，通过容器注入对象。 作用：用于模块解耦。 DI：Dependency Injection，即依赖注入，只关心资源使用，不关心资源来源。 AOP 《轻松理解AOP(面向切面编程)》 《Spring AOP详解》 《Spring AOP的实现原理》 Spring AOP使用的动态代理，主要有两种方式：JDK动态代理和CGLIB动态代理。 《Spring AOP 实现原理与 CGLIB 应用》 Spring AOP 框架对 AOP 代理类的处理原则是：如果目标对象的实现类实现了接口，Spring AOP 将会采用 JDK 动态代理来生成 AOP 代理类；如果目标对象的实现类没有实现接口，Spring AOP 将会采用 CGLIB 来生成 AOP 代理类 UML 《UML教程》 微服务思想 《微服务架构设计》 《微服务架构技术栈选型手册》 康威定律 《微服务架构的理论基础 - 康威定律》 定律一：组织沟通方式会通过系统设计表达出来，就是说架构的布局和组织结构会有相似。 定律二：时间再多一件事情也不可能做的完美，但总有时间做完一件事情。一口气吃不成胖子，先搞定能搞定的。 定律三：线型系统和线型组织架构间有潜在的异质同态特性。种瓜得瓜，做独立自治的子系统减少沟通成本。 定律四：大的系统组织总是比小系统更倾向于分解。合久必分，分而治之。 《微服务架构核⼼20讲》 运维 &amp; 统计 &amp; 技术支持常规监控 《腾讯业务系统监控的修炼之路》 监控的方式：主动、被动、旁路(比如舆情监控) 监控类型： 基础监控、服务端监控、客户端监控、监控、用户端监控 监控的目标：全、块、准 核心指标：请求量、成功率、耗时 《开源还是商用？十大云运维监控工具横评》 Zabbix、Nagios、Ganglia、Zenoss、Open-falcon、监控宝、 360网站服务监控、阿里云监控、百度云观测、小蜜蜂网站监测等。 《监控报警系统搭建及二次开发经验》 命令行监控工具 《常用命令行监控工具》 top、sar、tsar、nload 《20个命令行工具监控 Linux 系统性能》 《JVM性能调优监控工具jps、jstack、jmap、jhat、jstat、hprof使用详解》 APMAPM — Application Performance Management 《Dapper，大规模分布式系统的跟踪系统》 CNCF OpenTracing，中文版 主要开源软件，按字母排序 Apache SkyWalking CAT CNCF jaeger Pinpoint Zipkin 《开源APM技术选型与实战》 主要基于 Google的Dapper（大规模分布式系统的跟踪系统） 思想。 统计分析 《流量统计的基础：埋点》 常用指标：访问与访客、停留时长、跳出率、退出率、转化率、参与度 《APP埋点常用的统计工具、埋点目标和埋点内容》 第三方统计：友盟、百度移动、魔方、App Annie、talking data、神策数据等。 《美团点评前端无痕埋点实践》 所谓无痕、即通过可视化工具配置采集节点，在前端自动解析配置并上报埋点数据，而非硬编码。 持续集成(CI/CD) 《持续集成是什么？》 《8个流行的持续集成工具》 Jenkins 《使用Jenkins进行持续集成》 环境分离开发、测试、生成环境分离。 《开发环境、生产环境、测试环境的基本理解和区》 自动化运维Ansible 《Ansible中文权威指南》 《Ansible基础配置和企业级项目实用案例》 puppet 《自动化运维工具——puppet详解》 chef 《Chef 的安装与使用》 测试TDD 理论 《深度解读 - TDD（测试驱动开发）》 基于测试用例编码功能代码，XP（Extreme Programming）的核心实践. 好处：一次关注一个点，降低思维负担；迎接需求变化或改善代码的设计；提前澄清需求；快速反馈； 单元测试 《Java单元测试之JUnit篇》 《JUnit 4 与 TestNG 对比》 TestNG 覆盖 JUnit 功能，适用于更复杂的场景。 《单元测试主要的测试功能点》 模块接口测试、局部数据结构测试、路径测试 、错误处理测试、边界条件测试 。 压力测试 《Apache ab 测试使用指南》 《大型网站压力测试及优化方案》 《10大主流压力/负载/性能测试工具推荐》 《真实流量压测工具 tcpcopy应用浅析》 《nGrinder 简易使用教程》 全链路压测 《京东618：升级全链路压测方案，打造军演机器人ForceBot》 《饿了么全链路压测的探索与实践》 《四大语言，八大框架｜滴滴全链路压测解决之道》 《全链路压测经验》 A/B 、灰度、蓝绿测试 《技术干货 | AB 测试和灰度发布探索及实践》 《nginx 根据IP 进行灰度发布》 《蓝绿部署、A/B 测试以及灰度发布》 虚拟化 《VPS的三种虚拟技术OpenVZ、Xen、KVM优缺点比较》 KVM 《KVM详解，太详细太深入了，经典》 《【图文】KVM 虚拟机安装详解》 Xen 《Xen虚拟化基本原理详解》 OpenVZ 《开源Linux容器 OpenVZ 快速上手指南》 容器技术Docker 《几张图帮你理解 docker 基本原理及快速入门》 《Docker 核心技术与实现原理》 《Docker 教程》 云技术OpenStack 《OpenStack构架知识梳理》 DevOps 《一分钟告诉你究竟DevOps是什么鬼？》 《DevOps详解》 文档管理 Confluence-收费文档管理系统 GitLab? Wiki 中间件Web ServerNginx 《Ngnix的基本学习-多进程和Apache的比较》 Nginx 通过异步非阻塞的事件处理机制实现高并发。Apache 每个请求独占一个线程，非常消耗系统资源。 事件驱动适合于IO密集型服务(Nginx)，多进程或线程适合于CPU密集型服务(Apache)，所以Nginx适合做反向代理，而非web服务器使用。 《nginx与Apache的对比以及优缺点》 nginx只适合静态和反向代理，不适合处理动态请求。 OpenResty 官方网站 《浅谈 OpenResty》 通过 Lua 模块可以在Nginx上进行开发。 Apache Httpd 官方网站 Tomcat架构原理 《TOMCAT原理详解及请求过程》 《Tomcat服务器原理详解》 《Tomcat 系统架构与设计模式,第 1 部分: 工作原理》 《四张图带你了解Tomcat系统架构》 《JBoss vs. Tomcat: Choosing A Java Application Server》 Tomcat 是轻量级的 Serverlet 容器，没有实现全部 JEE 特性（比如持久化和事务处理），但可以通过其他组件代替，比如Srping。 Jboss 实现全部了JEE特性，软件开源免费、文档收费。 调优方案 《Tomcat 调优方案》 启动NIO模式（或者APR）；调整线程池；禁用AJP连接器（Nginx+tomcat的架构，不需要AJP）； 《tomcat http协议与ajp协议》 《AJP与HTTP比较和分析》 AJP 协议（8009端口）用于降低和前端Server（如Apache，而且需要支持AJP协议）的连接数(前端)，通过长连接提高性能。 并发高时，AJP协议优于HTTP协议。 Jetty 《Jetty 的工作原理以及与 Tomcat 的比较》 《jetty和tomcat优势比较》 架构比较:Jetty的架构比Tomcat的更为简单。 性能比较：Jetty和Tomcat性能方面差异不大，Jetty默认采用NIO结束在处理I/O请求上更占优势，Tomcat默认采用BIO处理I/O请求，Tomcat适合处理少数非常繁忙的链接，处理静态资源时性能较差。 其他方面：Jetty的应用更加快速，修改简单，对新的Servlet规范的支持较好;Tomcat 对JEE和Servlet 支持更加全面。 缓存 《缓存失效策略（FIFO 、LRU、LFU三种算法的区别）》 本地缓存 《HashMap本地缓存》 《EhCache本地缓存》 堆内、堆外、磁盘三级缓存。 可按照缓存空间容量进行设置。 按照时间、次数等过期策略。 《Guava Cache》 简单轻量、无堆外、磁盘缓存。 《Nginx本地缓存》 《Pagespeed—懒人工具，服务器端加速》 客户端缓存 《浏览器端缓存》 主要是利用 Cache-Control 参数。 《H5 和移动端 WebView 缓存机制解析与实战》 服务端缓存Web缓存 nuster - nuster cache varnish - varnish cache squid - squid cache Memcached 《Memcached 教程》 《深入理解Memcached原理》 采用多路复用技术提高并发性。 slab分配算法： memcached给Slab分配内存空间，默认是1MB。分配给Slab之后 把slab的切分成大小相同的chunk，Chunk是用于缓存记录的内存空间，Chunk 的大小默认按照1.25倍的速度递增。好处是不会频繁申请内存，提高IO效率，坏处是会有一定的内存浪费。 《Memcached软件工作原理》 《Memcache技术分享：介绍、使用、存储、算法、优化、命中率》 《memcache 中 add 、 set 、replace 的区别》 区别在于当key存在还是不存在时，返回值是true和false的。 《memcached全面剖析》 Redis 《Redis 教程》 《redis底层原理》 使用 ziplist 存储链表，ziplist是一种压缩链表，它的好处是更能节省内存空间，因为它所存储的内容都是在连续的内存区域当中的。 使用 skiplist(跳跃表)来存储有序集合对象、查找上先从高Level查起、时间复杂度和红黑树相当，实现容易，无锁、并发性好。 《Redis持久化方式》 RDB方式：定期备份快照，常用于灾难恢复。优点：通过fork出的进程进行备份，不影响主进程、RDB 在恢复大数据集时的速度比 AOF 的恢复速度要快。缺点：会丢数据。 AOF方式：保存操作日志方式。优点：恢复时数据丢失少，缺点：文件大，回复慢。 也可以两者结合使用。 《分布式缓存–序列3–原子操作与CAS乐观锁》 架构 《Redis单线程架构》 回收策略 《redis的回收策略》 Tair 官方网站 《Tair和Redis的对比》 特点：可以配置备份节点数目，通过异步同步到备份节点 一致性Hash算法。 架构：和Hadoop 的设计思想类似，有Configserver，DataServer，Configserver 通过心跳来检测，Configserver也有主备关系。 几种存储引擎: MDB，完全内存性，可以用来存储Session等数据。 Rdb（类似于Redis），轻量化，去除了aof之类的操作，支持Restfull操作 LDB（LevelDB存储引擎），持久化存储，LDB 作为rdb的持久化，google实现，比较高效，理论基础是LSM(Log-Structured-Merge Tree)算法，现在内存中修改数据，达到一定量时（和内存汇总的旧数据一同写入磁盘）再写入磁盘，存储更加高效，县比喻Hash算法。 Tair采用共享内存来存储数据，如果服务挂掉（非服务器），重启服务之后，数据亦然还在。 消息队列 《消息队列-推/拉模式学习 &amp; ActiveMQ及JMS学习》 RabbitMQ 消费者默认是推模式（也支持拉模式）。 Kafka 默认是拉模式。 Push方式：优点是可以尽可能快地将消息发送给消费者，缺点是如果消费者处理能力跟不上，消费者的缓冲区可能会溢出。 Pull方式：优点是消费端可以按处理能力进行拉去，缺点是会增加消息延迟。 《Kafka、RabbitMQ、RocketMQ等消息中间件的对比 —— 消息发送性能和区别》 消息总线消息总线相当于在消息队列之上做了一层封装，统一入口，统一管控、简化接入成本。 《消息总线VS消息队列》 消息的顺序 《如何保证消费者接收消息的顺序》 RabbitMQ支持事务，推拉模式都是支持、适合需要可靠性消息传输的场景。 《RabbitMQ的应用场景以及基本原理介绍》 《消息队列之 RabbitMQ》 《RabbitMQ之消息确认机制（事务+Confirm）》 RocketMQJava实现，推拉模式都是支持，吞吐量逊于Kafka。可以保证消息顺序。 《RocketMQ 实战之快速入门》 《RocketMQ 源码解析》 ActiveMQ纯Java实现，兼容JMS，可以内嵌于Java应用中。 《ActiveMQ消息队列介绍》 Kafka高吞吐量、采用拉模式。适合高IO场景，比如日志同步。 官方网站 《各消息队列对比，Kafka深度解析，众人推荐，精彩好文！》 《Kafka分区机制介绍与示例》 Redis 消息推送生产者、消费者模式完全是客户端行为，list 和 拉模式实现，阻塞等待采用 blpop 指令。 《Redis学习笔记之十：Redis用作消息队列》 ZeroMQ TODO 定时调度单机定时调度 《linux定时任务cron配置》 《Linux cron运行原理》 fork 进程 + sleep 轮询 《Quartz使用总结》 《Quartz源码解析 —- 触发器按时启动原理》 《quartz原理揭秘和源码解读》 定时调度在 QuartzSchedulerThread 代码中，while()无限循环，每次循环取出时间将到的trigger，触发对应的job，直到调度器线程被关闭。 分布式定时调度 《这些优秀的国产分布式任务调度系统，你用过几个？》 opencron、LTS、XXL-JOB、Elastic-Job、Uncode-Schedule、Antares 《Quartz任务调度的基本实现原理》 Quartz集群中，独立的Quartz节点并不与另一其的节点或是管理节点通信，而是通过相同的数据库表来感知到另一Quartz应用的 《Elastic-Job-Lite 源码解析》 《Elastic-Job-Cloud 源码解析》 RPC 《从零开始实现RPC框架 - RPC原理及实现》 核心角色：Server: 暴露服务的服务提供方、Client: 调用远程服务的服务消费方、Registry: 服务注册与发现的注册中心。 《分布式RPC框架性能大比拼 dubbo、motan、rpcx、gRPC、thrift的性能比较》 Dubbo 官方网站 dubbo实现原理简单介绍 SPI TODO Thrift 官方网站 《Thrift RPC详解》 支持多语言，通过中间语言定义接口。 gRPC服务端可以认证加密，在外网环境下，可以保证数据安全。 官方网站 《你应该知道的RPC原理》 数据库中间件Sharding Jdbc 官网 日志系统日志搜集 《从零开始搭建一个ELKB日志收集系统》 《用ELK搭建简单的日志收集分析系统》 《日志收集系统-探究》 配置中心 Apollo - 携程开源的配置中心应用 Spring Boot 和 Spring Cloud 支持推、拉模式更新配置 支持多种语言 《基于zookeeper实现统一配置管理》 《 Spring Cloud Config 分布式配置中心使用教程》 servlet 3.0 异步特性可用于配置中心的客户端 《servlet3.0 新特性——异步处理》 API 网关主要职责：请求转发、安全认证、协议转换、容灾。 《API网关那些儿》 《谈API网关的背景、架构以及落地方案》 《使用Zuul构建API Gateway》 《Spring Cloud Gateway 源码解析》 《HTTP API网关选择之一Kong介绍》 网络协议OSI 七层协议 《OSI七层协议模型、TCP/IP四层模型学习笔记》 TCP/IP 《深入浅出 TCP/IP 协议》 《TCP协议中的三次握手和四次挥手》 HTTP 《http协议详解(超详细)》 HTTP2.0 《HTTP 2.0 原理详细分析》 《HTTP2.0的基本单位为二进制帧》 利用二进制帧负责传输。 多路复用。 HTTPS 《https原理通俗了解》 使用非对称加密协商加密算法 使用对称加密方式传输数据 使用第三方机构签发的证书，来加密公钥，用于公钥的安全传输、防止被中间人串改。 《八大免费SSL证书-给你的网站免费添加Https安全加密》 网络模型 《web优化必须了解的原理之I/o的五种模型和web的三种工作模式》 五种I/O模型：阻塞I/O，非阻塞I/O，I/O复用、事件(信号)驱动I/O、异步I/O，前四种I/O属于同步操作，I/O的第一阶段不同、第二阶段相同，最后的一种则属于异步操作。 三种 Web Server 工作方式：Prefork(多进程)、Worker方式(线程方式)、Event方式。 《select、poll、epoll之间的区别总结》 select，poll，epoll本质上都是同步I/O，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的。 select 有打开文件描述符数量限制，默认1024（2048 for x64），100万并发，就要用1000个进程、切换开销大；poll采用链表结构，没有数量限制。 select，poll “醒着”的时候要遍历整个fd集合，而epoll在“醒着”的时候只要判断一下就绪链表是否为空就行了，通过回调机制节省大量CPU时间；select，poll每次调用都要把fd集合从用户态往内核态拷贝一次，而epoll只要一次拷贝。 poll会随着并发增加，性能逐渐下降，epoll采用红黑树结构，性能稳定，不会随着连接数增加而降低。 《select，poll，epoll比较 》 在连接数少并且连接都十分活跃的情况下，select和poll的性能可能比epoll好，毕竟epoll的通知机制需要很多函数回调。 《深入理解Java NIO》 NIO 是一种同步非阻塞的 IO 模型。同步是指线程不断轮询 IO 事件是否就绪，非阻塞是指线程在等待 IO 的时候，可以同时做其他任务 《BIO与NIO、AIO的区别》 《两种高效的服务器设计模型：Reactor和Proactor模型》 Epoll 《epoll使用详解（精髓）》 Java NIO 《深入理解Java NIO》 《Java NIO编写Socket服务器的一个例子》 kqueue 《kqueue用法简介》 连接和短连接 《TCP/IP系列——长连接与短连接的区别》 框架 《Netty原理剖析》 Reactor 模式介绍。 Netty 是 Reactor 模式的一种实现。 零拷贝（Zero-copy） 《对于 Netty ByteBuf 的零拷贝(Zero Copy) 的理解》 多个物理分离的buffer，通过逻辑上合并成为一个，从而避免了数据在内存之间的拷贝。 序列化(二进制协议)Hessian 《Hessian原理分析》Binary-RPC;不仅仅是序列化 Protobuf 《Protobuf协议的Java应用例子》Goolge出品、占用空间和效率完胜其他序列化类库，如Hessian；需要编写 .proto 文件。 《Protocol Buffers序列化协议及应用》 * 关于协议的解释；缺点：可读性差; 《简单的使用 protobuf 和 protostuff》 protostuff 的好处是不用写 .proto 文件，Java 对象直接就可以序列化。 数据库基础理论数据库设计的三大范式 《数据库的三大范式以及五大约束》 第一范式：数据表中的每一列（每个字段）必须是不可拆分的最小单元，也就是确保每一列的原子性； 第二范式（2NF）：满足1NF后，要求表中的所有列，都必须依赖于主键，而不能有任何一列与主键没有关系，也就是说一个表只描述一件事情； 第三范式：必须先满足第二范式（2NF），要求：表中的每一列只与主键直接相关而不是间接相关，（表中的每一列只能依赖于主键）； MySQL原理 《MySQL的InnoDB索引原理详解》 《MySQL存储引擎－－MyISAM与InnoDB区别》 两种类型最主要的差别就是Innodb 支持事务处理与外键和行级锁 《myisam和innodb索引实现的不同》 InnoDB 《一篇文章带你读懂Mysql和InnoDB》 优化 《MySQL36条军规》 《MYSQL性能优化的最佳20+条经验》 《SQL优化之道》 《mysql数据库死锁的产生原因及解决办法》 《导致索引失效的可能情况》 《 MYSQL分页limit速度太慢优化方法》 原则上就是缩小扫描范围。 索引聚集索引, 非聚集索引 《MySQL 聚集索引/非聚集索引简述》 《MyISAM和InnoDB的索引实现》 MyISAM 是非聚集，InnoDB 是聚集 复合索引 《复合索引的优点和注意事项》 自适应哈希索引(AHI) 《InnoDB存储引擎——自适应哈希索引》 explain 《MySQL 性能优化神器 Explain 使用分析》 NoSQLMongoDB MongoDB 教程 《Mongodb相对于关系型数据库的优缺点》 优点：弱一致性（最终一致），更能保证用户的访问速度；内置GridFS，支持大容量的存储；Schema-less 数据库，不用预先定义结构；内置Sharding；相比于其他NoSQL，第三方支持丰富；性能优越； 缺点：mongodb不支持事务操作；mongodb占用空间过大；MongoDB没有如MySQL那样成熟的维护工具，这对于开发和IT运营都是个值得注意的地方； Hbase 《简明 HBase 入门教程（开篇）》 《深入学习HBase架构原理》 《传统的行存储和（HBase）列存储的区别》 《Hbase与传统数据库的区别》 空数据不存储，节省空间，且适用于并发。 《HBase Rowkey设计》 rowkey 按照字典顺序排列，便于批量扫描。 通过散列可以避免热点。 搜索引擎搜索引擎原理 《倒排索引–搜索引擎入门》 Lucene 《Lucene入门简介》 Elasticsearch 《Elasticsearch学习，请先看这一篇！》 《Elasticsearch索引原理》 Solr 《 Apache Solr入门教程》 《elasticsearch与solr比较》 sphinx 《Sphinx 的介绍和原理探索》 性能性能优化方法论 《15天的性能优化工作，5方面的调优经验》 代码层面、业务层面、数据库层面、服务器层面、前端优化。 《系统性能优化的几个方面》 容量评估 《联网性能与容量评估的方法论和典型案例》 《互联网架构，如何进行容量设计？》 评估总访问量、评估平均访问量QPS、评估高峰QPS、评估系统、单机极限QPS CDN 网络 《CDN加速原理》 《国内有哪些比较好的 CDN？》 连接池 《主流Java数据库连接池比较与开发配置实战》 性能调优 《九大Java性能调试工具，必备至少一款》 大数据流式计算Storm 官方网站 《最详细的Storm入门教程》 Flink 《Flink之一 Flink基本原理介绍》 Kafka Stream 《Kafka Stream调研：一种轻量级流计算模式》 应用场景例如： 广告相关实时统计； 推荐系统用户画像标签实时更新； 线上服务健康状况实时监测； 实时榜单； 实时数据统计。 Hadoop 《用通俗易懂的话说下hadoop是什么,能做什么》 《史上最详细的Hadoop环境搭建》 HDFS 《【Hadoop学习】HDFS基本原理》 MapReduce 《用通俗易懂的大白话讲解Map/Reduce原理》 《 简单的map-reduce的java例子》 Yarn 《初步掌握Yarn的架构及原理》 Spark 《Spark(一): 基本架构及原理》 安全web 安全XSS 《xss攻击原理与解决方法》CSRF 《CSRF原理及防范》 SQL 注入 《SQL注入》 Hash Dos 《邪恶的JAVA HASH DOS攻击》 利用JsonObjet 上传大Json，JsonObject 底层使用HashMap；不同的数据产生相同的hash值，使得构建Hash速度变慢，耗尽CPU。 《一种高级的DoS攻击-Hash碰撞攻击》 《关于Hash Collision DoS漏洞：解析与解决方案》 脚本注入 《上传文件漏洞原理及防范》 漏洞扫描工具 《DVWA》 W3af OpenVAS详解 验证码 《验证码原理分析及实现》 《详解滑动验证码的实现原理》 滑动验证码是根据人在滑动滑块的响应时间，拖拽速度，时间，位置，轨迹，重试次数等来评估风险。 《淘宝滑动验证码研究》 DDoS 防范 《学习手册：DDoS的攻击方式及防御手段》 《免费DDoS攻击测试工具大合集》 用户隐私信息保护 用户密码非明文保存，加动态salt。 身份证号，手机号如果要显示，用 “*” 替代部分字符。 联系方式在的显示与否由用户自己控制。 TODO 《个人隐私包括哪些》 《在互联网上，隐私的范围包括哪些？》 《用户密码保存》 序列化漏洞 《Lib之过？Java反序列化漏洞通用利用分析》 加密解密对称加密 《常见对称加密算法》 DES、3DES、Blowfish、AES DES 采用 56位秘钥，Blowfish 采用1到448位变长秘钥，AES 128，192和256位长度的秘钥。 DES 秘钥太短（只有56位）算法目前已经被 AES 取代，并且 AES 有硬件加速，性能很好。 哈希算法 《常用的哈希算法》 MD5 和 SHA-1 已经不再安全，已被弃用。 目前 SHA-256 是比较安全的。 《基于Hash摘要签名的公网URL签名验证设计方案》 非对称加密 《常见非对称加密算法》 RSA、DSA、ECDSA(螺旋曲线加密算法) 和 RSA 不同的是 DSA 仅能用于数字签名，不能进行数据加密解密，其安全性和RSA相当，但其性能要比RSA快。 256位的ECC秘钥的安全性等同于3072位的RSA秘钥。 《区块链的加密技术》 服务器安全 《Linux强化论：15步打造一个安全的Linux服务器》 数据安全数据备份TODO 网络隔离内外网分离TODO 登录跳板机在内外环境中通过跳板机登录到线上主机。 《搭建简易堡垒机》 授权、认证RBAC 《基于组织角色的权限设计》 《权限系统与RBAC模型概述》 《Spring整合Shiro做权限控制模块详细案例分析》 OAuth2.0 《理解OAuth 2.0》 《一张图搞定OAuth2.0》 双因素认证（2FA）2FA - Two-factor authentication，用于加强登录验证 常用做法是 登录密码 + 手机验证码（或者令牌Key，类似于与网银的 USB key） 【《双因素认证（2FA）教程》】(http://www.ruanyifeng.com/blog/2017/11/2fa-tutorial.html) 单点登录(SSO) 《单点登录原理与简单实现》 CAS单点登录框架 常用开源框架开源协议 《开源协议的选择》 如何选择一个开源软件协议 日志框架Log4j、Log4j2 《log4j 详细讲解》 《log4j2 实际使用详解》 《Log4j1,Logback以及Log4j2性能测试对比》 Log4J 异步日志性能优异。 Logback 《最全LogBack 详解、含java案例和配置说明》 ORM 《ORM框架使用优缺点》 主要目的是为了提高开发效率。 MyBatis： 《mybatis缓存机制详解》 一级缓存是SqlSession级别的缓存，缓存的数据只在SqlSession内有效 二级缓存是mapper级别的缓存，同一个namespace公用这一个缓存，所以对SqlSession是共享的；使用 LRU 机制清理缓存，通过 cacheEnabled 参数开启。 《MyBatis学习之代码生成器Generator》 网络框架TODO Web 框架Spring 家族Spring Spring 简明教程 Spring Boot 官方网站 《Spring Boot基础教程》 Spring Cloud Spring Boot 中文索引站 Spring Cloud 中文文档 《Spring Cloud基础教程》 工具框架 《Apache Commons 工具类介绍及简单使用》 《Google guava 中文教程》 分布式设计扩展性设计 《架构师不可不知的十大可扩展架构》 总结下来，通用的套路就是分布、缓存及异步处理。 《可扩展性设计之数据切分》 水平切分+垂直切分 利用中间件进行分片如，MySQL Proxy。 利用分片策略进行切分，如按照ID取模。 《说说如何实现可扩展性的大型网站架构》 分布式服务+消息队列。 《大型网站技术架构（七）–网站的可扩展性架构》 稳定性 &amp; 高可用 《系统设计：关于高可用系统的一些技术方案》 可扩展：水平扩展、垂直扩展。 通过冗余部署，避免单点故障。 隔离：避免单一业务占用全部资源。避免业务之间的相互影响 2. 机房隔离避免单点故障。 解耦：降低维护成本，降低耦合风险。减少依赖，减少相互间的影响。 限流：滑动窗口计数法、漏桶算法、令牌桶算法等算法。遇到突发流量时，保证系统稳定。 降级：紧急情况下释放非核心功能的资源。牺牲非核心业务，保证核心业务的高可用。 熔断：异常情况超出阈值进入熔断状态，快速失败。减少不稳定的外部依赖对核心服务的影响。 自动化测试：通过完善的测试，减少发布引起的故障。 灰度发布：灰度发布是速度与安全性作为妥协，能够有效减少发布故障。 《关于高可用的系统》 设计原则：数据不丢(持久化)；服务高可用(服务副本)；绝对的100%高可用很难，目标是做到尽可能多的9，如99.999%（全年累计只有5分钟）。 硬件负载均衡 《转！！负载均衡器技术Nginx和F5的优缺点对比》 主要是和F5对比。 《软/硬件负载均衡产品 你知多少？》 软件负载均衡 《几种负载均衡算法》 轮寻、权重、负载、最少连接、QoS 《DNS负载均衡》 配置简单，更新速度慢。 《Nginx负载均衡》 简单轻量、学习成本低；主要适用于web应用。 《借助LVS+Keepalived实现负载均衡 》 配置比较负载、只支持到4层，性能较高。 《HAProxy用法详解 全网最详细中文文档》 支持到七层（比如HTTP）、功能比较全面，性能也不错。 《Haproxy+Keepalived+MySQL实现读均衡负载》 主要是用户读请求的负载均衡。 《rabbitmq+haproxy+keepalived实现高可用集群搭建》 限流 《谈谈高并发系统的限流》 计数器：通过滑动窗口计数器，控制单位时间内的请求次数，简单粗暴。 漏桶算法：固定容量的漏桶，漏桶满了就丢弃请求，比较常用。 令牌桶算法：固定容量的令牌桶，按照一定速率添加令牌，处理请求前需要拿到令牌，拿不到令牌则丢弃请求，或进入丢队列，可以通过控制添加令牌的速率，来控制整体速度。Guava 中的 RateLimiter 是令牌桶的实现。 Nginx 限流：通过 limit_req 等模块限制并发连接数。 应用层容灾 《防雪崩利器：熔断器 Hystrix 的原理与使用》 雪崩效应原因：硬件故障、硬件故障、程序Bug、重试加大流量、用户大量请求。 雪崩的对策：限流、改进缓存模式(缓存预加载、同步调用改异步)、自动扩容、降级。 Hystrix设计原则： 资源隔离：Hystrix通过将每个依赖服务分配独立的线程池进行资源隔离, 从而避免服务雪崩。 熔断开关：服务的健康状况 = 请求失败数 / 请求总数，通过阈值设定和滑动窗口控制开关。 命令模式：通过继承 HystrixCommand 来包装服务调用逻辑。 《缓存穿透，缓存击穿，缓存雪崩解决方案分析》 《缓存击穿、失效以及热点key问题》 主要策略：失效瞬间：单机使用锁；使用分布式锁；不过期； 热点数据：热点数据单独存储；使用本地缓存；分成多个子key； 跨机房容灾 《“异地多活”多机房部署经验谈》 通过自研中间件进行数据同步。 《异地多活（异地双活）实践经验》 注意延迟问题，多次跨机房调用会将延时放大数倍。 建房间专线很大概率会出现问题，做好运维和程序层面的容错。 不能依赖于程序端数据双写，要有自动同步方案。 数据永不在高延迟和较差网络质量下，考虑同步质量问题。 核心业务和次要业务分而治之，甚至只考虑核心业务。 异地多活监控部署、测试也要跟上。 业务允许的情况下考虑用户分区，尤其是游戏、邮箱业务。 控制跨机房消息体大小，越小越好。 考虑使用docker容器虚拟化技术，提高动态调度能力。 容灾技术及建设经验介绍 容灾演练流程 《依赖治理、灰度发布、故障演练，阿里电商故障演练系统的设计与实战经验》 常见故障画像 案例：预案有效性、预案有效性、故障复现、架构容灾测试、参数调优、参数调优、故障突袭、联合演练。 平滑启动 平滑重启应用思路1.端流量（如vip层）、2. flush 数据(如果有)、3, 重启应用 《JVM安全退出（如何优雅的关闭java服务）》推荐推出方式：System.exit，Kill SIGTERM；不推荐 kill-9；用 Runtime.addShutdownHook 注册钩子。 《常见Java应用如何优雅关闭》Java、Srping、Dubbo 优雅关闭方式。 数据库扩展读写分离模式 《Mysql主从方案的实现》 《搭建MySQL主从复制经典架构》 《Haproxy+多台MySQL从服务器(Slave) 实现负载均衡》 《DRBD+Heartbeat+Mysql高可用读写分离架构》 DRDB 进行磁盘复制，避免单点问题。 《MySQL Cluster 方式》 分片模式 《分库分表需要考虑的问题及方案》 中间件： 轻量级：sharding-jdbc、TSharding；重量级：Atlas、MyCAT、Vitess等。 问题：事务、Join、迁移、扩容、ID、分页等。 事务补偿：对数据进行对帐检查;基于日志进行比对;定期同标准数据来源进行同步等。 分库策略：数值范围；取模；日期等。 分库数量：通常 MySQL 单库 5千万条、Oracle 单库一亿条需要分库。 《MySql分表和表分区详解》 分区：是MySQL内部机制，对客户端透明，数据存储在不同文件中，表面上看是同一个表。 分表：物理上创建不同的表、客户端需要管理分表路由。 服务治理服务注册与发现 《永不失联！如何实现微服务架构中的服务发现？》 客户端服务发现模式：客户端直接查询注册表，同时自己负责负载均衡。Eureka 采用这种方式。 服务器端服务发现模式：客户端通过负载均衡查询服务实例。 《SpringCloud服务注册中心比较:Consul vs Zookeeper vs Etcd vs Eureka》 CAP支持：Consul（CA）、zookeeper（cp）、etcd（cp） 、euerka（ap） 作者认为目前 Consul 对 Spring cloud 的支持比较好。 《基于Zookeeper的服务注册与发现》 优点：API简单、Pinterest，Airbnb 在用、多语言、通过watcher机制来实现配置PUSH，能快速响应配置变化。 服务路由控制 《分布式服务框架学习笔记4 服务路由》 原则：透明化路由 负载均衡策略：随机、轮询、服务调用延迟、一致性哈希、粘滞连接 本地路由有限策略：injvm(优先调用jvm内部的服务)，innative(优先使用相同物理机的服务),原则上找距离最近的服务。 配置方式：统一注册表；本地配置；动态下发。 分布式一致CAP 与 BASE 理论 《从分布式一致性谈到CAP理论、BASE理论》 一致性分类：强一致(立即一致)；弱一致(可在单位时间内实现一致，比如秒级)；最终一致(弱一致的一种，一定时间内最终一致) CAP：一致性、可用性、分区容错性(网络故障引起) BASE：Basically Available（基本可用）、Soft state（软状态）和Eventually consistent（最终一致性） BASE理论的核心思想是：即使无法做到强一致性，但每个应用都可以根据自身业务特点，采用适当的方式来使系统达到最终一致性。 分布式锁 《分布式锁的几种实现方式》 基于数据库的分布式锁：优点：操作简单、容易理解。缺点：存在单点问题、数据库性能够开销较大、不可重入； 基于缓存的分布式锁：优点：非阻塞、性能好。缺点：操作不好容易造成锁无法释放的情况。 Zookeeper 分布式锁：通过有序临时节点实现锁机制，自己对应的节点需要最小，则被认为是获得了锁。优点：集群可以透明解决单点问题，避免锁不被释放问题，同时锁可以重入。缺点：性能不如缓存方式，吞吐量会随着zk集群规模变大而下降。 《基于Zookeeper的分布式锁》 清楚的原理描述 + Java 代码示例。 《jedisLock—redis分布式锁实现》 基于 setnx(set if ont exists)，有则返回false，否则返回true。并支持过期时间。 《Memcached 和 Redis 分布式锁方案》 利用 memcached 的 add（有别于set）操作，当key存在时，返回false。 分布式一致性算法PAXOS 《分布式系列文章——Paxos算法原理与推导》 《Paxos–&gt;Fast Paxos–&gt;Zookeeper分析》 《【分布式】Zookeeper与Paxos》 Zab 《Zab：Zookeeper 中的分布式一致性协议介绍》 Raft 《Raft 为什么是更易理解的分布式一致性算法》 三种角色：Leader（领袖）、Follower（群众）、Candidate（候选人） 通过随机等待的方式发出投票，得票多的获胜。 Gossip 《Gossip算法》 两阶段提交、多阶段提交 《关于分布式事务、两阶段提交协议、三阶提交协议》 幂等 《分布式系统—幂等性设计》 幂等特性的作用：该资源具备幂等性，请求方无需担心重复调用会产生错误。 常见保证幂等的手段：MVCC（类似于乐观锁）、去重表(唯一索引)、悲观锁、一次性token、序列号方式。 分布式一致方案 《分布式系统事务一致性解决方案》 《保证分布式系统数据一致性的6种方案》 分布式 Leader 节点选举 《利用zookeeper实现分布式leader节点选举》 TCC(Try/Confirm/Cancel) 柔性事务 《传统事务与柔性事务》 基于BASE理论：基本可用、柔性状态、最终一致。 解决方案：记录日志+补偿（正向补充或者回滚）、消息重试(要求程序要幂等)；“无锁设计”、采用乐观锁机制。 分布式文件系统 说说分布式文件存储系统-基本架构 ？ 《各种分布式文件系统的比较》 ？ HDFS：大批量数据读写，用于高吞吐量的场景，不适合小文件。 FastDFS：轻量级、适合小文件。 唯一ID 生成全局唯一ID 《高并发分布式系统中生成全局唯一Id汇总》 Twitter 方案（Snowflake 算法）：41位时间戳+10位机器标识（比如IP，服务器名称等）+12位序列号(本地计数器) Flicker 方案：MySQL自增ID + “REPLACE INTO XXX:SELECT LAST_INSERT_ID();” UUID：缺点，无序，字符串过长，占用空间，影响检索性能。 MongoDB 方案：利用 ObjectId。缺点：不能自增。 《TDDL 在分布式下的SEQUENCE原理》 在数据库中创建 sequence 表，用于记录，当前已被占用的id最大值。 每台客户端主机取一个id区间（比如 1000~2000）缓存在本地，并更新 sequence 表中的id最大值记录。 客户端主机之间取不同的id区间，用完再取，使用乐观锁机制控制并发。 一致性Hash算法 《一致性哈希算法》 设计思想 &amp; 开发模式DDD(Domain-driven Design - 领域驱动设计) 《浅谈我对DDD领域驱动设计的理解》 概念：DDD 主要对传统软件开发流程(分析-设计-编码)中各阶段的割裂问题而提出，避免由于一开始分析不明或在软件开发过程中的信息流转不一致而造成软件无法交付（和需求方设想不一致）的问题。DDD 强调一切以领域（Domain）为中心，强调领域专家（Domain Expert）的作用，强调先定义好领域模型之后在进行开发，并且领域模型可以指导开发（所谓的驱动）。 过程：理解领域、拆分领域、细化领域，模型的准确性取决于模型的理解深度。 设计：DDD 中提出了建模工具，比如聚合、实体、值对象、工厂、仓储、领域服务、领域事件来帮助领域建模。 《领域驱动设计的基础知识总结》 领域（Doamin）本质上就是问题域，比如一个电商系统，一个论坛系统等。 界限上下文（Bounded Context）：阐述子域之间的关系，可以简单理解成一个子系统或组件模块。 领域模型（Domain Model）：DDD的核心是建立（用通用描述语言、工具—领域通用语言）正确的领域模型；反应业务需求的本质，包括实体和过程；其贯穿软件分析、设计、开发 的整个过程；常用表达领域模型的方式：图、代码或文字； 领域通用语言：领域专家、开发设计人员都能立即的语言或工具。 经典分层架构：用户界面/展示层、应用层、领域层、基础设施层，是四层架构模式。 使用的模式： 关联尽量少，尽量单项，尽量降低整体复杂度。 实体（Entity）：领域中的唯一标示，一个实体的属性尽量少，少则清晰。 值对象（Value Object）：没有唯一标识，且属性值不可变，小二简单的对象，比如Date。 领域服务（Domain Service）： 协调多个领域对象，只有方法没有状态(不存数据)；可以分为应用层服务，领域层服务、基础层服务。 聚合及聚合根（Aggregate，Aggregate Root）：聚合定义了一组具有内聚关系的相关对象的集合；聚合根是对聚合引用的唯一元素；当修改一个聚合时，必须在事务级别；大部分领域模型中，有70%的聚合通常只有一个实体，30%只有2~3个实体；如果一个聚合只有一个实体，那么这个实体就是聚合根；如果有多个实体，那么我们可以思考聚合内哪个对象有独立存在的意义并且可以和外部直接进行交互； 工厂（Factory）：类似于设计模式中的工厂模式。 仓储（Repository）：持久化到DB，管理对象，且只对聚合设计仓储。 《领域驱动设计(DDD)实现之路》 聚合：比如一辆汽车（Car）包含了引擎（Engine）、车轮（Wheel）和油箱（Tank）等组件，缺一不可。 《领域驱动设计系列（2）浅析VO、DTO、DO、PO的概念、区别和用处》 命令查询职责分离(CQRS)CQRS — Command Query Responsibility Seperation 《领域驱动设计系列 (六)：CQRS》 核心思想：读写分离（查询和更新在不同的方法中），不同的流程只是不同的设计方式，CQ代码分离，分布式环境中会有明显体现（有冗余数据的情况下），目的是为了高性能。 《DDD CQRS架构和传统架构的优缺点比较》 最终一致的设计理念；依赖于高可用消息中间件。 《CQRS架构简介》 一个实现 CQRS 的抽象案例。 《深度长文：我对CQRS/EventSourcing架构的思考》 CQRS 模式分析 + 12306 抢票案例 贫血，充血模型 《贫血，充血模型的解释以及一些经验》 失血模型：老子和儿子分别定义，相互不知道，二者实体定义中完全没有业务逻辑，通过外部Service进行关联。 贫血模型：老子知道儿子，儿子也知道老子；部分业务逻辑放到实体中；优点：各层单项依赖，结构清楚，易于维护；缺点：不符合OO思想，相比于充血模式，Service层较为厚重； 充血模型：和贫血模型类似，区别在于如何划分业务逻辑。优点：Service层比较薄，只充当Facade的角色，不和DAO打交道、复合OO思想；缺点：非单项依赖，DO和DAO之间双向依赖、和Service层的逻辑划分容易造成混乱。 肿胀模式：是一种极端情况，取消Service层、全部业务逻辑放在DO中；优点：符合OO思想、简化了分层；缺点：暴露信息过多、很多非DO逻辑也会强行并入DO。这种模式应该避免。 作者主张使用贫血模式。 Actor 模式TODO 响应式编程ReactorTODO RxJavaTODO Vert.xTODO DODAF2.0 《DODAF2.0方法论》 《DODAF2.0之能力视角如何落地》 Serverless无需过多关系服务器的服务架构理念。 《什么是Serverless无服务器架构？》 Serverless 不代表出去服务器，而是去除对服务器运行状态的关心。 Serverless 代表一思维方式的转变，从“构建一套服务在一台服务器上，对对个事件进行响应转变为构建一个为服务器，来响应一个事件”。 Serverless 不代表某个具体的框架。 《如何理解Serverless？》 依赖于 Baas （(Mobile) Backend as a Service） 和 Faas （Functions as a service） Service Mesh 《什么是Service Mesh？》 《初识 Service Mesh》 《什么是Service Mesh？》 项目管理架构评审 《架构设计之如何评审架构设计说明书》 《人人都是架构师：非功能性需求》 重构 《架构之重构的12条军规》 代码规范 《阿里巴巴Java开发手册》 代码 Review制度还是制度!另外，每个公司需要根据自己的需求和目标制定自己的 check list 《为什么你做不好 Code Review？》 代码 review 做的好，在于制度建设。 《从零开始Code Review》 《Code Review Checklist》 《Java Code Review Checklist》 《如何用 gitlab 做 code review》 RUP 《运用RUP 4+1视图方法进行软件架构设计》 看板管理 《说说看板在项目中的应用》 SCRUMSCRUM - 争球 3个角色:Product Owner(PO) 产品负责人;Scrum Master（SM），推动Scrum执行;Team 开发团队。 3个工件：Product Backlog 产品TODOLIST，含优先级;Sprint Backlog 功能开发 TODO LIST；燃尽图； 五个价值观：专注、勇气、公开、承诺、尊重。 《敏捷项目管理流程-Scrum框架最全总结！》 《敏捷其实很简单3—敏捷方法之scrum》 敏捷开发TODO 极限编程（XP）XP - eXtreme Programming 《主流敏捷开发方法：极限编程XP》 是一种指导开发人员的方法论。 4大价值： 沟通：鼓励口头沟通，提高效率。 简单：够用就好。 反馈：及时反馈、通知相关人。 勇气：提倡拥抱变化，敢于重构。 5个原则：快速反馈、简单性假设、逐步修改、提倡更改（小步快跑）、优质工作（保证质量的前提下保证小步快跑）。 5个工作：阶段性冲刺；冲刺计划会议；每日站立会议；冲刺后review；回顾会议。 结对编程边写码，边review。能够增强代码质量、减少bug。 《结对编程》 PDCA 循环质量管理P——PLAN 策划，D——DO 实施，C——CHECK 检查，A——ACT 改进 《PDCA》 FMEA管理模式TODO 通用业务术语TODO 技术趋势TODO 政策、法规TODO 法律严格遵守刑法253法条我国刑法第253条之一规定： 国家机关或者金融、电信、交通、教育、医疗等单位的工作人员，违反国家规定，将本单位在履行职责或者提供服务过程中获得的公民个人信息，出售或者非法提供给他人，情节严重的，处3年以下有期徒刑或者拘役，并处或者单处罚金。 窃取或者以其他方法非法获取上述信息，情节严重的，依照前款的规定处罚。 单位犯前两款罪的，对单位判处罚金，并对其直接负责的主管人员和其他直接责任人员，依照各该款的规定处罚。 最高人民法院、最高人民检察院关于执行《中华人民共和国刑法》确定罪名的补充规定（四）规定：触犯刑法第253条之一第1款之规定，构成“出售、非法提供公民个人信息罪”；触犯刑法第253条之一第2款之规定，构成“非法获取公民个人信息罪” 《非法获取公民个人信息罪》 架构师素质 《架构师画像》 业务理解和抽象能力 NB的代码能力 全面：1. 在面对业务问题上，架构师脑海里是否会浮现出多种技术方案；2. 在做系统设计时是否考虑到了足够多的方方面面；3. 在做系统设计时是否考虑到了足够多的方方面面； 全局：是否考虑到了对上下游的系统的影响。 权衡：权衡投入产出比；优先级和节奏控制； 《关于架构优化和设计，架构师必须知道的事情》 要去考虑的细节：模块化、轻耦合、无共享架构；减少各个组件之前的依赖、注意服务之间依赖所有造成的链式失败及影响等。 基础设施、配置、测试、开发、运维综合考虑。 考虑人、团队、和组织的影响。 《如何才能真正的提高自己，成为一名出色的架构师？》 《架构师的必备素质和成长途径》 素质：业务理解、技术广度、技术深度、丰富经验、沟通能力、动手能力、美学素养。 成长路径：2年积累知识、4年积累技能和组内影响力、7年积累部门内影响力、7年以上积累跨部门影响力。 《架构设计师—你在哪层楼？》 第一层的架构师看到的只是产品本身 第二层的架构师不仅看到自己的产品，还看到了整体的方案 第三层的架构师看到的是商业价值 团队管理TODO 招聘资讯行业资讯 36kr Techweb 公众号列表TODO 博客团队博客 阿里中间件博客 美团点评技术团队博客 个人博客 阮一峰的网络日志 酷壳 - COOLSHELL-陈皓 hellojava-阿里毕玄 Cm’s Blog 程序猿DD-翟永超-《Spring Cloud微服务实战》作者 综合门户、社区国内： CSDN 老牌技术社区、不必解释。 51cto.com ITeye 偏 Java 方向 博客园 ChinaUnix 偏 Linux 方向 开源中国社区 深度开源 伯乐在线 涵盖 IT职场、Web前端、后端、移动端、数据库等方面内容，偏技术端。 ITPUB 腾讯云— 云+社区 阿里云— 云栖社区 IBM DeveloperWorks 开发者头条 LinkedKeeper 国外： DZone Reddit 问答、讨论类社区 segmentfault 问答+专栏 知乎 stackoverflow 行业数据分析 艾瑞网 QUEST MOBILE 国家数据 TalkingData 专项网站 测试: 领测国际 测试窝 TesterHome 运维: * [运维派](http://www.yunweipai.com/) * [Abcdocker](https://www.abcdocker.com/) Java: ImportNew 专注于 Java 技术分享 HowToDoInJava 英文博客 安全 红黑联盟 FreeBuf 大数据 中国大数据 其他专题网站： DockerInfo 专注于 Docker 应用及咨询、教程的网站。 Linux公社 Linux 主题社区 其他类 程序员技能图谱 推荐参考书在线电子书 《深入理解Spring Cloud与微服务构建》 《阿里技术参考图册-研发篇》 《阿里技术参考图册-算法篇》 《2018美团点评技术年货（合辑）》70M InfoQ《架构师》月刊 《架构师之路》 纸质书开发方面 《阿里巴巴Java开发手册》京东 淘宝 架构方面 《软件架构师的12项修炼：技术技能篇》京东 淘宝 《架构之美》京东 淘宝 《分布式服务架构》京东 淘宝 《聊聊架构》 京东 淘宝 《云原生应用架构实践》京东 淘宝 《亿级流量网站架构核心技术》京东 淘宝 《淘宝技术这十年》京东 淘宝 《企业IT架构转型之道-中台战略思想与架构实战》 京东 淘宝 《高可用架构（第1卷）》京东 淘宝 技术管理方面 《CTO说》京东 淘宝 《技术管理之巅》京东 淘宝 《网易一千零一夜：互联网产品项目管理实战》京东 淘宝 基础理论 《数学之美》京东 淘宝 《编程珠玑》京东 淘宝 工具方面TODO 大数据方面技术资源开源资源 github Apache 软件基金会 手册、文档、教程国内： W3Cschool Runoob.com HTML 、 CSS、XML、Java、Python、PHP、设计模式等入门手册。 Love2.io 很多很多中文在线电子书，是一个全新的开源技术文档分享平台。 gitbook.cn 付费电子书。 ApacheCN AI、大数据方面系列中文文档。 国外： Quick Code 免费在线技术教程。 gitbook.com 有部分中文电子书。 Cheatography Cheat Sheets 大全，单页文档网站。 Tutorialspoint 知名教程网站，提供Java、Python、JS、SQL、大数据等高质量入门教程。 在线课堂 学徒无忧 极客时间 segmentfault 斯达克学院 牛客网 极客学院 51CTO学院 会议、活动 QCon ArchSummit GITC全球互联网技术大会 活动发布平台: 活动行 常用APP 极客时间 得到 找工作 Boss直聘 拉勾网 猎聘 100Offer 工具 极客搜索 技术文章搜索引擎。 代码托管 Coding 码云 文件服务 七牛 又拍云 综合云服务商 阿里云 腾讯云 百度云 新浪云 金山云 亚马逊云(AWS) 谷歌云 微软云 VPS Linode","tags":[{"name":"后端架构师技术图谱","slug":"后端架构师技术图谱","permalink":"https://xinxiamu.github.io/tags/后端架构师技术图谱/"}]},{"title":"centos常用命令收藏","date":"2018-06-11T09:37:52.000Z","path":"2018/06/11/linux-centos-command/","text":"本文主要记录常用的命令…… 以备查询使用…… 查看各种硬件信息https://blog.csdn.net/dream_broken/article/details/52883883 日志/var/log/message 系统启动后的信息和错误日志，是Red Hat Linux中最常用的日志之一 /var/log/secure 与安全相关的日志信息 /var/log/maillog 与邮件相关的日志信息 /var/log/cron 与定时任务相关的日志信息 /var/log/spooler 与UUCP和news设备相关的日志信息 /var/log/boot.log 守护进程启动和停止相关的日志消息 磁盘和分区# mount | column -t # 查看挂接的分区状态 # fdisk -l # 查看所有分区 # swapon -s # 查看所有交换分区 # hdparm -i /dev/hda # 查看磁盘参数(仅适用于IDE设备) # dmesg | grep IDE # 查看启动时IDE设备检测状况 网络# ifconfig # 查看所有网络接口的属性 # iptables -L # 查看防火墙设置 # route -n # 查看路由表 # netstat -lntp # 查看所有监听端口 # netstat -antp # 查看所有已经建立的连接 # netstat -s # 查看网络统计信息 用户# w # 查看活动用户 # id &lt;用户名&gt; # 查看指定用户信息 # last # 查看用户登录日志 # cut -d: -f1 /etc/passwd # 查看系统所有用户 # cut -d: -f1 /etc/group # 查看系统所有组 # crontab -l # 查看当前用户的计划任务 服务# chkconfig –list # 列出所有系统服务 # chkconfig –list | grep on # 列出所有启动的系统服务 查看系统信息# uname -a # 查看内核/操作系统/CPU信息 # cat /etc/issue # cat /etc/redhat-release # 查看操作系统版本 # cat /proc/cpuinfo # 查看CPU信息 # hostname # 查看计算机名 # lspci -tv # 列出所有PCI设备 # lsusb -tv # 列出所有USB设备 # lsmod # 列出加载的内核模块 # env # 查看环境变量 查看端口占用netstat -lnp|grep 8000 设置自启动在生产环境，一些基础应用环境需要系统启动的时候自动启动…… 服务自启动设置执行命令systemctl enable *即可。 例如设置docker服务自启动：systemctl enable docker.service 脚本自启动参考：一、添加开机自启服务 在CentOS 7中添加开机自启服务非常方便，只需要两条命令(以Jenkins为例)： systemctl enable jenkins.service #设置jenkins服务为自启动服务 sysstemctl start jenkins.service #启动jenkins服务 二、添加开机自启脚本 在centos7中增加脚本有两种常用的方法，以脚本autostart.sh为例： #!/bin/bash #description:开机自启脚本 /usr/local/tomcat/bin/startup.sh #启动tomcat 方法一 1、赋予脚本可执行权限（/opt/script/autostart.sh是你的脚本路径） chmod +x /opt/script/autostart.sh 2、打开/etc/rc.d/rc/local文件，在末尾增加如下内容 /opt/script/autostart.sh 3、在centos7中，/etc/rc.d/rc.local的权限被降低了，所以需要执行如下命令赋予其可执行权限 chmod +x /etc/rc.d/rc.local 方法二 1、将脚本移动到/etc/rc.d/init.d目录下 mv /opt/script/autostart.sh /etc/rc.d/init.d 2、增加脚本的可执行权限 chmod +x /etc/rc.d/init.d/autostart.sh 3、添加脚本到开机自动启动项目中 cd /etc/rc.d/init.d chkconfig --add autostart.sh chkconfig autostart.sh on 系统进程管理查看进程信息1.根据端口，查看进程信息# lsof -i:8011 //查看端口，找到进程pid # cd /proc/pid # ll --------------------------------------------------------- [root@izwz9bwlp4pyxy4mnxaycez 1113]# ll total 0 dr-xr-xr-x 2 root root 0 10月 31 17:30 attr -rw-r--r-- 1 root root 0 11月 5 10:24 autogroup -r-------- 1 root root 0 11月 5 10:24 auxv -r--r--r-- 1 root root 0 11月 5 10:24 cgroup --w------- 1 root root 0 11月 5 10:24 clear_refs -r--r--r-- 1 root root 0 10月 8 21:02 cmdline -rw-r--r-- 1 root root 0 11月 5 10:24 comm -rw-r--r-- 1 root root 0 11月 5 10:24 coredump_filter -r--r--r-- 1 root root 0 11月 5 10:24 cpuset lrwxrwxrwx 1 root root 0 11月 5 10:24 cwd -&gt; / -r-------- 1 root root 0 11月 1 15:13 environ lrwxrwxrwx 1 root root 0 11月 5 10:24 exe -&gt; /server/java/jdk/bin/java dr-x------ 2 root root 0 10月 31 17:30 fd dr-x------ 2 root root 0 11月 1 11:53 fdinfo -rw-r--r-- 1 root root 0 11月 5 10:24 gid_map -r-------- 1 root root 0 11月 5 10:24 io -r--r--r-- 1 root root 0 11月 5 10:24 limits -rw-r--r-- 1 root root 0 11月 5 10:24 loginuid dr-x------ 2 root root 0 11月 5 10:24 map_files -r--r--r-- 1 root root 0 11月 5 10:24 maps -rw------- 1 root root 0 11月 5 10:24 mem -r--r--r-- 1 root root 0 11月 5 10:24 mountinfo -r--r--r-- 1 root root 0 11月 5 10:24 mounts -r-------- 1 root root 0 11月 5 10:24 mountstats dr-xr-xr-x 5 root root 0 11月 5 10:24 net dr-x--x--x 2 root root 0 11月 5 10:24 ns -r--r--r-- 1 root root 0 11月 5 10:24 numa_maps -rw-r--r-- 1 root root 0 11月 5 10:24 oom_adj -r--r--r-- 1 root root 0 11月 5 10:24 oom_score -rw-r--r-- 1 root root 0 11月 5 10:24 oom_score_adj -r--r--r-- 1 root root 0 11月 5 10:24 pagemap -r-------- 1 root root 0 11月 5 10:24 patch_state -r--r--r-- 1 root root 0 11月 5 10:24 personality -rw-r--r-- 1 root root 0 11月 5 10:24 projid_map lrwxrwxrwx 1 root root 0 11月 5 10:24 root -&gt; / -rw-r--r-- 1 root root 0 11月 5 10:24 sched -r--r--r-- 1 root root 0 11月 5 10:24 schedstat -r--r--r-- 1 root root 0 11月 5 10:24 sessionid -rw-r--r-- 1 root root 0 11月 5 10:24 setgroups -r--r--r-- 1 root root 0 11月 5 10:24 smaps -r--r--r-- 1 root root 0 11月 5 10:24 stack -r--r--r-- 1 root root 0 10月 8 21:02 stat -r--r--r-- 1 root root 0 11月 5 10:24 statm -r--r--r-- 1 root root 0 10月 8 21:02 status -r--r--r-- 1 root root 0 11月 5 10:24 syscall dr-xr-xr-x 30 root root 0 11月 5 10:24 task -r--r--r-- 1 root root 0 11月 5 10:24 timers -rw-r--r-- 1 root root 0 11月 5 10:24 uid_map -r--r--r-- 1 root root 0 11月 5 10:24 wchan 2.查看进程# ps aux | less --查看所有运行中的进程 # ps -A --查看系统中的每个进程。 # ps -u vivek --查看用户vivek运行的进程 3.动态显示进程# top 按q退出，按h进入帮助 4.树状显示进程[root@izwz9bwlp4pyxy4mnxaycez ~]# pstree systemd─┬─aliyun-service ├─atd ├─auditd───{auditd} ├─crond ├─dbus-daemon ├─dhclient ├─irqbalance ├─26*[java───27*[{java}]] ├─java───26*[{java}] ├─2*[java───32*[{java}]] ├─java───23*[{java}] ├─java───21*[{java}] ├─java───61*[{java}] ├─java───247*[{java}] ├─java───57*[{java}] ├─java───49*[{java}] ├─login───bash ├─mysqld_safe───mysqld───128*[{mysqld}] ├─mysqld_safe───mysqld───194*[{mysqld}] ├─10*[nginx───nginx] ├─ntpd ├─polkitd───5*[{polkitd}] ├─redis-server───2*[{redis-server}] ├─rsyslogd───2*[{rsyslogd}] ├─sshd─┬─3*[sshd───bash] │ ├─2*[sshd───bash───2*[tail]] │ ├─sshd───bash───pstree │ └─sshd───sshd ├─systemd-journal ├─systemd-logind ├─systemd-udevd ├─tuned───4*[{tuned}] └─wrapper─┬─java───53*[{java}] └─{wrapper} 将进程快照储存到文件中输入下列命令： # top -b -n1 &gt; /tmp/process.log 你也可以将结果通过邮件发给自己： # top -b -n1 | mail -s &apos;Process snapshot&apos; you@example.com 查看服务器情况1.查看服务器CPU型号grep &quot;model name&quot; /proc/cpuinfo | cut -f2 -d: 2.查看服务器内存容量grep MemTotal /proc/meminfo grep MemTotal /proc/meminfo | cut -f2 -d: free -m |grep &quot;Mem&quot; | awk &apos;{print $2}&apos; 3.查看服务器的CPU是32位还是64位getconf LONG_BIT 4.查看当前Linux的版本more /etc/redhat-release cat /etc/redhat-release 5.查看Linux内核版本uname -r uname -a 6.查看服务器当前时间date 7.查看服务器硬盘和分区df -h fdisk -l 8.查看挂载情况mount 9.查看目录大小du /etc -sh 10.查看服务器初始安装的软件包cat -n /root/install.log more /root/install.log | wc -l 11.查看已经安装的软件包rpm -qa rpm -qa | wc -l yum list installed | wc -l 12.查看服务器键盘布局cat /etc/sysconfig/keyboard cat /etc/sysconfig/keyboard | grep KEYTABLE | cut -f2 -d= 13.查看Selinux状态sestatus sestatus | cut -f2 -d: cat /etc/sysconfig/selinux 14.查看服务器网卡的ip，Mac地址,在ifcfg-eth0 文件里你可以看到mac，网关等信息。ifconfig cat /etc/sysconfig/network-scripts/ifcfg-eth0 | grep IPADDR cat /etc/sysconfig/network-scripts/ifcfg-eth0 | grep IPADDR | cut -f2 -d= ifconfig eth0 |grep &quot;inet addr:&quot; |awk &apos;{print $2}&apos;|cut -c 6- ifconfig | grep &apos;inet addr:&apos;| grep -v &apos;127.0.0.1&apos; | cut -d: -f2 | awk &apos;{ print $1}&apos; 15.查看服务器默认网关cat /etc/sysconfig/network 16.查看服务器的默认DNScat /etc/resolv.conf 17.查看服务器默认语言echo $LANG $LANGUAGE cat /etc/sysconfig/i18n 18.查看服务器所属时区和UTC时间cat /etc/sysconfig/clock 19.查看服务器主机名hostname cat /etc/sysconfig/network 20.查看文件大小ll -h a.txt CentOS挂载新硬盘参考：http://blog.sina.com.cn/s/blog_6177e8400101ntvu.html1.查看当前硬盘使用状况： df -h 2.查看新硬盘 fdisk -l 新添加的硬盘的编号为 /dev/xvdb /dev/xvde /dev/vdb 3.硬盘分区 1)进入fdisk模式 /sbin/fdisk /dev/vdb 2)输入n进行分区 3)选择分区类型 这里有两个选项： p: 主分区 linux上主分区最多能有4个 e: 扩展分区 linux上扩展分区只能有1个，扩展分区创建后不能直接使用，还要在扩展分区上创建逻辑分区。 这里我选择的p。 4)选择分区个数 可以选择4个分区，这里我只分成1个分区 5)设置柱面，这里选择默认值就可以 6)输入w，写入分区表，进行分区 4.格式化分区 将新分区格式化为ext4文件系统1)如果创建的是主分区mkfs -t ext4 /dev/vdb1 5.挂载硬盘1)创建挂载点在根目录下创建sqjr目录mkdir /server /sqjr2)将/dev/vdb1挂载到/sqjr下 mount /dev/vdb1 /server /sqjr 6.设置开机启动自动挂载新创建的分区不能开机自动挂载，每次重启机器都要手动挂载。设置开机自动挂载需要修改/etc/fstab文件vi /etc/fstab在文件的最后增加一行/dev/vdb1 /server ext4 defaults 1 2 7.取消挂载 /dev/xvdb1umount /dev/vdb1 8.重启reboot -n 清理缓存，释放内存1.清理yum缓存使用yum clean 命令，yum clean 的参数有headers, packages, metadata, dbcache, plugins, expire-cache, rpmdb, all yum clean headers #清理/var/cache/yum的headers yum clean packages #清理/var/cache/yum下的软件包 yum clean metadata ... 2.Linux释放内存 释放网页缓存(To free pagecache): sync; echo 1 &gt; /proc/sys/vm/drop_caches 释放目录项和索引(To free dentries and inodes): sync; echo 2 &gt; /proc/sys/vm/drop_caches 释放网页缓存，目录项和索引（To free pagecache, dentries and inodes）: sync; echo 3 &gt; /proc/sys/vm/drop_caches 利用curl获取本机的外网ip#oray国内地址，返回速度快 curl -s http://ddns.oray.com/checkip | awk -F &quot;: &quot; &apos;{print $2}&apos; | awk -F &quot;\\&lt;&quot; &apos;{print $1}&apos; #返回快 curl ident.me curl myip.dnsomatic.com #返回较快 curl whatismyip.akamai.com curl https://tnx.nl/ip #返回慢，不推荐 curl ifconfig.me curl icanhazip.com curl ipecho.net/plain 挂载磁盘1.查看已挂载script123456789[root@xc-product-server-hn003 ~]# df -hFilesystem Size Used Avail Use% Mounted ondevtmpfs 3.7G 0 3.7G 0% /devtmpfs 3.7G 0 3.7G 0% /dev/shmtmpfs 3.7G 564K 3.7G 1% /runtmpfs 3.7G 0 3.7G 0% /sys/fs/cgroup/dev/vda1 40G 4.3G 36G 11% /overlay 40G 4.3G 36G 11% /var/lib/docker/overlay2/fe37037ef94f25079e4fdaeb9bc4485574cb309d032839b9638db0c1ffd88802/mergedtmpfs 755M 0 755M 0% /run/user/0 2.查看磁盘情况script1234567891011121314151617181920212223[root@xc-product-server-hn003 ~]# fdisk -lDisk /dev/vda: 40 GiB, 42949672960 bytes, 83886080 sectorsUnits: sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisklabel type: dosDisk identifier: 0x4500abcfDevice Boot Start End Sectors Size Id Type/dev/vda1 * 2048 83886046 83883999 40G 83 LinuxDisk /dev/vdb: 100 GiB, 107374182400 bytes, 209715200 sectorsUnits: sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytes``` 有磁盘`/dev/vdb`未挂载。下面挂载到目录`/server`下。3.创建挂载点`/server````shell scriptmkdir /server 4.格式化磁盘script123456789101112[root@xc-product-server-hn003 ~]# mkfs.ext4 /dev/vdbmke2fs 1.45.4 (23-Sep-2019)Creating filesystem with 26214400 4k blocks and 6553600 inodesFilesystem UUID: 0a280208-edad-4186-8ded-ab5550fdb0dcSuperblock backups stored on blocks: 32768, 98304, 163840, 229376, 294912, 819200, 884736, 1605632, 2654208, 4096000, 7962624, 11239424, 20480000, 23887872Allocating group tables: done Writing inode tables: done Creating journal (131072 blocks): doneWriting superblocks and filesystem accounting information: done 5.永久挂载script1vim /etc/fstab 添加一行：/dev/vdb /server ext4 defaults 0 0 123456789101112# # /etc/fstab# Created by anaconda on Mon Aug 24 06:23:59 2020## Accessible filesystems, by reference, are maintained under &apos;/dev/disk/&apos;.# See man pages fstab(5), findfs(8), mount(8) and/or blkid(8) for more info.## After editing this file, run &apos;systemctl daemon-reload&apos; to update systemd# units generated from this file.#UUID=32f2af94-a1cd-4880-bb61-9ede22264d88 / xfs defaults 0 0/dev/vdb /server ext4 defaults 0 0 保存，退出vim。 6.重启系统生效script1reboot 7.再次查看，看是否挂载成功script12345678910[root@xc-product-server-hn003 ~]# clear[root@xc-product-server-hn003 ~]# df -hFilesystem Size Used Avail Use% Mounted ondevtmpfs 3.7G 0 3.7G 0% /devtmpfs 3.7G 0 3.7G 0% /dev/shmtmpfs 3.7G 472K 3.7G 1% /runtmpfs 3.7G 0 3.7G 0% /sys/fs/cgroup/dev/vda1 40G 4.3G 36G 11% //dev/vdb 98G 61M 93G 1% /servertmpfs 755M 0 755M 0% /run/user/0 看到/dev/vdb已经挂载成功。 路由https://blog.csdn.net/hzhsan/article/details/44753533 1.查看路由表 script1# route -n # 查看路由表 2.添加路由 script1sudo route add -net 172.17.1.0 netmask 255.255.255.0 gw 192.168.0.48 3.删除路由 防火墙开启防火墙提示：Unit is masked的解决办法那是因为锁定了防火墙，需要解锁。 防火墙锁定，解锁解锁：script12[root@website ~]# systemctl unmask firewalldRemoved symlink /etc/systemd/system/firewalld.service. 再次锁定： script1[root@website ~]# systemctl mask firewalld 启动、关闭防火墙查看防火墙状态script1234567891011121314[root@xc-product-server-hn002 ~]# systemctl status firewalld.service ● firewalld.service - firewalld - dynamic firewall daemon Loaded: loaded (/usr/lib/systemd/system/firewalld.service; disabled; vendor preset: enabled) Active: inactive (dead) since Tue 2021-01-12 14:43:51 CST; 10min ago Docs: man:firewalld(1) Process: 90155 ExecStart=/usr/sbin/firewalld --nofork --nopid $FIREWALLD_ARGS (code=exited, status=0/SUCCESS) Main PID: 90155 (code=exited, status=0/SUCCESS)Jan 12 14:39:26 xc-product-server-hn002 systemd[1]: Starting firewalld - dynamic firewall daemon...Jan 12 14:39:27 xc-product-server-hn002 systemd[1]: Started firewalld - dynamic firewall daemon.Jan 12 14:39:27 xc-product-server-hn002 firewalld[90155]: WARNING: AllowZoneDrifting is enabled. This is considered an insecure configuration option. It will be removed in a future release. Please consider disabling it now.Jan 12 14:43:50 xc-product-server-hn002 systemd[1]: Stopping firewalld - dynamic firewall daemon...Jan 12 14:43:51 xc-product-server-hn002 systemd[1]: firewalld.service: Succeeded.Jan 12 14:43:51 xc-product-server-hn002 systemd[1]: Stopped firewalld - dynamic firewall daemon. 启动防火墙： script1systemctl start firewalld.service 关闭防火墙： script1systemctl stop firewalld.service","tags":[]},{"title":"redis哨兵模式","date":"2018-06-11T09:27:25.000Z","path":"2018/06/11/redis-sentinel/","text":"","tags":[{"name":"redis哨兵模式","slug":"redis哨兵模式","permalink":"https://xinxiamu.github.io/tags/redis哨兵模式/"}]},{"title":"redis发布订阅特性介绍","date":"2018-06-11T09:24:37.000Z","path":"2018/06/11/redis-pub-sub/","text":"","tags":[{"name":"redis发布订阅","slug":"redis发布订阅","permalink":"https://xinxiamu.github.io/tags/redis发布订阅/"}]},{"title":"redis实现分布式锁","date":"2018-06-11T09:22:58.000Z","path":"2018/06/11/redis-distributed-lock/","text":"","tags":[{"name":"redis分布式锁","slug":"redis分布式锁","permalink":"https://xinxiamu.github.io/tags/redis分布式锁/"}]},{"title":"mysql使用问题记录","date":"2018-06-01T14:46:53.000Z","path":"2018/06/01/mysql-practice/","text":"本文记录在实际使用mysql过程遇到的问题…… 配置my.cnf[mysqld] port = 3910 character-set-client-handshake = FALSE character-set-server = utf8mb4 collation-server = utf8mb4_unicode_ci init_connect=&apos;SET NAMES utf8mb4&apos; default_authentication_plugin = mysql_native_password skip-name-resolve # 一下三个配置，解决too manay connection问题。 max_connections=1000 # 最大连接数，默认100 wait_timeout = 300 # interactive_timeout = 500 log-bin = mysql-bin server-id = 1 [client] default-character-set=utf8mb4 [mysql] default-character-set=utf8mb4 mysql5.7更改数据库密码强度和长度set global validate_password_policy=0; set global validate_password_length=4; mysql5.7，创建登录用户，并对用户赋权只能查看某个数据库CREATE USER &apos;redmine&apos;@&apos;localhost&apos; IDENTIFIED BY &apos;my_password&apos;; GRANT ALL PRIVILEGES ON redmine.* TO &apos;redmine&apos;@&apos;localhost&apos;; flush privileges; 创建用户redmine,密码为：redmine，只对数据库redmine拥有读写权限。 设置超时 数据库连接时间太短，会自动释放，业务代码没执行完成，就断开了。设置太长，会导致整个系统被拖慢。所以要设置一个恰当的时间。 SHOW GLOBAL VARIABLES LIKE &apos;%timeout%&apos; SET GLOBAL wait_timeout=10000 mysql too many connections 解决方法以下三个配置，解决too manay connection问题。 max_connections=1000 # 最大连接数，默认100 wait_timeout = 300 # interactive_timeout = 500 新建用户并授权只能本机登录：script1234567891011121314CREATE USER 'service_scf_root'@'localhost' IDENTIFIED BY '84012d469d52d8e29a4b95ef87dd6d97';GRANT ALL PRIVILEGES ON service_scf.* TO'service_scf_root'@'localhost';flush privileges;``` 可远程登录：```shell scriptCREATE USER 'service_scf_root'@'%' IDENTIFIED BY '84012d469d52d8e29a4b95ef87dd6d97';GRANT ALL PRIVILEGES ON service_scf.* TO 'service_scf_root'@'%';flush privileges; 参考：https://www.jianshu.com/p/fc40067c4dc9https://jingyan.baidu.com/article/fc07f989c5c6bd52fee5192c.html 1.分组查询报错 错误： 1055 - Expression #1 of SELECT list is not in GROUP BY clause and contains nonaggregated column ‘service_abs_ss_local.hta.id’ which is not functionally dependent on columns in GROUP BY clause; this is incompatible with sql_mode=only_full_group_by 解决方案： 参考： https://blog.csdn.net/qq_42175986/article/details/82384160 创建用户，授权script12345CREATE USER 'jinnuo_root'@'%' IDENTIFIED BY 'a1234567';grant select,insert,update,references,delete,create,drop,alter,index,trigger,create routine,alter routine,execute,create view,show view,lock tables,event on jinnuo.* to jinnuo_root;flush privileges;ALTER USER 'jinnuo_root'@'%' IDENTIFIED WITH mysql_native_password BY 'a1234567';flush privileges;","tags":[{"name":"mysql使用问题收藏","slug":"mysql使用问题收藏","permalink":"https://xinxiamu.github.io/tags/mysql使用问题收藏/"}]},{"title":"项目管理系统Redmine使用","date":"2018-06-01T13:35:04.000Z","path":"2018/06/01/redmine-start/","text":"在软件开发过程中，项目管理的有效性直接会影响到项目开发的进度，质量，还有整个团队的协助。总之，没有一个好的项目管理系统，这对项目经理来说就像是上了战场，却没有任何武器一样，必定败仗。 下面介绍这款比较流行的项目管理工具redmine。有了它，项目经理就可以对整个项目的开发全过程进行管理。任务的分配、bug的跟踪、知识库的建立等等…… 官网 在ubuntu下安装参考：http://www.redmine.org/projects/redmine/wiki/Guide ### 下载redmine安装包 网址：http://www.redmine.org/projects/redmine/wiki/Download wget http://www.redmine.org/releases/redmine-3.4.5.tar.gz 安装Ruby环境参考官网说明，注意redmine版本对ruby版本的要求。 1.下载地址：http://ftp.ruby-lang.org/pub/ruby/ //下载 zmt@zmt-Lenovo:~/Desktop/work/tools$ wget http://ftp.ruby-lang.org/pub/ruby/2.4/ruby-2.4.4.tar.gz zmt@zmt-Lenovo:~/Desktop/work/tools$ tar -zxvf ruby-2.4.4.tar.gz //查询openssl安装路径 zmt@zmt-Lenovo:~$ openssl version -a OpenSSL 1.1.0g 2 Nov 2017 built on: reproducible build, date unspecified platform: debian-amd64 compiler: gcc -DDSO_DLFCN -DHAVE_DLFCN_H -DNDEBUG -DOPENSSL_THREADS -DOPENSSL_NO_STATIC_ENGINE -DOPENSSL_PIC -DOPENSSL_IA32_SSE2 -DOPENSSL_BN_ASM_MONT -DOPENSSL_BN_ASM_MONT5 -DOPENSSL_BN_ASM_GF2m -DSHA1_ASM -DSHA256_ASM -DSHA512_ASM -DRC4_ASM -DMD5_ASM -DAES_ASM -DVPAES_ASM -DBSAES_ASM -DGHASH_ASM -DECP_NISTZ256_ASM -DPADLOCK_ASM -DPOLY1305_ASM -DOPENSSLDIR=&quot;\\&quot;/usr/lib/ssl\\&quot;&quot; -DENGINESDIR=&quot;\\&quot;/usr/lib/x86_64-linux-gnu/engines-1.1\\&quot;&quot; OPENSSLDIR: &quot;/usr/lib/ssl&quot; ENGINESDIR: &quot;/usr/lib/x86_64-linux-gnu/engines-1.1&quot; //看上面结果，确定openssl安装dir为：/usr/lib/ssl //安装： $ cd ruby-2.4.4 $ ./configure --with-openssl-dir=/usr/lib/ssl $ make $ sudo make install 3.检查是否安装成功： zmt@zmt-Lenovo:~$ ruby -v ruby 2.4.4p296 (2018-03-28 revision 63013) [x86_64-linux] 看到上面显示说明安装成功。 创建空的数据库，并初始化用户一般数据库名为redmine,但是可以自己更改。 1.MySQL 创建数据库登录用户redmine，密码为redmine //mysql要求５.6或以上版本 CREATE DATABASE redmine CHARACTER SET utf8mb4; CREATE USER &apos;redmine&apos;@&apos;localhost&apos; IDENTIFIED BY &apos;my_password&apos;; GRANT ALL PRIVILEGES ON redmine.* TO &apos;redmine&apos;@&apos;localhost&apos;; //刷新权限 flush privileges; 数据库连接配置设置解压下载的redmine-3.4.5.tar.gz， 并进入解压包内。 在config目录下，可以看到文件database.yml.example，复制该文件命名为database.yml，放在同一个目录config下。下面就可以编辑文件database.yml了。 1.mysql的配置 默认端口3306 production: adapter: mysql2 database: redmine host: localhost username: redmine password: redmine 不是3306端口，如下配置： production: adapter: mysql2 database: redmine host: localhost port: 3307 username: redmine password: redmine 按照以上配置修改好，保存并退出。 redmine运行相关依赖包安装Redmine uses Bundler to manage gems dependencies. 1.首先按照Bundler sudo gem install bundler 报错误： zmt@zmt-Lenovo:~$ gem install bundler ERROR: While executing gem ... (Gem::Exception) Unable to require openssl, install OpenSSL and rebuild ruby (preferred) or use non-HTTPS sources 意思是，要要求系统按照OpenSSL，然后按上面步骤重新编译安装ruby。 按照openssl： sudo apt-get install openssl 重新编译按照ruby后再执行gem install bundler。 还是不行，可能是因为不是以root用户安装的缘故。 _注：_ 没关系，我们不通过网络安装，而是直接下载gem安装包安装。 安装RubyGems安装 如果第一步能执行成功，不需要另外安装rubygems，因为安装ruby的时候已经安装。 网址：https://rubygems.org/ 下载并安装： # wget https://rubygems.global.ssl.fastly.net/rubygems/rubygems-2.6.6.tgz # tar zxvf rubygems-2.6.6.tgz # cd rubygems-2.6.6.tgz # ruby setup.rb //显示版本好，说民安装成功 zmt@zmt-Lenovo:~/Desktop/work/tools/rubygems-2.6.6$ gem -v 2.6.6 安装成功，重新执行步骤1，即安装Bundler，执行： gem install bundler 2.然后可以利用bundler安装redmine相关依赖包 Then you can install all the gems required by Redmine using the following command: bundle install --without development test &lt;&lt;—-未完—&gt;&gt; Centos7下安装全过程记录参考网址：http://www.redmine.org/projects/redmine/wiki/RedmineInstall 应用版本信息：redmine： redmine-3.4.6.tar.gzruby： ruby-2.3.6.tar.gz 首先安装系统相关包： yum -y install patch make gcc gcc-c++ gcc-g77 flex* bison file yum -y install libtool libtool-libs libtool-ltdl-devel* autoconf kernel-devel automake libmcrypt* yum -y install libjpeg libjpeg-devel libpng libpng-devel libpng10 libpng10-devel gd gd-devel yum -y install freetype freetype-devel libxml2 libxml2-devel zlib zlib-devel yum -y install glib2 glib2-devel bzip2 bzip2-devel libevent libevent-devel yum -y install ncurses ncurses-devel curl curl-devel e2fsprogs yum -y install e2fsprogs-devel krb5 krb5-devel libidn libidn-devel yum -y install openssl openssl-devel vim-minimal nano sendmail yum -y install fonts-chinese gettext gettext-devel yum -y install gmp-devel pspell-devel yum -y install readline* libxslt* pcre* net-snmp* gmp* libtidy* yum -y install ImageMagick* subversion* 下载redmine安装包可以在官网下载正式发布的二进制包下载。 创建空的数据库以及相关数据库用户首先要保证已经安装好数据库。下面以mysql为例进行安装。mysql版本&gt;5.5.2。创建脚本： CREATE DATABASE redmine CHARACTER SET utf8mb4; #CREATE USER &apos;redmine&apos;@&apos;localhost&apos; IDENTIFIED BY &apos;my_password&apos;; #这样的，navicat客户端无法登录 CREATE USER &apos;redmine&apos;@&apos;localhost&apos; IDENTIFIED WITH mysql_native_password BY &apos;my_password&apos;; GRANT ALL PRIVILEGES ON redmine.* TO &apos;redmine&apos;@&apos;localhost&apos;; 为redmine配置数据库首先，解压redmine包，并进入config目录。 [root@ymu config]# cp database.yml.example database.yml 然后编辑database.yml： production: adapter: mysql2 database: redmine host: localhost port: 3307 username: redmine password: redmine _注意_: 主机名用localhost可能报错，要改成127.0.0.1。 安装依赖包1.安装ruby环境。 安装上面描述方式，ruby源码包安装方式。选择版本安装。 系统源安装。yum install gem。会自动安装ruby环境。 下面采用源码编译安装方式。检查是否安装成功：ruby -v gem -v 问题解决：安装完ruby却提示[/usr/bin/ruby: No such file or directory] ln -s /usr/local/bin/ruby /usr/bin/rubyln -s /usr/local/bin/gem /usr/bin/gem 2.安装bundler redmine的依赖包都通过bundler来安装。 gem install bundler 3.安装所有依赖 执行下面命令前，记得要按照上面方法安装所有系统依赖包。 [root@ymu ~]# cd /server/tools/redmine-3.4.6/ [root@ymu redmine-3.4.6]# bundle install --without development test 安全生成存储会话bundle exec rake generate_secret_token 创建表[root@ymu redmine-3.4.6]# bundle exec rake generate_secret_token [root@ymu redmine-3.4.6]# RAILS_ENV=production bundle exec rake db:migrate 查看数据库，可以看到已经创建了很多表。 设置数据库默认数据[root@ymu redmine-3.4.6]# RAILS_ENV=production bundle exec rake redmine:load_default_data Select language: ar, az, bg, bs, ca, cs, da, de, el, en, en-GB, es, es-PA, et, eu, fa, fi, fr, gl, he, hr, hu, id, it, ja, ko, lt, lv, mk, mn, nl, no, pl, pt, pt-BR, ro, ru, sk, sl, sq, sr, sr-YU, sv, th, tr, uk, vi, zh, zh-TW [en] zh ==================================== Default configuration data loaded. 记得：输入zh，然后按下回车。否则会是英文版本数据。 设置文件权限 如果上面的所有操作都是root用户，那么就不必要设置文件权限，可以跳过此步骤。 （上面以root操作，跳过这步骤） 如果不是在root超级用户下，则要设置文件权限，否则redmine应用程序无法操作一些文件权限。 在redmine解压根目录下，这些文件必须赋予权限： files (storage of attachments) log (application log file production.log) tmp and tmp/pdf (create these ones if not present, used to generate PDF documents among other things) public/plugin_assets (assets of plugins) 如果没有这些文件： mkdir -p tmp tmp/pdf public/plugin_assets sudo chown -R redmine:redmine files log tmp public/plugin_assets sudo chmod -R 755 files log tmp public/plugin_assets 如果都有： sudo chown -R redmine:redmine files log tmp public/plugin_assets sudo chmod -R 755 files log tmp public/plugin_assets _注意_:保证下面目录不包含可执行文件。 sudo find files log tmp public/plugin_assets -type f -exec chmod -x {} + 测试是否安装成功按照下面经验执行操作： bundle exec rails server webrick -e production //在redmine安装目录下执行 //注意，服务器端执行上面命令可能报错，可能是端口不可用，可以改变端口： bundle exec rails server webrick -e production -p 8889 改变端口执行服务成功，但是在客户机子不能访问，此时要这么执行： bundle exec rails server webrick -e production -b 0.0.0.0 -p 8889 ok搞定 守护进程模式执行： nohup bundle exec rails server webrick -e production -b 0.0.0.0 -p 8889 &amp; 或者： bundle exec rails server webrick -e production -b 0.0.0.0 -p 8889 -d 然后就可以访问：http：//loaclhost:port。 登录redmine默认账号密码：username=adminpwd=admin 打开网址后，用默认账号密码登录后，会要求修改密码。把密码改为：username=adminpwd=admin123 按页面提示，填写修改相关信息即可。 修改配置（不修改则采用默认的配置）redmine的配置设置文件放在：config/configuration.yml。如果要自己定义配置，则可以copy config/configuration.yml.example to config/configuration.yml，然后编辑configuration.yml文件即可。 记得：修改配置文件后重启redmine，否则不生效。 重启redmine采用直接kill掉： lsof -i:3000 kill -9 pid 开机自启编辑启动文件 vi /etc/rc.local 最后一行或者适当的位置，加入一下内容。此处必须用绝对路径。注意根据实际redmine路径来填写。 /usr/local/rvm/rubies/ruby-2.0.0-p598/bin/ruby /root/redmine-2.6.0/script/rails server webrick -e production -d 设置Email/SMTP服务器项目管理中，分配了任务或者测试提交了bug给某个开发人员，那么可以通过邮件及时的提醒他。 下面我们就来配置邮件服务器：参考：http://www.redmine.org/projects/redmine/wiki/EmailConfiguration 1.编辑配置文件：config/configuration.yml 添加邮箱服务器配置，异步发送邮件（qq邮箱为例子）： email_delivery: delivery_method: :async_smtp async_smtp_settings: address: &quot;smtp.qq.com&quot; port: 25 authentication: :login domain: &apos;qq.com&apos; user_name: &apos;932852117@qq.com&apos; password: &apos;××××××&apos; 下面是实际操作内容： # default configuration options for all environments default: # Outgoing emails configuration # See the examples below and the Rails guide for more configuration options: # http://guides.rubyonrails.org/action_mailer_basics.html#action-mailer-configuration email_delivery: delivery_method: :async_smtp async_smtp_settings: address: &quot;smtp.qq.com&quot; port: 25 authentication: :login domain: &apos;qq.com&apos; user_name: &apos;932852117@qq.com&apos; password: &apos;××××××&apos; # ==== Simple SMTP server at localhost 2.开启邮箱服务器 3.重启redmine并测试是否配置成功。 登录redmine，在管理-&gt;配置中： 输入配置的邮箱地址后，保存。然后点击右下角的发送测试邮件： 看到绿色提示邮件已发送至 zhangmutian@xcsqjr.com。证明配置已成功，可以愉快的使用了。 scm配置主要是svn和git版本库管理工具。 如：svn的scm_subversion_command: &quot;svn_replacement.exe&quot; 只需要安装svn或者git服务端，然后在配置文件指向即可。 其它的配置一般采用默认的就好了。 1.附件存储路径。attachments_storage_path: /var/redmine/files2.日志保存路径。 等等…… 恭喜恭喜，到此，你已成功安装redmine了，并且它已经具备了该有的基础功能了。赶紧来看下它帅帅的样子吧： 尽情的去探索redmine很多很多，酷酷的特性吧，让它正真成为你在项目管理中的瑞士军刀……","tags":[]},{"title":"spring-boot消息国际化","date":"2018-05-18T01:58:40.000Z","path":"2018/05/18/spring-boot-messages/","text":"","tags":[{"name":"spring mvc国际化","slug":"spring-mvc国际化","permalink":"https://xinxiamu.github.io/tags/spring-mvc国际化/"}]},{"title":"shiro安全框架入门","date":"2018-05-14T03:22:37.000Z","path":"2018/05/14/shiro-start/","text":"Apache Shiro(官网)是个java的安全框架，轻便、api简单、功能全面的特性获得 许多开发者的青睐。其提供了认证、授权、加密以及会话管理等功能…… 一.介绍1.功能特性Shiro 包含 10 个内容，如下图： Authentication: 身份认证，拥有合法身份才能登录系统并使用。 Authorization： 授权验证。即认证某个已经得到身份认证的用户是否拥有对某个功能或者某种资源的使用权限。 Session Manager： 会话管理。用户登录后，没退出之前，为一次会话，所有的信息都在会话中。会话可以是javase环境，也可以是java web环境。 Cryptography： 加密，保护数据的安全性。 Web Support： web支持，把shiro容易的集成到web环境中。 Caching： 缓存，用户登陆后，用户的信息、拥有的角色权限不必每次查，缓存起来。 Concurrency： shiro 支持多线程应用的并发验证，即如在一个线程中开启另一个线程，能把权限自动传播过去。 Testing：提供测试支持。 Run As：允许一个用户假装为另一个用户（如果他们允许）的身份进行访问。 Remember Me：记住我，这个是非常常见的功能，即一次登录后，下次再来的话不用登录了。 2.运行原理1.原理图1（应用程序角度）： Subject：主体，代表当前“用户”，这里的用户指的不仅仅是登录用户，指的是任何与该系统交互的主体。所有的Subject都和SecurityManager绑定，与Subject的任何交互都委托给SecurityManager来处理。 SecurityManager： 安全管理器，是shiro的核心功能。它负责所有的安全操作管理，管理这所有的Subject。类似于SpringMvc中的DispatcherServlet控制器。 Realm： 域。所有的安全数据保存，获取都要通过Realm。SecurityManager和它交互，获取相关数据。Realm就类似于数据源DataSource。 2.原理图2（内部架构）： Subject：主体。 SecurityManager：安全管理器。 Authenticator： 认证器，负责对主体的身份认证。可以自定义，重新设定认证策略，即什么情况下才算认证通过。 Authrizer： 授权器，或者访问控制器。决定主体是否有权限进行相应操作。 Realm： 可以一个或者多个。可以是jdbc，redis，内存等实现。 SessionManager： 会话管理器。 SessionDAO： 数据访问对象，用于会话的CRUD。可以自定义，控制session存储的位置，关系数据库，redis等。另外，可以使用缓存，提高性能。 CacheManager： 缓存管理器。 Cryptography： 密码模块。提供了一些加解密算法。 3.过滤器应用到web系统中时，Shiro会默认创建一些过滤器对客户端请求进行过滤。常用过滤器有： 过滤器简称 对应的 Java 类 anon org.apache.shiro.web.filter.authc.AnonymousFilter authc org.apache.shiro.web.filter.authc.FormAuthenticationFilter authcBasic org.apache.shiro.web.filter.authc.BasicHttpAuthenticationFilter perms org.apache.shiro.web.filter.authz.PermissionsAuthorizationFilter port org.apache.shiro.web.filter.authz.PortFilter rest org.apache.shiro.web.filter.authz.HttpMethodPermissionFilter roles org.apache.shiro.web.filter.authz.RolesAuthorizationFilter ssl org.apache.shiro.web.filter.authz.SslFilter user org.apache.shiro.web.filter.authc.UserFilter logout org.apache.shiro.web.filter.authc.LogoutFilter noSessionCreation org.apache.shiro.web.filter.session.NoSessionCreationFilter 说明： /admins/**=anon # 表示该 uri 可以匿名访问 /admins/**=auth # 表示该 uri 需要认证才能访问 /admins/**=authcBasic # 表示该 uri 需要 httpBasic 认证 /admins/**=perms[user:add:*] # 表示该 uri 需要认证用户拥有 user:add:* 权限才能访问 /admins/**=port[8081] # 表示该 uri 需要使用 8081 端口 /admins/**=rest[user] # 相当于 /admins/**=perms[user:method]，其中，method 表示 get、post、delete 等 /admins/**=roles[admin] # 表示该 uri 需要认证用户拥有 admin 角色才能访问 /admins/**=ssl # 表示该 uri 需要使用 https 协议 /admins/**=user # 表示该 uri 需要认证或通过记住我认证才能访问 /logout=logout # 表示注销,可以当作固定配置 _注意_ anon，authcBasic，auchc，user 是认证过滤器。 perms，roles，ssl，rest，port 是授权过滤器。 二.认证1.认证路程图： 2.使用代码示例： 123456789101112131415161718192021222324252627282930313233343536373839404142package com.example.springboot2shirostart;import org.apache.shiro.SecurityUtils;import org.apache.shiro.authc.UsernamePasswordToken;import org.apache.shiro.mgt.DefaultSecurityManager;import org.apache.shiro.realm.SimpleAccountRealm;import org.apache.shiro.subject.Subject;import org.junit.Before;import org.junit.Test;/** * 简单认证 */public class AuthenticationTest &#123; SimpleAccountRealm simpleAccoutRealm = new SimpleAccountRealm(); @Before public void addUser() &#123; simpleAccoutRealm.addAccount(\"zmt\",\"123456\");// simpleAccoutRealm.addAccount(\"zmt1\",\"123456\"); &#125; @Test public void testAuthentication() &#123; //1.创建securityManager环境 DefaultSecurityManager defaultSecurityManager = new DefaultSecurityManager(); defaultSecurityManager.setRealm(simpleAccoutRealm); //2.主体提交认证请求 SecurityUtils.setSecurityManager(defaultSecurityManager); Subject subject = SecurityUtils.getSubject(); UsernamePasswordToken token = new UsernamePasswordToken(\"zmt\",\"123456\"); subject.login(token); System.out.println(\"isAuthenticated:\" + subject.isAuthenticated());//已认证 subject.logout();//退出登录 System.out.println(\"isAuthenticated:\" + subject.isAuthenticated());//未认证 &#125;&#125; 三.授权1.流程图： 2。代码示例： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849package com.example.springboot2shirostart;import org.apache.shiro.SecurityUtils;import org.apache.shiro.authc.UsernamePasswordToken;import org.apache.shiro.mgt.DefaultSecurityManager;import org.apache.shiro.realm.SimpleAccountRealm;import org.apache.shiro.subject.Subject;import org.junit.Before;import org.junit.Test;/** * 简单认证 */public class AuthenticationTest &#123; SimpleAccountRealm simpleAccoutRealm = new SimpleAccountRealm(); @Before public void addUser() &#123;// simpleAccoutRealm.addAccount(\"zmt\",\"123456\");// simpleAccoutRealm.addAccount(\"zmt1\",\"123456\"); simpleAccoutRealm.addAccount(\"zmt\",\"123456\",\"admin\",\"user\"); //添加角色 &#125; @Test public void testAuthentication() &#123; //1.创建securityManager环境 DefaultSecurityManager defaultSecurityManager = new DefaultSecurityManager(); defaultSecurityManager.setRealm(simpleAccoutRealm); //2.主体提交认证请求 SecurityUtils.setSecurityManager(defaultSecurityManager); Subject subject = SecurityUtils.getSubject(); UsernamePasswordToken token = new UsernamePasswordToken(\"zmt\",\"123456\"); subject.login(token); System.out.println(\"isAuthenticated:\" + subject.isAuthenticated());//已认证 subject.checkRole(\"admin\"); //admin通过，admin1报错 subject.checkRoles(\"admin\",\"user1\"); //拥有该两个角色// subject.logout();//退出登录// System.out.println(\"isAuthenticated:\" + subject.isAuthenticated());//未认证 &#125;&#125; 四.Shiro自定义Realm1.IniRealm讲解代码样例： 123456789101112131415161718192021222324252627282930313233343536373839404142package com.example.springboot2shirostart;import org.apache.shiro.SecurityUtils;import org.apache.shiro.authc.UsernamePasswordToken;import org.apache.shiro.mgt.DefaultSecurityManager;import org.apache.shiro.realm.text.IniRealm;import org.apache.shiro.subject.Subject;import org.junit.Test;/** * 简单认证 */public class IniRealmTest &#123; @Test public void test1() &#123; IniRealm iniRealm = new IniRealm(\"classpath:user.ini\"); //1.创建securityManager环境 DefaultSecurityManager defaultSecurityManager = new DefaultSecurityManager(); defaultSecurityManager.setRealm(iniRealm); //2.主体提交认证请求 SecurityUtils.setSecurityManager(defaultSecurityManager); Subject subject = SecurityUtils.getSubject(); UsernamePasswordToken token = new UsernamePasswordToken(\"zmt\",\"123456\"); subject.login(token); System.out.println(\"isAuthenticated:\" + subject.isAuthenticated());//已认证 subject.checkRole(\"admin\"); //admin通过，admin1报错 subject.checkRoles(\"admin\",\"user\"); //拥有该两个角色 //权限 subject.checkPermission(\"user:delete\");// subject.checkPermission(\"user:insert\"); //报错，么有insert权限 subject.checkPermission(\"user:update\"); //报错，没有update权限 &#125;&#125; 123456编辑：user.ini[users]zmt=123456,admin,user[roles]admin=user:delete,user:update 2.JdbcRealm讲解用户、角色、权限数据都在数据库里面。而不是在配置文件里面。两种方式，一种是使用默认查询语句；另外一种是自己设计表，写sql语句，不必遵守默认的。 2.1.默认方式 首先，创建相关默认数据表： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172/*Navicat MySQL Data TransferSource Server : localhostSource Server Version : 50718Source Host : localhost:3307Source Database : shiro-testTarget Server Type : MYSQLTarget Server Version : 50718File Encoding : 65001Date: 2018-10-15 17:09:45*/SET FOREIGN_KEY_CHECKS=0;-- ------------------------------ Table structure for roles_permissions-- ----------------------------DROP TABLE IF EXISTS `roles_permissions`;CREATE TABLE `roles_permissions` ( `id` int(11) NOT NULL AUTO_INCREMENT, `role_name` varchar(255) NOT NULL, `permission` varchar(255) NOT NULL, PRIMARY KEY (`id`), KEY `role_name` (`role_name`), CONSTRAINT `roles_permissions_ibfk_1` FOREIGN KEY (`role_name`) REFERENCES `user_roles` (`role_name`)) ENGINE=InnoDB AUTO_INCREMENT=2 DEFAULT CHARSET=utf8mb4;-- ------------------------------ Records of roles_permissions-- ----------------------------INSERT INTO `roles_permissions` VALUES ('1', 'admin', 'user:select');-- ------------------------------ Table structure for user_roles-- ----------------------------DROP TABLE IF EXISTS `user_roles`;CREATE TABLE `user_roles` ( `id` int(11) NOT NULL AUTO_INCREMENT, `username` varchar(255) NOT NULL, `role_name` varchar(255) DEFAULT NULL, PRIMARY KEY (`id`), KEY `username` (`username`), KEY `role_name` (`role_name`), CONSTRAINT `user_roles_ibfk_1` FOREIGN KEY (`username`) REFERENCES `users` (`username`)) ENGINE=InnoDB AUTO_INCREMENT=2 DEFAULT CHARSET=utf8mb4;-- ------------------------------ Records of user_roles-- ----------------------------INSERT INTO `user_roles` VALUES ('1', 'zmt', 'admin');-- ------------------------------ Table structure for users-- ----------------------------DROP TABLE IF EXISTS `users`;CREATE TABLE `users` ( `id` int(11) NOT NULL AUTO_INCREMENT, `username` varchar(255) NOT NULL, `password` varchar(255) NOT NULL, `password_salt` varchar(255) NOT NULL, PRIMARY KEY (`id`), KEY `username` (`username`)) ENGINE=InnoDB AUTO_INCREMENT=2 DEFAULT CHARSET=utf8mb4;-- ------------------------------ Records of users-- ----------------------------INSERT INTO `users` VALUES ('1', 'zmt', '123456', 'abcd');SET FOREIGN_KEY_CHECKS=1; 代码样例： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556package com.example.springboot2shirostart;import com.alibaba.druid.pool.DruidDataSource;import org.apache.shiro.SecurityUtils;import org.apache.shiro.authc.UsernamePasswordToken;import org.apache.shiro.mgt.DefaultSecurityManager;import org.apache.shiro.realm.jdbc.JdbcRealm;import org.apache.shiro.subject.Subject;import org.junit.Test;/** * 简单认证 */public class JdbcRealmTest &#123; DruidDataSource dataSource = new DruidDataSource(); &#123; dataSource.setUrl(\"jdbc:mysql://localhost:3307/shiro-test\"); dataSource.setUsername(\"root\"); dataSource.setPassword(\"root\"); &#125; /** * 查询默认的数据表做相关操作。 */ @Test public void test1() &#123; JdbcRealm jdbcRealm = new JdbcRealm(); jdbcRealm.setDataSource(dataSource); //设置数据源 jdbcRealm.setPermissionsLookupEnabled(true); //是否可以查看权限。默认为false。不打开，则无法查看权限 //1.创建securityManager环境 DefaultSecurityManager defaultSecurityManager = new DefaultSecurityManager(); defaultSecurityManager.setRealm(jdbcRealm); //2.主体提交认证请求 SecurityUtils.setSecurityManager(defaultSecurityManager); Subject subject = SecurityUtils.getSubject(); UsernamePasswordToken token = new UsernamePasswordToken(\"zmt\",\"123456\");//用户 subject.login(token); System.out.println(\"isAuthenticated:\" + subject.isAuthenticated());//已认证 subject.checkRole(\"admin\"); //admin通过，admin1报错// subject.checkRoles(\"admin\",\"user\"); //拥有该两个角色 //权限 subject.checkPermission(\"user:select\");//jdbcRealm.setPermissionsLookupEnabled(true);// subject.checkPermission(\"user:insert\"); //报错，么有insert权限// subject.checkPermission(\"user:update\"); //报错，没有update权限 &#125;&#125; 2.2.自己设计表写查询语句 创建数据表不必遵循默认规范，表名、字段名都可以自定义。 脚本：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566/*Navicat MySQL Data TransferSource Server : localhostSource Server Version : 50718Source Host : localhost:3307Source Database : shiro-testTarget Server Type : MYSQLTarget Server Version : 50718File Encoding : 65001Date: 2018-10-17 11:42:25*/SET FOREIGN_KEY_CHECKS=0;-- ------------------------------ Table structure for test_role_permissions-- ----------------------------DROP TABLE IF EXISTS `test_role_permissions`;CREATE TABLE `test_role_permissions` ( `id` int(11) NOT NULL AUTO_INCREMENT, `role_name` varchar(255) NOT NULL, `permission` varchar(255) NOT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB AUTO_INCREMENT=2 DEFAULT CHARSET=utf8mb4;-- ------------------------------ Records of test_role_permissions-- ----------------------------INSERT INTO `test_role_permissions` VALUES ('1', 'caiwu', 'user:update');-- ------------------------------ Table structure for test_user-- ----------------------------DROP TABLE IF EXISTS `test_user`;CREATE TABLE `test_user` ( `id` int(11) NOT NULL AUTO_INCREMENT, `user_name` varchar(255) NOT NULL, `password` varchar(255) NOT NULL, PRIMARY KEY (`id`), KEY `username` (`user_name`)) ENGINE=InnoDB AUTO_INCREMENT=2 DEFAULT CHARSET=utf8mb4;-- ------------------------------ Records of test_user-- ----------------------------INSERT INTO `test_user` VALUES ('1', 'xr', '123456');-- ------------------------------ Table structure for test_user_role-- ----------------------------DROP TABLE IF EXISTS `test_user_role`;CREATE TABLE `test_user_role` ( `id` int(11) NOT NULL AUTO_INCREMENT, `test_user_name` varchar(255) NOT NULL, `role_name` varchar(255) DEFAULT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB AUTO_INCREMENT=2 DEFAULT CHARSET=utf8mb4;-- ------------------------------ Records of test_user_role-- ----------------------------INSERT INTO `test_user_role` VALUES ('1', 'xr', 'caiwu');SET FOREIGN_KEY_CHECKS=1; 代码样例：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758package com.example.springboot2shirostart;import com.alibaba.druid.pool.DruidDataSource;import org.apache.shiro.SecurityUtils;import org.apache.shiro.authc.UsernamePasswordToken;import org.apache.shiro.mgt.DefaultSecurityManager;import org.apache.shiro.realm.jdbc.JdbcRealm;import org.apache.shiro.subject.Subject;import org.junit.Test;/** * 简单认证 */public class JdbcRealmTest &#123; DruidDataSource dataSource = new DruidDataSource(); &#123; dataSource.setUrl(\"jdbc:mysql://localhost:3307/shiro-test\"); dataSource.setUsername(\"root\"); dataSource.setPassword(\"root\"); &#125; @Test public void test2() &#123; JdbcRealm jdbcRealm = new JdbcRealm(); jdbcRealm.setDataSource(dataSource); //设置数据源 jdbcRealm.setPermissionsLookupEnabled(true); //是否可以查看权限。默认为false。不打开，则无法查看权限 //创建sql语句，使用自己的表、sql来验证 String sql_auth = \"SELECT `password` FROM test_user WHERE user_name = ?\"; jdbcRealm.setAuthenticationQuery(sql_auth); String sql_role = \"SELECT role_name FROM test_user_role WHERE test_user_name = ?\"; jdbcRealm.setUserRolesQuery(sql_role); String sql_permisstion = \"SELECT permission FROM test_role_permissions WHERE role_name = ?\"; jdbcRealm.setPermissionsQuery(sql_permisstion); //1.创建securityManager环境 DefaultSecurityManager defaultSecurityManager = new DefaultSecurityManager(); defaultSecurityManager.setRealm(jdbcRealm); //2.主体提交认证请求 SecurityUtils.setSecurityManager(defaultSecurityManager); Subject subject = SecurityUtils.getSubject(); UsernamePasswordToken token = new UsernamePasswordToken(\"xr\",\"123456\");//用户 subject.login(token); System.out.println(\"isAuthenticated:\" + subject.isAuthenticated());//已认证 subject.checkRole(\"caiwu\"); //权限 subject.checkPermission(\"user:update\");//jdbcRealm.setPermissionsLookupEnabled(true); &#125;&#125; 3.自定义Realm 创建类CustomRealm 自定义Realm需要继承AuthorizingRealm。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697package com.example.springboot2shirostart;import org.apache.shiro.authc.AuthenticationException;import org.apache.shiro.authc.AuthenticationInfo;import org.apache.shiro.authc.AuthenticationToken;import org.apache.shiro.authc.SimpleAuthenticationInfo;import org.apache.shiro.authz.AuthorizationInfo;import org.apache.shiro.authz.SimpleAuthorizationInfo;import org.apache.shiro.realm.AuthorizingRealm;import org.apache.shiro.subject.PrincipalCollection;import java.util.HashMap;import java.util.HashSet;import java.util.Map;import java.util.Set;public class CustomRealm extends AuthorizingRealm &#123; final String realmName = this.getClass().getSimpleName(); //自定义realm名称 Map&lt;String,String&gt; userMap = new HashMap&lt;&gt;(16); &#123; userMap.put(\"zmt\",\"123456\"); userMap.put(\"xr\",\"654321\"); super.setName(realmName); //设置名称 &#125; @Override protected AuthorizationInfo doGetAuthorizationInfo(PrincipalCollection principals) &#123; String username = (String) principals.getPrimaryPrincipal(); //从数据库或者缓存中获取角色数据。 Set&lt;String&gt; roles = getRolesByUsername(username); Set&lt;String&gt; permissions = getPermissionByUsername(username); SimpleAuthorizationInfo authorizationInfo = new SimpleAuthorizationInfo(); authorizationInfo.setStringPermissions(permissions); //设置权限 authorizationInfo.setRoles(roles); //设置角色 return authorizationInfo; &#125; /** * 模拟通过用户名获取权限。 * @param username * @return */ private Set&lt;String&gt; getPermissionByUsername(String username) &#123; Set&lt;String&gt; permissions = new HashSet&lt;&gt;(); permissions.add(\"admin:delete\"); permissions.add(\"user:select\"); permissions.add(\"user:update\"); return permissions; &#125; /** * 模拟获取角色。根据用户名获取角色。 * @param username * @return */ private Set&lt;String&gt; getRolesByUsername(String username) &#123; Set&lt;String&gt; roles = new HashSet&lt;&gt;(); roles.add(\"admin\"); roles.add(\"user\"); return roles; &#125; @Override protected AuthenticationInfo doGetAuthenticationInfo(AuthenticationToken token) throws AuthenticationException &#123; //从主体传过来认证信息,获得用户名 String username = (String) token.getPrincipal(); System.out.println(\"username:\" + username); //通过用户名到数据库中获取凭证 String pwd = getPwdByUsername(username); if (pwd == null) &#123; return null; &#125; SimpleAuthenticationInfo authenticationInfo = new SimpleAuthenticationInfo(username,pwd,realmName); return authenticationInfo; &#125; /** * 模拟获取数据库数据。根据用户名获取用户密码 * @param username 用户名。 * @return */ private String getPwdByUsername(String username) &#123; return userMap.get(username); &#125;&#125; 测试： 12345678910111213141516171819202122232425262728293031323334353637383940package com.example.springboot2shirostart;import org.apache.shiro.SecurityUtils;import org.apache.shiro.authc.UsernamePasswordToken;import org.apache.shiro.mgt.DefaultSecurityManager;import org.apache.shiro.subject.Subject;import org.junit.Test;/** * 简单认证 */public class CustomRealmTest &#123; @Test public void test1() &#123; CustomRealm customRealm = new CustomRealm();//自定义Realm //1.创建securityManager环境 DefaultSecurityManager defaultSecurityManager = new DefaultSecurityManager(); defaultSecurityManager.setRealm(customRealm); //2.主体提交认证请求 SecurityUtils.setSecurityManager(defaultSecurityManager); Subject subject = SecurityUtils.getSubject(); UsernamePasswordToken token = new UsernamePasswordToken(\"zmt\",\"123456\");//用户 subject.login(token); System.out.println(\"isAuthenticated:\" + subject.isAuthenticated());//已认证// subject.checkRole(\"admin\"); //admin通过，admin1报错 subject.checkRoles(\"admin\",\"user\"); //拥有该两个角色 //权限 subject.checkPermission(\"user:select\");//jdbcRealm.setPermissionsLookupEnabled(true);// subject.checkPermission(\"user:insert\"); //报错，么有insert权限 subject.checkPermission(\"user:update\"); //有update权限 &#125;&#125; 五.Shiro加密前面介绍的密码都是明文的，实际的密码在数据库中是加密的。 下面在自定义的Realm中使用加密。 代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102package com.example.springboot2shirostart;import org.apache.shiro.authc.AuthenticationException;import org.apache.shiro.authc.AuthenticationInfo;import org.apache.shiro.authc.AuthenticationToken;import org.apache.shiro.authc.SimpleAuthenticationInfo;import org.apache.shiro.authz.AuthorizationInfo;import org.apache.shiro.authz.SimpleAuthorizationInfo;import org.apache.shiro.realm.AuthorizingRealm;import org.apache.shiro.subject.PrincipalCollection;import org.apache.shiro.util.ByteSource;import java.util.HashMap;import java.util.HashSet;import java.util.Map;import java.util.Set;public class CustomRealm extends AuthorizingRealm &#123; final String realmName = this.getClass().getSimpleName(); //自定义realm名称 Map&lt;String,String&gt; userMap = new HashMap&lt;&gt;(16); &#123;// userMap.put(\"zmt\",\"123456\");// userMap.put(\"zmt\",\"e10adc3949ba59abbe56e057f20f883e\"); //数据库的密码是密文，不加盐 userMap.put(\"zmt\",\"640a19b710290a9ff4d72e70cdd21913\"); //md5加盐密码 userMap.put(\"xr\",\"654321\"); super.setName(realmName); //设置名称 &#125; @Override protected AuthorizationInfo doGetAuthorizationInfo(PrincipalCollection principals) &#123; String username = (String) principals.getPrimaryPrincipal(); //从数据库或者缓存中获取角色数据。 Set&lt;String&gt; roles = getRolesByUsername(username); Set&lt;String&gt; permissions = getPermissionByUsername(username); SimpleAuthorizationInfo authorizationInfo = new SimpleAuthorizationInfo(); authorizationInfo.setStringPermissions(permissions); //设置权限 authorizationInfo.setRoles(roles); //设置角色 return authorizationInfo; &#125; /** * 模拟通过用户名获取权限。 * @param username * @return */ private Set&lt;String&gt; getPermissionByUsername(String username) &#123; Set&lt;String&gt; permissions = new HashSet&lt;&gt;(); permissions.add(\"admin:delete\"); permissions.add(\"user:select\"); permissions.add(\"user:update\"); return permissions; &#125; /** * 模拟获取角色。根据用户名获取角色。 * @param username * @return */ private Set&lt;String&gt; getRolesByUsername(String username) &#123; Set&lt;String&gt; roles = new HashSet&lt;&gt;(); roles.add(\"admin\"); roles.add(\"user\"); return roles; &#125; @Override protected AuthenticationInfo doGetAuthenticationInfo(AuthenticationToken token) throws AuthenticationException &#123; //从主体传过来认证信息,获得用户名 String username = (String) token.getPrincipal(); System.out.println(\"username:\" + username); //通过用户名到数据库中获取凭证 String pwd = getPwdByUsername(username); if (pwd == null) &#123; return null; &#125; SimpleAuthenticationInfo authenticationInfo = new SimpleAuthenticationInfo(username,pwd,realmName); authenticationInfo.setCredentialsSalt(ByteSource.Util.bytes(\"aaa\")); //密码加盐后，这里要加上这句 return authenticationInfo; &#125; /** * 模拟获取数据库数据。根据用户名获取用户密码 * @param username 用户名。 * @return */ private String getPwdByUsername(String username) &#123; return userMap.get(username); &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657package com.example.springboot2shirostart;import org.apache.shiro.SecurityUtils;import org.apache.shiro.authc.UsernamePasswordToken;import org.apache.shiro.authc.credential.HashedCredentialsMatcher;import org.apache.shiro.crypto.hash.Md5Hash;import org.apache.shiro.mgt.DefaultSecurityManager;import org.apache.shiro.subject.Subject;import org.junit.Test;/** * 简单认证 */public class CustomRealmTest &#123; @Test public void test1() &#123; CustomRealm customRealm = new CustomRealm();//自定义Realm //1.创建securityManager环境 DefaultSecurityManager defaultSecurityManager = new DefaultSecurityManager(); defaultSecurityManager.setRealm(customRealm); //设置散列加密 HashedCredentialsMatcher matcher = new HashedCredentialsMatcher(); matcher.setHashAlgorithmName(\"md5\");//设置加密方式 matcher.setHashIterations(1); //设置加密次数 customRealm.setCredentialsMatcher(matcher); //设置加密对象 //2.主体提交认证请求 SecurityUtils.setSecurityManager(defaultSecurityManager); Subject subject = SecurityUtils.getSubject(); UsernamePasswordToken token = new UsernamePasswordToken(\"zmt\",\"e10adc3949ba59abbe56e057f20f883e\");//用户,密码MD5加密。明文：123456 subject.login(token); System.out.println(\"isAuthenticated:\" + subject.isAuthenticated());//已认证// subject.checkRole(\"admin\"); //admin通过，admin1报错 subject.checkRoles(\"admin\",\"user\"); //拥有该两个角色 //权限 subject.checkPermission(\"user:select\");//jdbcRealm.setPermissionsLookupEnabled(true);// subject.checkPermission(\"user:insert\"); //报错，么有insert权限 subject.checkPermission(\"user:update\"); //有update权限 &#125; @Test public void genPwd() &#123;// Md5Hash md5Hash = new Md5Hash(\"123456\"); //md5加密密码，不加盐// System.out.println(\"md5加密：\" + md5Hash); Md5Hash md5Hash = new Md5Hash(\"e10adc3949ba59abbe56e057f20f883e\",\"aaa\"); //md5加密密码，加盐，密码更加难以识破，盐一般用随机数，这里写死 System.out.println(\"md5加盐加密：\" + md5Hash); &#125;&#125; 六.shiro会话","tags":[{"name":"shiro入门","slug":"shiro入门","permalink":"https://xinxiamu.github.io/tags/shiro入门/"}]},{"title":"spring cloud feign自定义","date":"2018-05-08T12:36:02.000Z","path":"2018/05/08/scloud-feign-config/","text":"参考：https://www.jianshu.com/p/755b15ff0249","tags":[{"name":"feign","slug":"feign","permalink":"https://xinxiamu.github.io/tags/feign/"}]},{"title":"spring cloud Hystrix监控","date":"2018-05-08T07:30:31.000Z","path":"2018/05/08/scloud-hystrix-dashboard/","text":"参考：https://www.jianshu.com/p/b7b20fc09ca9 https://blog.csdn.net/liaokailin/article/details/51344281 单个节点监控聚合监控","tags":[{"name":"hystrix,dashboard","slug":"hystrix-dashboard","permalink":"https://xinxiamu.github.io/tags/hystrix-dashboard/"}]},{"title":"spring cloud 熔断器,服务降级","date":"2018-05-08T03:21:35.000Z","path":"2018/05/08/scloud-hystrix/","text":"##","tags":[{"name":"hystrix","slug":"hystrix","permalink":"https://xinxiamu.github.io/tags/hystrix/"}]},{"title":"javapoet根据编译注解自动生成代码","date":"2018-05-03T12:54:06.000Z","path":"2018/05/03/javapoet-apt-annotation/","text":"本文介绍利用apt技术，使用javapoet框架优雅的在编译阶段自动生成代码…… 引入相关依赖包和插件1.依赖包 &lt;!-- https://mvnrepository.com/artifact/com.google.auto.service/auto-service --&gt; &lt;dependency&gt; &lt;groupId&gt;com.google.auto.service&lt;/groupId&gt; &lt;artifactId&gt;auto-service&lt;/artifactId&gt; &lt;version&gt;1.0-rc4&lt;/version&gt; &lt;/dependency&gt; &lt;!--优雅生成代码--&gt; &lt;!--https://github.com/square/javapoet--&gt; &lt;dependency&gt; &lt;groupId&gt;com.squareup&lt;/groupId&gt; &lt;artifactId&gt;javapoet&lt;/artifactId&gt; &lt;version&gt;1.10.0&lt;/version&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; javapoet是square公司出品的用来优雅生成代码库。网址： https://github.com/square/javapoet google auto-service是google公司的一个库，用来自动注册服务。 2.apt插件 &lt;plugin&gt; &lt;groupId&gt;com.mysema.maven&lt;/groupId&gt; &lt;artifactId&gt;apt-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.1.3&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;goals&gt; &lt;goal&gt;process&lt;/goal&gt; &lt;/goals&gt; &lt;phase&gt;generate-sources&lt;/phase&gt; &lt;configuration&gt; &lt;outputDirectory&gt;${project.basedir}/target/generated-sources/java&lt;/outputDirectory&gt; &lt;processor&gt;com.example.demo.HelloProcessor&lt;/processor&gt; &lt;processors&gt; &lt;processor&gt;com.example.demo.HelloProcessor&lt;/processor&gt; &lt;/processors&gt; &lt;showWarnings&gt;true&lt;/showWarnings&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; 可以在插件中添加注解处理类。在编译时将会调用相关注解处理类做处理生成代码。 demo演示 1.新建注解类HelloAnnotation package com.example.demo; import java.lang.annotation.ElementType; import java.lang.annotation.Retention; import java.lang.annotation.RetentionPolicy; import java.lang.annotation.Target; @Retention(RetentionPolicy.CLASS) @Target(ElementType.TYPE) public @interface HelloAnnotation { } 2.新建注解处理类HelloProcessor package com.example.demo; import com.google.auto.service.AutoService; import com.squareup.javapoet.JavaFile; import com.squareup.javapoet.MethodSpec; import com.squareup.javapoet.TypeSpec; import javax.annotation.processing.*; import javax.lang.model.SourceVersion; import javax.lang.model.element.Element; import javax.lang.model.element.Modifier; import javax.lang.model.element.Name; import javax.lang.model.element.TypeElement; import java.io.IOException; import java.lang.reflect.Method; import java.util.Collections; import java.util.Set; @AutoService(Processor.class) @SupportedAnnotationTypes(value = {&quot;com.example.demo.HelloAnnotation&quot;}) @SupportedSourceVersion(SourceVersion.RELEASE_8) public final class HelloProcessor extends AbstractProcessor { private Filer filer; @Override public synchronized void init(ProcessingEnvironment processingEnv) { super.init(processingEnv); filer = processingEnv.getFiler(); // for creating file System.out.println(&quot;&gt;&gt;&gt;processor init:&quot; + filer.toString()); } @Override public boolean process(Set&lt;? extends TypeElement&gt; annotations, RoundEnvironment roundEnv) { System.out.println(&quot;&gt;&gt;&gt;&gt; process:&quot; + annotations.size()); for (TypeElement element : annotations) { /*Set&lt;? extends Element&gt; aa = roundEnv.getElementsAnnotatedWith(element); for (Element e: aa) { String name = e.getClass().getTypeName(); System.out.println(&quot;&gt;&gt;&gt;name:&quot; + name); Name s = e.getSimpleName(); System.out.println(&quot;&gt;&gt;&gt;aa:&quot; + s.toString()); *//*Method[] m = e.getClass().getMethods(); for (int i = 0; i &lt; m.length; i++) { Method mm = m[i]; System.out.println(mm.getName()); }*//* }*/ System.out.println(&quot;&gt;&gt;&gt;&gt;&gt;&gt; process：&quot; + element.getQualifiedName().toString()); if (element.getQualifiedName().toString().equals(HelloAnnotation.class.getCanonicalName())) { // main method MethodSpec main = MethodSpec.methodBuilder(&quot;main&quot;) .addModifiers(Modifier.PUBLIC, Modifier.STATIC) .returns(void.class) .addParameter(String[].class, &quot;args&quot;) .addStatement(&quot;$T.out.println($S)&quot;, System.class, &quot;Hello, JavaPoet!&quot;) .build(); // HelloWorld class TypeSpec helloWorld = TypeSpec.classBuilder(&quot;HelloWorld&quot;) .addModifiers(Modifier.PUBLIC, Modifier.FINAL) .addMethod(main) .build(); try { // build com.example.HelloWorld.java JavaFile javaFile = JavaFile.builder(&quot;com.example&quot;, helloWorld) .addFileComment(&quot; This codes are generated automatically. Do not modify!&quot;) .build(); // write to file javaFile.writeTo(filer); javaFile.writeTo(System.out); } catch (IOException e) { e.printStackTrace(); } } } return true; } //采用注解 /*@Override public Set&lt;String&gt; getSupportedAnnotationTypes() { return Collections.singleton(HelloAnnotation.class.getCanonicalName()); }*/ //采用注解 /* @Override public SourceVersion getSupportedSourceVersion() { return SourceVersion.latestSupported(); }*/ } 加上注解@AutoService(Processor.class)，该注解为auto-service中的类，加上该注解，编译时候将会自动注册服务。在类路径下新增META-INF/services文件夹，并注册服务。 关键，覆盖方法process，并在该方法中利用javapoet库相关特性，优雅生成想要的java代码，并输出.java文件。输出路径可以在maven插件中配置。 3.定义使用类 package com.example.demo; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; @HelloAnnotation @SpringBootApplication public class DemoApplication { public static void main(String[] args) { SpringApplication.run(DemoApplication.class, args); // HelloWorld.main(null); } } 在类上添加注解@HelloAnnotation。那么用mvn install或者运行该类编译代码时，将会调用注解处理类HelloProcessor进行代码生成。 _注意_:在引入apt插件后，要去掉java的编译时注解，只能二选其一，否则apt会生成一次代码，java编译时注解还会生成一次代码，将重复报错。 用apt插件，去掉processor中的@AutoService(Processor.class)注解。 用java编译时注解，在processor引入@AutoService(Processor.class)注解，不需要apt插件。 &lt;&lt;完&gt;&gt;","tags":[{"name":"javapoet-apt-annotation","slug":"javapoet-apt-annotation","permalink":"https://xinxiamu.github.io/tags/javapoet-apt-annotation/"}]},{"title":"spring-boot过滤器篇","date":"2018-04-26T06:40:54.000Z","path":"2018/04/26/spring-boot-filter/","text":"本文记录在spring-boot环境下，添加配置过滤器。以及过滤器的一些常见使用…… 在spring-boot项目中添加过滤器方式一1.创建类TestFilter,并实现Filter接口 package com.ymu.servicecommon.filter; import org.apache.logging.log4j.LogManager; import org.apache.logging.log4j.Logger; import javax.servlet.*; import java.io.IOException; /** * 功能简述:&lt;br&gt; * 过滤器配置测试。 * * @author zmt * @create 2018-04-26 下午5:15 * @updateTime * @since 1.0.0 */ public class TestFilter implements Filter { protected final Logger logger = LogManager.getLogger(this.getClass()); @Override public void init(FilterConfig filterConfig) throws ServletException { logger.debug(&quot;&gt;&gt;&gt;&gt;testFilter init&quot;); } @Override public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain) throws IOException, ServletException { logger.debug(&quot;&gt;&gt;&gt;&gt;testFilter doFilter&quot;); filterChain.doFilter(servletRequest,servletResponse); } @Override public void destroy() { logger.debug(&quot;&gt;&gt;&gt;&gt;testFilter destroy&quot;); } } 2.注解bean package com.ymu.servicecommon.config; import com.ymu.servicecommon.filter.TestFilter; import org.springframework.boot.web.servlet.FilterRegistrationBean; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; @Configuration public class MainConfig { /** * 配置过滤器 * @return */ @Bean public FilterRegistrationBean indexFilterRegistration() { FilterRegistrationBean registration = new FilterRegistrationBean(new TestFilter()); registration.addUrlPatterns(&quot;/*&quot;); // registration.addInitParameter(&quot;abc&quot;, &quot;abc-value&quot;); registration.setName(&quot;testFilter&quot;); return registration; } } 方式二1.创建过滤器IndexFilter2 package com.example.filter; import java.io.IOException; import javax.servlet.Filter; import javax.servlet.FilterChain; import javax.servlet.FilterConfig; import javax.servlet.ServletException; import javax.servlet.ServletRequest; import javax.servlet.ServletResponse; import javax.servlet.annotation.WebFilter; @WebFilter(urlPatterns = &quot;/*&quot;, filterName = &quot;indexFilter2&quot;) public class IndexFilter2 implements Filter{ @Override public void destroy() { System.out.println(&quot;filter2 destroy method&quot;); } @Override public void doFilter(ServletRequest arg0, ServletResponse arg1, FilterChain arg2) throws IOException, ServletException { System.out.println(&quot;filter2 doFilter method&quot;); } @Override public void init(FilterConfig arg0) throws ServletException { System.out.println(&quot;filter2 init method&quot;); } } 2.在程序启动入库加入注解ServletComponentScan @SpringBootApplication @ServletComponentScan public class SpringBootSimpleApplication { public static void main(String[] args) { SpringApplication.run(SpringBootSimpleApplication.class, args); } } 多个过滤器调用顺序在spring-boot中通过注解@Order来标识。这个order的默认值是Integer.MAX_VALUE 也就是int的最大值。多个过滤器会按照order属性的大小从小到大执行。 1.代码设置 package com.ymu.servicecommon.config; import com.ymu.servicecommon.filter.Test2Filter; import com.ymu.servicecommon.filter.TestFilter; import org.springframework.boot.web.servlet.FilterRegistrationBean; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; @Configuration public class MainConfig { /** * 配置过滤器 * @return */ @Bean public FilterRegistrationBean testFilterRegistration() { FilterRegistrationBean registration = new FilterRegistrationBean(new TestFilter()); registration.addUrlPatterns(&quot;/*&quot;); // registration.addInitParameter(&quot;abc&quot;, &quot;abc-value&quot;); registration.setName(&quot;testFilter&quot;); registration.setOrder(Integer.MAX_VALUE); //设置过滤器执行先后顺序，多个按从小到大执行 return registration; } @Bean public FilterRegistrationBean test2FilterRegistration() { FilterRegistrationBean registration = new FilterRegistrationBean(new Test2Filter()); registration.addUrlPatterns(&quot;/*&quot;); // registration.addInitParameter(&quot;abc&quot;, &quot;abc-value&quot;); registration.setName(&quot;test2Filter&quot;); registration.setOrder(Integer.MAX_VALUE-1); //设置过滤器执行先后顺序，多个按从小到大执行 return registration; } } 启动程序，观察执行顺序。 请求接口，观察执行顺序。 在过滤器中为请求添加http请求头信息1.定义类ModifyHttpServletRequestWrapper.java package com.ymu.framework.web; import javax.servlet.http.HttpServletRequest; import javax.servlet.http.HttpServletRequestWrapper; import java.util.*; public class ModifyHttpServletRequestWrapper extends HttpServletRequestWrapper { private Map&lt;String, String&gt; customHeaders; public ModifyHttpServletRequestWrapper(HttpServletRequest request) { super(request); this.customHeaders = new HashMap&lt;&gt;(); } public void putHeader(String name, String value) { this.customHeaders.put(name, value); } public String getHeader(String name) { String value = this.customHeaders.get(name); if (value != null) { return value; } return ((HttpServletRequest) getRequest()).getHeader(name); } public Enumeration&lt;String&gt; getHeaderNames() { Set&lt;String&gt; set = new HashSet&lt;&gt;(customHeaders.keySet()); Enumeration&lt;String&gt; enumeration = ((HttpServletRequest) getRequest()).getHeaderNames(); while (enumeration.hasMoreElements()) { String name = enumeration.nextElement(); set.add(name); } return Collections.enumeration(set); } } 2.定义过滤器，编辑 @Override public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain) throws IOException, ServletException { logger.debug(&quot;&gt;&gt;&gt;&gt;indexFilter doFilter&quot;); //添加或者更改header信息 HttpServletRequest request = (HttpServletRequest) servletRequest; String apiVersion = request.getHeader(&quot;Content-Version&quot;); if (null == apiVersion || &quot;&quot;.equals(apiVersion)) { ModifyHttpServletRequestWrapper requestWrapper = new ModifyHttpServletRequestWrapper(request); requestWrapper.putHeader(&quot;Content-Version&quot;,&quot;-1&quot;); filterChain.doFilter(requestWrapper,servletResponse); } else { filterChain.doFilter(request,servletResponse); } } 重点代码： ModifyHttpServletRequestWrapper requestWrapper = new ModifyHttpServletRequestWrapper(request); requestWrapper.putHeader(&quot;Content-Version&quot;,&quot;-1&quot;); filterChain.doFilter(requestWrapper,servletResponse);","tags":[{"name":"spring-boot-filter","slug":"spring-boot-filter","permalink":"https://xinxiamu.github.io/tags/spring-boot-filter/"}]},{"title":"Spring cloud微服务：分布式配置中心-加密解密","date":"2018-04-21T14:22:30.000Z","path":"2018/04/21/scloud-config-server-encrypt-decrypt/","text":"在spring cloud微服务开发过程中，很多的配置文件需要暴露给相关开发人员来维护。但是，配置文件里面可能涉及到一些敏感的配置信息如数据库，第三方账号等。因此，为了安全，就非常有必要对这些数据加密了。以保护这些信息安全。 安装JCE在使用Spring Cloud Config的加密解密功能时，有一个必要的前提需要我们注意。为了启用该功能，我们需要在配置中心的运行环境中安装不限长度的JCE版本（Unlimited Strength Java Cryptography Extension）。虽然，JCE功能在JRE中自带，但是默认使用的是有长度限制的版本。我们可以从Oracle的官方网站中下载到它，它是一个压缩包，解压后可以看到下面三个文件： README.txt local_policy.jar US_export_policy.jar 我们需要将local_policy.jar和US_export_policy.jar两个文件复制到$JAVA_HOME/jre/lib/security目录下，覆盖原来的默认内容。到这里，加密解密的准备工作就完成了。 JCE下载地址：Java 8 JCE 查看相关端点安装后，重启config-server。可以通过浏览器查看一些相关信息： /encrypt/status：查看加密功能状态的端点 /key：查看密钥的端点 /encrypt：对请求的body内容进行加密的端点 /decrypt：对请求的body内容进行解密的端点 配置密钥对称加解密暂时不做介绍。推荐直接用下面非对称方式！ 非对称加解密使用非对称加解密具有更高安全性…… 使用JDK工具keytool生成密钥对。 它的位置在： %JAVA_HOME%\\bin\\keytool.exe。 使用下面命令在当前文件夹下生成密钥对(默认有效期90天，这里设置成-validity 365天，一年)： keytool -genkeypair -alias config-server -keyalg RSA \\ -dname &quot;CN=zhangmutian, OU=company, O=organization, L=city, ST=province, C=china&quot; \\ -keypass 222222 \\ -keystore config-server.jks \\ -storepass 111111 \\ -validity 365 \\ 参考：http://cloud.spring.io/spring-cloud-static/Edgware.SR3/multi/multi__spring_cloud_config_server.html#_creating_a_key_store_for_testing 配置bootstrap.yml把生成的config-server.jks文件放在config-server项目的classpath中。并在bootstrap.yml中添加一下配置： encrypt: keyStore: location: classpath:/config-server.jks password: 11111 alias: config-server secret: 222222 注：另外，以上配置信息也可以在环境变量中配置，它们对应的具体变量名如下： ENCRYPT_KEY_STORE_LOCATION ENCRYPT_KEY_STORE_ALIAS ENCRYPT_KEY_STORE_PASSWORD ENCRYPT_KEY_STORE_SECRET 重新启动项目，浏览：http://192.168.1.104:3331/encrypt/status { &quot;status&quot;: &quot;OK&quot; } 说明配置成功了。 对配置加密先在命令窗口对具体配置明文进行加密,如： 对明文zmt加密（认证用户名为admin、密码为123456） mutian@mutian-ThinkPad-T440p:~$ curl -u admin:123456 http://192.168.1.104:3331/encrypt -d zmt AQB43S/okputI/v009zUuV/1XYmKSQROyYwWCWMC8phPeQa00/ABmS8QByz4ZWE57buwM1GIQ9lkmh8Yafgy6QUryq/XJk/oIck1zuN6M7IMepAFaJE4J8i4y5/LdH5h6gpfW06MeSiQbjg+393ztnDH37lWakfxEJ5yNtevXbV/LQC6u8bPvd/4riDHmgJYq8d7INJZKh4Y9TX+5a9a2YGivTuhn+qHruOylP43eMiK0EuUkmJF3B2zD6t8CWu5M84vnHjDVLFGmLuK3xfRpmG83ofl+86XjgdE+TlqcId+hRpfD28ELluU4Oc/N7ujNZAmKa2OtK0jve7oz27dQnrMDh5n6qkGAIcjNoeHLa7EgkP9XEargjGLkaXewHME56Q= 对密文解密： mutian@mutian-ThinkPad-T440p:~$ curl -u admin:123456 http://192.168.1.104:3331/decrypt -d AQB43S/okputI/v009zUuV/1XYmKSQROyYwWCWMC8phPeQa00/ABmS8QByz4ZWE57buwM1GIQ9lkmh8Yafgy6QUryq/XJk/oIck1zuN6M7IMepAFaJE4J8i4y5/LdH5h6gpfW06MeSiQbjg+393ztnDH37lWakfxEJ5yNtevXbV/LQC6u8bPvd/4riDHmgJYq8d7INJZKh4Y9TX+5a9a2YGivTuhn+qHruOylP43eMiK0EuUkmJF3B2zD6t8CWu5M84vnHjDVLFGmLuK3xfRpmG83ofl+86XjgdE+TlqcId+hRpfD28ELluU4Oc/N7ujNZAmKa2OtK0jve7oz27dQnrMDh5n6qkGAIcjNoeHLa7EgkP9XEargjGLkaXewHME56Q= zmt 在配置文件中配置密文： 通过上面用curl命令请求把明文加密后，然后如下添加到配置文件中。{cipher}代表是密文，需要解密。 api: password: &apos;{cipher}AQB0sf3nKuMq6wmRGs1CVDs3Oq+gdkfhX7F4M5txKI0CUpezKl02GI1mWmY4e6Ch/tI0UP9KRLv5VADrF8qESSPrZjD+uQR+op/N1hEZmKOMS/BpgipudiskeuifHPk2ffscN6pJns4VrfRwW3Io9yyOJ0/mAQxD46IcppraE2Z4gwplLvRU0U7pLB2mxpBqhi24ZKUW3MHRRD5rF4AMyXQw9SEyfyXYWpBGxSgMGfeV/TU4d4DVSYy8Y7Ji0Rf41m/59V24bjjYaJL2B77+WLyKlGHlV/hfrCOcz45NgqS00TGjNfieO1DlWHZi/YvYN4UUF0InRFI2gnGzWumEnJSYhHWqO3hdVr9mO+BI8DskngMGapYQrJVc7Pdpo27h3Io=&apos; 调用显示： @Value(&quot;${api.password}&quot;) private String apiPwd; @Override public VTestResp test3(@SensitiveFormat String name) { VTestResp testResp = new VTestResp(); testResp.setName(name + &quot;&gt;&gt;&gt;&gt;&quot; + apiPwd); return testResp; } 结果： { &quot;name&quot;: &quot;abc&gt;&gt;&gt;&gt;ymu123456&quot;, &quot;sex&quot;: 0 } 对特殊字符加密问题参考：http://blog.didispace.com/spring-cloud-config-sp-char-encryp","tags":[{"name":"spring-cloud(配置中心加解密)","slug":"spring-cloud-配置中心加解密","permalink":"https://xinxiamu.github.io/tags/spring-cloud-配置中心加解密/"}]},{"title":"redis命令搜集","date":"2018-03-23T09:36:34.000Z","path":"2018/03/23/redis-common/","text":"1.查看所有的key &gt; KEYS * 2.清空所有key和数据 &gt; flushall","tags":[{"name":"redis命令","slug":"redis命令","permalink":"https://xinxiamu.github.io/tags/redis命令/"}]},{"title":"Spring-Cache使用","date":"2018-03-23T09:29:57.000Z","path":"2018/03/23/spring-boot-cache/","text":"","tags":[{"name":"spring cache","slug":"spring-cache","permalink":"https://xinxiamu.github.io/tags/spring-cache/"}]},{"title":"服务网格istio入门","date":"2018-03-13T00:57:27.000Z","path":"2018/03/13/istio-start/","text":"参考网址： http://www.servicemesher.com/blog/istio-service-mesh-tutorial/","tags":[{"name":"istio","slug":"istio","permalink":"https://xinxiamu.github.io/tags/istio/"}]},{"title":"k8s入门","date":"2018-03-13T00:56:45.000Z","path":"2018/03/13/k8s-start/","text":"","tags":[{"name":"k8s","slug":"k8s","permalink":"https://xinxiamu.github.io/tags/k8s/"}]},{"title":"Vault学习","date":"2018-03-09T02:11:17.000Z","path":"2018/03/09/vault-study/","text":"Valut是个密码管理工具，用来安全的管理例如数据库、应用程序api等等等的密码…… 特性： 1.安全的私密信息存储 2.动态的私密信息支持 3.提供对于私密信息的更新，延长有效时间的功能 4.灵活的权限控制 5.多种客户端登录验证方式 参考：https://www.vaultproject.io/intro/index.html 安装Valut1.下载地址：https://www.vaultproject.io/downloads.html 2.解压解压后只有一个名为vualt的可执行文件。该文件可以安全的移动位置。 配置环境变量，把vault可执行文件所在目录添加到环境变量： export PATH=$PATH:/home/mutian/dev/bin 检验是否成功： mutian@mutian-ThinkPad-T440p:~$ vault Usage: vault &lt;command&gt; [args] Common commands: read Read data and retrieves secrets write Write data, configuration, and secrets delete Delete secrets and configuration list List data or secrets login Authenticate locally server Start a Vault server status Print seal and HA status unwrap Unwrap a wrapped secret Other commands: audit Interact with audit devices auth Interact with auth methods lease Interact with leases operator Perform operator-specific tasks path-help Retrieve API help for paths policy Interact with policies secrets Interact with secrets engines ssh Initiate an SSH session token Interact with tokens 表示环境变量添加准确，已经安装成功。 3.install completions $ vault -autocomplete-install 然后重新启动shell窗口，输入命令vault，然后按Tab键，将出现命令参数提示。如下： mutian@mutian-ThinkPad-T440p:~$ vault audit lease operator read ssh unwrap auth list path-help secrets status write delete login policy server token mutian@mutian-ThinkPad-T440p:~$ vault ## 启动服务 启动开发环境开发环境只用来在本机做开发使用，数据保存在内存，所以千万不能在生产环境使用。 mutian@mutian-ThinkPad-T440p:~$ vault server -dev ==&gt; Vault server configuration: Cgo: disabled Cluster Address: https://127.0.0.1:8201 Listener 1: tcp (addr: &quot;127.0.0.1:8200&quot;, cluster address: &quot;127.0.0.1:8201&quot;, tls: &quot;disabled&quot;) Log Level: info Mlock: supported: true, enabled: false Redirect Address: http://127.0.0.1:8200 Storage: inmem Version: Vault v0.9.5 Version Sha: 36edb4d42380d89a897e7f633046423240b710d9 WARNING! dev mode is enabled! In this mode, Vault runs entirely in-memory and starts unsealed with a single unseal key. The root token is already authenticated to the CLI, so you can immediately begin using Vault. You may need to set the following environment variable: $ export VAULT_ADDR=&apos;http://127.0.0.1:8200&apos; The unseal key and root token are displayed below in case you want to seal/unseal the Vault or re-authenticate. Unseal Key: CHZrUesD0FeIHV/5lzkeKehzYh+pNjd0GH5wzG0VjSE= Root Token: 182a4bb0-1165-a049-6e7a-e0dbef229a28 Development mode should NOT be used in production installations! ==&gt; Vault server started! Log data will stream in below: 看到上面内容说明已经启动成功，在前台运行的。 验证服务是否在成功运行： mutian@mutian-ThinkPad-T440p:~$ vault status Error checking seal status: Get https://127.0.0.1:8200/v1/sys/seal-status: http: server gave HTTP response to HTTPS client mutian@mutian-ThinkPad-T440p:~$ 看到以上提示：错误，所以启动没成功。因为没配置回环访问。执行如下命令： export VAULT_ADDR=http://127.0.0.1:8200 再次查看vault服务运行状态: mutian@mutian-ThinkPad-T440p:~$ vault status Key Value --- ----- Seal Type shamir Sealed false Total Shares 1 Threshold 1 Version 0.9.5 Cluster Name vault-cluster-bcf3f2f8 Cluster ID c2649684-fe35-3820-983b-f324a51b115c HA Enabled false 看到了上面的内容，则证明服务启动成功。 为了方便CLI使用vault命令，建议配置环境变量；安全起见，建议设置环境变量只在当前客户端生效，命令： 功能 命令 说明 设置vault访问地址 export VAULT_ADDR=http://127.0.0.1:8200 vault命令作用的vault服务的地址 设置Vault PATH export PATH=$PATH:&lt; vault install path &gt; vault install path：vault安装路径 设置访问token export VAULT_TOKEN=&lt; token &gt; token：登录vault时的token，首次登录可使用root token 设置是否跳过核查 export VAULT_SKIP_VERIFY=false 使用TSL访问时需要设置，未使用证书忽略此项 设置访问证书 export VAULT_CAPATH=/usr/local/vault/work/ca/certs/ca.cert.pem 使用TSL访问时需要设置，未使用证书忽略此项 保存私密信息 下面是简单的写入信息命令： mutian@mutian-ThinkPad-T440p:~$ vault write secret/hello value=world Success! Data written to: secret/hello 这会把键值对信息写入到路劲secret/hello中。 键为value,值为world。 也可以一次性写入多个键值保存： mutian@mutian-ThinkPad-T440p:~$ vault write secret/hello value=world excited=yesSuccess! Data written to: secret/hello 读取私密信息 显示该路径下所有保存键值对： mutian@mutian-ThinkPad-T440p:~$ vault read secret/hello Key Value --- ----- refresh_interval 768h excited yes value world 获取单个的值： mutian@mutian-ThinkPad-T440p:~$ vault read -field value secret/hello world 删除路径下键值 删除所有： mutian@mutian-ThinkPad-T440p:~$ vault delete secret/hello Success! Data deleted (if it existed) at: secret/hello mutian@mutian-ThinkPad-T440p:~$ vault read secret/hello No value found at secret/hello 看上面命令，说明已经把保存到路径secret/hello下的键值信息全部删除。 秘密引擎上面内容中，我们知道怎么保存信息，读取信息，删除信息，但是注意到没，只能保存到路径secret/hello下面，这个是默认的。当你试图保存到其他路径下时候，将报错。 mutian@mutian-ThinkPad-T440p:~$ vault write ~/dev name=zmt Error writing data to home/mutian/dev: Error making API request. URL: PUT http://127.0.0.1:8200/v1/home/mutian/dev Code: 404. Errors: * no handler for route &apos;home/mutian/dev&apos; 默认下，在路劲secret/.Vault开启一个ｋｖ引擎。这个ｋｖ引擎可写入，读取数据到后台存储。 开启一个新的kv私密引擎 mutian@mutian-ThinkPad-T440p:~$ vault secrets enable -path=abs kv Success! Enabled the kv secrets engine at: abs/ mutian@mutian-ThinkPad-T440p:~$ vault secrets list Path Type Description abs/ kv n/a cubbyhole/ cubbyhole per-token private secret storage identity/ identity identity store secret/ kv key/value secret storage sys/ system system endpoints used for control, policy and debugging 通过命令vault secrets list可以看到，第一个就是就是我们刚才开启的新私密引擎。 往该新建私密引擎保存私密信息： mutian@mutian-ThinkPad-T440p:~$ vault write abs/my-secret name=zmt Success! Data written to: abs/my-secret mutian@mutian-ThinkPad-T440p:~$ vault write abs/hello target=world Success! Data written to: abs/hello mutian@mutian-ThinkPad-T440p:~$ vault write abs/airplane type=boeing class=787 Success! Data written to: abs/airplane mutian@mutian-ThinkPad-T440p:~$ 查看该私密引擎下所有key mutian@mutian-ThinkPad-T440p:~$ vault list abs Keys ---- airplane hello my-secret 关闭私密引擎 当一个私密引擎不再使用的话，我们就可以调用命令来停用它。 当停用一个私密引擎的时候，该私密引擎将撤销，对应的保存的私密信息将会被移除。 mutian@mutian-ThinkPad-T440p:~$ vault secrets disable abs/ Success! Disabled the secrets engine (if it existed) at: abs/ mutian@mutian-ThinkPad-T440p:~$ vault secrets list Path Type Description ---- ---- ----------- cubbyhole/ cubbyhole per-token private secret storage identity/ identity identity store secret/ kv key/value secret storage sys/ system system endpoints used for control, policy and debugging 上面结果中，已经再看不到私密引擎abs/ 什么是私密引擎（Secrets Engine） 上面我们学会了如何启动停止一个私密引擎，那私密引擎到底是个什么东西呢？ 实际上，私密引擎就类似一个虚拟文件系统，所有的read/write/delete/list操作都在它下面进行，然后私密引擎自己决定如何来响应请求。 这是一种抽象，这种抽象具有强大的作用，它提供统一的接口，直接面对物理系统、数据库等，除此之外，一些独特的环境如AWS IAM、动态sql等，都可以统一使用增删改查这些操作接口。 动态私密信息保存","tags":[{"name":"vault","slug":"vault","permalink":"https://xinxiamu.github.io/tags/vault/"}]},{"title":"jwt初识","date":"2018-03-08T08:47:23.000Z","path":"2018/03/08/jwt-study/","text":"JSON Web Token（JWT）是目前比较流行的跨域身份验证的解决方案。也是系统间信息交互的好助手。下面介绍其机制和原理，以及使用！ jwt是什么JSON Web Token (JWT)是一个开放标准(RFC 7519)，它定义了一种紧凑的、自包含的方式，用于作为JSON对象在各方之间安全地传输信息。该信息可以被验证和信任，因为它是数字签名的。 什么时候使用jwt Authentication（认证）、Authorization（授权）: 这是jwt使用的最广的场景。一旦用户登录后，返回jwt令牌，后续客户端携带该令牌作为身份访问授权的api资源。可以使用jwt来做单点登录，开销很小，并且可以轻松的跨域。 Information Exchange (信息交换) : 在各方系统之间安全的传递消息，jwt无疑是一种很好的方式。因为jwt可以被签名，例如用公钥/私钥对，可以确定发送人就是所指定的那个人。同时，还可以验证内容有没有被篡改。 不依赖session机制： 以往通过seesion会话机制来做验证，但是如果session保存在内存，就无法做分布式系统，因为分布式环境中要求请求无状态。即使把session持久化到如redis，关系数据库或者文件系统中能解决无状态问题，但是这个对业务侵入大，且持久化过程失败的话，整个验证过程就失败，系统开销也大。jwt直接把数据存储在客户端，每次请求携带上就可以认证，简单且开销小。 JSON Web Token的结构 jwt要三部分组成，它们之间用圆点（.）隔开。三部分分别是： Header Payload Signature 所以，一个jwt看起来应该是这个样子： xxxxxxxxxx.yyyyyyyyyyyyyyyyyyyyyyyyyyyyyyy.zzzzzzzzzzzz Headerheader由两部分组成：类型（“JWT”）和算法名称（比如：HMAC SHA256或者RSA等等）。 像下面： { &quot;alg&quot;: &quot;HS256&quot;, &quot;typ&quot;: &quot;JWT&quot; } alg表示使用的签名算法，默认为HMAC SHA256（写为HS256）；typ表示令牌的类型，JWT令牌统一写为JWT。 最后，要用Base64URL算法对上面json对象编码转为字符串作为JWT的第一部分。 Payloadjwt的有效载体payload,声明关于实体（通常指用户）和其它数据，声明有三种类型：registered, public 和 private。 Registered claims : 预定义的声明，不是强制的，但是推荐。指定7个默认的字段供选择： 1.iss：发行人 2.exp：到期时间 3.sub：主题 4.aud：用户 5.nbf：在此之前不可用 6.iat：发布时间 7.jti：JWT ID用于标识该JW Public claims : 公开的，可以随意定义。 Private claims : 用于在同意使用它们的各方之间共享信息，并且不是注册的或公开的声明。 下面是个例子： { &quot;sub&quot;: &quot;1234567890&quot;, &quot;name&quot;: &quot;chongchong&quot;, &quot;admin&quot;: true } 对payload进行Base64URL编码就得到JWT的第二部分。 注意： 不要在JWT的payload或header中放置敏感信息，除非它们是加密的。使用https或者加密算法才可以添加敏感信息，否则有信息泄露可能。 Signature签名哈希为了得到签名部分，你必须有编码过的header、编码过的payload、一个秘钥，签名算法是header中指定的那个，然对它们签名即可。 例如： HMACSHA256(base64UrlEncode(header) + &quot;.&quot; + base64UrlEncode(payload), secret) 签名是用于验证消息在传递过程中有没有被更改，并且，对于使用私钥签名的token，它还可以验证JWT的发送方是否为它所称的发送方。secret必须保持在服务器，不可泄露。 Base64URL算法如前所述，JWT头和有效载荷序列化的算法都用到了Base64URL。该算法和常见Base64算法类似，稍有差别。 作为令牌的JWT可以放在URL中（例如api.example/?token=xxx）。 Base64中用的三个字符是”+”，”/“和”=”，由于在URL中有特殊含义，因此Base64URL中对他们做了替换：”=”去掉，”+”用”-“替换，”/“用”_”替换，这就是Base64URL算法，很简单吧。 jwt工作机制认证的时候，当用户用他们的凭证登录成功后，服务端将会按照上面方式生成一个jwt返回给客户端。此后，该token就是用户的凭证了，后面每次请求都带上该token。你必须要非常小心的保护该token，在客户端保存令牌的时间不能超过令牌的有效时间。 每次客户端请求受保护的路由或者资源，都得带上该token，一般的，放在Authorization header中，用Bearer schema。 header应该看起来是这样的： Authorization: Bearer &lt;token&gt; 服务端会在过滤器或者拦截器中，拦截每次请求，并检查Authorization header中的JWT是否有效。如果有效，则可以访问相关资源，否则返回token失效，此时客户端应该要重新登录获取最新的token。 如果jwt中包含足够的必要数据，那么可以减少查询数据库的次数。尽管不一定必要。例如，保存用户username到jwt中，而不仅仅保存id,下次服务端接到请求，就可以直接使用username，而不必根据id再查一遍。 如果token是在授权头（Authorization header）中发送的，那么跨源资源共享(CORS)将不会成为问题，因为它不使用cookie。 注意： 1.每一次请求都需要token。2.Token应该放在请求header中。3.我们还需要将服务器设置为接受来自所有域的请求，用Access-Control-Allow-Origin: *。 JWT与OAuth的区别1.OAuth2是一种授权框架 ，JWT是一种认证协议。2.无论使用哪种方式切记用HTTPS来保证数据的安全性。3.OAuth2用在使用第三方账号登录的情况(比如使用weibo, qq, github登录某个app)，而JWT是用在前后端分离, 需要简单的对后台API进行保护时使用。 基于Token的身份认证 与 基于服务器的身份认证总结1、JWT默认不加密，但可以加密。生成原始令牌后，可以使用改令牌再次对其进行加密。 2、当JWT未加密方法是，一些私密数据无法通过JWT传输。 3、JWT不仅可用于认证，还可用于信息交换。善用JWT有助于减少服务器请求数据库的次数。 4、JWT的最大缺点是服务器不保存会话状态，所以在使用期间不可能取消令牌或更改令牌的权限。也就是说，一旦JWT签发，在有效期内将会一直有效。 5、JWT本身包含认证信息，因此一旦信息泄露，任何人都可以获得令牌的所有权限。为了减少盗用，JWT的有效期不宜设置太长。对于某些重要操作，用户在使用时应该每次都进行进行身份验证。 6、为了减少盗用和窃取，JWT不建议使用HTTP协议来传输代码，而是使用加密的HTTPS协议进行传输。","tags":[]},{"title":"ubuntu使用常用命令收集","date":"2018-03-01T08:02:21.000Z","path":"2018/03/01/linux-ubuntu-commom/","text":"记录在使用ubuntu系统过程中常见命令…… 查看占用端口netstat -ln|grep 8388或者lsof -i:8388 关闭端口下应用kill -9 PID号 防火墙1.安装 sudo apt-get install ufw 2.启用 sudo ufw enable sudo ufw default deny 运行以上两条命令后，开启了防火墙，并在系统启动时自动开启。 3.开启/禁用 sudo ufw allow|deny [service] 打开或关闭某个端口，例如： sudo ufw allow smtp 允许所有的外部IP访问本机的25/tcp (smtp)端口 sudo ufw allow 22/tcp 允许所有的外部IP访问本机的22/tcp (ssh)端口 sudo ufw allow 53 允许外部访问53端口(tcp/udp) sudo ufw allow from 192.168.1.100 允许此IP访问所有的本机端口 sudo ufw allow proto udp 192.168.0.1 port 53 to 192.168.0.2 port 53 sudo ufw deny smtp 禁止外部访问smtp服务 sudo ufw delete allow smtp 删除上面建立的某条规则 4.查看防火墙状态 sudo ufw status 开启/关闭防火墙 (默认设置是’disable’) # ufw enable|disable 5.UFW 使用范例： 允许 53 端口 $ sudo ufw allow 53 禁用 53 端口 $ sudo ufw delete allow 53 允许 80 端口 $ sudo ufw allow 80/tcp 禁用 80 端口 $ sudo ufw delete allow 80/tcp 允许 smtp 端口 $ sudo ufw allow smtp 删除 smtp 端口的许可 $ sudo ufw delete allow smtp 允许某特定 IP $ sudo ufw allow from 192.168.254.254 删除上面的规则 $ sudo ufw delete allow from 192.168.254.254","tags":[]},{"title":"Ubuntu16.0.4安装docker-ce","date":"2018-02-28T01:55:22.000Z","path":"2018/02/28/docker-install-ubuntu16/","text":"本文介绍在Ubuntu环境下安装Docker ce…… 参考：https://docs.docker.com/install/linux/docker-ce/ubuntu/ 卸载旧版本：$ sudo apt-get remove docker docker-engine docker.io 安装系统可选内核参考：https://docs.docker.com/install/linux/docker-ce/ubuntu/#supported-storage-drivers 使用 APT 安装 更新系统包 $ sudo apt-get update 添加ca证书 由于apt源使用HTTPS以确保软件下载过程中不被篡改。因此,我们首先需要添加使用HTTPS传输的软件包以及CA证书。 $ sudo apt-get install \\ apt-transport-https \\ ca-certificates \\ curl \\ software-properties-common 如果出现错误： E: Could not get lock /var/lib/dpkg/lock - open (11: Resource temporarily unavailable) E: Unable to lock the administration directory (/var/lib/dpkg/), is another process using it? 执行下面命令： mutian@mutian-ThinkPad-T440p:~$ sudo rm /var/cache/apt/archives/lock mutian@mutian-ThinkPad-T440p:~$ sudo rm /var/lib/dpkg/lock 然后再重试。 添加软件源的GPG密钥 为了确认所下载软件包的合法性,需要添加软件源的GPG密钥。 $ curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - 验证密钥： mutian@mutian-ThinkPad-T440p:~$ sudo apt-key fingerprint 0EBFCD88 pub 4096R/0EBFCD88 2017-02-22 Key fingerprint = 9DC8 5822 9FC7 DD38 854A E2D8 8D81 803C 0EBF CD88 uid Docker Release (CE deb) &lt;docker@docker.com&gt; sub 4096R/F273FCD8 2017-02-22 mutian@mutian-ThinkPad-T440p:~$ 添加Docker软件源 然后,我们需要向source.list 中添加Docker软件源 $ sudo add-apt-repository \\ &quot;deb [arch=amd64] https://download.docker.com/linux/ubuntu \\ $(lsb_release -cs) \\ stable&quot; 以上命令会添加稳定版本的 Docker CE APT 镜像源,如果需要最新或者测试版本的Docker CE 请将 stable 改为 edge 或者 test。从 Docker 17.06 开始,edge test 版本的APT 镜像源也会包含稳定版本的 Docker。 安装DOCKER CE 1.更新系统包 $ sudo apt-get update 2.安装 $ sudo apt-get install docker-ce 镜像加速国内从Docker Hub拉取镜像有时会遇到困难,此时可以配置镜像加速器。Docker 官方和国内很多云服务商都提供了国内加速器服务,例如: Docker官方提供的中国registry mirror 阿里云加速器 DaoCloud 加速器 我们以Docker官方加速器为例进行介绍。 Ubuntu16.04+、Debian 8+、CentOS7环境下： 对于使用 systemd 的系统,请在/etc/docker/daemon.json中写入如下内容(如果文件不存在请新建该文件) { &quot;registry-mirrors&quot;: [ &quot;https://registry.docker-cn.com&quot; ] } 注意,一定要保证该文件符合json规范,否则Docker将不能启动。 之后重新启动服务。 $ sudo systemctl daemon-reload $ sudo systemctl restart docker 测试安装是否成功$ sudo docker run hello-world 如图出现则表示安装成功：","tags":[{"name":"docker ce安装","slug":"docker-ce安装","permalink":"https://xinxiamu.github.io/tags/docker-ce安装/"}]},{"title":"idea创建类，方法注解提示模板","date":"2018-02-10T06:30:29.000Z","path":"2018/02/10/idea-file-template/","text":"为了规范编码，在开发项目前，理应让团队每个人成员按公司编码规范定制好注释模板…… java类的注解模板 首先，打开设计：File-&gt;Settings-&gt;file and code template #parse(&quot;File Header.java&quot;)这句：include 名字为File Header的模板进来。 定义如图： 模板内容： /** * 功能简述:&lt;br&gt; * * * @author zmt * @create ${YEAR}-${MONTH}-${DAY} ${TIME} * @updateTime * @since 1.0.0 */ java方法模板在File-&gt;Settings-&gt;Editor-&gt;Live Templates下添加自定义Template Group，并在自定义Template Group下添加自定义Template 创建mygroup的Template,并定义名为/**的template。如下图： 模板内容： /** * 功能描述: &lt;br&gt; * 〈$END$〉 * $param$ * @return: $return$ * @since: 1.0.0 * @author: $user$ * @date: $DATE$ $TIME$ */ 编辑模板的变量内容： 点击右边的Edit Variables: 添加变量内容，如图： 注意：$param$这么添加，否则无效： groovyScript(&quot;def result=&apos;&apos;; def params=\\&quot;${_1}\\&quot;.replaceAll(&apos;[\\\\\\\\[|\\\\\\\\]|\\\\\\\\s]&apos;, &apos;&apos;).split(&apos;,&apos;).toList(); for(i = 0; i &lt; params.size(); i++) {result+=&apos;* @param &apos; + params[i] + ((i &lt; params.size() - 1) ? &apos;\\\\n &apos; : &apos;&apos;)}; return result&quot;, methodParameters()) 选定作用域： 是应用在类上，还是方法上 测试： 在完成如上配置后，只需在方法内执行/**+Tab键即可生成注释，切记这里说的是方法内部，因为methodParameters()的作用域只在方法内部，这也是Intellij IDEA比较蛋疼的一点。 注意：在方法内部操作或者在方法尾部，总之要在方法参数后面，再把注解剪切到方法头上，否则parameters无效","tags":[]},{"title":"concourse持续集成使用教程","date":"2018-02-10T02:35:22.000Z","path":"2018/02/10/concourse-tutorial/","text":"官网：https://concourse.ci/","tags":[{"name":"concourse","slug":"concourse","permalink":"https://xinxiamu.github.io/tags/concourse/"}]},{"title":"maven使用经验记录","date":"2018-02-03T02:00:23.000Z","path":"2018/02/03/maven-ofen/","text":"本文记录在开发过程中经常性使用到的maven特性…… 导出maven依赖的jar包到目录方法一：在pom目录下执行命令mvn dependency:copy-dependencies 方法二：eclipse项目下：选择项目的pom.xml文件，点击右键菜单中的Run As,见下图红框中，在弹出的Configuration窗口中，输入 dependency:copy-dependencies后，点击运行maven项目所依赖的jar包会导出到targed/dependency目录中。 maven打包时候跳过test检查方法一： 在pom目录下执行命令mvn clean install -Dmaven.test.skip=true 方法二： 在pom中添加插件 &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-surefire-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;skipTests&gt;true&lt;/skipTests&gt; &lt;/configuration&gt; &lt;/plugin&gt; 指定测试或者开发等环境执行命令script12345678mvn clean install deploy -Pprod``` 关键是`-Pprod`这里，这里表示指定prod环境执行。 ### 指定settings.xml执行```shell scriptmvn install --settings E:\\apache-maven-3.3.9\\conf\\settings-ztesoft.xml -Dmaven.test.skip=true 查看环境12$ mvn help:active-profiles 列出当前激活的Profile$ mvn help:all-profiles 列出当前所有的Profile 打包jar普通打包会把maven依赖包一起打包。 &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;source&gt;1.8&lt;/source&gt; &lt;target&gt;1.8&lt;/target&gt; &lt;/configuration&gt; &lt;/plugin&gt; 不打包lib在spring boot中实践，不打包maven依赖包，减少打包后jar的大小。让后启动指定main类，并指定依赖包目录lib。 &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-jar-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;archive&gt; &lt;manifest&gt; &lt;mainClass&gt;com.xcsqjr.StartAbsServiceAllApplication&lt;/mainClass&gt; &lt;addClasspath&gt;true&lt;/addClasspath&gt; &lt;classpathPrefix&gt;lib/&lt;/classpathPrefix&gt; &lt;/manifest&gt; &lt;manifestEntries&gt; &lt;Class-Path&gt;./&lt;/Class-Path&gt; &lt;/manifestEntries&gt; &lt;/archive&gt; &lt;/configuration&gt; &lt;/plugin&gt; jar包无法更新下来，爆本地已有缓存有时候，maven依赖包拉取失败，但是有部分内容已经拉取，一部分没拉去，再次更新的时候，不会再次去远程仓库拉取。所以会报错误： Maven-010-maven 编译报错：Failure to ... in ... was cached in the local repository, resolution will not be reattempted until the update interval of nexus has elapsed or updates are forced. 解决办法是，在maven配置文件setting.xml中加入如下策略： &lt;profile&gt; &lt;id&gt;dev&lt;/id&gt; &lt;repositories&gt; &lt;!--自己私仓,下载jar--&gt; &lt;repository&gt; &lt;id&gt;ymu-public&lt;/id&gt; &lt;name&gt;ymu nexus&lt;/name&gt; &lt;url&gt;http://119.145.41.171:8085/repository/maven-public/&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;updatePolicy&gt;always&lt;/updatePolicy&gt; &lt;/snapshots&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;updatePolicy&gt;always&lt;/updatePolicy&gt; &lt;/releases&gt; &lt;/repository&gt; &lt;repository&gt; &lt;id&gt;central&lt;/id&gt; &lt;url&gt;http://central&lt;/url&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;updatePolicy&gt;always&lt;/updatePolicy&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;updatePolicy&gt;always&lt;/updatePolicy&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;/repositories&gt; &lt;pluginRepositories&gt; &lt;!--私服，插件--&gt; &lt;pluginRepository&gt; &lt;id&gt;ymu-public&lt;/id&gt; &lt;name&gt;ymu nexus&lt;/name&gt; &lt;url&gt;http://119.145.41.171:8085/repository/maven-public/&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;updatePolicy&gt;always&lt;/updatePolicy&gt; &lt;/snapshots&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;updatePolicy&gt;always&lt;/updatePolicy&gt; &lt;/releases&gt; &lt;/pluginRepository&gt; &lt;pluginRepository&gt; &lt;id&gt;central&lt;/id&gt; &lt;url&gt;http://central&lt;/url&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;updatePolicy&gt;always&lt;/updatePolicy&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;updatePolicy&gt;always&lt;/updatePolicy&gt; &lt;/snapshots&gt; &lt;/pluginRepository&gt; &lt;/pluginRepositories&gt; &lt;/profile&gt; 关键加上属性&lt;updatePolicy&gt;always&lt;/updatePolicy&gt; 常用maven中央仓库地址1、http://www.sonatype.org/nexus/ 私服nexus工具使用 2、http://mvnrepository.com/ （推荐） 3、http://repo1.maven.org/maven2 4、http://maven.aliyun.com/nexus/content/groups/public/ 阿里云 （强力推荐） 5、http://repo2.maven.org/maven2/ 私服nexus工具使用 6、http://uk.maven.org/maven2/ 7、http://repository.jboss.org/nexus/content/groups/public 8、http://maven.oschina.net/content/groups/public/ oschina可惜啦，以前一直用这个，不过现在有阿里云来擦屁股啦 9、http://mirrors.ibiblio.org/maven2/ 10、http://maven.antelink.com/content/repositories/central/ 11、http://nexus.openkoala.org/nexus/content/groups/Koala-release/ 12、http://maven.tmatesoft.com/content/groups/public/ ---------------------- spring的 ------------------------- &lt;repository&gt; &lt;id&gt;spring-snapshots&lt;/id&gt; &lt;name&gt;Spring Snapshots&lt;/name&gt; &lt;url&gt;https://repo.spring.io/libs-snapshot-local&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;repository&gt; &lt;id&gt;spring-milestones&lt;/id&gt; &lt;name&gt;Spring Milestones&lt;/name&gt; &lt;url&gt;https://repo.spring.io/libs-milestone-local&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;repository&gt; &lt;id&gt;spring-releases&lt;/id&gt; &lt;name&gt;Spring Releases&lt;/name&gt; &lt;url&gt;https://repo.spring.io/libs-release-local&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; 从私服无法拉取构件 方法一：上传第三方jar到私服，再应用。 方法二：找到第三方jar包所在的第三方私服，然后在自己的私服中做代理请求。 可以看到里面代理了很多第三方私服，阿里云的，spring的，等。然后整合到maven-pblicgroup组中即可。","tags":[{"name":"maven常用功能","slug":"maven常用功能","permalink":"https://xinxiamu.github.io/tags/maven常用功能/"}]},{"title":"docker学习-第三课：镜像","date":"2018-02-02T13:36:08.000Z","path":"2018/02/02/docker-lesson3-images/","text":"Docker 运行容器前需要本地存在对应的镜像,如果镜像不存在本地,Docker 会从镜像仓库下载(默认是Docker Hub 公共注册服务器中的仓库)。 本章将介绍更多关于镜像的内容,包括: 从仓库获取镜像; 管理本地主机上的镜像; 介绍镜像实现的基本原理。 获取镜像在官方Docker Hub有大量高质量可用镜像。下面我们来看怎样获取这些镜像。 从Docker 镜像仓库获取镜像的命令是docker pull。其命令格式为: docker pull [选项] [Docker Registry 地址[:端口号]/]仓库名[:标签] 具体的先选可以通过docker pull --help命令查看。镜像名称的格式： Docker 镜像仓库地址:地址的格式一般是&lt;域名/IP&gt;[:端口号]。默认地址是Docker Hub。 仓库名:如之前所说,这里的仓库名是两段式名称,即&lt;用户名&gt;/&lt;软件名&gt;。对于Docker Hub,如果不给出用户名,则默认为library,也就是官方镜像。 比如: $ docker pull ubuntu:16.04 16.04: Pulling from library/ubuntu bf5d46315322: Pull complete 9f13e0ac480c: Pull complete e8988b5b3097: Pull complete 40af181810e7: Pull complete e6f7c7e5c03e: Pull complete Digest: sha256:147913621d9cdea08853f6ba9116c2e27a3ceffecf3b492983ae97c3d643fbbe Status: Downloaded newer image for ubuntu:16.04 上面的命令中没有给出Docker镜像仓库地址,因此将会从Docker Hub获取镜像。而镜像名称是ubuntu:16.04 ,因此将会获取官方镜像library/ubuntu 仓库中标签为16.04的镜像。 例子： mutian@mutian-ThinkPad-T440p:~$ sudo docker pull centos [sudo] password for mutian: Using default tag: latest latest: Pulling from library/centos af4b0a2388c6: Pull complete Digest: sha256:6247c7082d4c86c61b00f7f2e3edbf7f072a24aa8edc28b5b68b3de3101bc1ce Status: Downloaded newer image for centos:latest mutian@mutian-ThinkPad-T440p:~$ 运行有了镜像后,我们就能够以这个镜像为基础启动并运行一个容器。以上面的为例,如果我们打算启动里面的bash并且进行交互式操作的话,可以执行下面的命令。 sudo docker run -it --rm centos bash [root@5f6c0a6b41c1 ~]# cat /etc/os-release NAME=&quot;CentOS Linux&quot; VERSION=&quot;7 (Core)&quot; ID=&quot;centos&quot; ID_LIKE=&quot;rhel fedora&quot; VERSION_ID=&quot;7&quot; PRETTY_NAME=&quot;CentOS Linux 7 (Core)&quot; ANSI_COLOR=&quot;0;31&quot; CPE_NAME=&quot;cpe:/o:centos:centos:7&quot; HOME_URL=&quot;https://www.centos.org/&quot; BUG_REPORT_URL=&quot;https://bugs.centos.org/&quot; CENTOS_MANTISBT_PROJECT=&quot;CentOS-7&quot; CENTOS_MANTISBT_PROJECT_VERSION=&quot;7&quot; REDHAT_SUPPORT_PRODUCT=&quot;centos&quot; REDHAT_SUPPORT_PRODUCT_VERSION=&quot;7&quot; [root@5f6c0a6b41c1 ~]# 通过上面信息我们可以看到容器内系统信息。 命令说明： docker run就是运行容器的命令,具体格式我们会在 容器 一节进行详细讲解,我们这里简要的说明一下上面用到的参数。 -it:这是两个参数,一个是-i:交互式操作,一个是-t终端。我们这里打算进入bash执行一些命令并查看返回结果,因此我们需要交互式终端。 --rm:这个参数是说容器退出后随之将其删除。默认情况下,为了排障需求,退出的容器并不会立即删除,除非手动docker rm。我们这里只是随便执行个命令,看看结果,不需要排障和保留结果,因此使用--rm可以避免浪费空间。 centos:这是指用centos镜像为基础来启动容器。 bash:放在镜像名后的是命令,这里我们希望有个交互式Shell,因此用的是bash。 进入系统后我们可以执行任何linux下的命令。 最后我们通过exit退出了这个容器。退出后，之前操作的所有内容将删除，重新进入系统，已经看不到。因为加了--rm命令。 列出所有的镜像想列出所有已经下载的镜像，可以使用命令docker image ls mutian@mutian-ThinkPad-T440p:~$ sudo docker image ls [sudo] password for mutian: REPOSITORY TAG IMAGE ID CREATED SIZE centos latest ff426288ea90 7 weeks ago 207MB hello-world latest f2a91732366c 3 months ago 1.85kB 上面列表包含了仓库名、标签、镜像ID、创建时间以及所占用空间。镜像 ID 则是镜像的唯一标识,一个镜像可以对应多个标签。 镜像体积SIZE：上面个看到的镜像体积可能比Docker Hub上的大，因为Docker Hub上的是压缩的，本地的是解压后的。所有镜像的总体积会比每个加起来的小，因为镜像是分层存储的，有些镜像共用相同部分。 你可以通过以下命令来便捷的查看镜像、容器、数据卷所占用的空间。 mutian@mutian-ThinkPad-T440p:~$ sudo docker system df TYPE TOTAL ACTIVE SIZE RECLAIMABLE Images 2 1 207.2MB 207.2MB (99%) Containers 1 0 0B 0B Local Volumes 0 0 0B 0B Build Cache 虚悬镜像 如上图，命令查出来的就是虚悬镜像。其产生的原因是：由于新旧镜像同名,旧镜像名称被取消,从而出现仓库名、标签均为的镜像。 这种镜像已经失去了存在的意义，是可以删除的，可以用下面命令删除： $ sudo docker image prune 中间层镜像为了加速镜像构建、重复利用资源,Docker会利用中间层镜像。所以在使用一段时间后,可能会看到一些依赖的中间层镜像。默认的docker image ls列表中只会显示顶层镜像,如果希望显示包括中间层镜像在内的所有镜像的话,需要加 -a参数。 $ sudo docker image ls -a 这样会看到很多无标签的镜像,与之前的虚悬镜像不同,这些无标签的镜像很多都是中间层镜像,是其它镜像所依赖的镜像。这些无标签镜像不应该删除,否则会导致上层镜像因为依赖丢失而出错。实际上,这些镜像也没必要删除,因为之前说过,相同的层只会存一遍,而这些镜像是别的镜像的依赖,因此并不会因为它们被列出来而多存了一份,无论如何你也会需要它们。只要删除那些依赖它们的镜像后,这些依赖的中间层镜像也会被连带删除。 列出部分镜像上面查看的是全部镜像，有的时候我们只是需要查看需要查看的镜像。 根据仓库名称列出镜像： sudo docker image ls centos REPOSITORY TAG IMAGE ID CREATED SIZE centos latest ff426288ea90 7 weeks ago 207MB 列出特定的某个镜像,也就是说指定仓库名和标签 过滤查找镜像，使用--filter。具体使用请百度。 以特定格式显示 只显示ID列： sudo docker image ls -q ff426288ea90 f2a91732366c 用go模板语法定制格式显示比如,下面的命令会直接列出镜像结果,并且只包含镜像ID和仓库名: mutian@mutian-ThinkPad-T440p:~$ sudo docker image ls --format &quot;{{.ID}}:{{.Repository}}&quot; ff426288ea90:centos f2a91732366c:hello-world 或者打算以表格等距显示,并且有标题行,和默认一样,不过自己定义列: mutian@mutian-ThinkPad-T440p:~$ sudo docker image ls --format &quot;table{{.ID}}\\t{{.Repository}}\\t{{.Tag}}&quot; IMAGE ID REPOSITORY TAG ff426288ea90 centos latest f2a91732366c hello-world latest 删除本地镜像可以使用docker image rm命令来删除本地镜像。格式如下： $ docker image rm [选项] &lt;镜像1&gt; [&lt;镜像2&gt; ...] 用 ID、镜像名、摘要删除镜像 mutian@mutian-ThinkPad-T440p:~$ sudo docker image ls REPOSITORY TAG IMAGE ID CREATED SIZE nginx latest e548f1a579cf 7 days ago 109MB centos latest ff426288ea90 7 weeks ago 207MB hello-world latest #删除hello-world，段id，id一部分，能区分就行。 mutian@mutian-ThinkPad-T440p:~$ sudo docker rm f2a91 用仓库名删除： $ sudo docker image rm hello-world 当然,更精确的是使用镜像摘要删除镜像。 mutian@mutian-ThinkPad-T440p:~$ sudo docker image ls --digests 用 docker image ls命令来配合 比如,我们需要删除所有仓库名为redis的镜像: $ docker image rm $(docker image ls -q redis) 利用commit理解镜像构成镜像是一层一层构成的。 现在让我们以定制一个Web 服务器为例子,来讲解镜像是如何构建的。 docker run --name webserver -d -p 80:80 nginx 在浏览器可查看： 现在,假设我们非常不喜欢这个欢迎页面,我们希望改成欢迎 Docker的文字,我们可以使用docker exec命令进入容器,修改其内容 &gt; sudo docker exec -it webserver bash root@3729b97e8226:/# echo &apos;&lt;h1&gt;Hello,Docker!&lt;/h1&gt;&apos; &gt; /usr/share/nginx/html/index.html root@3729b97e8226:/# exit 然后刷新浏览器，就可以看到更改了。 我们修改了容器的文件,也就是改动了容器的存储层。我们可以通过docker diff命令看到具体的改动。 下面我们可以用下面的命令将容器保存为镜像： mutian@mutian-ThinkPad-T440p:~$ sudo docker commit \\ &gt; --author &quot;zmt&quot; \\ &gt; --message &quot;修改了默认页面&quot; \\ &gt; webserver \\ &gt; nginx:v2 sha256:e8023c09eed50cf1dead0b2e9da1f8e324db7f1adf7fbb042371b0503ccd71c3 #查看 mutian@mutian-ThinkPad-T440p:~$ sudo docker image ls REPOSITORY TAG IMAGE ID CREATED SIZE nginx v2 e8023c09eed5 8 seconds ago 109MB nginx latest e548f1a579cf 7 days ago 109MB centos latest ff426288ea90 7 weeks ago 207MB hello-world latest 查看镜像内历史记录： $ docker history nginx:v2 新的镜像定制好后,我们可以来运行这个镜像。 mutian@mutian-ThinkPad-T440p:~$ sudo docker run --name web2 -d -p 81:80 nginx:v2 在浏览器查看：http://localhost:81/ 停止容器：sudo docker kill --signal=SIGINT web2 至此,我们第一次完成了定制镜像,使用的是docker commit命令,手动操作给旧的镜像添加了新的一层,形成新的镜像,对镜像多层存储应该有了更直观的感觉。 注意：通常不会使用docker commit来创建镜像，这样容易导致镜像臃肿。另外也无法知道每次更改，变成黑箱操作。 使用Dockerfile定制镜像从上面commit我们知道，镜像是一层层定制，为了把整个定制层次透明，于是我们用脚本命令方式，把整个层次透明化，同时减少创建臃肿的镜像。而这个脚本文件，就是Dockerfile。 Dockerfile是一个文本文件,其内包含了一条条的指令(Instruction),每一条指令构建一层,因此每一条指令的内容,就是描述该层应当如何构建。 简单例子：1.创建Dockerfile文件 mutian@mutian-ThinkPad-T440p:~$ mkdir mynginx mutian@mutian-ThinkPad-T440p:~$ cd mynginx/ mutian@mutian-ThinkPad-T440p:~/mynginx$ touch Dockerfile 2.打开Dockerfile文件，编辑如下内容： FROM nginx RUN echo &apos;&lt;h1&gt;您好，我是Nginx！&lt;/h1&gt;&apos; &gt; /usr/share/nginx/html/index.html 3.构建镜像进入Dockerfile所在目录，执行命令： mutian@mutian-ThinkPad-T440p:~/mynginx$ sudo docker build -t nginx:v3 . Sending build context to Docker daemon 2.048kB Step 1/2 : FROM nginx ---&gt; e548f1a579cf Step 2/2 : RUN echo &apos;&lt;h1&gt;您好，我是Nginx！&lt;/h1&gt;&apos; &gt; /usr/share/nginx/html/index.html ---&gt; Running in d8c0149adf7e Removing intermediate container d8c0149adf7e ---&gt; b92f375b41f0 Successfully built b92f375b41f0 Successfully tagged nginx:v3 4.查看 mutian@mutian-ThinkPad-T440p:~/mynginx$ sudo docker image ls REPOSITORY TAG IMAGE ID CREATED SIZE nginx v3 b92f375b41f0 About a minute ago 109MB nginx v2 e8023c09eed5 17 hours ago 109MB nginx latest e548f1a579cf 8 days ago 109MB centos latest ff426288ea90 7 weeks ago 207MB hello-world latest f2a91732366c 3 months ago 我们看到，TAG为v3的镜像就是我们刚才构建。 FROM指定基础镜像定制镜像必须是以一个镜像为基础来构建，基础镜像是必须要指定的，而FROM命令就是指定基础镜像，且第一步就要指定。 除了选择一些先前定制好的镜像作为基础镜像，Docker还存在一个特殊的镜像，名为scratch，表示空镜像，是个虚拟的概念，不实际存在。 FROM scratch ... 如果以scratch为基础，则意味着不以任何镜像为基础，后面所写的命令将作为镜像的第一层存在。 对于一些二进制的可执行文件，直接最为第一层存在，不依赖其它运行时系统支持，可以用空镜像。类似go语言编译的程序。 RUN 执行命令RUN命令是用来执行命令行命令的，就像shell脚本一样，用来执行linux命令。 注意避免错误： FROM debian:jessie RUN apt-get update RUN apt-get install -y gcc libc6-dev make RUN wget -O redis.tar.gz &quot;http://download.redis.io/releases/redis-3.2.5.tar.gz&quot; RUN mkdir -p /usr/src/redis RUN tar -xzf redis.tar.gz -C /usr/src/redis --strip-components=1 RUN make -C /usr/src/redis RUN make -C /usr/src/redis install 每一个指令都会创建一层，每层都会带有上层垃圾，因此一定要避免这样写。正确的写法如下： FROM debian:jessie RUN buildDeps=&apos;gcc libc6-dev make&apos; \\ &amp;&amp; apt-get update \\ &amp;&amp; apt-get install -y $buildDeps \\ &amp;&amp; wget -O redis.tar.gz &quot;http://download.redis.io/releases/redis-3.2.5.tar.gz&quot; \\ &amp;&amp; mkdir -p /usr/src/redis \\ &amp;&amp; tar -xzf redis.tar.gz -C /usr/src/redis --strip-components=1 \\ &amp;&amp; make -C /usr/src/redis \\ &amp;&amp; make -C /usr/src/redis install \\ &amp;&amp; rm -rf /var/lib/apt/lists/* \\ &amp;&amp; rm redis.tar.gz \\ &amp;&amp; rm -r /usr/src/redis \\ &amp;&amp; apt-get purge -y --auto-remove $buildDeps 用了&amp;&amp;，这和shell执行命令一样，就相当一个命令，所以算一层。执行完后，一定要记得删除不必要的垃圾数据，垃圾包。在编写Dockerfile时候，一定要面向类似事件的思维，比如，安装redis环境，是一个事件，算一层。安装mysql，算一个事件，一层。 Dockerfile指令详解上面我们已经了解了From、RUN指令，下面我们来介绍其余的…… COPY复制文件格式： COPY &lt;源路径&gt;... &lt;目标路径&gt; COPY [&quot;&lt;源路径1&gt;&quot;,... &quot;&lt;目标路径&gt;&quot;] 源路径指当前电脑系统文件路径，目标路径指容器的文件路径。 COPY指令将从构建上下文目录中&lt;源路径&gt;的文件/目录复制到新的一层的镜像内的&lt;目标路径&gt;位置。比如: COPY package.json /usr/src/app/ &lt;源路径&gt;可以是多个，甚至可以是通配符，只要满足GO的filepath.Match规则，如： COPY hom* /mydir/ COPY hom?.txt /mydir/ &lt;目标路径&gt; 可以是容器内的绝对路径，也可以是相对于工作目录的相对路径（工作目录可以用WORKDIR指令来指定） 注意一点： 使用 COPY指令,源文件的各种元数据都会保留。比如读、写、执行权限、文件变更时间等。 ADD 更高级的复制文件ADD指令和COPY指令本质上是一样的，只是添加了更多功能。 它的源文件可以是个url，也可以是tar，如果是tar还可以自动解压。 但是，如果是url，下载下来后，还要新建一层解压，授权，因此不如用COPY ，然后用wget命令。 在某个场景下，自动解压缩功能非常有用。 如： FROM scratch ADD ubuntu-xenial-core-cloudimg-amd64-root.tar.gz / ... _注意_： 在COPY 和ADD指令中选择的时候,可以遵循这样的原则,所有的文件复制均使用COPY指令,仅在需要自动解压缩的场合使用ADD。 CMD容器启动命令也有两种格式： shell格式：CMD &lt;命令&gt; exec格式：CMD [&quot;可执行文件&quot;, &quot;参数1&quot;, &quot;参数2&quot;...] 参数列表格式: CMD [&quot;参数1&quot;, &quot;参数2&quot;...] 。在指定了ENTRYPOINT指令后,用CMD指定具体的参数。 在指令格式上，推荐exec格式。 Docker不是虚拟机，只是一个进程。因此，在容器中启动程序，不要以后台形式启动，要以前台形式启动。容器内没有后台概念。 不要这样启动： CMD service ginx start 直接启动可执行文件，并以前台形式启动： CMD [&quot;nginx&quot;,&quot;-g&quot;,&quot;daemon off;&quot;] ENTRYPOINT入口点也分为：exec格式和shell格式 当指定了ENTRYPOINT后，就会把CMD的内容作为参数传给ENTRYPOINT指令，换句话说实际执行时，将变为： &lt;ENTRYPOINT&gt; &quot;&lt;CMD&gt;&quot; 场景一：把镜像当成命令一样使用。 FROM ubuntu:16.04 RUN apt-get update \\ &amp;&amp; apt-get install -y curl \\ &amp;&amp; rm -rf /var/lib/apt/lists/* CMD [ &quot;curl&quot;, &quot;-s&quot;, &quot;http://ip.cn&quot; ] 执行： $ docker run myip 当前 IP:61.148.226.66 来自:北京市 联通 再执行： $ docker run myip -i docker: Error response from daemon: invalid header field value &quot;oci runtime error: con tainer_linux.go:247: starting container process caused \\&quot;exec: \\\\\\&quot;-i\\\\\\&quot;: executable file not found in $PATH\\&quot;\\n&quot;. 可以看到，报错了，因为-i不能参数不能传到CMD上去。 正确方式： FROM ubuntu:16.04 RUN apt-get update \\ &amp;&amp; apt-get install -y curl \\ &amp;&amp; rm -rf /var/lib/apt/lists/* ENTRYPOINT [ &quot;curl&quot;, &quot;-s&quot;, &quot;http://ip.cn&quot; ] 执行： $ docker run myip 当前 IP:61.148.226.66 来自:北京市 联通 $ docker run myip -i HTTP/1.1 200 OK Server: nginx/1.8.0 Date: Tue, 22 Nov 2016 05:12:40 GMT Content-Type: text/html; charset=UTF-8 Vary: Accept-Encoding X-Powered-By: PHP/5.6.24-1~dotdeb+7.1 X-Cache: MISS from cache-2 X-Cache-Lookup: MISS from cache-2:80 X-Cache: MISS from proxy-2_6 Transfer-Encoding: chunked Via: 1.1 cache-2:80, 1.1 proxy-2_6:8006 Connection: keep-alive 当前 IP:61.148.226.66 来自:北京市 联通 可以看到,这次成功了。这是因为当存在ENTRYPOINT后,CMD的内容将会作为参数传给ENTRYPOINT,而这里-i就是新的CMD,因此会作为参数传给curl,从而达到了我们预`期的效果。 场景二： 在应用程序启动前等做一些初始化工作。 比如启动redis，不以root，而以redis用户身份启动。 FROM alpine:3.4 ... RUN addgroup -S redis &amp;&amp; adduser -S -G redis redis ... ENTRYPOINT [&quot;docker-entrypoint.sh&quot;] EXPOSE 6379 CMD [&quot;redis-server&quot;] 可以看到其中为了redis服务创建了redis用户,并在最后指定了ENTRYPOINT为docker-entrypoint.sh脚本。 #!/bin/sh ... #allow the container to be started with `--user` if [&quot;$1&quot; = &apos;redis-server&apos; -a &quot;$(id -u)&quot; = &apos;0&apos;]; then chown -R redis . exec su-exec redis &quot;$0&quot; &quot;$@&quot; fi exec &quot;$@&quot; 执行： $ docker run -it redis id uid=0(root) gid=0(root) groups=0(root) ENV 设置环境变量格式有两种: ENV &lt;key&gt; &lt;value&gt; ENV &lt;key1&gt;=&lt;value1&gt; &lt;key2&gt;=&lt;value2&gt;... 如： ENV VERSION=1.0 DEBUG=on \\ NAME=&quot;Happy Feet&quot; 这里展示了用法，还展示了换行，有空格的话用双引号。 定义了变量，后面的命令中就可以使用了。可以使用它的命令如下一些： ADD 、 COPY 、 ENV 、 EXPOSE 、 LABEL 、 USER 、 WORKDIR 、 VOLUME 、 STOPSIGNAL 、 ONBU ILD node官方Dockerfile例子： ENV NODE_VERSION 7.2.0 RUN curl -SLO &quot;https://nodejs.org/dist/v$NODE_VERSION/node-v$NODE_VERSION-linux-x64.ta r.xz&quot; \\ &amp;&amp; curl -SLO &quot;https://nodejs.org/dist/v$NODE_VERSION/SHASUMS256.txt.asc&quot; \\ &amp;&amp; gpg --batch --decrypt --output SHASUMS256.txt SHASUMS256.txt.asc \\ &amp;&amp; grep &quot; node-v$NODE_VERSION-linux-x64.tar.xz\\$&quot; SHASUMS256.txt | sha256sum -c - \\ &amp;&amp; tar -xJf &quot;node-v$NODE_VERSION-linux-x64.tar.xz&quot; -C /usr/local --strip-components= 1 \\ &amp;&amp; rm &quot;node-v$NODE_VERSION-linux-x64.tar.xz&quot; SHASUMS25 可以看到，定义了变量，后面就可以不断重复引入使用。改变的时候，只需要改一个地方。同时可以创建不同的多个镜像。 ARG 构建参数构建参数和ENV的效果一样,都是设置环境变量。所不同的是,ARG所设置的构建环境的环境变量,在将来容器运行时是不会存在这些环境变量的。但是不要因此就使用ARG保存密码之类的信息,因为docker history还是可以看到所有值的。 VOLUME 定义匿名卷两种格式： VOLUME [&quot;&lt;路径1&gt;&quot;, &quot;&lt;路径2&gt;&quot;...] VOLUME &lt;路径&gt; 不应该在容器存储层发生写操作。这样容器就能保持无状态的。对于动态数据，文件，我们应该保存到卷中。为了防止用户在运行时将动态文件写到存储层，所以要预先指定动态文件写入的目录挂载为卷，如下： VOLUME /data 这里，指定/data为匿名卷，任何写入该目录下的数据都不会写入到容器存储层。这样容器就是无状态的。可以运行时替换掉所挂载卷： docker run -d -v mydata:/data xxxx 在这行命令中,就使用了mydata这个命名卷挂载到了/data这个位置,替代了Dockerfile中定义的匿名卷的挂载配置。 EXPOSE 声明端口格式：EXPOSE &lt;端口1&gt; [&lt;端口2&gt;...] EXPOSE指令是声明运行时容器提供服务端口,这只是一个声明,在运行时并不会因为这个声明应用就会开启这个端口的服务。 要将EXPOSE和在运行时使用-p &lt;宿主端口&gt;:&lt;容器端口&gt;区分开来。-p,是映射宿主端口和容器端口,换句话说,就是将容器的对应端口服务公开给外界访问,而EXPOSE仅仅是声明容器打算使用什么端口而已,并不会自动在宿主进行端口映射。 WORKDIR指定工作目录格式：WORKDIR &lt;工作目录路径&gt; 该命令可以指定工作目录（当前目录），后面各层都使用该指定目录。该目录如果不存在，则会创建空目录。 写Dockerfile千万不能按照shell的思维写，应为docker是分层的。比如下面错误写法： RUN cd /app RUN echo &quot;hello&quot; &gt; world.txt 构建后，你会发现找不到/app/world.txt文件。原因是：在shell中执行命令，是在同一进程中，操作的是同样的内存。但是在docker中不是。你知道，每一个RUN命令都是构建一层的，启动不同的容器。第一次RUN只是操作进入/app目录，没有操作任何文件变更，只是内存的变化而已，第二次启动了个新的容器，跟第一层的容器完全没关系了。所以：在写Dockerfile到时候，一定要有分层的思维，每一个完整的操作要在同一层里面做。 如果要改变以后各层的工作目录都在指定的工作目录，那么WORKDIR指令就派上用场了。 USER指定当前用户格式:USER &lt;用户名&gt; 用户名系统已经添加好 和WORKDIR一样，都会影响后面的每一层。改变执行后面命令的执行身份。 下面建立用户，并切换到该用户，启动redis： RUN groupadd -r redis &amp;&amp; useradd -r -g redis edis USER redis RUN [&quot;redis-server&quot;] 如果以root执行脚本，在执行期间想切换用户，可以参考下面做法： # 建立redis用户,并使用gosu换另一个用户执行命令 RUN groupadd -r redis &amp;&amp; useradd -r -g redis redis #下载gosu RUN wget -O /usr/local/bin/gosu &quot;https://github.com/tianon/gosu/releases/download/1.7/ gosu-amd64&quot; \\ &amp;&amp; chmod +x /usr/local/bin/gosu \\ &amp;&amp; gosu nobody true #设置CMD,并以另外的用户执行 CMD [&quot;exec&quot;,&quot;gosu&quot;,&quot;redis&quot;,&quot;redis-server&quot;] gosu使用更多信息参考：https://github.com/tianon/gosu HEALTHCHECK 健康检查格式： HEALTHCHECK [选项] CMD &lt;命令&gt;:设置检查容器健康状况的命令 HEALTHCHECK NONE:如果基础镜像有健康检查指令,使用这行可以屏蔽掉其健康检查指令。 该指令是告诉Docker应该如何进行判断容器的状态是否正常。 ONBUILD 为他人做嫁衣裳格式: ONBUILD &lt;其它指令&gt; ONBUILD 后面的指令，在当前镜像构建的时候是不会执行的，只有以它所在的镜像为基础镜像的镜像在构建的时候才会执行。 Docker中其它的命令都是为了定制当前的镜像准备的，只有ONBUILD是为了他人而准备。 所以，这里就可以看出，该指令可以用来做命令的继承。类似maven中的父pom。把ONBUILD后面的命令都看做各个子Dockerfile的共用命令。 FROM node:slim RUN mkdir /app WORKDIR /app ONBUILD COPY ./package.json /app ONBUILD RUN [&quot;npm&quot;, &quot;install&quot;] ONBUILD COPY . /app/ CMD [&quot;npm&quot;, &quot;start&quot;] 后面每一个子Dockerfile只需要以上面镜像伟基础镜像: FROM my-node 这样，ONBUILD后面的指令都会在每个子Dockerfile中执行。 删除本地镜像可以使用命令docker rmi，格式： `docker rmi [选项] &lt;镜像1&gt; [&lt;镜像2&gt; ...]` _注意_: docker rm 命令是删除容器,不要混淆。 可以用ID、镜像名、摘要删除镜像： mutian@mutian-ThinkPad-T440p:~$ sudo docker images [sudo] password for mutian: REPOSITORY TAG IMAGE ID CREATED SIZE mysql/mysql-server latest 02d081b9c73e 2 months ago 300MB nginx v3 b92f375b41f0 4 months ago 109MB nginx v2 e8023c09eed5 4 months ago 109MB nginx latest e548f1a579cf 4 months ago 109MB centos latest ff426288ea90 5 months ago 207MB hello-world latest f2a91732366c 7 months ago 1.85kB season/fastdfs latest c6cc94c34f8e 2 years ago 205MB 用短id删除，人工输入的时候使用，方便： $ docker rmi ff4 用长id，一般使用脚本的时候： $ docker rmi f2a91732366c 用镜像名,&lt;仓库名&gt;:&lt;标签&gt;： docker rmi nginx：v3 使用摘要，最精确： 查看摘要： mutian@mutian-ThinkPad-T440p:~$ sudo docker images --digests REPOSITORY TAG DIGEST IMAGE ID CREATED SIZE mysql/mysql-server latest sha256:f1cb1e3f0124601b1496f485e9f4401ad10138294b5a38d932089daafd555e34 02d081b9c73e 2 months ago 300MB nginx v3 &lt;none&gt; b92f375b41f0 4 months ago 109MB nginx v2 &lt;none&gt; e8023c09eed5 4 months ago 109MB nginx latest sha256:4771d09578c7c6a65299e110b3ee1c0a2592f5ea2618d23e4ffe7a4cab1ce5de e548f1a579cf 4 months ago 109MB centos latest sha256:6247c7082d4c86c61b00f7f2e3edbf7f072a24aa8edc28b5b68b3de3101bc1ce ff426288ea90 5 months ago 207MB hello-world latest sha256:083de497cff944f969d8499ab94f07134c50bcf5e6b9559b27182d3fa80ce3f7 f2a91732366c 7 months ago 1.85kB season/fastdfs latest sha256:408acdebaa278e8ed875f7c63aa0c7ac8e633cf92f615d8295d279e137217003 c6cc94c34f8e 2 years ago 205MB 删除： docker rmi centos@sha256:6247c7082d4c86c61b00f7f2e3edbf7f072a24aa8edc28b5b68b3de3101bc1ce Untagged和Deleted仔细观察，发现两种删除行为。 实际上，镜像都是一层层的，一个镜像有多个标签，只有每个标签都取消了，才有可能删除镜像。删除的时候从上最上层往下，逐步判断删除。 用docker images命令来配合配合docker images -q，可以成批的删除你想要删除的镜像，可以指定你想要删除的镜像。 删除虚悬镜像： $ docker rmi $(docker images -q -f dangling=true) 删除所有仓库名为redis的镜像: $ docker rmi $(docker images -q redis) 删除所有在mongo:3.2之前的镜像: $ docker rmi $(docker images -q -f before=mongo:3.2) docker image后面版本，推荐使用docker image来管理镜像。 如删除： $ docker image rm 基于本地模板导入导出镜像把镜像上传到docker公共仓库https://hub.docker.com 现在上面网址中注册： 1.登录docker [root@xr-server-dev ~]# docker login Login with your Docker ID to push and pull images from Docker Hub. If you don&apos;t have a Docker ID, head over to https://hub.docker.com to create one. Username: xinxiamu Password: Login Succeeded 2.对本地自定义的docker镜像打标签，必须先打标签： [root@xr-server-dev ~]# docker tag fastdfs-server:v1 xinxiamu/fdfs-server:0.1 3.上传到hub.docker.com: [root@xr-server-dev ~]# docker push xinxiamu/fdfs-server:0.1 The push refers to repository [docker.io/xinxiamu/fdfs-server] 77f438662c4e: Pushed 7051cce03d08: Pushed 47262386cb42: Pushed 89b5ef66bef1: Pushed 6498ec7e0c6f: Pushed 939591e6b702: Pushed d99d7b3f4b3f: Pushed e5f0ae3c8627: Pushed 79332ca36cf7: Pushed d69483a6face: Pushed 0.1: digest: sha256:811bc129bc6da0fe648e8dc4388dac39db592d86c14f4df87b2b70fc13b80fb5 size: 2403 刷新页面可以看到已经上传： 把镜像上传到私服后面章节有介绍…… 镜像的实现原理UnionFS 配置镜像加速器注册阿里云账号后，即可在阿里云控制台（https://cr.console.aliyun.com/#/accelerator）看到类似如下的页面。 按照上图说明配置即可。","tags":[{"name":"docker镜像","slug":"docker镜像","permalink":"https://xinxiamu.github.io/tags/docker镜像/"}]},{"title":"docker学习-第二课：发布一个web应用","date":"2018-02-02T03:00:11.000Z","path":"2018/02/02/docker-lesson2/","text":"介绍docker镜像的创建，容器的运行，并发布应用到容器，浏览器访问…… 参考网址：https://github.com/docker/labs/tree/master/beginner/","tags":[{"name":"docker镜像创建、docker容器启动、docker发布web应用","slug":"docker镜像创建、docker容器启动、docker发布web应用","permalink":"https://xinxiamu.github.io/tags/docker镜像创建、docker容器启动、docker发布web应用/"}]},{"title":"docker学习-第一课：基础概念理解","date":"2018-02-02T02:16:25.000Z","path":"2018/02/02/docker-lesson1/","text":"Docker 包括三个基本概念镜像(Image)容器(Container)仓库(Repository)理解了这三个概念,就理解了 Docker 的整个生命周期。 Docker镜像docker镜像就像是一个只读的模板。 例如：一个docker镜像可以包含一个完整的centos系统，里面只安装了nginx或者其他的应用程序。 镜像可以用来创建容器。甚至多个容器。 Docker 提供了一个很简单的机制来创建镜像或者更新现有的镜像,用户甚至可以直接从其他人那里下载一个已经做好的镜像来直接使用。 Docker容器docker利用容器来运行应用。 容器是从镜像创建的运行实例。它可以被启动、开始、停止、删除。每个容器都是相互隔离的、保证安全的平台 可以把容器看做是一个简易版的 Linux 环境(包括root用户权限、进程空间、用户空间和网络空间等)和运行在其中的应用程序。 注：镜像是只读的,容器在启动的时候创建一层可写层作为最上层。 Docker仓库仓库是集中存放镜像文件的场所。有时候会把仓库和仓库注册服务器(Registry)混为一谈,并不严格区分。实际上,仓库注册服务器上往往存放着多个仓库,每个仓库中又包含了多个镜像,每个镜像有不同的标签(tag)。 仓库分为公开仓库(Public)和私有仓库(Private)两种形式。 最大的公开仓库是Docker Hub,存放了数量庞大的镜像供用户下载。 国内的公开仓库包括Docker Pool等,可以提供大陆用户更稳定快速的访问。 当然,用户也可以在本地网络内创建一个私有仓库。 当用户创建了自己的镜像之后就可以使用 push 命令将它上传到公有或者私有仓库,这样下次在另外一台机器上使用这个镜像时候,只需要从仓库上 pull 下来就可以了。 注:Docker 仓库的概念跟Git类似,注册服务器可以理解为GitHub这样的托管服务。","tags":[{"name":"基础概念","slug":"基础概念","permalink":"https://xinxiamu.github.io/tags/基础概念/"}]},{"title":"fastdfs-分布式文件系统安装使用","date":"2018-02-01T02:51:36.000Z","path":"2018/02/01/fastdfs-start/","text":"本文记录FastDFS分布式文件系统的在服务器的搭建，配置以及使用…… 网址：https://github.com/happyfish100/fastdfs 参考：http://blog.csdn.net/xyang81/article/details/52837974http://blog.csdn.net/playadota/article/details/78381109 centos下搭建第一步：安装依赖安装fastdfs之前，先要安装相关依赖包libfastcommon。 下载地址：https://github.com/happyfish100/libfastcommon.git git clone https://github.com/happyfish100/libfastcommon.git 编译安装： &gt; cd libfastcommon &gt; ./make.sh &gt; ./make.sh install 第二部：安装fastdfs下载：https://github.com/happyfish100/fastdfs step 2. download FastDFS source package and unpack it,tar xzf FastDFS_v5.x.tar.gz step 3. enter the FastDFS dir cd FastDFS step 4. execute: ./make.sh step 5. make install ./make.sh install` step 6. edit/modify the config file of tracker and storage cd /etc/fdfs/ cp tracker.conf.sample tracker.conf cp storage.conf.sample storage.conf mkdir -p /server/data/fdfs 首先修改配置文件： /etc/fdfs/tracker.conf，修改路径到/server/data/fdfs目录。 base_path=/server/data/fdfs/tracker 启动： #start the tracker server: /usr/bin/fdfs_trackerd /etc/fdfs/tracker.conf restart #in Linux, you can start fdfs_trackerd as a service: /sbin/service fdfs_trackerd start 检查启动是否成功： ps -ef | grep fdfs_trackerd 设置tracker服务开启启动： 修改配置文件： /etc/fdfs/storag.conf，修改路径到/server/data/fdfs目录，同时配置tracker_server地址。 # the base path to store data and log files base_path=/server/data/fdfs/storeage # tracker_server can ocur more than once, and tracker_server format is # &quot;host:port&quot;, host can be hostname or ip address tracker_server=192.168.1.36:22122 # store_path#, based 0, if store_path0 not exists, it&apos;s value is base_path # the paths must be exist store_path0=/server/data/fdfs/storeage #store_path1=/home/yuqing/fastdfs2 启动： #start the storage server: /usr/bin/fdfs_storaged /etc/fdfs/storage.conf restart #in Linux, you can start fdfs_storaged as a service: /sbin/service fdfs_storaged start 检查启动是否成功： ps -ef | grep fdfs_storaged 停止: `/usr/bin/fdfs_trackerd /etc/fdfs/tracker.conf stop` 设置storage服务开机启动 停止： /usr/bin/fdfs_storaged /etc/fdfs/storage.conf stop …… 测试更改`/etc/fdfs/下client.conf配置文件。 base_path=~/dev/fastdfs/data/clienttracker_server=192.168.147 不能是localhost或者127.0.0.1 mutian@mutian-ThinkPad-T440p:~$ /usr/bin/fdfs_test /etc/fdfs/client.conf upload /home/mutian/ifconfig.sh This is FastDFS client test program v5.08 Copyright (C) 2008, Happy Fish / YuQing FastDFS may be copied only under the terms of the GNU General Public License V3, which may be found in the FastDFS source kit. Please visit the FastDFS Home Page http://www.csource.org/ for more detail. [2018-03-06 09:48:19] DEBUG - base_path=/home/mutian/dev/fastdfs/data/client, connect_timeout=30, network_timeout=60, tracker_server_count=1, anti_steal_token=0, anti_steal_secret_key length=0, use_connection_pool=0, g_connection_pool_max_idle_time=3600s, use_storage_id=0, storage server id count: 0 tracker_query_storage_store_list_without_group: server 1. group_name=, ip_addr=192.168.1.146, port=23000 group_name=group1, ip_addr=192.168.1.146, port=23000 storage_upload_by_filename group_name=group1, remote_filename=M00/00/00/wKgBklqd82OAfszHAAAAHR6tZH87071.sh source ip address: 192.168.1.146 file timestamp=2018-03-06 09:48:19 file size=29 file crc32=514679935 example file url: http://192.168.1.146/group1/M00/00/00/wKgBklqd82OAfszHAAAAHR6tZH87071.sh storage_upload_slave_by_filename group_name=group1, remote_filename=M00/00/00/wKgBklqd82OAfszHAAAAHR6tZH87071_big.sh source ip address: 192.168.1.146 file timestamp=2018-03-06 09:48:19 file size=29 file crc32=514679935 example file url: http://192.168.1.146/group1/M00/00/00/wKgBklqd82OAfszHAAAAHR6tZH87071_big.sh mutian@mutian-ThinkPad-T440p:~$ #### mutian@mutian-ThinkPad-T440p:~/Pictures$ /usr/bin/fdfs_upload_file /etc/fdfs/client.conf aa.png group1/M00/00/00/wKgBklqgqI6AbB6yAAGUbXc7zK4788.png mutian@mutian-ThinkPad-T440p:~/Pictures$ cd mutian@mutian-ThinkPad-T440p:~$ /usr/bin/fdfs_upload_file /etc/fdfs/client.conf south_air.zip group1/M00/00/00/wKgBklqgqSaABpepFCjSUGWmckg821.zip ubuntu下搭建验证过，上面过程适用…… 集成nginx模块参考：https://github.com/happyfish100/fastdfs-nginx-module/blob/master/INSTALL 1.下载fastdfs-nginx-module git clone https://github.com/happyfish100/fastdfs-nginx-module.git 注意：安装的FastDFS版本 &gt;= 5.11 2.安装nginx-1.8.1 下载：http://nginx.org/en/download.html &gt; ./configure --prefix=~/nginx \\ --add-module=/home/mutian/fastdfs-nginx-module/src &gt; make; make install 3.更改nginx配置，添加一行。 如果文件分组 location ~/group([0-9])/M00 { ngx_fastdfs_module; } 如果没分组 location /M00 { root /home/mutian/dev/fastdfs/data/storage/data; ngx_fastdfs_module; } 注意： A、8888 端口值是要与/etc/fdfs/storage.conf 中的 http.server_port=8888 相对应, 因为 http.server_port 默认为 8888,如果想改成 80,则要对应修改过来。 B、Storage 对应有多个 group 的情况下,访问路径带 group 名,如/group1/M00/00/00/xxx, 对应的 Nginx 配置为: location ~/group([0-9])/M00 { ngx_fastdfs_module; } 4.拷贝fdfs_storage的文件存储软链接 ln -s /home/mutian/dev/fastdfs/data/storage/data /home/mutian/dev/fastdfs/data/storage/data/M00 5.更改配置mod_fastdfs.conf 拷贝到相关目录： cp ~/dev/fastdfs/fastdfs-nginx-module/src/mod_fastdfs.conf /etc/fdfs/ 更改内容： connect_timeout=10 base_path=/tmp tracker_server=ip01:22122 storage_server_port=23000 group_name=group1 url_have_group_name = true store_path0=/home/mutian/dev/fastdfs/data/storage 6.复制FastDFS 的部分配置文件到/etc/fdfs目录 mutian@mutian-ThinkPad-T440p:~$ cd /home/mutian/dev/fastdfs/fastdfs-5.11/conf/ mutian@mutian-ThinkPad-T440p:~/dev/fastdfs/fastdfs-5.11/conf$ ls anti-steal.jpg http.conf storage.conf tracker.conf client.conf mime.types storage_ids.conf cp http.conf mime.types /etc/fdfs/ 7.启动nginx ~/dev/nginx/sbin/nginx -s stop; ~/dev/nginx/sbin/nginx 8.测试按上面步骤，上传个文件，然后在浏览器打开： http://ip:port/group1/M00/00/00/tlxkwlhttsGAU2ZXAAC07quU0oE095.png or http://ip/group1/M00/00/00/tlxkwlhttsGAU2ZXAAC07quU0oE095.png","tags":[]},{"title":"虚拟开发环境-Vagrant","date":"2018-01-23T02:04:27.000Z","path":"2018/01/23/vagrant-start/","text":"介绍vagrant，为公司搭建统一的开发环境。最终会输出一个统一的虚拟开发环境，然后就可以分发给团队中所有的开发人员，大家在一致的开发环境中编辑，验证代码…… 从此,告别“在我的机子上运行没问题的……”这个看似很有道理的扯皮了。 官网网址：https://www.vagrantup.com/ vagrant安装安装开源虚拟机VirtualBox注意安装版本和vagrant版本要对应，否则后面会出现各种问题。这里安装最新版本。 下载地址：https://www.virtualbox.org/wiki/Downloads 选择自己电脑系统对应版本。 axel -n 10 https://download.virtualbox.org/virtualbox/5.2.14/virtualbox-5.2_5.2.14-123301~Ubuntu~xenial_amd64.deb 然后，执行安装命令sudo dpkg -i *.deb进行安装即可。 安装过程中可能会缺少依赖包，把依赖包安装即可： 安装依赖包：mutian@mutian-ThinkPad-T440p:~/Downloads$ sudo apt install libsdl1.2debian 重新执行安装命令： 安装没有任何错误。 已安装到系统。 windows下安装问题：安装Virtualbox的时候回滚，并提示发生一个严重的错误。 解决方法如下： 打开服务选项 ：win + R 然后在跳出来的编辑框 键入 services.msc 然后回车 1.Device Install Service 2.Device Setup Manager 开启这两个服务，然后右键安装程序，以管理员身份运行，然后就能安装啦~ 安装vagrant安装最新版本。 下载地址：https://www.vagrantup.com/downloads.html 下载自己电脑系统对应版本。 axel -n 10 https://releases.hashicorp.com/vagrant/2.1.2/vagrant_2.1.2_x86_64.deb 然后，执行安装命令sudo dpkg -i vagrant_2.1.2_x86_64.deb进行安装即可。 查看安装是否成功： mutian@mutian-ThinkPad-T440p:~/Downloads$ vagrant -v Vagrant 2.1.2 表明安装已经成功，版本2.1.2。 添加Box官方box源：https://app.vagrantup.com/boxes/search 网络不好，需要翻墙。或者通过其它途径下载想要的box。 查看所有已下载box vagrant box list 添加box vagrant box add centos/7 执行上面命令会添加相应box到vagrant系统，如果没有，会先从box官源下载。 再次执行vagrant box list便可以看到。 离线方式：https://cloud.centos.org/centos/7/vagrant/x86_64/images/ 下载相应box镜像，然后执行命令添加box： vagrant box add centos/7 aa.box 创造自己box 创建目录 mutian@mutian-ThinkPad-T440p:~/dev/vagrant$ mkdir xcsqjr-dev/ 初始化，创建配置文件 mutian@mutian-ThinkPad-T440p:~/dev/vagrant$ cd xcsqjr-dev/ mutian@mutian-ThinkPad-T440p:~/dev/vagrant/xcsqjr-dev$ vagrant init centos/7 A `Vagrantfile` has been placed in this directory. You are now ready to `vagrant up` your first virtual environment! Please read the comments in the Vagrantfile as well as documentation on `vagrantup.com` for more information on using Vagrant. 会在当前目录下创建文件Vagrantfile。然后就可以编辑该文件，做一些配置： # -*- mode: ruby -*- # vi: set ft=ruby : # All Vagrant configuration is done below. The &quot;2&quot; in Vagrant.configure # configures the configuration version (we support older styles for # backwards compatibility). Please don&apos;t change it unless you know what # you&apos;re doing. Vagrant.configure(&quot;2&quot;) do |config| # The most common configuration options are documented and commented below. # For a complete reference, please see the online documentation at # https://docs.vagrantup.com. # Every Vagrant development environment requires a box. You can search for # boxes at https://vagrantcloud.com/search. # ----------- 一些相关配置 start ----------------# config.vm.box = &quot;centos/7&quot; #和已经下载的box名字一致 config.vm.hostname = &quot;ymu&quot; #config.vm.box_version = &quot;1.1.0&quot; config.vm.box_url = &quot;http://ymu.box&quot; # 对虚拟机的一些配置 config.vm.provider &quot;virtualbox&quot; do |vb| # # Display the VirtualBox GUI when booting the machine # vb.gui = true # # # Customize the amount of memory on the VM: vb.memory = &quot;1024&quot; #为虚拟机分配内存 vb.cpus = 2 #为虚拟机分配cup，分2核心 vb.name = &quot;centos7_ymu&quot; #虚拟机名称 end # ----------- 一些相关配置 end ----------------# # Disable automatic box update checking. If you disable this, then # boxes will only be checked for updates when the user runs # `vagrant box outdated`. This is not recommended. # config.vm.box_check_update = false # Create a forwarded port mapping which allows access to a specific port # within the machine from a port on the host machine. In the example below, # accessing &quot;localhost:8080&quot; will access port 80 on the guest machine. # NOTE: This will enable public access to the opened port # config.vm.network &quot;forwarded_port&quot;, guest: 80, host: 8080 # Create a forwarded port mapping which allows access to a specific port # within the machine from a port on the host machine and only allow access # via 127.0.0.1 to disable public access # config.vm.network &quot;forwarded_port&quot;, guest: 80, host: 8080, host_ip: &quot;127.0.0.1&quot; # Create a private network, which allows host-only access to the machine # using a specific IP. # config.vm.network &quot;private_network&quot;, ip: &quot;192.168.33.10&quot; # Create a public network, which generally matched to bridged network. # Bridged networks make the machine appear as another physical device on # your network. # config.vm.network &quot;public_network&quot; # Share an additional folder to the guest VM. The first argument is # the path on the host to the actual folder. The second argument is # the path on the guest to mount the folder. And the optional third # argument is a set of non-required options. # config.vm.synced_folder &quot;../data&quot;, &quot;/vagrant_data&quot; # Provider-specific configuration so you can fine-tune various # backing providers for Vagrant. These expose provider-specific options. # Example for VirtualBox: # # config.vm.provider &quot;virtualbox&quot; do |vb| # # Display the VirtualBox GUI when booting the machine # vb.gui = true # # # Customize the amount of memory on the VM: # vb.memory = &quot;1024&quot; # end # # View the documentation for the provider you are using for more # information on available options. # Enable provisioning with a shell script. Additional provisioners such as # Puppet, Chef, Ansible, Salt, and Docker are also available. Please see the # documentation for more information about their specific syntax and use. # config.vm.provision &quot;shell&quot;, inline: &lt;&lt;-SHELL # apt-get update # apt-get install -y apache2 # SHELL end 启动虚拟机 mutian@mutian-ThinkPad-T440p:~$ cd dev/vagrant/ymu-dev/ mutian@mutian-ThinkPad-T440p:~/dev/vagrant/ymu-dev$ vagrant up Bringing machine &apos;default&apos; up with &apos;virtualbox&apos; provider... ==&gt; default: Checking if box &apos;centos/7&apos; is up to date... ==&gt; default: Clearing any previously set forwarded ports... ==&gt; default: Clearing any previously set network interfaces... ==&gt; default: Preparing network interfaces based on configuration... default: Adapter 1: nat ==&gt; default: Forwarding ports... default: 22 (guest) =&gt; 2222 (host) (adapter 1) ==&gt; default: Running &apos;pre-boot&apos; VM customizations... ==&gt; default: Booting VM... ==&gt; default: Waiting for machine to boot. This may take a few minutes... default: SSH address: 127.0.0.1:2222 default: SSH username: vagrant default: SSH auth method: private key 打开virtualbox,可以看到centos7_ymu的虚拟机已经启动。 进入该虚拟机 vagrant ssh mutian@mutian-ThinkPad-T440p:~/dev/vagrant/ymu-dev$ vagrant ssh Last login: Mon Jul 9 07:40:01 2018 from 10.0.2.2 [vagrant@ymu ~]$ 下面就可以在里面，类似在真实的服务器操作系统里面一样，安装各种开发软件，配置各种开发环境了。 登出虚拟机 [vagrant@ymu ~]$ logout Connection to 127.0.0.1 closed. mutian@mutian-ThinkPad-T440p:~/dev/vagrant/ymu-dev$ 停止运行虚拟机 mutian@mutian-ThinkPad-T440p:~/dev/vagrant/ymu-dev$ vagrant halt ==&gt; default: Attempting graceful shutdown of VM... 挂起虚拟机 vagrant shutdown 重新加载配置启动 vagrant reload 配置config.vm.box = &quot;centos/7&quot; #和已经下载的box名字一致 config.vm.hostname = &quot;ymu&quot; #config.vm.box_version = &quot;1.1.0&quot; config.vm.box_url = &quot;http://ymu.box&quot; config.vm.synced_folder &quot;/home/mutian/dev/java/github/ymu-micro-service&quot;, &quot;/vagrant&quot;, :ext4 =&gt; true #共享文件夹 配置共享文件注：如果不配置共享目录，默认会把Vagrantfile文件所在的目录同步到虚拟机中的、vagrant目录下。 config.vm.synced_folder &quot;/home/mutian/dev/java/github/ymu-micro-service&quot;, &quot;/vagrant&quot;, :ext4 =&gt; true #共享文件夹 第一个路径为宿主电脑文件夹，第二个为同步的虚拟机文件夹。宿主机文件夹中所有内容将实时同步到虚拟机中文件夹下。 注意文件类型。在ubuntu下查询自己系统文件类型执行命令df -lhT。 登录虚拟机，进入/vagrant,将看到： [vagrant@ymu vagrant]$ ls logs ymu-config-repo ymu-hystrix-dashboard ymu-server-eureka target ymu-config-server ymu-hystrix-turbine ymu-service-basic 看到宿舍机相关目录下的内容同步过来了。 所以，这个时候，你就可以只在宿主机编辑代码，在虚拟机里面编译执行了。 配置网络为自己的box安装各种应用环境docker安装设置自启动：systemctl enable docker.service 参考之前blog。 安装nginx docker运行方式 传统按照方式。 安装redis docker运行方式 https://hub.docker.com/_/redis/ 传统按照方式。 打包分发1.打包，把上面自己定制的box打包。命令： vagrant package --output xxx.box vagrant package --output xxx.box --base 虚拟机名称 2.分发，把打好的包通过优盘等，给其它人用。 3.更新软件 老用户 新用户用最新的打包即可。 实时共享文件的问题通常，默认的，启动虚拟机后或者重新启动虚拟机，会同步Vagrantfile所在目录到虚拟机的目录/vagrant下，但是修改了宿主机的文件，不能实时同步到虚拟机。 下面介绍宿主机通过安装rsync来实时同步宿主机子的文件到虚拟机。 https://www.vagrantup.com/docs/synced-folders/rsync.html window下安装rsync通过安装来cygwin安装rsync。cygwin的网址：https://cygwin.com/install.html。下载安装即可。 安装好后，配置Vagrantfile文件。具体配置查看:https://www.vagrantup.com/docs/synced-folders/rsync.html config.vm.synced_folder &quot;.&quot;, &quot;/vagrant&quot;,type:&quot;rsync&quot; 或 config.vm.synced_folder &quot;.&quot;, &quot;/vagrant&quot;,type:&quot;rsync&quot;,rsync__auto:&quot;true&quot; 启动或者重启vagrant reload,然后执行vagrant rsync-auto. 试试改变宿主机的文件，就实时同步到虚拟机了。只能单向把宿主机的文件同步到虚拟机。 命令说明: type：rsync，关键，指定类型。 rsync__auto：默认是true，如果不配置。如果设置了false，则不实时同步该宿主机目录。 linux系统安装rsyncyun install rsync win7启动powershell版本过低问题F:\\xrlj.github.com\\xrlj-vagrant-dev&gt;vagrant up The version of powershell currently installed on this host is less than the required minimum version. Please upgrade the installed version of powershell to the minimum required version and run the command again. Installed version: 2 Minimum required version: 3 要求powershell版本3以上，所以要升级powershell。 下面是升级powershell到4.0的方法： https://social.technet.microsoft.com/wiki/contents/articles/21016.how-to-install-windows-powershell-4-0.aspx 下载对应版本。win7 sp1下载这个：Windows6.1-KB2819745-x64-MultiPkg.msu 学习资源 http://www.imooc.com/learn/805 https://github.com/apanly/mooc","tags":[{"name":"vagrant-start","slug":"vagrant-start","permalink":"https://xinxiamu.github.io/tags/vagrant-start/"}]},{"title":"rabbitMq实战记录","date":"2018-01-19T04:12:57.000Z","path":"2018/01/19/rabbitmq-action/","text":"rabbitMq使用记录，好记性不如烂…… 避免消息堆积？1） 采用workqueue，多个消费者监听同一队列。 2）接收到消息以后，而是通过线程池，异步消费。 如何避免消息丢失？1） 消费者的ACK机制。可以防止消费者丢失消息。 但是，如果在消费者消费之前，MQ就宕机了，消息就没了？ 2）可以将消息进行持久化。要将消息持久化，前提是：队列、Exchange都持久化","tags":[]},{"title":"redis安装","date":"2018-01-18T12:55:18.000Z","path":"2018/01/18/redis-install/","text":"本文介绍在linux系统下redis的安装使用…… redis在ubuntu系统下的安装一、下载，安装，测试Download, extract and compile Redis with: $ wget http://download.redis.io/releases/redis-3.2.0.tar.gz $ tar xzf redis-3.2.0.tar.gz $ cd redis-3.2.0 $ make The binaries that are now compiled are available in the src directory. Run Redis with: $ src/redis-server You can interact with Redis using the built-in client: $ src/redis-cli redis&gt; set foo bar OK redis&gt; get foo &quot;bar&quot; 二、设置直接使用redis的启动，客户端命令make编译redis后，执行命令 $ cd redis-3.2.0 $ sudo make install src中的目录会被复制到/usr/local/bin，这样直接就可以使用src下的一些执行命令。然后可以直接在命令行下执行这些redis命令： xiaocao@xiaocao-pc:~$ redis-cli 127.0.0.1:6379&gt; get foo &quot;123456&quot; 127.0.0.1:6379&gt; 启动服务：xiaocao@xiaocao-pc:~$ redis-server 三、src目录下执行文件说明：redis-check-aof //AOF文件修复工具redis-cli //Redis命令行客户端，最常用redis-server //Redis服务器，最常用redis-benchmark //Redis性能测试工具redis-check-rdb //redis-sentinel //Sentinel服务器，2.8版本后 四、启动，停止redis服务1、直接启动：make install后执行命令：$ redis-server //默认端口是6379自定义端口启动：执行命令：$ redis-server --port 63802、通过初始化脚本启动redis，使得redis能随系统自动运行（在生产环境服务器更推荐此方法）(1)配置初始化脚本。 a. $ cd ~/java/redis-3.2.0/utils将utils目录下的redis_init_script文件复制一份到/etc/init.d目录中。文件名改为redis_端口号。端口号是redis监听的端口号，客户端连接的端口号。 b.修改（redis_端口号） 脚本第6行的REDISPORT变量的值为同样的端口号。 （2）建立需要的文件夹： /etc/redis //存放Redis的配置文件/var/redis/端口号 //存放Redis的持久化文件 (3)修改配置文件： a、$ cd ~/java/redis-3.2.0 b、将配置文件模板redis.conf复制一份到/etc/redis目录中，以端口号命名，如“6380.conf”。 c、修改参数( 6380.conf )： 参数：daemonize 值： yes 说明：使redis以守护进程模式运行 pidfile /var/run/redis_端口号.pid 设置redis的PID的文件位置 port 端口号 设置redis监听的端口号 dir /var/redis/端口号 设置持久化文件存放位置 d、现在可以使用/etc/init.d/redis_端口号start来启动redis了。 e、执行下面命令使得redis随系统自动启动： $ sudo update-rc.d redis_端口号 defaults //配置随机启动命令 redis_6380为初始化脚本文件 3、正确停止redis服务命令：$ redis-cli SHUTDOWN /默认的 或者$ redis-cli -p 6380 SHUTDOWN当redis收到SHUTDOWN命令后，先断开所有客户端连接，然后根据配置执行持久化，最后完成退出。 4、关闭后再启动：service redis_6380 -p 6380 start #启动6380端口实例的redis $ cd /etc/init.d &amp;&amp; ./redis_6380 start #默认启动6379端口实例的redis centos7下安装redis 下载源码。 编译安装： 编译前需要安装依赖 yum install -y gcc tcl 然后再编译 make -j 4 MALLOC=libc 如果要自动启动：`make install -j 4 MALLOC=libc`","tags":[{"name":"redis-install","slug":"redis-install","permalink":"https://xinxiamu.github.io/tags/redis-install/"}]},{"title":"rabbitmq快速安装","date":"2018-01-02T08:02:01.000Z","path":"2018/01/02/rabbitmq-install/","text":"本文介绍rabbitmq在各系统平台下的安装…… 在Centos下的快速安装一、安装erlangsudo yum install erlang 检查是否安装好： [root@localhost /]# erl Erlang R16B03-1 (erts-5.10.4) [source] [64-bit] [smp:4:4] [async-threads:10] [hipe] [kernel-poll:false] 二、安装rabbitmq （1）下载安装包wget http://www.rabbitmq.com/releases/rabbitmq-server/v3.6.0/rabbitmq-server-3.6.0-1.noarch.rpm （2）安装 &gt; rpm --import https://www.rabbitmq.com/rabbitmq-release-signing-key.asc &gt; yum install rabbitmq-server-3.6.0-1.noarch.rpm （3）启用web管理插件rabbitmq-plugins enable rabbitmq_management 三、启动RabbitMQchkconfig rabbitmq-server on //开机启动设置service rabbitmq-server start 四、打开对应端口 # firewall-cmd --permanent --zone=public --add-port=5672/tcp # firewall-cmd --permanent --zone=public --add-port=15672/tcp # firewall-cmd --reload 五、打开网页http://119.23.78.160:15672/ 在Ubuntu下的快速安装安装最新版，参考网址：http://www.rabbitmq.com/install-debian.html 注：下面安装的不是最新版本。一. 安装对应erlang版本：erlang-nox (&gt;= 1:19.3-1) | esl-erlang (&gt;= 1:19.3-1).sudo apt-get install erlang-nox 二. 安装rabbitMq: $ sudo apt-get update $ sudo apt-get install rabbitmq-server 三. 启用web管理插件： sudo rabbitmq-plugins enable rabbitmq_management 四. 访问打开：http://localhost:15672 五. 登录（本机）：用户：guest密码：guest 注：guest用户是系统用户，默认是不允许远程登录的。如果是在服务器端安装，需要添加用户才能远程登录。 docker安装rabbitMq参考：https://hub.docker.com/_/rabbitmq?tab=description 执行下面命令安装： docker run --hostname myRabbit --restart=always --name my-rabbitmq -v /server/data/rabbitmq:/var/lib/rabbitmq -e RABBITMQ_DEFAULT_USER=ymu -e RABBITMQ_DEFAULT_PASS=123456 -e RABBITMQ_DEFAULT_VHOST=ymu_vhost -p 15672:15672 -p 4369:4369 -p 5671-5672:5671-5672 -p 15671:15671 -p 25672:25672 -d rabbitmq:3-management 安装成功后，在浏览器输入： http://ip:15672，进入控制台。 账号：ymu密码：123456 参数说明： -e 指定环境变量；（RABBITMQ_DEFAULT_VHOST：默认虚拟机名；RABBITMQ_DEFAULT_USER：默认的用户名；RABBITMQ_DEFAULT_PASS：默认用户名的密码） –hostname 主机名（RabbitMQ的一个重要注意事项是它根据所谓的 “节点名称” 存储数据，默认为主机名）； 端口说明： 4369 (epmd), 25672 (Erlang distribution) 5672, 5671 (AMQP 0-9-1 without and with TLS)应用访问端口号 15672 (if management plugin is enabled)控制台端口号 61613, 61614 (if STOMP is enabled) 1883, 8883 (if MQTT is enabled)","tags":[{"name":"rabbitmq-install","slug":"rabbitmq-install","permalink":"https://xinxiamu.github.io/tags/rabbitmq-install/"}]},{"title":"redis配置","date":"2017-12-06T06:13:01.000Z","path":"2017/12/06/redis-conf/","text":"","tags":[{"name":"redis,密码,安全","slug":"redis-密码-安全","permalink":"https://xinxiamu.github.io/tags/redis-密码-安全/"}]},{"title":"idea集成XRebel分析web应用性能","date":"2017-12-04T07:50:14.000Z","path":"2017/12/04/idea-XRebel/","text":"XRebel 是不间断运行在 web 应用的交互式分析器，当发现问题会在浏览器中显示警告信息。XRebel 会实时监测应用代码的性能指标和可能会发生的问题。 XRebel官方简明教程在这里 http://zeroturnaround.com/software/xrebel/quick-start/ 官方下载地址在这里 https://zeroturnaround.com/software/xrebel/download/#!/have-license","tags":[]},{"title":"centos免密码登录","date":"2017-11-30T06:53:47.000Z","path":"2017/11/30/centos-login-without-pwd/","text":"配置免密码登录服务器。不用每次都要输入密码。 环境说明客户机:Mac OS X服务器:CentOS 7客户端:OpenSSH,OS X及大多数Linux都内置了OpenSSH.’ssh -v’命令可以查看版本. 客户机配置 查看~/.ssh文件夹,若已经存在有公钥文件(id_rsa.pub),私钥文件(id_rsa),则可以跳过客户端配置. 生成密钥文件.$ ssh-keygen 然后一路回车.然后~/.ssh下会生成id_rsa.pub和id_rsa, 其中id_rsa文件起到唯一标识你的客户机的作用.注意:不要改这两个文件的文件名,ssh登陆时会读取id_rsa文件. 服务器配置1.修改sshd配置文件(/etc/ssh/sshd_config).找到以下内容，并去掉注释符”#“ RSAAuthentication yes (我新购的机器Centos7.4的，无需配置这句)PubkeyAuthentication yesAuthorizedKeysFile .ssh/authorized_keys 2.配置authorized_keys文件.若’~/.ssh/authorized_keys’不存在,则建立.ssh文件夹和authorized_keys文件.将上文中客户机id_rsa.pub的内容拷贝到authorized_keys中.PS:可以在客户机中执行命令来拷贝: cat ~/.ssh/id_rsa.pub | ssh user@host “cat - &gt;&gt; ~/.ssh/authorized_keys” 注意:1 .ssh目录的权限必须是7002 .ssh/authorized_keys文件权限必须是600 重启ssh： service sshd restart然后客户先先执行：ssh -v user@host (-v 调试模式)会显示一些登陆信息.若登陆失败,或者仍然要输入密码,可以在服务器查看日志文件:/var/log/secure.若登陆成功,则以后就可以用’ssh user@host’ 直接登陆了,不用输入密码. 更简单方式1、执行命令：ssh-keygen -t rsa -C “xx@qq.com“(随便编个字符串，一般用邮箱）2、之后一路回车就行啦；会在～（home）目录下中产生.ssh（隐藏）文件夹；3、里面有两个文件id_rsa(私钥)、id_rsa.pub(公钥)文件 yutao@localhost ~]$ ssh-copy-id yutao@192.168.161.132 #把秘钥拷贝到远程服务器","tags":[{"name":"centos登录","slug":"centos登录","permalink":"https://xinxiamu.github.io/tags/centos登录/"}]},{"title":"jenkins-java-maven持续集成（CentOs7）","date":"2017-11-28T01:15:26.000Z","path":"2017/11/28/jenkins-java-maven/","text":"传统的开发是开发，打包测试，开发，打包测试，且每次都是全量打包。这给运维，测试带来大量没必要的工作量，同时每次全量打包导致系统每次测试不全面，bug不断，测试，开发，运维叫苦连天。因此持续集成开发势在必行。 参考：http://www.jianshu.com/p/a7d7df97fe4b 1. 安装并运行jenkins-war 下载 运行 java -jar jenkins.war --httpPort=8080. 在浏览器访问 http://localhost:8080. 记得开防火墙。 图一： 2. 初次访问配置 按图一红色提示，在服务器对应目录下找到安全密码，拷贝进去登录。 按照页面想到，安装插件，如果不确定要安装什么插件，那就选择推荐的插件按钮即可。 创建管理员账号，按照页面设置即可。 这样，下面就可以开始使用jenkins了。 3. maven，svn,springboot下持续构建java应用 安装maven环境。下载maven 3.1 配置jenkins 点击系统管理。 配置各种环境： maven setting.xml jdk,取消自动安装 maven,取消自动安装 3.2 安装maven插件 点击直接安装即可。 3.3 创建新项目 选定。 点击ok。 3.4 配置项目各种信息 3.5 开始构建项目 查看构建结果 然后再服务器相关目录下就能看到构建后的jar包: 3.6 构建后配置构建成功后，我们需要发布项目到远程服务器，或者执行等一系列动作。 3.6.1 直接执行jar修改项目配置： 添加成功构建后要执行的脚本： 注意脚本写法，如果是后台执行： BUILD_ID=dontKillMe nohup /usr/local/SBA/startup.sh &amp; 3.6.2 发布jar到远程服务器，并执行 下载相关插件： 在系统设置中添加远程服务器： 在项目中设置，选定远程服务器： 注意： 备份，执行远程服务器上的jar包 在远程服务器上设置脚本，放在目录：server/bin： 停止应用脚本stop.sh： # 将应用停止 #stop.sh #!/bin/bash echo &quot;Stopping SpringBoot Application&quot; pid=`ps -ef | grep jenkins-demo*.jar | grep -v grep | awk &apos;{print $2}&apos;` if [ -n &quot;$pid&quot; ] then kill -9 $pid fi 备份应用脚本replace.sh: #replace.sh 用于将上次构建的结果备份，然后将新的构建结果移动到合适的位置 #!/bin/bash # 先判断文件是否存在，如果存在，则备份 file=&quot;/server/java/apps/jenkins-demo.jar&quot; if [ -f &quot;$file&quot; ] then mv /server/java/apps/jenkins-demo.jar /server/java/apps/backup/jenkins-demo.jar.`date +%Y%m%d%H%M%S` fi mv /server/java/apps/jenkins-demo*.jar /server/java/apps/jenkins-demo.jar 启动应用包脚本start.sh: # startup.sh 启动项目 #!/bin/bash echo &quot;授予当前用户权限&quot; chmod 777 /server/java/apps/jenkins-demo.jar echo &quot;执行.....&quot; java -jar /server/java/apps/jenkins-demo.jar 注意：启动脚本如果是放在和jenkins同一个服务器上，后台执行nohub java -jar /server/java/apps/jenkins-demo.jar &amp;不起作用，所在要在jenkins上这样配置BUILD_ID=dontKillMe nohup /usr/local/SBA/startup.sh &amp; 如果是远程服务器，就可以改成： # startup.sh 启动项目 #!/bin/bash echo &quot;授予当前用户权限&quot; chmod 777 /server/java/apps/jenkins-demo.jar echo &quot;执行.....&quot; nohup java -jar /server/java/apps/jenkins-demo.jar &gt; jenkins-demo.out 2&gt;&amp; 1 &amp; 设置远程服务器执行脚本： 如果是jenkins所在服务器执行后台jar，要注意，远程服务器其实可以去掉，在脚本改成后台执行就可以。 备注：1.替换jar包中的文件 jar -uvf rpds.jar BOOT-INF/classes/db.properties 2.启动jar应用程序shell脚本 #!/bin/sh # chkconfig: 2345 64 36 ## java env #################### zhengjianyan ####################### export JAVA_HOME=/server/java/jdk export JRE_HOME=$JAVA_HOME/jre BASE_PATH=/server/java/service/com.xcsqjr.scf.service VERSION=1.0.0 ## service name APP_NAME=all SERVICE_DIR=$BASE_PATH/com.xcsqjr.scf.service.$APP_NAME SERVICE_NAME=com.xcsqjr.scf.service.$APP_NAME-$VERSION #JAR_NAME=$SERVICE_DIR/$SERVICE_NAME/target\\.jar JAR_NAME=$SERVICE_DIR/target/$SERVICE_NAME.jar PID=$SERVICE_NAME\\.pid rm -rf $SERVICE_DIR/target/*.tmp cd $BASE_PATH cd .. $JAVA_HOME/bin/jar uvf $SERVICE_DIR/target/$SERVICE_NAME.jar application.properties cd $SERVICE_DIR case &quot;$1&quot; in start) nohup $JRE_HOME/bin/java -Xms128m -Xmx256m -jar $JAR_NAME &gt;/dev/null 2&gt;&amp;1 &amp; echo $! &gt; $SERVICE_DIR/target/$PID echo &quot;=== start $SERVICE_NAME&quot; ;; stop) kill `cat $SERVICE_DIR/target/$PID` rm -rf $SERVICE_DIR/target/$PID echo &quot;=== stop $SERVICE_NAME&quot; sleep 5 P_ID=`ps -ef | grep -w &quot;$SERVICE_NAME&quot; | grep -v &quot;grep&quot; | awk &apos;{print $2}&apos;` if [ &quot;$P_ID&quot; == &quot;&quot; ]; then echo &quot;=== $SERVICE_NAME process not exists or stop success&quot; else echo &quot;=== $SERVICE_NAME process pid is:$P_ID&quot; echo &quot;=== begin kill $SERVICE_NAME process, pid is:$P_ID&quot; kill -9 $P_ID fi ;; restart) $0 stop sleep 2 $0 start echo &quot;=== restart $SERVICE_NAME&quot; ;; *) echo &quot;==== restart =====&quot; ## restart $0 stop sleep 5 $0 start ;; esac exit 0","tags":[{"name":"jenkins-java-maven","slug":"jenkins-java-maven","permalink":"https://xinxiamu.github.io/tags/jenkins-java-maven/"}]},{"title":"mysql性能优化神器explain","date":"2017-11-21T05:36:04.000Z","path":"2017/11/21/mysql-explain/","text":"MySQL 性能优化神器 Explain 使用分析 mysql mysql优化 永顺 1月16日发布赞 | 6收藏 | 503.2k 次浏览简介MySQL 提供了一个 EXPLAIN 命令, 它可以对 SELECT 语句进行分析, 并输出 SELECT 执行的详细信息, 以供开发人员针对性优化.EXPLAIN 命令用法十分简单, 在 SELECT 语句前加上 Explain 就可以了, 例如: EXPLAIN SELECT * from user_info WHERE id &lt; 300;准备为了接下来方便演示 EXPLAIN 的使用, 首先我们需要建立两个测试用的表, 并添加相应的数据: CREATE TABLE `user_info` ( `id` BIGINT(20) NOT NULL AUTO_INCREMENT, `name` VARCHAR(50) NOT NULL DEFAULT &apos;&apos;, `age` INT(11) DEFAULT NULL, PRIMARY KEY (`id`), KEY `name_index` (`name`) ) ENGINE = InnoDB DEFAULT CHARSET = utf8 INSERT INTO user_info (name, age) VALUES (&apos;xys&apos;, 20); INSERT INTO user_info (name, age) VALUES (&apos;a&apos;, 21); INSERT INTO user_info (name, age) VALUES (&apos;b&apos;, 23); INSERT INTO user_info (name, age) VALUES (&apos;c&apos;, 50); INSERT INTO user_info (name, age) VALUES (&apos;d&apos;, 15); INSERT INTO user_info (name, age) VALUES (&apos;e&apos;, 20); INSERT INTO user_info (name, age) VALUES (&apos;f&apos;, 21); INSERT INTO user_info (name, age) VALUES (&apos;g&apos;, 23); INSERT INTO user_info (name, age) VALUES (&apos;h&apos;, 50); INSERT INTO user_info (name, age) VALUES (&apos;i&apos;, 15); CREATE TABLE `order_info` ( `id` BIGINT(20) NOT NULL AUTO_INCREMENT, `user_id` BIGINT(20) DEFAULT NULL, `product_name` VARCHAR(50) NOT NULL DEFAULT &apos;&apos;, `productor` VARCHAR(30) DEFAULT NULL, PRIMARY KEY (`id`), KEY `user_product_detail_index` (`user_id`, `product_name`, `productor`) ) ENGINE = InnoDB DEFAULT CHARSET = utf8 INSERT INTO order_info (user_id, product_name, productor) VALUES (1, &apos;p1&apos;, &apos;WHH&apos;); INSERT INTO order_info (user_id, product_name, productor) VALUES (1, &apos;p2&apos;, &apos;WL&apos;); INSERT INTO order_info (user_id, product_name, productor) VALUES (1, &apos;p1&apos;, &apos;DX&apos;); INSERT INTO order_info (user_id, product_name, productor) VALUES (2, &apos;p1&apos;, &apos;WHH&apos;); INSERT INTO order_info (user_id, product_name, productor) VALUES (2, &apos;p5&apos;, &apos;WL&apos;); INSERT INTO order_info (user_id, product_name, productor) VALUES (3, &apos;p3&apos;, &apos;MA&apos;); INSERT INTO order_info (user_id, product_name, productor) VALUES (4, &apos;p1&apos;, &apos;WHH&apos;); INSERT INTO order_info (user_id, product_name, productor) VALUES (6, &apos;p1&apos;, &apos;WHH&apos;); INSERT INTO order_info (user_id, product_name, productor) VALUES (9, &apos;p8&apos;, &apos;TE&apos;); EXPLAIN 输出格式EXPLAIN 命令的输出内容大致如下: mysql&gt; explain select * from user_info where id = 2\\G *************************** 1. row *************************** id: 1 select_type: SIMPLE table: user_info partitions: NULL type: const possible_keys: PRIMARY key: PRIMARY key_len: 8 ref: const rows: 1 filtered: 100.00 Extra: NULL 1 row in set, 1 warning (0.00 sec) 各列的含义如下: id: SELECT 查询的标识符. 每个 SELECT 都会自动分配一个唯一的标识符. select_type: SELECT 查询的类型. table: 查询的是哪个表 partitions: 匹配的分区 type: join 类型 possible_keys: 此次查询中可能选用的索引 key: 此次查询中确切使用到的索引. ref: 哪个字段或常数与 key 一起被使用 rows: 显示此查询一共扫描了多少行. 这个是一个估计值. filtered: 表示此查询条件所过滤的数据的百分比 extra: 额外的信息接下来我们来重点看一下比较重要的几个字段. select_typeselect_type 表示了查询的类型, 它的常用取值有: SIMPLE, 表示此查询不包含 UNION 查询或子查询PRIMARY, 表示此查询是最外层的查询UNION, 表示此查询是 UNION 的第二或随后的查询DEPENDENT UNION, UNION 中的第二个或后面的查询语句, 取决于外面的查询UNION RESULT, UNION 的结果SUBQUERY, 子查询中的第一个 SELECTDEPENDENT SUBQUERY: 子查询中的第一个 SELECT, 取决于外面的查询. 即子查询依赖于外层查询的结果.最常见的查询类别应该是 SIMPLE 了, 比如当我们的查询没有子查询, 也没有 UNION 查询时, 那么通常就是 SIMPLE 类型, 例如: mysql&gt; explain select * from user_info where id = 2\\G *************************** 1. row *************************** id: 1 select_type: SIMPLE table: user_info partitions: NULL type: const possible_keys: PRIMARY key: PRIMARY key_len: 8 ref: const rows: 1 filtered: 100.00 Extra: NULL 1 row in set, 1 warning (0.00 sec) 如果我们使用了 UNION 查询, 那么 EXPLAIN 输出 的结果类似如下: mysql&gt; EXPLAIN (SELECT * FROM user_info WHERE id IN (1, 2, 3)) -&gt; UNION -&gt; (SELECT * FROM user_info WHERE id IN (3, 4, 5)); +----+--------------+------------+------------+-------+---------------+---------+---------+------+------+----------+-----------------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+--------------+------------+------------+-------+---------------+---------+---------+------+------+----------+-----------------+ | 1 | PRIMARY | user_info | NULL | range | PRIMARY | PRIMARY | 8 | NULL | 3 | 100.00 | Using where | | 2 | UNION | user_info | NULL | range | PRIMARY | PRIMARY | 8 | NULL | 3 | 100.00 | Using where | | NULL | UNION RESULT | &lt;union1,2&gt; | NULL | ALL | NULL | NULL | NULL | NULL | NULL | NULL | Using temporary | +----+--------------+------------+------------+-------+---------------+---------+---------+------+------+----------+-----------------+ 3 rows in set, 1 warning (0.00 sec) table 表示查询涉及的表或衍生表 typetype 字段比较重要, 它提供了判断查询是否高效的重要依据依据. 通过 type 字段, 我们判断此次查询是 全表扫描 还是 索引扫描 等.type 常用类型type 常用的取值有:system: 表中只有一条数据. 这个类型是特殊的 const 类型.const: 针对主键或唯一索引的等值查询扫描, 最多只返回一行数据. const 查询速度非常快, 因为它仅仅读取一次即可.例如下面的这个查询, 它使用了主键索引, 因此 type 就是 const 类型的. mysql&gt; explain select from user_info where id = 2\\G ** 1. row *** id: 1 select_type: SIMPLE table: user_info partitions: NULL type: const possible_keys: PRIMARY key: PRIMARY key_len: 8 ref: const rows: 1 filtered: 100.00 Extra: NULL 1 row in set, 1 warning (0.00 sec) eq_ref: 此类型通常出现在多表的 join 查询, 表示对于前表的每一个结果, 都只能匹配到后表的一行结果. 并且查询的比较操作通常是 =, 查询效率较高. 例如: mysql&gt; EXPLAIN SELECT * FROM user_info, order_info WHERE user_info.id = order_info.user_id\\G *************************** 1. row *************************** id: 1 select_type: SIMPLE table: order_info partitions: NULL type: index possible_keys: user_product_detail_index key: user_product_detail_index key_len: 314 ref: NULL rows: 9 filtered: 100.00 Extra: Using where; Using index *************************** 2. row *************************** id: 1 select_type: SIMPLE table: user_info partitions: NULL type: eq_ref possible_keys: PRIMARY key: PRIMARY key_len: 8 ref: test.order_info.user_id rows: 1 filtered: 100.00 Extra: NULL 2 rows in set, 1 warning (0.00 sec) ref: 此类型通常出现在多表的 join 查询, 针对于非唯一或非主键索引, 或者是使用了 最左前缀 规则索引的查询.例如下面这个例子中, 就使用到了 ref 类型的查询: mysql&gt; EXPLAIN SELECT * FROM user_info, order_info WHERE user_info.id = order_info.user_id AND order_info.user_id = 5\\G *************************** 1. row *************************** id: 1 select_type: SIMPLE table: user_info partitions: NULL type: const possible_keys: PRIMARY key: PRIMARY key_len: 8 ref: const rows: 1 filtered: 100.00 Extra: NULL *************************** 2. row *************************** id: 1 select_type: SIMPLE table: order_info partitions: NULL type: ref possible_keys: user_product_detail_index key: user_product_detail_index key_len: 9 ref: const rows: 1 filtered: 100.00 Extra: Using index 2 rows in set, 1 warning (0.01 sec) range: 表示使用索引范围查询, 通过索引字段范围获取表中部分数据记录. 这个类型通常出现在 =, &lt;&gt;, &gt;, &gt;=, &lt;, &lt;=, IS NULL, &lt;=&gt;, BETWEEN, IN() 操作中.当 type 是 range 时, 那么 EXPLAIN 输出的 ref 字段为 NULL, 并且 key_len 字段是此次查询中使用到的索引的最长的那个.例如下面的例子就是一个范围查询: mysql&gt; EXPLAIN SELECT * -&gt; FROM user_info -&gt; WHERE id BETWEEN 2 AND 8 \\G *************************** 1. row *************************** id: 1 select_type: SIMPLE table: user_info partitions: NULL type: range possible_keys: PRIMARY key: PRIMARY key_len: 8 ref: NULL rows: 7 filtered: 100.00 Extra: Using where 1 row in set, 1 warning (0.00 sec) index: 表示全索引扫描(full index scan), 和 ALL 类型类似, 只不过 ALL 类型是全表扫描, 而 index 类型则仅仅扫描所有的索引, 而不扫描数据.index 类型通常出现在: 所要查询的数据直接在索引树中就可以获取到, 而不需要扫描数据. 当是这种情况时, Extra 字段 会显示 Using index.例如: mysql&gt; EXPLAIN SELECT name FROM user_info \\G *************************** 1. row *************************** id: 1 select_type: SIMPLE table: user_info partitions: NULL type: index possible_keys: NULL key: name_index key_len: 152 ref: NULL rows: 10 filtered: 100.00 Extra: Using index 1 row in set, 1 warning (0.00 sec) 上面的例子中, 我们查询的 name 字段恰好是一个索引, 因此我们直接从索引中获取数据就可以满足查询的需求了, 而不需要查询表中的数据. 因此这样的情况下, type 的值是 index, 并且 Extra 的值是 Using index. ALL: 表示全表扫描, 这个类型的查询是性能最差的查询之一. 通常来说, 我们的查询不应该出现 ALL 类型的查询, 因为这样的查询在数据量大的情况下, 对数据库的性能是巨大的灾难. 如一个查询是 ALL 类型查询, 那么一般来说可以对相应的字段添加索引来避免.下面是一个全表扫描的例子, 可以看到, 在全表扫描时, possible_keys 和 key 字段都是 NULL, 表示没有使用到索引, 并且 rows 十分巨大, 因此整个查询效率是十分低下的. mysql&gt; EXPLAIN SELECT age FROM user_info WHERE age = 20 \\G *************************** 1. row *************************** id: 1 select_type: SIMPLE table: user_info partitions: NULL type: ALL possible_keys: NULL key: NULL key_len: NULL ref: NULL rows: 10 filtered: 10.00 Extra: Using where 1 row in set, 1 warning (0.00 sec) type 类型的性能比较通常来说, 不同的 type 类型的性能关系如下:ALL &lt; index &lt; range ~ index_merge &lt; ref &lt; eq_ref &lt; const &lt; systemALL 类型因为是全表扫描, 因此在相同的查询条件下, 它是速度最慢的.而 index 类型的查询虽然不是全表扫描, 但是它扫描了所有的索引, 因此比 ALL 类型的稍快.后面的几种类型都是利用了索引来查询数据, 因此可以过滤部分或大部分数据, 因此查询效率就比较高了.possible_keyspossible_keys 表示 MySQL 在查询时, 能够使用到的索引. 注意, 即使有些索引在 possible_keys 中出现, 但是并不表示此索引会真正地被 MySQL 使用到. MySQL 在查询时具体使用了哪些索引, 由 key 字段决定.key此字段是 MySQL 在当前查询时所真正使用到的索引.key_len表示查询优化器使用了索引的字节数. 这个字段可以评估组合索引是否完全被使用, 或只有最左部分字段被使用到.key_len 的计算规则如下:字符串char(n): n 字节长度varchar(n): 如果是 utf8 编码, 则是 3 n + 2字节; 如果是 utf8mb4 编码, 则是 4 n + 2 字节.数值类型:TINYINT: 1字节SMALLINT: 2字节MEDIUMINT: 3字节INT: 4字节BIGINT: 8字节时间类型DATE: 3字节TIMESTAMP: 4字节DATETIME: 8字节字段属性: NULL 属性 占用一个字节. 如果一个字段是 NOT NULL 的, 则没有此属性.我们来举两个简单的栗子: mysql&gt; EXPLAIN SELECT * FROM order_info WHERE user_id &lt; 3 AND product_name = &apos;p1&apos; AND productor = &apos;WHH&apos; \\G *************************** 1. row *************************** id: 1 select_type: SIMPLE table: order_info partitions: NULL type: range possible_keys: user_product_detail_index key: user_product_detail_index key_len: 9 ref: NULL rows: 5 filtered: 11.11 Extra: Using where; Using index 1 row in set, 1 warning (0.00 sec) 上面的例子是从表 order_info 中查询指定的内容, 而我们从此表的建表语句中可以知道, 表 order_info 有一个联合索引: KEYuser_product_detail_index(user_id,product_name,productor)不过此查询语句 WHERE user_id &lt; 3 AND product_name = ‘p1’ AND productor = ‘WHH’ 中, 因为先进行 user_id 的范围查询, 而根据 最左前缀匹配 原则, 当遇到范围查询时, 就停止索引的匹配, 因此实际上我们使用到的索引的字段只有 user_id, 因此在 EXPLAIN 中, 显示的 key_len 为 9. 因为 user_id 字段是 BIGINT, 占用 8 字节, 而 NULL 属性占用一个字节, 因此总共是 9 个字节. 若我们将user_id 字段改为 BIGINT(20) NOT NULL DEFAULT ‘0’, 则 key_length 应该是8. 上面因为 最左前缀匹配 原则, 我们的查询仅仅使用到了联合索引的 user_id 字段, 因此效率不算高. 接下来我们来看一下下一个例子: mysql&gt; EXPLAIN SELECT * FROM order_info WHERE user_id = 1 AND product_name = &apos;p1&apos; \\G; *************************** 1. row *************************** id: 1 select_type: SIMPLE table: order_info partitions: NULL type: ref possible_keys: user_product_detail_index key: user_product_detail_index key_len: 161 ref: const,const rows: 2 filtered: 100.00 Extra: Using index 1 row in set, 1 warning (0.00 sec) 这次的查询中, 我们没有使用到范围查询, key_len 的值为 161. 为什么呢? 因为我们的查询条件 WHERE user_id = 1 AND product_name = ‘p1’ 中, 仅仅使用到了联合索引中的前两个字段, 因此 keyLen(user_id) + keyLen(product_name) = 9 + 50 * 3 + 2 = 161 rowsrows 也是一个重要的字段. MySQL 查询优化器根据统计信息, 估算 SQL 要查找到结果集需要扫描读取的数据行数.这个值非常直观显示 SQL 的效率好坏, 原则上 rows 越少越好. ExtraEXplain 中的很多额外的信息会在 Extra 字段显示, 常见的有以下几种内容: Using filesort当 Extra 中有 Using filesort 时, 表示 MySQL 需额外的排序操作, 不能通过索引顺序达到排序效果. 一般有 Using filesort, 都建议优化去掉, 因为这样的查询 CPU 资源消耗大.例如下面的例子: mysql&gt; EXPLAIN SELECT * FROM order_info ORDER BY product_name \\G *************************** 1. row *************************** id: 1 select_type: SIMPLE table: order_info partitions: NULL type: index possible_keys: NULL key: user_product_detail_index key_len: 253 ref: NULL rows: 9 filtered: 100.00 Extra: Using index; Using filesort 1 row in set, 1 warning (0.00 sec) 我们的索引是 KEYuser_product_detail_index(user_id,product_name,productor)但是上面的查询中根据 product_name 来排序, 因此不能使用索引进行优化, 进而会产生 Using filesort.如果我们将排序依据改为 ORDER BY user_id, product_name, 那么就不会出现 Using filesort 了. 例如: mysql&gt; EXPLAIN SELECT * FROM order_info ORDER BY user_id, product_name \\G *************************** 1. row *************************** id: 1 select_type: SIMPLE table: order_info partitions: NULL type: index possible_keys: NULL key: user_product_detail_index key_len: 253 ref: NULL rows: 9 filtered: 100.00 Extra: Using index 1 row in set, 1 warning (0.00 sec) Using index“覆盖索引扫描”, 表示查询在索引树中就可查找所需数据, 不用扫描表数据文件, 往往说明性能不错 Using temporary查询有使用临时表, 一般出现于排序, 分组和多表 join 的情况, 查询效率不高, 建议优化.","tags":[{"name":"mysql-expain","slug":"mysql-expain","permalink":"https://xinxiamu.github.io/tags/mysql-expain/"}]},{"title":"mysql建表规范","date":"2017-11-20T05:51:19.000Z","path":"2017/11/20/mysql-create/","text":"在关系数据库中，良好的表结构设计有助于性能的提高，对后续的优化作用也极大。同时对后续的优化也意义重大。因此，在表设计阶段，必须要遵循一些规范。下面介绍在mysql中设计表的一些注意问题： 1. 选择优化的数据类型原则： 更小的通常更好更小的数据类型代表着占用更小的磁盘空间、内存和cpu，处理时需要的cpu时间也更小。但是一定要确定其可能的长度，不要低估这一点。否则到了后面需要添加长度，将会变得很麻烦。 简单就好简单的数据类型需要更小的cpu操作周期。比如整型比字符串操作代价更小，因为字符集和校对规则（排序）使得字符串比整型更加复杂。 尽量避免NULL通常情况下，应该设置成NOT NULL，给出默认值，除非真的需要存储NULL。可为NULL的列需要更多的存储空间，在NULL的列上添加索引也非常麻烦，因为，有可能建立索引的列最好设置成NOT NULL。通常，把NULL的列改成NOT NULL 对性能提升很小，所以调优时没必要这么做，除非真的是因为NULL引起。但记住，在计划添加索引的列上，尽量避免设计成可NULL。 1.1 整数类型整数类型：TINYINT、SMALLINT、MEDIUMINT、INT、BIGINT,分别对应8,16,14,32,64位存储空间。值的范围-2的N-1次方到2的N-1次方。整数有可选的UNSIGNED属性，表示非负值，选择该属性，可以使整数的上限提高一倍。有符号和无符号使用相同的存储空间，具有相同的性能，根据需要选择。整数计算通常使用64位的BIGINT。 1.2 实数类型实数是带有小数部分的数字。通常有：DECIMAL,DOUBLE,FLOAT。DOUBLE占用8位，FLOAT占用4位。两者用来做浮点近似计算。在做高精度计算时，使用DECIMAL，比如财务计算。 1.3 字符串类型VARCHAR 可变长，指定合适的分配长度更好。越短代表性能越好。CHAR 不可变长。少用。BINARY,VARBINARY类似上面两种，但是存储的是二进制。单确定不需要字符串比较时，存储为二进制更好，性能更高。BLOB 存储很大的数据量的字符串类型，二进制存储。TEXT 大文本。字符存储。 使用枚举代替字符串可以存储枚举对应整型或者字符串…… 1.4 日期和时间类型","tags":[{"name":"mysql建表规范","slug":"mysql建表规范","permalink":"https://xinxiamu.github.io/tags/mysql建表规范/"}]},{"title":"centos7安装docker-ce","date":"2017-11-15T05:55:39.000Z","path":"2017/11/15/docker-install-centos7/","text":"本文介绍docker在centos7系统上的安装。参考：https://docs.docker.com/engine/installation/linux/docker-ce/centos/#uninstall-old-versions参考中文：http://docs.docker-cn.com/engine/installation/linux/docker-ce/centos/#%E4%BD%BF%E7%94%A8%E9%95%9C%E5%83%8F%E4%BB%93%E5%BA%93%E8%BF%9B%E8%A1%8C%E5%AE%89%E8%A3%85 1. 卸载旧版本docker$ sudo yum remove docker \\ docker-client \\ docker-client-latest \\ docker-common \\ docker-latest \\ docker-latest-logrotate \\ docker-logrotate \\ docker-engine [root@iZj6ca50pk1lwxqo14jss8Z ~]# sudo yum remove docker \\ &gt; docker-common \\ &gt; docker-selinux \\ &gt; docker-engine Loaded plugins: fastestmirror No Match for argument: docker No Match for argument: docker-common No Match for argument: docker-selinux No Match for argument: docker-engine No Packages marked for removal --- 表明没有旧版本 旧版本的会安装在/var/lib/docker/，包括images，images, containers, volumes, 和 networks。docker ce现在命名为docker-ce。 2. 安装docker-ce共有三种方式安装,根据自己喜欢方式选择一种安装： 配置安装源，从安装源拉取安装。推荐，但是网络要好 下载安装包，执行安装。网络不好，采用。 下载脚本执行安装。开发环境这种方式方便。 2.1 repository方式安装，推荐第一次安装，需要先安装Docker repository,然后就可以从repository安装docker或者更新docker。 安装依赖包 $ sudo yum install -y yum-utils \\ device-mapper-persistent-data \\ lvm2 安装源 $ sudo yum-config-manager \\ --add-repo \\ https://download.docker.com/linux/centos/docker-ce.repo 可选: 开启edge和test源 $ sudo yum-config-manager --enable docker-ce-edge $ sudo yum-config-manager --enable docker-ce-test ----- 关闭： $ sudo yum-config-manager --disable docker-ce-edge 安装docker 4.1 安装最新版本 $ sudo yum install docker-ce docker-ce-cli containerd.io Warning: If you have multiple Docker repositories enabled, installing or updating without specifying a version in the yum install or yum update command will always install the highest possible version, which may not be appropriate for your stability needs.安装报错： 查看下面收集安装异常信息。 4.2 安装指定版本在生成环境，有时候要安装指定版本。 查看所有可用版本 $ yum list docker-ce --showduplicates | sort -r docker-ce.x86_64 17.09.ce-1.el7.centos docker-ce-stable 第二列是版本号。The contents of the list depend upon which repositories are enabled, and will be specific to your version of CentOS (indicated by the .el7 suffix on the version, in this example). Choose a specific version to install. The second column is the version string. You can use the entire version string, but you need to include at least to the first hyphen. The third column is the repository name, which indicates which repository the package is from and by extension its stability level. To install a specific version, append the version string to the package name and separate them by a hyphen (-). Note: The version string is the package name plus the version up to the first hyphen. In the example above, the fully qualified package name is docker-ce-17.06.1.ce. $ sudo yum install docker-ce-&lt;VERSION&gt; 如： sudo yum install docker-ce- 17.09.ce-1.el7.centos 4.3 启动docker $ sudo systemctl start docker 4.4 验证是否安装成功 $ sudo docker run hello-world 会下载docker镜像，然后执行，打印信息。 4.5 更新docker根据上面安装过程，重新安装即可。 2.2 安装包方式（更喜欢方式）如果无法使用安装源方式（网络不通），那就可以采用安装包方式。但是每次更新都要下载最新包。 下载安装包： 打开网址 https://download.docker.com/linux/centos/7/x86_64/stable/Packages/，下载.rpm合适版本下载。 Note: To install an edge package, change the word stable in the above URL to edge. Learn about stable and edge channels. 安装docker指向包所在路径，如果是更新，把install改成update $ sudo yum install /path/to/package.rpm 启动docker $ sudo systemctl start docker 验证是否安装成功 $ sudo docker run hello-world 看到红色标注部分说明安装成功。 更新docker-ce下载新的安装包，用yum -y upgrade替换yum -y install,指向新的安装包。 3. 卸载docker-ce 卸载docker安装包： script1yum list installed | grep docker 本机安装过旧版本docker.x86_64,docker-client.x86_64,docker-common.x86_64 全部删除安装的软件包 script123yum -y remove docker.x86_64 yum -y remove docker-client.x86_64 yum -y remove docker-common.x86_64 最新版本，一般script1sudo yum remove docker-ce docker-ce-cli containerd.io 卸载docker安装包不会自动删除相关资源，要手动删除： script1$ sudo rm -rf /var/lib/docker 安装异常问题1.安装docker遇到：package docker-ce-3:19.03.8-3.el7.x86_64 requires containerd.io &gt;= 1.2.2-3, but none of the providers can be installed 执行 yum install docker-ce docker-ce-cli containerd.io 提示： 错误问题: package docker-ce-3:19.03.8-3.el7.x86_64 requires containerd.io &gt;= 1.2.2-3, but none of the providers can be installed 解决方法：进入阿里云镜像地址：https://mirrors.aliyun.com/docker-ce/linux/centos/7/x86_64/edge/Packages/找到你想要的或者最新的containerd.io包，拼接在阿里云地址后面，如下：script1yum install -y https://mirrors.aliyun.com/docker-ce/linux/centos/7/x86_64/edge/Packages/containerd.io-1.2.13-3.1.el7.x86_64.rpm 然后再执行 yum install docker-ce docker-ce-cli containerd.io 即可。","tags":[{"name":"centos-docker-install","slug":"centos-docker-install","permalink":"https://xinxiamu.github.io/tags/centos-docker-install/"}]},{"title":"springboot跨域请求解决","date":"2017-11-15T01:43:12.000Z","path":"2017/11/15/spring-boot-cors/","text":"先推荐三篇文章跨域资源共享 CORS 详解同源策略和跨域访问详解js跨域问题springboot前后端分离跨域 什么是跨域要想了解跨域，就先要知道什么是同源策略。 同源策略，它是由Netscape提出的一个著名的安全策略。 同源策略（Same origin policy）是一种约定，它是浏览器最核心也最基本的安全功能，如果缺少了同源策略，则浏览器的正常功能可能都会受到影响。可以说Web是构建在同源策略基础之上的，浏览器只是针对同源策略的一种实现。 域：协议+地址(域名或IP)+端口 为什么要有同源策略可以简单的理解为：同源策略是一个安全策略，浏览器只是对同源策略的一种实现。它限制着只有同源的脚本(Javascript)才能调用该源的接口，以保护服务器资源或数据。 为什么要有跨域最常见的：多个系统前端需要调用另外系统的接口；前后端分开部署。 如何解决跨域JSONP 只能实现GET请求，但是被一些老浏览器支持。 代理 在服务器端处理其他源资源请求访问，使得浏览器端无跨域问题。 CORS 2014年1月16日，W3C的Web应用工作组（Web Applications Working Group）和Web应用安全工作组（Web AppSec）联合发布了跨源资源共享（Cross-Origin Resource Sharing）的W3C正式推荐标准（W3C Recommendation）。该标准定义了在必须访问跨域资源时，浏览器与服务端应该如何沟通，它提供一种机制，允许客户端（如浏览器）对非源站点的资源发出访问请求。所有提供跨源资源请求的API都可以使用本规范中定义的算法。 出于安全性的考虑，用户代理（如浏览器）通常拒绝跨站的访问请求，但这会限制运行在用户代理的Web应用通过Ajax或者其他机制从另一个站点访问资源、获取数据。跨源资源共享（CORS）扩充了这个模型，通过使用自定义的HTTP响应头部（HTTP Response Header），通知浏览器资源可能被哪些跨源站点以何种HTTP方法获得。例如，浏览器在访问 http://example.com 站点的Web应用时，Web应用如果需要跨站访问另一站点的资源 http://hello-world.example，就需要使用该标准。http://hello-world.example 在HTTP的响应头部中定义 Access-Control-Allow-Origin: http://example.org，通知浏览器允许 http://example.org 跨源从 http://hello-world.example上获取资源。 springboot跨域设置全局跨域 方法一： @Configuration public class WebConfig extends WebMvcConfigurationSupport { /** * 全局跨域设置 * * @param registry */ @Override protected void addCorsMappings(CorsRegistry registry) { registry.addMapping(&quot;/**&quot;) //放行哪些原始域 .allowedOrigins(&quot;*&quot;) //是否发送Cookie信息 .allowCredentials(true) //放行哪些原始域(请求方式) .allowedMethods(&quot;GET&quot;, &quot;POST&quot;, &quot;PUT&quot;, &quot;DELETE&quot;) //放行哪些原始域(头部信息) .allowedHeaders(&quot;*&quot;); // //暴露哪些头部信息（因为跨域访问默认不能获取全部头部信息） // .exposedHeaders(&quot;Header1&quot;, &quot;Header2&quot;); } } 局部跨域","tags":[{"name":"spring-cors","slug":"spring-cors","permalink":"https://xinxiamu.github.io/tags/spring-cors/"}]},{"title":"centos7下搭建maven私仓Nexus","date":"2017-11-12T06:47:38.000Z","path":"2017/11/12/centos-maven-nexus/","text":"项目组件化，共用jar包，统一获取墙外jar包…… 官方文档 sonatype 安装jdk参考其他文章…… 下载Nexus Repository OSS 下载地址：http://www.sonatype.com/download-oss-sonatype [root@iZj6ca50pk1lwxqo14jss8Z nexus]# axel -n 10 https://sonatype-download.global.ssl.fastly.net/nexus/3/nexus-3.6.0-02-unix.tar.gz 解压： [root@iZj6ca50pk1lwxqo14jss8Z nexus]# tar -zxvf nexus-3.6.0-02-unix.tar.gz 启动[root@iZj6ca50pk1lwxqo14jss8Z nexus]# cd nexus-3.6.0-02/bin/ [root@iZj6ca50pk1lwxqo14jss8Z bin]# ./nexus run 如果启动成功，可以看到： Started Sonatype Nexus OSS 3.6.0-02 防火墙开启8081端口。注意还要在阿里云控制后台安全组开启端口。 在浏览器访问：http://47.52.236.72:8081/可以看到： 配置为Linux Service 编辑bin/nexus.rc： [root@iZj6ca50pk1lwxqo14jss8Z ~]# vim /server/java/nexus/nexus-3.6.0-02/bin/nexus.rc 添加： run_as_user=”root” 在/etc/init.d放nexus软连接 ln -s /server/java/nexus/nexus-3.6.0-02/bin/nexus /etc/init.d/nexus 设置服务随系统自启命令：chkconfig [root@iZj6ca50pk1lwxqo14jss8Z ~]# cd /etc/init.d/ [root@iZj6ca50pk1lwxqo14jss8Z init.d]# chkconfig nexus on 启动 [root@iZj6ca50pk1lwxqo14jss8Z ~]# service nexus start WARNING: ************************************************************ WARNING: Detected execution as &quot;root&quot; user. This is NOT recommended! WARNING: ************************************************************ Starting nexus 界面操作1. 登录 默认账号密码：username: adminpwd: admin123 2. 修改admin密码 点击More 创建maven仓库 简单介绍下几种repository的类型: hosted，本地仓库，通常我们会部署自己的构件到这一类型的仓库。比如公司的第二方库。 proxy，代理仓库，它们被用来代理远程的公共仓库，如maven中央仓库。 group，仓库组，用来合并多个hosted/proxy仓库，当你的项目希望在多个repository使用资源时就不需要多次引用了，只需要引用一个group即可。 这里我们选择创建本地仓库： 填写内容： version policy，可以选Release或Snapshot，如果仓库开放给所有人，那选Release比较好，如果公司内部或自己用，其中一个就可以。 创建成功： 添加到maven-public仓库组： 查看仓库如果上传了项目，在Nexus用户界面，选择components -&gt; xiaoming-host","tags":[]},{"title":"centos7下jdk8安装","date":"2017-11-12T06:32:34.000Z","path":"2017/11/12/centos-jdk8-install/","text":"1、下载jdk(在官网找)如果还没安装axel，先安装axel：&gt; yum -y install axel &gt; axel -n 10 http://download.oracle.com/otn-pub/java/jdk/8u131-b11/d54c1d3a095b4ff2b6607d096fa80163/jdk-8u131-linux-x64.tar.gz?AuthParam=1500085329_9680fa6b22ed9ee487ee7730707b5039 2、新建安装目录 &gt; mkdir /usr/lib/jvm 3、解压jdk到安装目录下 &gt; tar xf jdk-8u131-linux-x64.tar.gz &gt; cd /usr/lib/jvm &gt; mv /server/tools/jdk1.8.0_131/ /usr/lib/jvm/ &gt; mv jdk1.8.0_131/ jdk8 #更改名字 4、配置环境变量 &gt; vim /etc/profile 键盘按a键进入编辑模式，在末尾添加： #jdkexport JAVA_HOME=/usr/lib/jvm/jdk8export JRE_HOME=${JAVA_HOME}/jreexport CLASSPATH=.:${JAVA_HOME}/lib:${JRE_HOME}/libexport PATH=${JAVA_HOME}/bin:$PATH 按Esc退出编辑模式按Shift+:,然后输入wq保存退出。 5、使环境变量生效 &gt; source /etc/profile 6、验证安装是否成功 &gt; java -version 如果安装成功会看到： java version &quot;1.8.0_131&quot; Java(TM) SE Runtime Environment (build 1.8.0_131-b11) Java HotSpot(TM) 64-Bit Server VM (build 25.131-b11, mixed mode)","tags":[{"name":"centos-jdk8-install","slug":"centos-jdk8-install","permalink":"https://xinxiamu.github.io/tags/centos-jdk8-install/"}]},{"title":"shadowsocks-go代理服务器搭建","date":"2017-11-11T09:05:31.000Z","path":"2017/11/11/shadowsocks-go/","text":"这是用来干嘛的，你懂的。 网址： shadowsocks sadowsocks-go 服务端编译好执行文件：Shadowsocks-server放到服务器，更改.json文件配置，解压直接执行.sh文件即可。 首先，买个国外的服务器再说吧…… 在服务器安装golang环境。 安装包：go1.9.2 这里不做介绍…… 在服务器安装git环境。 这里不做介绍…… 下载服务端代码shadowsocks-go. # on server go get github.com/shadowsocks/shadowsocks-go/cmd/shadowsocks-server golang环境会自动编译可执行代码到${GOPATH}/bin 执行启动 创建配置文件：touch /server/shadowsocks/shadowsocks.json 编辑shadowsocks.json： { &quot;server&quot;:&quot;30.12.6.2&quot;, &quot;server_port&quot;:8388, &quot;local_port&quot;:1080, &quot;password&quot;:&quot;123456&quot;, &quot;method&quot;: &quot;aes-256-cfb&quot;, &quot;timeout&quot;:600 } 说明：server:服务器ip地址；server_port:服务器端口；local_port:客户端代理端口；method:加密方式； 启动: shadowsocks-server -c /server/shadowsocks/shadowsocks.json &gt; /server/shadowsocks/log &amp;. 说明：-c 指定配置文件。log记录日志。&amp;. 后台执行 查看是否启动： [root@iZj6ca50pk1lwxqo14jss8Z ~]# netstat -lnp|grep 8388 tcp6 0 0 :::8388 :::* LISTEN 25719/shadowsocks-s 客户端linux系统编译好执行文件：Shadowsocks-client在linux客户端解压，修改.json配置文件中相关参数，启动即可。 windows系统直接下载客户端。网址安装包：Shadowsocks-win双击打开： 把服务器ip地址，还有设定的密码天上，确定即可。注意加密方法要和服务端设定的一致。 ubuntu系统 go客户端：go get github.com/shadowsocks/shadowsocks-go/cmd/shadowsocks-local由于被墙，客户端下载不了。所以要在服务端执行，然后再把可执行二进制文件下拉到本地。 配置客户端文件创建文件：shadowsocks-local.json编辑： { &quot;local_port&quot;: 1081, &quot;server_password&quot;: [ [&quot;127.0.0.1:8387&quot;, &quot;foobar&quot;], [&quot;127.0.0.1:8388&quot;, &quot;barfoo&quot;, &quot;aes-128-cfb&quot;] ] } 可以配置多个服务器，单个服务器，则去掉一个。 启动：类似服务端，用-c指定配置文件。 qt5客户端： 二进制包安装。安装网址 推荐，命令安装： #Ubuntu 14.04及更高版本 #添加ppa源 sudo add-apt-repository ppa:hzwhuang/ss-qt5 sudo apt-get update sudo apt-get install shadowsocks-qt5 #启动shadowsocks-qt5 可以通过which shadowsocks-qt5找到可执行文件的位置。 执行 ./shadowsocks-qt5(桌面板，可以通过搜索已安装的shadowsocks-qt5，点击图标启动) 移动 安卓客户端： 下载：Shadowsocks_v4.2.5_apkpure.com.apk 苹果客户端： 安装app：FirstWingy 修改浏览器代理 SOCKS5 127.0.0.1:local_port 如果可以，在chrome中可以安装代理设置插件 然后启动，试下访问：google linux下全局代理实验环境：Ubuntu系统 1.安装应用privoxy 一款工具，将socks代理转换成http。 sudo apt-get install privoxy 2.更改配置 sudo gedit /etc/privoxy/config ---------------------------------------------------------------- # 在 froward-socks4下面添加一条socks5的，因为shadowsocks为socks5， # 地址是127.0.0.1:1080。注意他们最后有一个“.” # forward-socks4 / socks-gw.example.com:1080 . forward-socks5 / 127.0.0.1:1080 . # 下面还存在以下一条配置，表示privoxy监听本机8118端口， # 把它作为http代理，代理地址为 http://localhost.8118/ 。 # 可以把地址改为 0.0.0.0:8118，表示外网也可以通过本机IP作http代理。 # 这样，你的外网IP为1.2.3.4，别人就可以设置 http://1.2.3.4:8118/ 为http代理。 listen-address localhost:8118 #端口可以随意设定 上面配置可能导致无法启动privoxy,新版本安全问题导致。改为： listen-address 192.168.1.115:8118 #端口可以随意设定 3.重启privoxy sudo systemctl restart privoxy.serivce 4.添加环境变量 vim ~/.bashrc ---- 添加两行： export http_proxy=http://127.0.0.1:8118/ export https_proxy=http://127.0.0.1:8118/ 5.使环境变量立即生效 source ~/.bashrc 说明：如果只是想临时的让当前命令窗口代理，那么只需要添加临时变量，不需要编辑~/.bashrc。只需要在当前命令窗口执行export http_proxy=http://127.0.0.1:8118/ export https_proxy=http://127.0.0.1:8118/","tags":[{"name":"shadowsocks-go","slug":"shadowsocks-go","permalink":"https://xinxiamu.github.io/tags/shadowsocks-go/"}]},{"title":"spring-boot异步调用","date":"2017-11-10T08:22:18.000Z","path":"2017/11/10/spring-boot-async/","text":"在一些场景中，为了快速响应页面，把一些对数据一致性要求没那么严格的业务逻辑放到异步执行，可以有效的提交系统性能。在spring-boot中，通过简单的注解 @Async 就可以实现，非常优雅，不用再像以前自己直接new线程。下面是其使用方式： 参考： http://blog.csdn.net/blueheart20/article/details/44648667 http://blog.csdn.net/liuchuanhong1/article/details/64132520 1. 启用异步操作功能很简单，只需要在主类中添加注解@EnableAsync 即可。 package com.ymu.demo.async; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.scheduling.annotation.EnableAsync; @EnableAsync @SpringBootApplication public class SpringBootAsyncApplication { public static void main(String[] args) { SpringApplication.run(SpringBootAsyncApplication.class, args); } } 2. 定义处理类，并添加方法package com.ymu.demo.async; import org.springframework.scheduling.annotation.Async; import org.springframework.scheduling.annotation.AsyncResult; import org.springframework.stereotype.Component; import java.util.Random; import java.util.concurrent.Future; @Component public class Task { public static Random random =new Random(); @Async public void webTest() throws Exception { System.out.println(&quot;开始测试异步&quot;); long start = System.currentTimeMillis(); Thread.sleep(random.nextInt(10000)); long end = System.currentTimeMillis(); System.out.println(&quot;完成测试异步，耗时：&quot; + (end - start) + &quot;毫秒&quot;); } @Async public Future&lt;String&gt; doTaskOne() throws Exception { System.out.println(&quot;开始做任务一&quot;); long start = System.currentTimeMillis(); Thread.sleep(random.nextInt(10000)); long end = System.currentTimeMillis(); System.out.println(&quot;完成任务一，耗时：&quot; + (end - start) + &quot;毫秒&quot;); return new AsyncResult&lt;&gt;(&quot;任务一完成&quot;); } @Async public Future&lt;String&gt; doTaskTwo() throws Exception { System.out.println(&quot;开始做任务二&quot;); long start = System.currentTimeMillis(); Thread.sleep(random.nextInt(10000)); long end = System.currentTimeMillis(); System.out.println(&quot;完成任务二，耗时：&quot; + (end - start) + &quot;毫秒&quot;); return new AsyncResult&lt;&gt;(&quot;任务二完成&quot;); } @Async public Future&lt;String&gt; doTaskThree() throws Exception { System.out.println(&quot;开始做任务三&quot;); long start = System.currentTimeMillis(); Thread.sleep(random.nextInt(10000)); long end = System.currentTimeMillis(); System.out.println(&quot;完成任务三，耗时：&quot; + (end - start) + &quot;毫秒&quot;); return new AsyncResult&lt;&gt;(&quot;任务三完成&quot;); } } 只需要在方法上添加注解@Async。方法webTest是无返回值的，其他的是有返回值，返回的数据类型为Future类型，其为一个接口。具体的结果类型为AsyncResult,这个是需要注意的地方。通过其返回类型，可以检测异步线程执行的情况。 3. 测试package com.ymu.demo.async; import org.junit.Test; import org.junit.runner.RunWith; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.boot.test.context.SpringBootTest; import org.springframework.test.context.junit4.SpringRunner; import java.util.concurrent.Future; @RunWith(SpringRunner.class) @SpringBootTest public class SpringBootAsyncApplicationTests { @Autowired private Task task; @Test public void contextLoads() { System.out.println(&quot;===============load context&quot;); } @Test public void test() throws Exception { long start = System.currentTimeMillis(); Future&lt;String&gt; task1 = task.doTaskOne(); Future&lt;String&gt; task2 = task.doTaskTwo(); Future&lt;String&gt; task3 = task.doTaskThree(); while(true) { if(task1.isDone() &amp;&amp; task2.isDone() &amp;&amp; task3.isDone()) { // 三个任务都调用完成，退出循环等待 break; } Thread.sleep(1000); } long end = System.currentTimeMillis(); System.out.println(&quot;任务全部完成，总耗时：&quot; + (end - start) + &quot;毫秒&quot;); } } package com.ymu.demo.async; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.RestController; @RestController public class IndexController { @Autowired Task task; @GetMapping(&quot;/index&quot;) public String index() throws Exception { task.webTest(); return &quot;index&quot;; } } 4. 基于@Async调用中的异常处理机制 在上面的异步调用中，调用者是无法感知异步线程的执行成功与否的。所以当要对异步线程执行异常做处理的时候，可以按下面方法来： 自定义实现AsyncTaskExecutor的任务执行器。 配置由自定义的TaskExecutor替代内置的任务执行器。 自定义的TaskExecutor","tags":[{"name":"spring-boot-async","slug":"spring-boot-async","permalink":"https://xinxiamu.github.io/tags/spring-boot-async/"}]},{"title":"idea插件利器","date":"2017-11-10T01:55:50.000Z","path":"2017/11/10/idea-good-plug/","text":"GsonFormat 作用：json字符串自动生成javabean工具。 使用： web开发利器emmet官网：https://emmet.io/ 热部署神器JRebelJRebel插件的安装以及破解最新版本破解服务器地址监听服务器地址： http://jrebel.cicoding.cn GUID生成器： http://jrebel.cicoding.cn/guid 监听配置格式： http://jrebel.cicoding.cn/GUID 生成的如下： http://jrebel.cicoding.cn/4B068EB5-0941-4645-1E98-FC077D530A61 idea版本： IntelliJ IDEA 2019.2 x64参考：https://blog.csdn.net/qq_41570658/article/details/96280146https://github.com/ilanyu/ReverseProxy/releases/tag/v1.4 1.第一步，idea在线安装JRebel插件。2.第二步，激活JRebel： 下载https://github.com/ilanyu/ReverseProxy/releases/tag/v1.4 并运行exe文件。 安装下图方式进行激活，License Server: http://127.0.0.1:8888/88414687-3b91-4286-89ba-2dc813b107ceemail: 932852117@qq.com 设置离线模式 激活成功后，你应该看到如下图： JRebel使用","tags":[]},{"title":"idea 使用问题收集","date":"2017-11-10T01:52:52.000Z","path":"2017/11/10/idea-use-ofen/","text":"maven控制台输出乱码问题描述： 执行maven命令，控制台输出中文乱码。 解决方案： 解决：maven默认环境为jdk,只需要改如下即可：在IDEA中，打开File | Settings | Build, Execution, Deployment | Build Tools | Maven | Runner在VM Options中添加-Dfile.encoding=GBK，切记一定是GBK。即使用UTF-8的话，依然是乱码，这是因为Maven的默认平台编码是GBK，如果你在命令行中输入mvn -version的话，会得到如下信息，根据Default locale可以看出","tags":[]},{"title":"spring-data-jpa动态数据源读写分离","date":"2017-11-08T15:02:49.000Z","path":"2017/11/08/spring-jpa-multiple-datasource/","text":"在代码层面配置多数据源，手动或者注解方式自动切换数据源，达到读写分离的目的。可以jpa，jdbc，mybatis共存。 1. 配置数据源采用阿里druid数据源配置连接池。 具体配置如下： package service.basic.user.config.ds; import com.alibaba.druid.filter.Filter; import com.alibaba.druid.filter.logging.Log4j2Filter; import com.alibaba.druid.filter.stat.StatFilter; import com.alibaba.druid.pool.DruidDataSource; import com.alibaba.druid.wall.WallConfig; import com.alibaba.druid.wall.WallFilter; import com.ymu.spcselling.infrastructure.dao.ds.DynamicDataSource; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.beans.factory.annotation.Qualifier; import org.springframework.context.annotation.*; import org.springframework.core.env.Environment; import javax.sql.DataSource; import java.sql.SQLException; import java.util.ArrayList; import java.util.HashMap; import java.util.List; import java.util.Map; /** * 配置数据源 */ @Configuration public class DataSourceConfig { /** * druid监控filter配置。 * @return */ @Bean public StatFilter statFilter() { StatFilter statFilter = new StatFilter(); statFilter.setSlowSqlMillis(5 * 1000); //超过5秒执行的为慢sql statFilter.setLogSlowSql(true); //日志记录慢sql statFilter.setMergeSql(true); //相同sql合并 return statFilter; } //----------- sql注入攻击防御配置 start ---------// @Bean public WallConfig wallConfig() { WallConfig wallConfig = new WallConfig(); wallConfig.setDir(&quot;classpath:druid/wall/mysql&quot;); //sql过滤规则装载位置。 return wallConfig; } @Bean public WallFilter wallFilter() { WallFilter wallFilter = new WallFilter(); wallFilter.setDbType(&quot;mysql&quot;); //指定数据库类型。 wallFilter.setConfig(wallConfig()); return wallFilter; } //----------- sql注入攻击防御配置 end ---------// /** * 打印sql语句。 * @return */ @Bean(name = &quot;log4j2Filter&quot;) public Log4j2Filter log4j2Filter() { Log4j2Filter log4j2Filter = new Log4j2Filter(); log4j2Filter.setConnectionLogEnabled(false); log4j2Filter.setResultSetLogEnabled(true); //显示sql log4j2Filter.setDataSourceLogEnabled(false); log4j2Filter.setStatementExecutableSqlLogEnable(true); //输出可执行的SQL log4j2Filter.setStatementLogEnabled(false); return log4j2Filter; } //-------------- 数据源配置 start ---------------// /** * 会员主库（spcs_user）数据源。 * * @return * @throws SQLException */ @Bean(name = &quot;spcsUserDataSourceWrite&quot;) @Qualifier(&quot;spcsUserDataSourceWrite&quot;) public DataSource spcsUserDataSource(@Autowired SpcsUserDSArgs args) throws SQLException { DruidDataSource dataSource = new DruidDataSource(); dataSource.setUrl(args.getUrl()); dataSource.setUsername(args.getUsername()); dataSource.setPassword(args.getPassword()); dataSource.setDriverClassName(args.getDriverClassName()); dataSource.setInitialSize(args.getInitialSize()); dataSource.setMinIdle(args.getMinIdle()); dataSource.setMaxActive(args.getMaxActive()); dataSource.setMaxWait(args.getMaxWait()); dataSource.setTimeBetweenEvictionRunsMillis(args.getTimeBetweenEvictionRunsMillis()); dataSource.setMinEvictableIdleTimeMillis(args.getMinEvictableIdleTimeMillis()); dataSource.setUseGlobalDataSourceStat(true); //合并多个DruidDataSource的监控数据 List&lt;Filter&gt; proxyFilters = new ArrayList&lt;&gt;(); proxyFilters.add(statFilter()); proxyFilters.add(log4j2Filter()); proxyFilters.add(wallFilter()); dataSource.setProxyFilters(proxyFilters); return dataSource; } /** * 会员从库（spcs_user_slave）数据源。 * * @return * @throws SQLException */ @Bean(name = &quot;spcsUserDataSourceRead_0&quot;) @Qualifier(&quot;spcsUserDataSourceRead_0&quot;) public DataSource spcsUserSlaveDataSource(@Autowired SpcsUserSlaveDSArgs args) throws SQLException { DruidDataSource dataSource = new DruidDataSource(); dataSource.setUrl(args.getUrl()); dataSource.setUsername(args.getUsername()); dataSource.setPassword(args.getPassword()); dataSource.setDriverClassName(args.getDriverClassName()); dataSource.setMinIdle(args.getMinIdle()); dataSource.setInitialSize(args.getInitialSize()); dataSource.setMaxActive(args.getMaxActive()); dataSource.setMaxWait(args.getMaxWait()); dataSource.setTimeBetweenEvictionRunsMillis(args.getTimeBetweenEvictionRunsMillis()); dataSource.setMinEvictableIdleTimeMillis(args.getMinEvictableIdleTimeMillis()); List&lt;Filter&gt; proxyFilters = new ArrayList&lt;&gt;(); proxyFilters.add(statFilter()); proxyFilters.add(log4j2Filter()); proxyFilters.add(wallFilter()); dataSource.setProxyFilters(proxyFilters); return dataSource; } /** * 动态数据源: 通过AOP在不同数据源之间动态切换 * * @return */ @Primary @Bean(name = &quot;dataSource&quot;) @Scope(&quot;singleton&quot;) @DependsOn({&quot;spcsUserDataSourceWrite&quot;,&quot;spcsUserDataSourceRead_0&quot;}) //要加入这个注解，在数据源初始化之后，再初始化本bean，否则会出现循环依赖注入无法启动。 public DataSource dynamicDataSource(@Qualifier(&quot;spcsUserDataSourceWrite&quot;) DataSource spcsUserDataSource, @Qualifier(&quot;spcsUserDataSourceRead_0&quot;) DataSource spcsUserSlaveDataSource) { // 配置多数据源 Map&lt;Object, Object&gt; dsMap = new HashMap&lt;&gt;(5); dsMap.put(DSType.SPCS_USER.name(), spcsUserDataSource); dsMap.put(DSType.SPCS_USER_SLAVE.name(), spcsUserSlaveDataSource); DynamicDataSource dynamicDataSource = new DynamicDataSource(); // 默认数据源 dynamicDataSource.setDefaultTargetDataSource(spcsUserDataSource); dynamicDataSource.setTargetDataSources(dsMap); return dynamicDataSource; } } 注意：dynamicDataSource中一定要加入注解 @Primary，单多个数据元时候，默认取该个，避免无法区分。另外特别注意注解：@DependsOn。一定要加该注解，在实际实际数据源注入后，再注入动态数据源，否则会出现循环依赖导致系统无法启动的局面。 2. 实现自己的数据源路由（关键）相当于多数据源的路由功能。 package com.ymu.spcselling.infrastructure.dao.ds; import org.slf4j.Logger; import org.slf4j.LoggerFactory; import org.springframework.jdbc.datasource.lookup.AbstractRoutingDataSource; public class DynamicDataSource extends AbstractRoutingDataSource { private static final Logger log = LoggerFactory.getLogger(DynamicDataSource.class); @Override protected Object determineCurrentLookupKey() { log.debug(&quot;数据源为{}&quot;, DataSourceContextHolder.getDS()); //可以做一个简单的负载均衡策略 return DataSourceContextHolder.getDS(); } } 3. 持有数据源package com.ymu.spcselling.infrastructure.dao.ds; import org.apache.logging.log4j.LogManager; import org.apache.logging.log4j.Logger; public class DataSourceContextHolder { private static final Logger LOGGER = LogManager.getLogger(DataSourceContextHolder.class); private static final ThreadLocal&lt;String&gt; contextHolder = new ThreadLocal&lt;&gt;(); /** * 设置数据源名。 * @param dbType */ public static void setDS(String dbType) { if (dbType == null) { throw new NullPointerException(&quot;数据源不能null&quot;); } LOGGER.debug(&quot;切换到{}数据源&quot;, dbType); contextHolder.set(dbType); } /** * 获取数据源名。 * @return */ public static String getDS() { return (contextHolder.get()); } /** * 清除数据源名。 */ public static void clearDS() { contextHolder.remove(); } } 4. 通过aop，注解方式持有数据源package service.basic.user.config.ds; import com.ymu.spcselling.infrastructure.dao.ds.DSInject; import com.ymu.spcselling.infrastructure.dao.ds.DataSourceContextHolder; import org.aspectj.lang.JoinPoint; import org.aspectj.lang.annotation.After; import org.aspectj.lang.annotation.Aspect; import org.aspectj.lang.annotation.Before; import org.aspectj.lang.reflect.MethodSignature; import org.springframework.stereotype.Component; import java.lang.reflect.Method; /** * 解析注入的数据源。 */ @Aspect @Component public class DynamicDataSourceAspect { @Before(&quot;@annotation(com.ymu.spcselling.infrastructure.dao.ds.DSInject)&quot;) public void beforeSwitchDS(JoinPoint point) { // 获得当前访问的class Class&lt;?&gt; className = point.getTarget().getClass(); // 获得访问的方法名 String methodName = point.getSignature().getName(); // 得到方法的参数的类型 Class[] argClass = ((MethodSignature) point.getSignature()).getParameterTypes(); String dataSource = DSType.SPCS_USER.name(); //默认主库 try { // 得到访问的方法对象 Method method = className.getMethod(methodName, argClass); // 判断是否存在@DBInject注解 if (method.isAnnotationPresent(DSInject.class)) { DSInject annotation = method.getAnnotation(DSInject.class); // 取出注解中的数据源名 dataSource = annotation.value(); } } catch (Exception e) { e.printStackTrace(); } // 切换数据源 DataSourceContextHolder.setDS(dataSource); } @After(&quot;@annotation(com.ymu.spcselling.infrastructure.dao.ds.DSInject)&quot;) public void afterSwitchDS(JoinPoint point) { DataSourceContextHolder.clearDS(); } } package com.ymu.spcselling.infrastructure.dao.ds; import java.lang.annotation.Documented; import java.lang.annotation.ElementType; import java.lang.annotation.Retention; import java.lang.annotation.RetentionPolicy; import java.lang.annotation.Target; @Target({ ElementType.PARAMETER, ElementType.METHOD }) @Retention(RetentionPolicy.RUNTIME) @Documented public @interface DSInject { String value() default &quot;&quot;; } 5. 配置jpapackage service.basic.user.config.ds; import com.ymu.spcselling.infrastructure.dao.BaseRepositoryFactoryBean; import net.sf.log4jdbc.sql.jdbcapi.DataSourceSpy; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.beans.factory.annotation.Qualifier; import org.springframework.boot.autoconfigure.orm.jpa.JpaProperties; import org.springframework.boot.orm.jpa.EntityManagerFactoryBuilder; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.context.annotation.Primary; import org.springframework.core.env.Environment; import org.springframework.data.jpa.repository.config.EnableJpaRepositories; import org.springframework.orm.jpa.JpaTransactionManager; import org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean; import org.springframework.transaction.PlatformTransactionManager; import org.springframework.transaction.annotation.EnableTransactionManagement; import service.basic.user.common.Constants; import javax.persistence.EntityManager; import javax.sql.DataSource; import java.util.Map; @Configuration @EnableTransactionManagement @EnableJpaRepositories(entityManagerFactoryRef = &quot;entityManagerFactorySpcsUserDB&quot;, transactionManagerRef = &quot;transactionManagerSpcsUserDB&quot;, basePackages = { Constants.SPCS_USER_REPOSITORY_PACKAGE_PATH}, repositoryFactoryBeanClass = BaseRepositoryFactoryBean.class) public class SpcsUserDBConfig { @Autowired Environment ev; @Autowired @Qualifier(&quot;dataSource&quot;) private DataSource dataSource; // 数据源 @Primary @Bean(name = &quot;entityManagerSpcsUser&quot;) public EntityManager entityManager(EntityManagerFactoryBuilder builder) { return entityManagerFactorySpcsUserDB(builder).getObject().createEntityManager(); } @Primary @Bean(name = &quot;entityManagerFactorySpcsUserDB&quot;) public LocalContainerEntityManagerFactoryBean entityManagerFactorySpcsUserDB(EntityManagerFactoryBuilder builder) { if (ev.acceptsProfiles(&quot;dev&quot;) || ev.acceptsProfiles(&quot;test&quot;) || ev.acceptsProfiles(&quot;update&quot;)) { dataSource = new DataSourceSpy(dataSource); // log4jdbc打印sql日志。 } return builder.dataSource(dataSource).properties(getVendorProperties(dataSource)) .packages(Constants.SPCS_USER_ENTITY_PACKAGE_PATH) .persistenceUnit(&quot;spcsUserUnit&quot;).build(); //实体管理器别名,多数据元要设置。 } private Map&lt;String, String&gt; getVendorProperties(DataSource dataSource) { JpaProperties jpaProperties = new JpaProperties(); return jpaProperties.getHibernateProperties(dataSource); } /** * 开启事务。 * * @param builder * @return */ @Primary @Bean(name = &quot;transactionManagerSpcsUserDB&quot;) public PlatformTransactionManager transactionManagerSpcsUserDB(EntityManagerFactoryBuilder builder) { return new JpaTransactionManager(entityManagerFactorySpcsUserDB(builder).getObject()); } } 注意: 注入的数据源为上面配置的动态数据源。@Autowired@Qualifier(“dataSource”)private DataSource dataSource; // 数据源 6. 配置spring jdbcTemplatepackage service.basic.user.config.ds; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.beans.factory.annotation.Qualifier; import org.springframework.boot.autoconfigure.AutoConfigureAfter; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.jdbc.core.JdbcTemplate; import javax.sql.DataSource; @Configuration @AutoConfigureAfter(DataSourceConfig.class) public class JdbcTemplateConfig { @Autowired @Qualifier(value = &quot;dataSource&quot;) private DataSource dataSource; /** * spring jdbc。 * * @return */ @Bean(name = &quot;jdbcTemplate&quot;) @Qualifier(&quot;jdbcTemplate&quot;) public JdbcTemplate jdbcTemplate() { return new JdbcTemplate(dataSource); } } 7. 使用 方式一：可在service层，也可在dao层做。在开始操作数据库前调用： DataSourceContextHolder.setDS(DSType.SPCS_USER_SLAVE.name()); //查询数据 DataSourceContextHolder.clearDS(); 方式二：通过注解，可在service层，也可在dao层做。 @DSInject(value = Constants.SPCS_USER_SLAVE) @Override public User getUserByMobile(String mobile) { return userDao.findUserByMobile(mobile); }","tags":[{"name":"jpa读写分离配置","slug":"jpa读写分离配置","permalink":"https://xinxiamu.github.io/tags/jpa读写分离配置/"}]},{"title":"分布式系统几大难点","date":"2017-11-08T06:57:10.000Z","path":"2017/11/08/distributed-difficulty/","text":"1. 分布式ID2. 分布式事务3. 分布式缓存以及缓存与数据库的同步4. 数据库集群同步延迟问题5. 分布式跨库连表查询6. 分布式定时任务7.分布式锁","tags":[]},{"title":"hibernate表关系映射示例","date":"2017-11-01T09:18:44.000Z","path":"2017/11/01/hibernate-relation-mapping/","text":"1. OneToOne一对一关系，存在n+1问题。 1.1 单向 @OneToOne 实体： @Entity(name = &quot;Phone&quot;) public static class Phone { @Id @GeneratedValue private Long id; @Column(name = &quot;`number`&quot;) private String number; @OneToOne @JoinColumn(name = &quot;details_id&quot;) private PhoneDetails details; public Phone() { } public Phone(String number) { this.number = number; } public Long getId() { return id; } public String getNumber() { return number; } public PhoneDetails getDetails() { return details; } public void setDetails(PhoneDetails details) { this.details = details; } } @Entity(name = &quot;PhoneDetails&quot;) public static class PhoneDetails { @Id @GeneratedValue private Long id; private String provider; private String technology; public PhoneDetails() { } public PhoneDetails(String provider, String technology) { this.provider = provider; this.technology = technology; } public String getProvider() { return provider; } public String getTechnology() { return technology; } public void setTechnology(String technology) { this.technology = technology; } } 生成sql： CREATE TABLE Phone ( id BIGINT NOT NULL , number VARCHAR(255) , details_id BIGINT , PRIMARY KEY ( id ) ) CREATE TABLE PhoneDetails ( id BIGINT NOT NULL , provider VARCHAR(255) , technology VARCHAR(255) , PRIMARY KEY ( id ) ) ALTER TABLE Phone ADD CONSTRAINT FKnoj7cj83ppfqbnvqqa5kolub7 FOREIGN KEY (details_id) REFERENCES PhoneDetails 操作： 作为外键，相当于ManyToOne作为外键操作 1.2 双向 @OneToOne 实体： @Entity(name = &quot;Phone&quot;) public static class Phone { @Id @GeneratedValue private Long id; @Column(name = &quot;`number`&quot;) private String number; @OneToOne(mappedBy = &quot;phone&quot;, cascade = CascadeType.ALL, orphanRemoval = true, fetch = FetchType.LAZY) private PhoneDetails details; public Phone() { } public Phone(String number) { this.number = number; } public Long getId() { return id; } public String getNumber() { return number; } public PhoneDetails getDetails() { return details; } public void addDetails(PhoneDetails details) { details.setPhone( this ); this.details = details; } public void removeDetails() { if ( details != null ) { details.setPhone( null ); this.details = null; } } } @Entity(name = &quot;PhoneDetails&quot;) public static class PhoneDetails { @Id @GeneratedValue private Long id; private String provider; private String technology; @OneToOne(fetch = FetchType.LAZY) @JoinColumn(name = &quot;phone_id&quot;) private Phone phone; public PhoneDetails() { } public PhoneDetails(String provider, String technology) { this.provider = provider; this.technology = technology; } public String getProvider() { return provider; } public String getTechnology() { return technology; } public void setTechnology(String technology) { this.technology = technology; } public Phone getPhone() { return phone; } public void setPhone(Phone phone) { this.phone = phone; } } 生成sql： CREATE TABLE Phone ( id BIGINT NOT NULL , number VARCHAR(255) , PRIMARY KEY ( id ) ) CREATE TABLE PhoneDetails ( id BIGINT NOT NULL , provider VARCHAR(255) , technology VARCHAR(255) , phone_id BIGINT , PRIMARY KEY ( id ) ) ALTER TABLE PhoneDetails ADD CONSTRAINT FKeotuev8ja8v0sdh29dynqj05p FOREIGN KEY (phone_id) REFERENCES Phone 操作： Phone phone = new Phone( &quot;123-456-7890&quot; ); PhoneDetails details = new PhoneDetails( &quot;T-Mobile&quot;, &quot;GSM&quot; ); phone.addDetails( details ); entityManager.persist( phone ); ------------------------------------- INSERT INTO Phone ( number, id ) VALUES ( &apos;123 - 456 - 7890&apos;, 1 ) INSERT INTO PhoneDetails ( phone_id, provider, technology, id ) VALUES ( 1, &apos;T - Mobile, GSM&apos;, 2 ) 2. OneToMany一对多关系，一般在多的一段维护，也可双边维护关系。 2.1 单向 @OneToMany association 实体: @Entity(name = &quot;Person&quot;) public static class Person { @Id @GeneratedValue private Long id; @OneToMany(cascade = CascadeType.ALL, orphanRemoval = true) private List&lt;Phone&gt; phones = new ArrayList&lt;&gt;(); public Person() { } public List&lt;Phone&gt; getPhones() { return phones; } } @Entity(name = &quot;Phone&quot;) public static class Phone { @Id @GeneratedValue private Long id; @Column(name = &quot;`number`&quot;) private String number; public Phone() { } public Phone(String number) { this.number = number; } public Long getId() { return id; } public String getNumber() { return number; } } sql生成： CREATE TABLE Person ( id BIGINT NOT NULL , PRIMARY KEY ( id ) ) CREATE TABLE Person_Phone ( Person_id BIGINT NOT NULL , phones_id BIGINT NOT NULL ) CREATE TABLE Phone ( id BIGINT NOT NULL , number VARCHAR(255) , PRIMARY KEY ( id ) ) ALTER TABLE Person_Phone ADD CONSTRAINT UK_9uhc5itwc9h5gcng944pcaslf UNIQUE (phones_id) ALTER TABLE Person_Phone ADD CONSTRAINT FKr38us2n8g5p9rj0b494sd3391 FOREIGN KEY (phones_id) REFERENCES Phone ALTER TABLE Person_Phone ADD CONSTRAINT FK2ex4e4p7w1cj310kg2woisjl2 FOREIGN KEY (Person_id) REFERENCES Person 操作代码： Person person = new Person(); Phone phone1 = new Phone( &quot;123-456-7890&quot; ); Phone phone2 = new Phone( &quot;321-654-0987&quot; ); person.getPhones().add( phone1 ); person.getPhones().add( phone2 ); entityManager.persist( person ); entityManager.flush(); person.getPhones().remove( phone1 ); ----------------------------------------------- INSERT INTO Person ( id ) VALUES ( 1 ) INSERT INTO Phone ( number, id ) VALUES ( &apos;123 - 456 - 7890&apos;, 2 ) INSERT INTO Phone ( number, id ) VALUES ( &apos;321 - 654 - 0987&apos;, 3 ) INSERT INTO Person_Phone ( Person_id, phones_id ) VALUES ( 1, 2 ) INSERT INTO Person_Phone ( Person_id, phones_id ) VALUES ( 1, 3 ) DELETE FROM Person_Phone WHERE Person_id = 1 INSERT INTO Person_Phone ( Person_id, phones_id ) VALUES ( 1, 3 ) DELETE FROM Phone WHERE id = 2 2.2 双向@OneToMany 实体： @Entity(name = &quot;Person&quot;) public static class Person { @Id @GeneratedValue private Long id; @OneToMany(mappedBy = &quot;person&quot;, cascade = CascadeType.ALL, orphanRemoval = true) private List&lt;Phone&gt; phones = new ArrayList&lt;&gt;(); public Person() { } public Person(Long id) { this.id = id; } public List&lt;Phone&gt; getPhones() { return phones; } public void addPhone(Phone phone) { phones.add( phone ); phone.setPerson( this ); } public void removePhone(Phone phone) { phones.remove( phone ); phone.setPerson( null ); } } @Entity(name = &quot;Phone&quot;) public static class Phone { @Id @GeneratedValue private Long id; @NaturalId @Column(name = &quot;`number`&quot;, unique = true) private String number; @ManyToOne private Person person; public Phone() { } public Phone(String number) { this.number = number; } public Long getId() { return id; } public String getNumber() { return number; } public Person getPerson() { return person; } public void setPerson(Person person) { this.person = person; } @Override public boolean equals(Object o) { if ( this == o ) { return true; } if ( o == null || getClass() != o.getClass() ) { return false; } Phone phone = (Phone) o; return Objects.equals( number, phone.number ); } @Override public int hashCode() { return Objects.hash( number ); } } 生成sql： CREATE TABLE Person ( id BIGINT NOT NULL , PRIMARY KEY ( id ) ) CREATE TABLE Phone ( id BIGINT NOT NULL , number VARCHAR(255) , person_id BIGINT , PRIMARY KEY ( id ) ) ALTER TABLE Phone ADD CONSTRAINT UK_l329ab0g4c1t78onljnxmbnp6 UNIQUE (number) ALTER TABLE Phone ADD CONSTRAINT FKmw13yfsjypiiq0i1osdkaeqpg FOREIGN KEY (person_id) REFERENCES Person 操作： Person person = new Person(); Phone phone1 = new Phone( &quot;123-456-7890&quot; ); Phone phone2 = new Phone( &quot;321-654-0987&quot; ); person.addPhone( phone1 ); person.addPhone( phone2 ); entityManager.persist( person ); entityManager.flush(); person.removePhone( phone1 ); ----------------------------------------- INSERT INTO Phone ( number, person_id, id ) VALUES ( &apos;123-456-7890&apos;, NULL, 2 ) INSERT INTO Phone ( number, person_id, id ) VALUES ( &apos;321-654-0987&apos;, NULL, 3 ) DELETE FROM Phone WHERE id = 2 3. ManyToOne多对一关系 3.1 @ManyToOne association相当于外键 实体 @Entity(name = &quot;Person&quot;) public static class Person { @Id @GeneratedValue private Long id; public Person() { } } @Entity(name = &quot;Phone&quot;) public static class Phone { @Id @GeneratedValue private Long id; @Column(name = &quot;`number`&quot;) private String number; @ManyToOne @JoinColumn(name = &quot;person_id&quot;, foreignKey = @ForeignKey(name = &quot;PERSON_ID_FK&quot;) ) private Person person; public Phone() { } public Phone(String number) { this.number = number; } public Long getId() { return id; } public String getNumber() { return number; } public Person getPerson() { return person; } public void setPerson(Person person) { this.person = person; } } sql生成： CREATE TABLE Person ( id BIGINT NOT NULL , PRIMARY KEY ( id ) ) CREATE TABLE Phone ( id BIGINT NOT NULL , number VARCHAR(255) , person_id BIGINT , PRIMARY KEY ( id ) ) ALTER TABLE Phone ADD CONSTRAINT PERSON_ID_FK FOREIGN KEY (person_id) REFERENCES Person 生命周期: Person person = new Person(); entityManager.persist( person ); Phone phone = new Phone( &quot;123-456-7890&quot; ); phone.setPerson( person ); entityManager.persist( phone ); entityManager.flush(); phone.setPerson( null ); 实际sql： INSERT INTO Person ( id ) VALUES ( 1 ) INSERT INTO Phone ( number, person_id, id ) VALUES ( &apos;123-456-7890&apos;, 1, 2 ) UPDATE Phone SET number = &apos;123-456-7890&apos;, person_id = NULL WHERE id = 2 4. ManyToMany多对多关系，两边都要维护。 4.1 单向 @ManyToMany 实体： @Entity(name = &quot;Person&quot;) public static class Person { @Id @GeneratedValue private Long id; @ManyToMany(cascade = {CascadeType.PERSIST, CascadeType.MERGE}) private List&lt;Address&gt; addresses = new ArrayList&lt;&gt;(); public Person() { } public List&lt;Address&gt; getAddresses() { return addresses; } } @Entity(name = &quot;Address&quot;) public static class Address { @Id @GeneratedValue private Long id; private String street; @Column(name = &quot;`number`&quot;) private String number; public Address() { } public Address(String street, String number) { this.street = street; this.number = number; } public Long getId() { return id; } public String getStreet() { return street; } public String getNumber() { return number; } } 生成sql： CREATE TABLE Address ( id BIGINT NOT NULL , number VARCHAR(255) , street VARCHAR(255) , PRIMARY KEY ( id ) ) CREATE TABLE Person ( id BIGINT NOT NULL , PRIMARY KEY ( id ) ) CREATE TABLE Person_Address ( Person_id BIGINT NOT NULL , addresses_id BIGINT NOT NULL ) ALTER TABLE Person_Address ADD CONSTRAINT FKm7j0bnabh2yr0pe99il1d066u FOREIGN KEY (addresses_id) REFERENCES Address ALTER TABLE Person_Address ADD CONSTRAINT FKba7rc9qe2vh44u93u0p2auwti FOREIGN KEY (Person_id) REFERENCES Person 操作： Person person1 = new Person(); Person person2 = new Person(); Address address1 = new Address( &quot;12th Avenue&quot;, &quot;12A&quot; ); Address address2 = new Address( &quot;18th Avenue&quot;, &quot;18B&quot; ); person1.getAddresses().add( address1 ); person1.getAddresses().add( address2 ); person2.getAddresses().add( address1 ); entityManager.persist( person1 ); entityManager.persist( person2 ); entityManager.flush(); person1.getAddresses().remove( address1 ); ------------------------------------------- INSERT INTO Person ( id ) VALUES ( 1 ) INSERT INTO Address ( number, street, id ) VALUES ( &apos;12A&apos;, &apos;12th Avenue&apos;, 2 ) INSERT INTO Address ( number, street, id ) VALUES ( &apos;18B&apos;, &apos;18th Avenue&apos;, 3 ) INSERT INTO Person ( id ) VALUES ( 4 ) INSERT INTO Person_Address ( Person_id, addresses_id ) VALUES ( 1, 2 ) INSERT INTO Person_Address ( Person_id, addresses_id ) VALUES ( 1, 3 ) INSERT INTO Person_Address ( Person_id, addresses_id ) VALUES ( 4, 2 ) DELETE FROM Person_Address WHERE Person_id = 1 INSERT INTO Person_Address ( Person_id, addresses_id ) VALUES ( 1, 3 ) 4.2 双向 @ManyToMany 实体： @Entity(name = &quot;Person&quot;) public static class Person { @Id @GeneratedValue private Long id; @NaturalId private String registrationNumber; @ManyToMany(cascade = {CascadeType.PERSIST, CascadeType.MERGE}) private List&lt;Address&gt; addresses = new ArrayList&lt;&gt;(); public Person() { } public Person(String registrationNumber) { this.registrationNumber = registrationNumber; } public List&lt;Address&gt; getAddresses() { return addresses; } public void addAddress(Address address) { addresses.add( address ); address.getOwners().add( this ); } public void removeAddress(Address address) { addresses.remove( address ); address.getOwners().remove( this ); } @Override public boolean equals(Object o) { if ( this == o ) { return true; } if ( o == null || getClass() != o.getClass() ) { return false; } Person person = (Person) o; return Objects.equals( registrationNumber, person.registrationNumber ); } @Override public int hashCode() { return Objects.hash( registrationNumber ); } } @Entity(name = &quot;Address&quot;) public static class Address { @Id @GeneratedValue private Long id; private String street; @Column(name = &quot;`number`&quot;) private String number; private String postalCode; @ManyToMany(mappedBy = &quot;addresses&quot;) private List&lt;Person&gt; owners = new ArrayList&lt;&gt;(); public Address() { } public Address(String street, String number, String postalCode) { this.street = street; this.number = number; this.postalCode = postalCode; } public Long getId() { return id; } public String getStreet() { return street; } public String getNumber() { return number; } public String getPostalCode() { return postalCode; } public List&lt;Person&gt; getOwners() { return owners; } @Override public boolean equals(Object o) { if ( this == o ) { return true; } if ( o == null || getClass() != o.getClass() ) { return false; } Address address = (Address) o; return Objects.equals( street, address.street ) &amp;&amp; Objects.equals( number, address.number ) &amp;&amp; Objects.equals( postalCode, address.postalCode ); } @Override public int hashCode() { return Objects.hash( street, number, postalCode ); } } 生成sql： CREATE TABLE Address ( id BIGINT NOT NULL , number VARCHAR(255) , postalCode VARCHAR(255) , street VARCHAR(255) , PRIMARY KEY ( id ) ) CREATE TABLE Person ( id BIGINT NOT NULL , registrationNumber VARCHAR(255) , PRIMARY KEY ( id ) ) CREATE TABLE Person_Address ( owners_id BIGINT NOT NULL , addresses_id BIGINT NOT NULL ) ALTER TABLE Person ADD CONSTRAINT UK_23enodonj49jm8uwec4i7y37f UNIQUE (registrationNumber) ALTER TABLE Person_Address ADD CONSTRAINT FKm7j0bnabh2yr0pe99il1d066u FOREIGN KEY (addresses_id) REFERENCES Address ALTER TABLE Person_Address ADD CONSTRAINT FKbn86l24gmxdv2vmekayqcsgup FOREIGN KEY (owners_id) REFERENCES Person 操作： Person person1 = new Person( &quot;ABC-123&quot; ); Person person2 = new Person( &quot;DEF-456&quot; ); Address address1 = new Address( &quot;12th Avenue&quot;, &quot;12A&quot;, &quot;4005A&quot; ); Address address2 = new Address( &quot;18th Avenue&quot;, &quot;18B&quot;, &quot;4007B&quot; ); person1.addAddress( address1 ); person1.addAddress( address2 ); person2.addAddress( address1 ); entityManager.persist( person1 ); entityManager.persist( person2 ); entityManager.flush(); person1.removeAddress( address1 ); ------------------------------------------ INSERT INTO Person ( registrationNumber, id ) VALUES ( &apos;ABC-123&apos;, 1 ) INSERT INTO Address ( number, postalCode, street, id ) VALUES ( &apos;12A&apos;, &apos;4005A&apos;, &apos;12th Avenue&apos;, 2 ) INSERT INTO Address ( number, postalCode, street, id ) VALUES ( &apos;18B&apos;, &apos;4007B&apos;, &apos;18th Avenue&apos;, 3 ) INSERT INTO Person ( registrationNumber, id ) VALUES ( &apos;DEF-456&apos;, 4 ) INSERT INTO Person_Address ( owners_id, addresses_id ) VALUES ( 1, 2 ) INSERT INTO Person_Address ( owners_id, addresses_id ) VALUES ( 1, 3 ) INSERT INTO Person_Address ( owners_id, addresses_id ) VALUES ( 4, 2 ) DELETE FROM Person_Address WHERE owners_id = 1 INSERT INTO Person_Address ( owners_id, addresses_id ) VALUES ( 1, 3 ) 4.3 双向 many-to-many with a link entity 实体： @Entity(name = &quot;Person&quot;) public static class Person implements Serializable { @Id @GeneratedValue private Long id; @NaturalId private String registrationNumber; @OneToMany(mappedBy = &quot;person&quot;, cascade = CascadeType.ALL, orphanRemoval = true) private List&lt;PersonAddress&gt; addresses = new ArrayList&lt;&gt;(); public Person() { } public Person(String registrationNumber) { this.registrationNumber = registrationNumber; } public Long getId() { return id; } public List&lt;PersonAddress&gt; getAddresses() { return addresses; } public void addAddress(Address address) { PersonAddress personAddress = new PersonAddress( this, address ); addresses.add( personAddress ); address.getOwners().add( personAddress ); } public void removeAddress(Address address) { PersonAddress personAddress = new PersonAddress( this, address ); address.getOwners().remove( personAddress ); addresses.remove( personAddress ); personAddress.setPerson( null ); personAddress.setAddress( null ); } @Override public boolean equals(Object o) { if ( this == o ) { return true; } if ( o == null || getClass() != o.getClass() ) { return false; } Person person = (Person) o; return Objects.equals( registrationNumber, person.registrationNumber ); } @Override public int hashCode() { return Objects.hash( registrationNumber ); } } @Entity(name = &quot;PersonAddress&quot;) public static class PersonAddress implements Serializable { @Id @ManyToOne private Person person; @Id @ManyToOne private Address address; public PersonAddress() { } public PersonAddress(Person person, Address address) { this.person = person; this.address = address; } public Person getPerson() { return person; } public void setPerson(Person person) { this.person = person; } public Address getAddress() { return address; } public void setAddress(Address address) { this.address = address; } @Override public boolean equals(Object o) { if ( this == o ) { return true; } if ( o == null || getClass() != o.getClass() ) { return false; } PersonAddress that = (PersonAddress) o; return Objects.equals( person, that.person ) &amp;&amp; Objects.equals( address, that.address ); } @Override public int hashCode() { return Objects.hash( person, address ); } } @Entity(name = &quot;Address&quot;) public static class Address implements Serializable { @Id @GeneratedValue private Long id; private String street; @Column(name = &quot;`number`&quot;) private String number; private String postalCode; @OneToMany(mappedBy = &quot;address&quot;, cascade = CascadeType.ALL, orphanRemoval = true) private List&lt;PersonAddress&gt; owners = new ArrayList&lt;&gt;(); public Address() { } public Address(String street, String number, String postalCode) { this.street = street; this.number = number; this.postalCode = postalCode; } public Long getId() { return id; } public String getStreet() { return street; } public String getNumber() { return number; } public String getPostalCode() { return postalCode; } public List&lt;PersonAddress&gt; getOwners() { return owners; } @Override public boolean equals(Object o) { if ( this == o ) { return true; } if ( o == null || getClass() != o.getClass() ) { return false; } Address address = (Address) o; return Objects.equals( street, address.street ) &amp;&amp; Objects.equals( number, address.number ) &amp;&amp; Objects.equals( postalCode, address.postalCode ); } @Override public int hashCode() { return Objects.hash( street, number, postalCode ); } } 生成sql： CREATE TABLE Address ( id BIGINT NOT NULL , number VARCHAR(255) , postalCode VARCHAR(255) , street VARCHAR(255) , PRIMARY KEY ( id ) ) CREATE TABLE Person ( id BIGINT NOT NULL , registrationNumber VARCHAR(255) , PRIMARY KEY ( id ) ) CREATE TABLE PersonAddress ( person_id BIGINT NOT NULL , address_id BIGINT NOT NULL , PRIMARY KEY ( person_id, address_id ) ) ALTER TABLE Person ADD CONSTRAINT UK_23enodonj49jm8uwec4i7y37f UNIQUE (registrationNumber) ALTER TABLE PersonAddress ADD CONSTRAINT FK8b3lru5fyej1aarjflamwghqq FOREIGN KEY (person_id) REFERENCES Person ALTER TABLE PersonAddress ADD CONSTRAINT FK7p69mgialumhegyl4byrh65jk FOREIGN KEY (address_id) REFERENCES Address 操作： Person person1 = new Person( &quot;ABC-123&quot; ); Person person2 = new Person( &quot;DEF-456&quot; ); Address address1 = new Address( &quot;12th Avenue&quot;, &quot;12A&quot;, &quot;4005A&quot; ); Address address2 = new Address( &quot;18th Avenue&quot;, &quot;18B&quot;, &quot;4007B&quot; ); entityManager.persist( person1 ); entityManager.persist( person2 ); entityManager.persist( address1 ); entityManager.persist( address2 ); person1.addAddress( address1 ); person1.addAddress( address2 ); person2.addAddress( address1 ); entityManager.flush(); log.info( &quot;Removing address&quot; ); person1.removeAddress( address1 ); --------------------------------------------------- INSERT INTO Person ( registrationNumber, id ) VALUES ( &apos;ABC-123&apos;, 1 ) INSERT INTO Person ( registrationNumber, id ) VALUES ( &apos;DEF-456&apos;, 2 ) INSERT INTO Address ( number, postalCode, street, id ) VALUES ( &apos;12A&apos;, &apos;4005A&apos;, &apos;12th Avenue&apos;, 3 ) INSERT INTO Address ( number, postalCode, street, id ) VALUES ( &apos;18B&apos;, &apos;4007B&apos;, &apos;18th Avenue&apos;, 4 ) INSERT INTO PersonAddress ( person_id, address_id ) VALUES ( 1, 3 ) INSERT INTO PersonAddress ( person_id, address_id ) VALUES ( 1, 4 ) INSERT INTO PersonAddress ( person_id, address_id ) VALUES ( 2, 3 ) DELETE FROM PersonAddress WHERE person_id = 1 AND address_id = 3","tags":[{"name":"hibernate-relation","slug":"hibernate-relation","permalink":"https://xinxiamu.github.io/tags/hibernate-relation/"}]},{"title":"teamcity持续集成使用","date":"2017-10-30T01:18:57.000Z","path":"2017/10/30/teamcity-use-start/","text":"","tags":[{"name":"teamcity-start","slug":"teamcity-start","permalink":"https://xinxiamu.github.io/tags/teamcity-start/"}]},{"title":"java代码优化收藏","date":"2017-10-27T06:57:24.000Z","path":"2017/10/27/java-code-optimization/","text":"收集java代码优雅的写法…… 收集1.https://www.infoq.cn/article/dwA5RVr96s1VtA75ltwz","tags":[]},{"title":"计算机基础-java二进制编码","date":"2017-10-27T06:57:22.000Z","path":"2017/10/27/java-bit/","text":"","tags":[]},{"title":"CGLIB介绍与原理","date":"2017-10-26T07:57:08.000Z","path":"2017/10/26/javase-cglib/","text":"http://blog.csdn.net/zghwaicsdn/article/details/50957474","tags":[{"name":"cglib","slug":"cglib","permalink":"https://xinxiamu.github.io/tags/cglib/"}]},{"title":"计算机基础-字符集","date":"2017-10-26T06:57:22.000Z","path":"2017/10/26/java-charset/","text":"https://blog.csdn.net/lzm18064126848/article/details/50484936","tags":[]},{"title":"Java Nio 缓冲区","date":"2017-10-25T06:57:22.000Z","path":"2017/10/25/java-core-nio-buffer/","text":"","tags":[]},{"title":"maven使用常见错误收集","date":"2017-10-25T06:41:24.000Z","path":"2017/10/25/maven-use-error-collect/","text":"本文收集使用maven过程中的常见错误。 问题：maven继承，使用 &lt;relativePath&gt;&lt;/relativePath&gt;，出现找不到指向pom，但是实际上已经正确指向了。 解决： The relative path of the parent pom.xml file within the check out. If not specified, it defaults to ../pom.xml. Maven looks for the parent POM first in this location on the filesystem, then the local repository, and lastly in the remote repo. relativePath allows you to select a different location, for example when your structure is flat, or deeper without an intermediate parent POM. However, the group ID, artifact ID and version are still required, and must match the file in the location given or it will revert to the repository for the POM. This feature is only for enhancing the development in a local checkout of that project. Set the value to an empty string in case you want to disable the feature and always resolve the parent POM from the repositories.Default value is: ../pom.xml.所以，要在每个父pom上都要加上groupId,artifactId,version。搞定。","tags":[{"name":"maven-error","slug":"maven-error","permalink":"https://xinxiamu.github.io/tags/maven-error/"}]},{"title":"Cron 语法","date":"2017-10-24T02:23:19.000Z","path":"2017/10/24/cron-grammar/","text":"一个cron表达式由6或7个时间元素组成。它们之间用空格分隔，依次为：[秒] [分] [小时] [日] [月] [星期] [年]cron语法主要用在定时任务上。linux系统有个类似的crontab。 序号 说明 是否必填 允许填写的值 允许的符号 1 秒 是 0－59 , - * / 2 分 是 0－59 , - * / 3 小时 是 0－23 , - * / 4 日 是 1－31 , - * ? / L W 5 月 是 1－12 or JAN-DEC , - * / 6 星期 是 1-7 or SUN-SAT , - * ? / L # 7 年 否 1970-2099 , - * / 其中每个元素值可以是一个确定值(6)，一个连续区间(9-12)，一个间隔时间(0/5)，一个列表(1，3，5)或通配符。 详细说明 “-”表示可选值范围，如在“小时”上设置“10-12”，表示10点、11点和12点触发。“，”表示可选的多个值，例如在“星期”上设置“MON，WED，FRI”，表示周一，周三和周五触发。“/”用于递增触发，如在“秒”上面设置“5/15”表示从第5秒开始，每15秒触发一次(5，20，35，50)；在“日”上设置“1/3”表示每月1号开始，每三天触发一次。 *表示所有值. 如在“分”上设置“*”，表示每分钟触发。“？”字符仅出现在“日”和“星期”两个元素上，表示不指定值。当这两个元素之一被指定了值以后，为了避免冲突，需要将另一个元素的值设为“？” “月”和“星期”元素上若使用英文字母是不区分大小写的，即MON与mon相同 “L” 字符仅出现在“日”和“星期”两个元素上，它是单词“last”的缩写。“L”在“日”元素上出现，表示每个月的最后一天；在“星期”元素上出现，表示每个月最后一个星期六。如果在“L”前有具体的内容，它就具有其他的含义了。例如：“6L”在“日”上出现，表示每月的倒数第６天；“5L”在“星期”上出现，表示每月的最后一个星期四 注意：在使用“L”参数时，不要指定列表或范围，因为这会导致问题 W表示离指定日期的最近那个工作日(周一至周五).例如在日字段上设置“15W”，表示离每月15号最近的那个工作日触发。如果15号正好是周六，则找最近的周五(14号)触发；如果15号是周未，则找最近的下周一(16号)触发；如果15号正好在工作日(周一至周五)，则就在该天触发。如果指定格式为“1W”，它则表示每月1号往后最近的工作日触发。如果1号正是周六，则将在3号下周一触发。(注，“W”前只能设置具体的数字，不允许区间“-”)。 小提示：“L”和 “W”可以一组合使用。如果在“日”上设置“LW”，则表示在本月的最后一个工作日触发； 常用示例 0 0 12 ? 每天12点触发 0 15 10 ? 每天10点15分触发 0 15 10 ? 每天10点15分触发 0 15 10 ? * 每天10点15分触发 0 15 10 ? 2005 2005年每天10点15分触发 0 14 * ? 每天14点到14点59分之间，每分钟触发一次 0 0/5 14 ? 每天14点到14点59分之间，每5分钟触发一次（从14点开始触发） 0 0/5 14，18 ? 每天14点到14点59分及18点到18点59分，每5分钟触发一次（分别从14点、18点开始触发） 0 0-5 14 ? 每天14点到14点05分之间，每分钟触发 0 10，44 14 ? 3 WED 3月份每周三14点10分和14点44分触发 0 15 10 ? * MON-FRI 周一到周五每天10点15分触发 0 15 10 15 * ? 每月15号10点15分触发 0 15 10 L * ? 每月最后一天的10点15分触发 0 15 10 ? * 6L 每月最后一个周五的10点15分触发 0 15 10 ? * 6L 2002-2005 从2002年到2005年每月一个周五的10点15分触发 0 15 10 ? * 6#3 每月第三个周五的10点15分触发 0 0 12 1/5 * ? 每月1号的12点开始触发，每隔5天触发一次 资料： 1.cron表达式生成器：http://cron.qqe2.com/","tags":[{"name":"cron-grammar","slug":"cron-grammar","permalink":"https://xinxiamu.github.io/tags/cron-grammar/"}]},{"title":"jvm优化-监控工具","date":"2017-10-20T04:52:40.000Z","path":"2017/10/20/jvm-look-tools/","text":"https://my.oschina.net/u/1859679/blog/1552290","tags":[{"name":"jvm监控工具","slug":"jvm监控工具","permalink":"https://xinxiamu.github.io/tags/jvm监控工具/"}]},{"title":"jvm优化-垃圾回收机制","date":"2017-10-20T04:51:08.000Z","path":"2017/10/20/jvm-gc/","text":"https://my.oschina.net/u/1859679/blog/1548866","tags":[{"name":"gc垃圾回收","slug":"gc垃圾回收","permalink":"https://xinxiamu.github.io/tags/gc垃圾回收/"}]},{"title":"http协议概述(学习笔记)","date":"2017-10-17T13:45:50.000Z","path":"2017/10/17/http-protocol-overview/","text":"HTTP被设计于上20世纪90年代初期，是一种可扩展性的协议。它是应用层的协议，虽然理论上它可以通过任何可靠的传输协议来发送，但是它还是通过TCP，或者是TLS－加密的TCP连接来发送。因为它很好的扩展性，时至今日它不仅被用来传输超文本文档，还用来传输图片、视频或者向服务器发送如HTML表单这样的信息。HTTP还可以根据网页需求，来获取部分web文档的内容来更新网页。https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Overview 1. 基于HTTP的组件系统2. HTTP 的基本性质3. HTTP 能控制什么4. HTTP 流5. HTTP 报文6. 总结","tags":[{"name":"http-overview","slug":"http-overview","permalink":"https://xinxiamu.github.io/tags/http-overview/"}]},{"title":"linux常用命令使用收藏","date":"2017-10-14T03:26:18.000Z","path":"2017/10/14/linux-command-use/","text":"收集linux系统实践过程常用的命令。方便查看！ 1. 系统用户管理1.1. 查看所有系统用户[root@izwz924c5ufaoooso1wswiz ~]# cat /etc/passwd 1.2. 查看系统用户对应的UID[root@izwz924c5ufaoooso1wswiz ~]# cat /etc/group 1.3. 添加系统用户&gt; useradd zmt 添加用户zmt&gt; passwd zmt 为用户zmt添加密码，输入密码即可 1.4. 删除系统用户&gt; userdel -r xz 加上-r参数，userdel会删除用户的HOME目录以及邮件目录 _警告_ 在有大量用户的环境中使用-r参数时要特别小心。你永远不知道用户是否在其HOME目录下存放了其他用户或其他程序要使用的重要文件。记住，在删除用户的HOME目录之前一定要检查清楚！ 1.5 修改用户表7-3 用户账户修改工具 命 令 描 述 usermod 修改用户账户的字段，还可以指定主要组以及附加组的所属关系 passwd 修改已有用户的密码 chpasswd 从文件中读取登录名密码对，并更新密码 chage 修改密码的过期日期 chfn 修改用户账户的备注信息 chsh 修改用户账户的默认登录shell 1. usermodusermod命令是用户账户修改工具中最强大的一个。它能用来修改/etc/passwd文件中的大部分字段，只需用与想修改的字段对应的命令行参数就可以了。参数大部分跟useradd命令的参数一样（比如，-c修改备注字段，-e修改过期日期，-g修改默认的登录组）。除此之外，还有另外一些可能派上用场的选项。 -l修改用户账户的登录名。 -L锁定账户，使用户无法登录。 -p修改账户的密码。 -U解除锁定，使用户能够登录。 -L选项尤其实用。它可以将账户锁定，使用户无法登录，同时无需删除账户和用户的数据。要让账户恢复正常，只要用-U选项就行了。 2. passwd和chpasswd改变用户密码的一个简便方法就是用passwd命令。 # passwd test Changing password for user test. New UNIX password: Retype new UNIX password: passwd: all authentication tokens updated successfully. # 如果只用passwd命令，它会改你自己的密码。系统上的任何用户都能改自己的密码，但只有root用户才有权限改别人的密码。-e选项能强制用户下次登录时修改密码。你可以先给用户设置一个简单的密码，之后再强制在下次登录时改成他们能记住的更复杂的密码。如果需要为系统中的大量用户修改密码，chpasswd命令可以事半功倍。chpasswd命令能从标准输入自动读取登录名和密码对（由冒号分割）列表，给密码加密，然后为用户账户设置。你也可以用重定向命令来将含有userid:passwd对的文件重定向给该命令。 # chpasswd &lt; users.txt # 2. 系统用户组管理2.1 查看所有用户组 &gt; cat /etc/grouproot:x:0:rootbin:x:1:root,bin,daemondaemon:x:2:root,bin,daemonsys:x:3:root,bin,admadm:x:4:root,adm,daemonrich:x:500:mama:x:501:katie:x:502:jessica:x:503:mysql:x:27:test:x:504: 和UID一样，GID在分配时也采用了特定的格式。系统账户用的组通常会分配低于500的GID值，而用户组的GID则会从500开始分配。/etc/group文件有4个字段： 组名 组密码 GID 属于该组的用户列表 2.2 创建新组[root@izwz924c5ufaoooso1wswiz ~]# groupadd spcs [root@izwz924c5ufaoooso1wswiz ~]# tail /etc/group mysql:x:1000: cgred:x:994: docker:x:993: nexus:x:1001: git:x:1002: elsearch:x:1003: epmd:x:992: rabbitmq:x:991: zmt:x:1004: spcs:x:1005: 为spcs组添加成员[root@izwz924c5ufaoooso1wswiz ~]# usermod -G spcs zmt[root@izwz924c5ufaoooso1wswiz ~]# usermod -G spcs git两个系统用户zmt、git将添加到用户组spcs。 _说明_ 如果更改了已登录系统账户所属的用户组，该用户必须登出系统后再登录，组关系的更改才能生效。 2.3 修改组在/etc/group文件中可以看到，需要修改的组信息并不多。groupmod命令可以修改已有组的GID（加-g选项）或组名（加-n选项）。 修改组名 # /usr/sbin/groupmod -n spcs spcselling # tail /etc/group haldaemon:x:68: xfs:x:43: gdm:x:42: rich:x:500: mama:x:501: katie:x:502: jessica:x:503: mysql:x:27: test:x:504: sharing:x:505:test,rich # 修改组名时，GID和组成员不会变，只有组名改变。由于所有的安全权限都是基于GID的，你可以随意改变组名而不会影响文件的安全性。 3. 文件权限管理4. 开机启动命令-chkconfig5. 文档操作5.1 复制文件-cp命令使用 文件到文件复制 将文档a复制成b（相当于备份并改名）。cp -i a b或，cp a b 文件到目录复制 将文档 file1复制到dir1目录下，复制后名称仍未file1cp -i file1 dir1或，cp file1 dir1 目录到目录复制 将目录dir1复制到dir2目录下，复制结果目录被改名为dir2cp -r dir1 dir2将目录dir1下所有文件包括文件夹，都复制到dir2目录下cp -r dir1/. dir2常见错误：1、提示cp: omitting directory错误复制目录时，使用-r选项即可递归拷贝，如下：cp -r dir1 dir2 6. 解压/压缩6.1 压缩 压缩 tar –cvf jpg.tar .jpg //将目录里所有jpg文件打包成tar.jpg tar –czf jpg.tar.gz .jpg //将目录里所有jpg文件打包成jpg.tar后，并且将其用gzip压缩，生成一个gzip压缩过的包，命名为jpg.tar.gz tar –cjf jpg.tar.bz2 .jpg //将目录里所有jpg文件打包成jpg.tar后，并且将其用bzip2压缩，生成一个bzip2压缩过的包，命名为jpg.tar.bz2 tar –cZf jpg.tar.Z .jpg //将目录里所有jpg文件打包成jpg.tar后，并且将其用compress压缩，生成一个umcompress压缩过的包，命名为jpg.tar.Z rar a jpg.rar .jpg //rar格式的压缩，需要先下载rar for linux zip jpg.zip .jpg //zip格式的压缩，需要先下载zip for linux 6.2 解压 解压 tar –xvf file.tar //解压 tar包 tar -xzvf file.tar.gz //解压tar.gz tar -xjvf file.tar.bz2 //解压 tar.bz2 tar –xZvf file.tar.Z //解压tar.Z unrar e file.rar //解压rar unzip file.zip //解压zip 6.3 ubuntu 下rar解压工具安装方法： 1、压缩功能 安装 sudo apt-get install rar 卸载 sudo apt-get remove rar 2、解压功能 安装 sudo apt-get install unrar 卸载 sudo apt-get remove unrar 压缩解压缩.rar 解压：rar x FileName.rar 压缩：rar a FileName.rar DirName 6.4 总结 1、*.tar 用 tar –xvf 解压 2、*.gz 用 gzip -d或者gunzip 解压 3、*.tar.gz和*.tgz 用 tar –xzf 解压 4、*.bz2 用 bzip2 -d或者用bunzip2 解压 5、*.tar.bz2用tar –xjf 解压 6、*.Z 用 uncompress 解压 7、*.tar.Z 用tar –xZf 解压 8、*.rar 用 unrar e解压 9、*.zip 用 unzip 解压 配置环境变量例子： ######## JAVA_HOME ####### JAVA_HOME=/server/java/jdk export JAVA_HOME PATH=$JAVA_HOME/bin:$JAVA_HOME/include:$JAVA_HOME/include/linux:$PATH export PATH CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar export CLASSPATH ######## MySQL ####### MYSQL_HOME=/server/databases/mysql-3810 export MYSQL_HOME PATH=$MYSQL_HOME/bin:$PATH export PATH SELinux 使用https://blog.csdn.net/yanjun821126/article/details/80828908 selinux 开启和关闭1.查看开启状态 /usr/sbin/sestatus -v ##如果SELinux status参数为enabled即为开启状态 ------------------------------- [root@xr-server selinux]# /usr/sbin/sestatus -v SELinux status: enabled SELinuxfs mount: /sys/fs/selinux SELinux root directory: /etc/selinux Loaded policy name: targeted Current mode: enforcing Mode from config file: enforcing Policy MLS status: enabled Policy deny_unknown status: allowed Max kernel policy version: 31 Process contexts: Current context: unconfined_u:unconfined_r:unconfined_t:s0-s0:c0.c1023 Init context: system_u:system_r:init_t:s0 /usr/sbin/sshd system_u:system_r:sshd_t:s0-s0:c0.c1023 File contexts: Controlling terminal: unconfined_u:object_r:user_devpts_t:s0 /etc/passwd system_u:object_r:passwd_file_t:s0 /etc/shadow system_u:object_r:shadow_t:s0 /bin/bash system_u:object_r:shell_exec_t:s0 /bin/login system_u:object_r:login_exec_t:s0 /bin/sh system_u:object_r:bin_t:s0 -&gt; system_u:object_r:shell_exec_t:s0 /sbin/agetty system_u:object_r:getty_exec_t:s0 /sbin/init system_u:object_r:bin_t:s0 -&gt; system_u:object_r:init_exec_t:s0 /usr/sbin/sshd system_u:object_r:sshd_exec_t:s0 也可以用下面命令查看： [root@xr-server selinux]# getenforce Enforcing 关闭1.临时关闭（不需要重启系统） setenforce 0 ##设置SELinux 成为permissive模式 ----------------------------------------------------- setenforce 1 ##设置SELinux 成为enforcing模式（开启） 2.修改配置文件关闭（需要重启系统） 修改/etc/selinux/config 文件 将SELINUX=enforcing改为SELINUX=disabled 然后重启系统即可。 免密码切换到root用户 Linux下普通用户切换到root用户下，默认情况是需要输入密码，这在自动化脚本里面很不方便，因此需要实现普通用户免密切换到root用户。 解决方案： 以root用户登录shell终端，执行vim /etc/sudoers命令，找到如下图所示位置： 在下方添加一行类似的数据，例如用户名称为elk,则添加内容为： ## Allow root to run any commands anywhere root ALL=(ALL) ALL vagrant ALL=(ALL) ALL vagrant是用户名。在vagrant下，执行sudo -s就可以直接切换到root了。其它的账号类似。 保存之后，在普通用户下输入sudo -s命令就可以直接免密切换到root账户了。","tags":[{"name":"linux-command","slug":"linux-command","permalink":"https://xinxiamu.github.io/tags/linux-command/"}]},{"title":"git在centos7下源码编译安装","date":"2017-10-14T02:04:31.000Z","path":"2017/10/14/git-install-in-centos7/","text":"一、安装依赖包yum -y install zlib-devel curl-devel openssl-devel perl cpio expat-devel gettext-devel openssl zlib autoconf tk perl-ExtUtils-MakeMaker 二、下载最新稳定版本安装包源码网址：https://github.com/git/git 三、查看是否已经安装了旧版本 git –version如果有显示版本信息，则先卸载旧版本yum -y remove gityum autoremove 四、解压安装包,并安装 cd /server/toolsunzip git-2.14.1.zipcd git-2.14.1make prefix=/server/git all #安装在目录/server/git下 make prefix=/server/git install 五、添加link ln -s /server/git/bin/git /usr/bin/注：这一步对于原本系统中有旧版git的系统很重要，会报告Link已存在，此时要删除原来的Link即/usr/bin/git，再执行第六步。 六、将git设置为默认路径，不然后面克隆时会报错 ln -s /server/git/bin/ git-upload-pack /usr/bin/git-upload-pack ln -s /server/git/bin/git-receive-pack /usr/bin/git-receive-pack 七、查看版本 git –version #两个横杆 更新git版本下载最新源码重新编译覆盖即可 —————————————– 官网 ————————————-从源代码安装有人觉得从源码安装 Git 更实用，因为你能得到最新的版本。 二进制安装程序倾向于有一些滞后，当然近几年 Git 已经成熟，这个差异不再显著。如果你想从源码安装 Git，需要安装 Git 依赖的库：curl、zlib、openssl、expat，还有libiconv。 如果你的系统上有 yum （如 Fedora）或者 apt-get（如基于 Debian 的系统），可以使用以下命令之一来安装最小化的依赖包来编译和安装 Git 的二进制版： $ sudo yum install curl-devel expat-devel gettext-devel \\ openssl-devel zlib-devel $ sudo apt-get install libcurl4-gnutls-dev libexpat1-dev gettext \\ libz-dev libssl-dev 为了能够添加更多格式的文档（如 doc, html, info），你需要安装以下的依赖包： $ sudo yum install asciidoc xmlto docbook2x $ sudo apt-get install asciidoc xmlto docbook2x 当你安装好所有的必要依赖，你可以继续从几个地方来取得最新发布版本的 tar 包。 你可以从 Kernel.org 网站获取，网址为 https://www.kernel.org/pub/software/scm/git，或从 GitHub 网站上的镜像来获得，网址为 https://github.com/git/git/releases。 通常在 GitHub 上的是最新版本，但 kernel.org 上包含有文件下载签名，如果你想验证下载正确性的话会用到。接着，编译并安装： $ tar -zxf git-2.0.0.tar.gz $ cd git-2.0.0 $ make configure $ ./configure --prefix=/usr $ make all doc info $ sudo make install install-doc install-html install-info 完成后，你可以使用 Git 来获取 Git 的升级： $ git clone git://git.kernel.org/pub/scm/git/git.git","tags":[{"name":"git-install-in-centos","slug":"git-install-in-centos","permalink":"https://xinxiamu.github.io/tags/git-install-in-centos/"}]},{"title":"git服务器使用","date":"2017-10-14T01:58:47.000Z","path":"2017/10/14/git-server-build/","text":"搭建git服务器之前，要在服务器上安装git环境。这里假定已经安装git环境。本篇主要有两部分内容，一、git服务器搭建、二、用户的分配以及用户对文件权限的控制。 首先安装最新版本git 创建git仓库一、创建git用户，用来管理git服务，为git设置密码 id git查看是否已经有该用户，如果没有则创建用户useradd zmtpasswd ** #设置zmt用户密码，注意记得密码 二、创建git仓库 mkdir -p /server/data/git/test.gitgit init –bare /server/data/git/test.git/ #初始化空的版本库于test.gitcd /server/data/git/chown -R zmt:gits test.git/ #把仓库的owner设置为gits用户组下zmt系统用户 三、客户端克隆仓库 git clone git@119.23.78.160:/server/data/git/test.gitCloning into ‘test’…The authenticity of host ‘119.23.78.160 (119.23.78.160)’ can’t be established.ECDSA key fingerprint is SHA256:u7IEulSBpZOfmqBXkr8tW4JJ423qbuM7kMERgAw6MMk.Are you sure you want to continue connecting (yes/no)? yesWarning: Permanently added ‘119.23.78.160’ (ECDSA) to the list of known hosts.git@119.23.78.160‘s password: #输入git系统用户密码：a1234567warning: You appear to have cloned an empty repository.","tags":[{"name":"git-server-build","slug":"git-server-build","permalink":"https://xinxiamu.github.io/tags/git-server-build/"}]},{"title":"TypeScript学习(一)","date":"2017-10-13T15:33:23.000Z","path":"2017/10/13/tslang-study-one/","text":"","tags":[]},{"title":"网站的高性能","date":"2017-10-13T02:33:45.000Z","path":"2017/10/13/website-high-performance/","text":"何为高性能网站:简单点概述就是：客户端发起请求到看到响应数据够快，最好是瞬时响应，这就是高性能。路漫漫其修远兮，吾将上下而求索！ 1. 网站高性能指标1.1 响应时间发出请求到收到响应所需要的时间(多次(如：一万次)请求的平均时间)。代表着系统的快慢。 1.2 并发数指系统能够同时处理请求的数目，这个数字也反映了系统的负载特性。对网站而言也就是指同时提交请求的用户数目。 网站系统注册用户数 &gt; 网站在线用户数 &gt; 网站并发用户数 1.3 吞吐量指单位时间内系统处理的请求数量，体现系统的整体处理能力。 衡量表达式： 请求数/秒 页面数/秒 处理的业务数/小时 量化指标： TPS(每秒事务数) HPS(每秒HTTP请求数) QPS(每秒查询数) 1.4 性能计数器描述服务器或操作系统性能的一些数据指标。 包括（下面部分）： System Load（系统负载） 对象与线程数 内存使用 CPU使用 磁盘与网络I/O 这些指标也是做系统监控的指标。 2. 性能测试以系统设计初期规划的性能指标为预期目标，对系统不断施加压力，验证系统在资源可接受范围内，是否能达到性能预期。 2.1 测试方法： 负载测试 压力测试 稳定性测试 2.2 测试报告看下面简单示例： 并发数 响应时间(ms) TPS 错误率(%) Load(负载) 内存(GB) 备注 10 500 20 0 5 8 性能测试 20 800 30 0 10 10 性能测试 30 1000 40 2 15 14 性能测试 40 1200 45 20 30 16 负载测试 60 2000 30 40 50 16 压力测试 80 超时 0 100 不详 不详 压力测试 3. 性能优化策略系统性能测试达不到预期，则需要找出系统瓶颈，分而治之，逐步优化。 3.1 性能分析检查请求处理的各个环节的日志，分析哪个环节响应时间不合理，超过预期；然后检查监控数据，分析影响性能的主要因素是内存、磁盘、网络、还是cpu，是代码问题还是架构不合理，或者是系统资源确实不够用了。 3.2 性能优化方法通常情况下，web系统可分为前端性能优化、应用服务器性能优化、存储服务器性能优化三大类。 4. Web前端性能优化4.1浏览器访问优化 减少页面请求数量 主要手段是合并CSS、合并js，合并图片。讲浏览器一次访问需要的js、css资源合并成一个文件。多张图片也可以合并。一个页面，服务端也尽可能在一次性请求中返回全部数据，以减少多次请求获取数据。 使用浏览器缓存 缓存静态资源js、css、图片。通过设置HTTP头Cache-Control和Expires属性。 启用压缩 服务端对文件压缩返回，浏览器解压，有效减少通信传输的数据量。 CSS放在页面最上面、js放在页面最下面 浏览器回下载完所有css才对整个页面渲染。浏览器下载完js回马上执行，可能阻塞页面，造成页面缓慢，所以放在下面。但是在界面解析时就要用到的js则放在上面。 减少Cookie传输每次请求都包含Cookie，所以Cookie数据量大的话必然会影响传输速度。因此，要慎重使用，必要的才保存。 4.2 CND加速4.3 反向代理5.","tags":[{"name":"website-high-performance","slug":"website-high-performance","permalink":"https://xinxiamu.github.io/tags/website-high-performance/"}]},{"title":"如何直接在github网站上更新你fork的repo","date":"2017-10-13T01:39:58.000Z","path":"2017/10/13/github-fork-repo-update/","text":"玩过github的人一定会在你自己的账号上fork了一些github开源项目。这些开源项目往往更新比较活跃，你今天fork用到你自己的项目中去了，过几个星期这个fork的origin可能有一些bugfix了，你怎么办呢？当然直接到Origin repo中去clone是一个方法，但是github的public repo有可能过一段时间就被作者删除了，你是否希望在origin即使已经被删除的情况下，你的账号下依然有你钟情的repo？ 解决上面的问题，最好的方法就是不定时地将origin的commit sync到你自己的fork repo中，一方面能够保持鲜活，另一方面有备无患。那么如何sync呢？又有几种方案，一种是你直接在本地clone的repo中，pull upstrame,做好merge，随后push到你自己的fork repo中。另外还有一种更加简便聪明的方法：只需在github网站上点几个鼠标，不用本地开发环境轻松搞定： 1.打开你的github fork repo; 2.点击Pull request;3.点击new pull request.默认情况下，github会比较original/your fork，这时应该不会有任何输出，因为你并没有做过任何变更；4.点击switching the base.这时github将反过来比较yourfork/original，这时你将看到original相对你fork时的所有commit;5.点击create a pull request for this comparison，这时将会反过来向你的repo提交一个pull request;6.这时你作为你自己fork的repo的owner，你就可以点击confirm the merge，大笔一挥，所有的改动都被你一网打尽了@！enjoy it! 附上比较费劲的另外一种更新办法： git remote add upstream &lt;pathtooriginalrepo&gt; git fetch upstream git merge upstream/master master git push origin master","tags":[]},{"title":"在Pivotal Web Service上发布Spring Boot应用","date":"2017-10-12T07:08:33.000Z","path":"2017/10/12/pivotal-web-service-start/","text":"PWS（Pivotal Web Service），由 Pivotal 公司提供的 ，可以运行Java, Grails, Play, Spring, Node.js, Ruby on Rails, Sinatra or Go 等Web应用的服务。本文将介绍一个 Hello World 级别的 Spring Boot 应用发布到 PWS 的过程。 1. 注册账号在 https://run.pivotal.io/ 注册一个账号，完成手机绑定。 2. 安装 cf CLI$ wget https://s3-us-west-1.amazonaws.com/cf-cli-releases/releases/v6.29.1/cf-cli-installer_6.29.1_x86-64.rpm $ rpm -ivh cf-cli-installer_6.29.1_x86-64.rpm 其他系统安装方式：Cloud Foundry Command Line Interface (cf CLI) 3. 打包应用3.1 下载srping-boot应用在 Github 上克隆一个 Spring Boot 的 hello world 的项目。git clone https://github.com/spring-guides/gs-spring-boot.git 3.2 maven打包在 gs-spring-boot/complete 路径下执行：$ mvn clean package 3.3 创建文件manifest.ymlgs-spring-boot/complete路径下，编写 manifest.yml 文件:$ vim manifest.yml 内容如下: applications: - name: myTestApp path: target/gs-spring-boot-0.1.0.jar 说明：name 为应用程序的名字，需自定义；path 为可执行的 jar 文件路径。 4. 发布应用4.1 登录 CLI$ cf login -a api.run.pivotal.io账号和密码填上面注册的。 4.2 提交应用$ cf push -m 1G 5.查看发布结果 在 Pivotal 控制台查看发布的应用程序 访问 https://mytestapp.cfapps.io/ 查看 Web 内容","tags":[{"name":"pws-push","slug":"pws-push","permalink":"https://xinxiamu.github.io/tags/pws-push/"}]},{"title":"scloud-zuul-filters网关过滤","date":"2017-10-11T08:56:22.000Z","path":"2017/10/11/scloud-zuul-filters/","text":"在一个微服务系统中，多个服务可能都需要做一些同样的非业务层面的鉴权，校验等，如果分散在各个服务中做，将加大维护难度。因此，放到统一网关中做同样的鉴权处理，简化维护。为了达到这个目的，因此需要在网关层做拦截，过滤。","tags":[{"name":"zuul-filters","slug":"zuul-filters","permalink":"https://xinxiamu.github.io/tags/zuul-filters/"}]},{"title":"spring-cloud-zuul网关入门","date":"2017-10-11T07:42:53.000Z","path":"2017/10/11/scloud-zuul-start/","text":"1. Zuul简介路由是微服务架构的不可或缺的一部分。例如：”/” 可能映射到你应用主页，/api/users映射到用户服务，/api/shop映射到购物服务。Zuul。Zuul是Netflix出品的一个基于JVM路由和服务端的负载均衡器。 能做什么： Authentication Insights Stress Testing Canary Testing Dynamic Routing Service Migration Load Shedding Security Static Response handling Active/Active traffic management 引入网关后，整个微服务架构演变为: 2. 使用Zuul2.1 引入Zuul组件&lt;dependencies&gt; &lt;!--引入网关组件--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-zuul&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--读取配置中心--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-config&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 2.2 开启Zuul/** * 使用@EnableZuulProxy注解激活zuul。 * 跟进该注解可以看到该注解整合了@EnableCircuitBreaker、@EnableDiscoveryClient，是个组合注解，目的是简化配置。 */ @EnableZuulProxy @SpringBootApplication public class SpcsellingApiGatewayApp { public static void main(String[] args) { new SpringApplicationBuilder(SpcsellingApiGatewayApp.class).run(args); } } 2.3 添加基本配置(.yml )spring: application: name: api-gateway --- eureka: instance: hostname: api.spcs.com #域名 client: service-url: defaultZone: http://localhost:1111/eureka/ #注册发现服务 --- #从配置中心读取配置 spring: cloud: config: name: api-gateway profile: dev label: master fail-fast: true discovery: enabled: true service-id: config-server username: admin password: 123456 #配置路由 zuul: routes: api-a: path: /a/** stripPrefix: true service-id: service-a #服务id api-b: path: /b/** stripPrefix: true service-id: service-b #服务id 首先向eureka注册自己，服务名称为api-gateway；请求路由示例：api.spcs.com/a/users/1 将路由到服务service-a,为：localhost:8001/users/1。b服务的路由也类似。 3. 具体配置使用3.1 负载均衡访问服务application.yml. zuul: routes: users: path: /myusers/** serviceId: users # 关闭ribbon负载均衡器 ribbon: eureka: enabled: false #user服务 users: ribbon: listOfServers: example.com,google.com #多个实例","tags":[{"name":"zuul-start","slug":"zuul-start","permalink":"https://xinxiamu.github.io/tags/zuul-start/"}]},{"title":"jackson使用录","date":"2017-10-01T01:07:36.000Z","path":"2017/10/01/jackson-show-time/","text":"简介Jackson库是一个“旨在为开发者提供更快，更正确，更轻量级，更符合人性思维” 的类库。Jackson为处理JSON格式提供了三种模型的处理方法。 流式API或者增量解析/产生（ incremental parsing/generation）：读写JSON内容被作为离散的事件。 树模型：提供一个可变内存树表示JSON文档。 数据绑定（Data binding）：实现JSON与POJO（简单的Java对象（Plain Old Java Object））的转换。 一般的，我们更加关心json和javad对象的互相转换，这也是程序开发中最常用的。要使用jackson,要下载下面依赖包：http://repo1.maven.org/maven2/com/fasterxml/jackson/core/ &lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-core&lt;/artifactId&gt; &lt;version&gt;2.9.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-databind&lt;/artifactId&gt; &lt;version&gt;2.9.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-annotations&lt;/artifactId&gt; &lt;version&gt;2.9.1&lt;/version&gt; &lt;/dependency&gt; 1. Jackson Annotations介绍","tags":[{"name":"jackson","slug":"jackson","permalink":"https://xinxiamu.github.io/tags/jackson/"}]},{"title":"HashiCorp Vault使用　","date":"2017-09-30T15:40:58.000Z","path":"2017/09/30/hashicorp-vault/","text":"１. 简介HashiCorp Vault是一个私密信息管理的工具。在应用开发中，特别是微服务开发中，用来更好的保护诸如数据库密码，api权限密码，第三方一些账号密码等，以避免在配置文件或者代码中明文硬编码，造成泄露。其在spring-cloud中也有很好的应用。官网：https://www.vaultproject.io/ 1.1 什么是私密信息私密信息主要是一些需要保密的值或者键值对，很多时候会和敏感信息混淆。 这里举几个私密信息的例子： 数据库登录信息 SSL证书 云服务商的ACCESS KEY（比如AWS Cloud的IAM信息） 其他加密用的密钥 API的认证信息 1.2 Vault的目标和特性Vault的目标是成为私密信息的唯一来源，即一个集中化的管理工具。而私密信息的需求方可以程序化的获得所需的信息。对于私密信息，还应该有完善的审计和可视化方法，并且作为一个集中化的依赖，Vault自身必须是高可用的，对于云数据中心友好的安全架构。 Vault为了实现这些目标提供了以下特性： 安全的私密信息存储 动态的私密信息支持 提供对于私密信息的更新，延长有效时间的功能 高度灵活的权限控制 多种客户端验证方式 2. Vault的使用2.1 源码编译安装 安装go环境，配置GOPATH。查看以前配置记录，这里不做介绍。golang 安装git环境查看以前配置记录，这里不做介绍。git 下载源码 $ mkdir -p $GOPATH/src/github.com/hashicorp &amp;&amp; cd $!$ git clone https://github.com/hashicorp/vault.git$ cd vault 下载相关依赖包 $ make bootstrap 编译安装到./bin/下 $ make dev 验证安装是否成功注意查看输出信息，确认vault在环境变量下。 $ vault -v 《未完，待续……》","tags":[{"name":"hashicorp-vault","slug":"hashicorp-vault","permalink":"https://xinxiamu.github.io/tags/hashicorp-vault/"}]},{"title":"spring-boot异常统一处理","date":"2017-09-30T01:33:12.000Z","path":"2017/09/30/spring-boot-exception/","text":"参考：https://www.infoq.cn/article/x-XFMSsN8IrDO2YR0T82 https://my.oschina.net/u/4007037/blog/3049044","tags":[]},{"title":"restful-api设计摘要","date":"2017-09-29T14:07:54.000Z","path":"2017/09/29/restful-api-dev/","text":"本文来源网络第三方。restfull api代码风格思想，参考： RESTful API 《理解RESTful架构》 https://restfulapi.net/resource-naming/ 一. 协议API与用户的通信协议，总是使用HTTPs协议。 二. 域名应该尽量将API部署在专用域名之下。 https://api.example.com 如果确定API很简单，不会有进一步扩展，可以考虑放在主域名下。 https://example.org/api/ 三. 版本（Versioning）应该将API的版本号放入URL。 https://api.example.com/v1/ 另一种做法是，将版本号放在HTTP头信息中，但不如放入URL方便和直观。Github采用这种做法。 四. 路径（Endpoint）路径又称”终点”（endpoint），表示API的具体网址。 在RESTful架构中，每个网址代表一种资源（resource），所以网址中不能有动词，只能有名词，而且所用的名词往往与数据库的表格名对应。一般来说，数据库中的表都是同种记录的”集合”（collection），所以API中的名词也应该使用复数。 举例来说，有一个API提供动物园（zoo）的信息，还包括各种动物和雇员的信息，则它的路径应该设计成下面这样。 https://api.example.com/v1/zoos https://api.example.com/v1/animals https://api.example.com/v1/employees 五. HTTP动词对于资源的具体操作类型，由HTTP动词表示。常用的HTTP动词有下面五个（括号里是对应的SQL命令）。 GET（SELECT）：从服务器取出资源（一项或多项）。 POST（CREATE）：在服务器新建一个资源。 PUT（UPDATE）：在服务器更新资源（客户端提供改变后的完整资源）。 PATCH（UPDATE）：在服务器更新资源（客户端提供改变的属性）。 DELETE（DELETE）：从服务器删除资源。 还有两个不常用的HTTP动词。 HEAD：获取资源的元数据。 OPTIONS：获取信息，关于资源的哪些属性是客户端可以改变的。 下面是一些例子。 GET /zoos：列出所有动物园 POST /zoos：新建一个动物园 GET /zoos/ID：获取某个指定动物园的信息 PUT /zoos/ID：更新某个指定动物园的信息（提供该动物园的全部信息） PATCH /zoos/ID：更新某个指定动物园的信息（提供该动物园的部分信息） DELETE /zoos/ID：删除某个动物园 GET /zoos/ID/animals：列出某个指定动物园的所有动物 DELETE /zoos/ID/animals/ID：删除某个指定动物园的指定动物 六. 过滤信息（Filtering）如果记录数量很多，服务器不可能都将它们返回给用户。API应该提供参数，过滤返回结果。 下面是一些常见的参数。 ?limit=10：指定返回记录的数量 ?offset=10：指定返回记录的开始位置。 ?page=2&amp;per_page=100：指定第几页，以及每页的记录数。 ?sortby=name&amp;order=asc：指定返回结果按照哪个属性排序，以及排序顺序。 ?animal_type_id=1：指定筛选条件 参数的设计允许存在冗余，即允许API路径和URL参数偶尔有重复。比如，GET /zoo/ID/animals 与 GET /animals?zoo_id=ID 的含义是相同的。 七. 状态码（Status Codes）服务器向用户返回的状态码和提示信息，常见的有以下一些（方括号中是该状态码对应的HTTP动词）。 200 OK - [GET]：服务器成功返回用户请求的数据，该操作是幂等的（Idempotent）。 201 CREATED - [POST/PUT/PATCH]：用户新建或修改数据成功。 202 Accepted - [*]：表示一个请求已经进入后台排队（异步任务） 204 NO CONTENT - [DELETE]：用户删除数据成功。 400 INVALID REQUEST - [POST/PUT/PATCH]：用户发出的请求有错误，服务器没有进行新建或修改数据的操作，该操作是幂等的。 401 Unauthorized - [*]：表示用户没有权限（令牌、用户名、密码错误）。 403 Forbidden - [*] 表示用户得到授权（与401错误相对），但是访问是被禁止的。 404 NOT FOUND - [*]：用户发出的请求针对的是不存在的记录，服务器没有进行操作，该操作是幂等的。 406 Not Acceptable - [GET]：用户请求的格式不可得（比如用户请求JSON格式，但是只有XML格式）。 410 Gone -[GET]：用户请求的资源被永久删除，且不会再得到的。 422 Unprocesable entity - [POST/PUT/PATCH] 当创建一个对象时，发生一个验证错误。 500 INTERNAL SERVER ERROR - [*]：服务器发生错误，用户将无法判断发出的请求是否成功。 状态码的完全列表参见这里。 八. 错误处理（Error handling）如果状态码是4xx，就应该向用户返回出错信息。一般来说，返回的信息中将error作为键名，出错信息作为键值即可。 { error: &quot;Invalid API key&quot; } 九. 返回结果针对不同操作，服务器向用户返回的结果应该符合以下规范。 GET /collection：返回资源对象的列表（数组） GET /collection/resource：返回单个资源对象 POST /collection：返回新生成的资源对象 PUT /collection/resource：返回完整的资源对象 PATCH /collection/resource：返回完整的资源对象 DELETE /collection/resource：返回一个空文档 十. 超媒体api(Hypermedia API)RESTful API最好做到Hypermedia，即返回结果中提供链接，连向其他API方法，使得用户不查文档，也知道下一步应该做什么。 比如，当用户向api.example.com的根目录发出请求，会得到这样一个文档。 {&quot;link&quot;: { &quot;rel&quot;: &quot;collection https://www.example.com/zoos&quot;, &quot;href&quot;: &quot;https://api.example.com/zoos&quot;, &quot;title&quot;: &quot;List of zoos&quot;, &quot;type&quot;: &quot;application/vnd.yourformat+json&quot; }} 上面代码表示，文档中有一个link属性，用户读取这个属性就知道下一步该调用什么API了。rel表示这个API与当前网址的关系（collection关系，并给出该collection的网址），href表示API的路径，title表示API的标题，type表示返回类型。 Hypermedia API的设计被称为HATEOAS。Github的API就是这种设计，访问api.github.com会得到一个所有可用API的网址列表。 { &quot;current_user_url&quot;: &quot;https://api.github.com/user&quot;, &quot;authorizations_url&quot;: &quot;https://api.github.com/authorizations&quot;, // ... } 从上面可以看到，如果想获取当前用户的信息，应该去访问api.github.com/user，然后就得到了下面结果。 { &quot;message&quot;: &quot;Requires authentication&quot;, &quot;documentation_url&quot;: &quot;https://developer.github.com/v3&quot; } 面代码表示，服务器给出了提示信息，以及文档的网址。","tags":[{"name":"restful-api","slug":"restful-api","permalink":"https://xinxiamu.github.io/tags/restful-api/"}]},{"title":"spring-boot开发常见异常收录","date":"2017-09-28T16:31:25.000Z","path":"2017/09/29/spring-boot-dev-error-show/","text":"jpa篇1 异常一：缺少jpa数据源配置异常描述：Cannot determine embedded database driver class for database type NONE 原因：该异常在spring-boot应用启动时候报异常。是因为maven依赖中依赖如了jpa，所以系统会自动配置试图注入jpa数据源。但是如果没又配置数据源，则会报该异常。 1.1 处理方法一在pom中剔除jpa注入 &lt;dependency&gt; &lt;groupId&gt;com.ymu.spcselling&lt;/groupId&gt; &lt;artifactId&gt;spcselling-infrastructure&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-jpa&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; 1.2 不传递依赖&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-jpa&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt;&lt;!--不在子应用中传递--&gt; &lt;/dependency&gt; 1.3 在@SpringBootApplication中排除其注入@SpringBootApplication(exclude={DataSourceAutoConfiguration.class,HibernateJpaAutoConfiguration.class}) 2 自动创建表指定Mysql搜索引擎类型解决方法，只需要在配置文件添加如下代码: # 指定生成表名的存储引擎为InneoDB spring.jpa.properties.hibernate.dialect=org.hibernate.dialect.MySQL5InnoDBDialect 启动类配置1.让一个类型不被ComponentScan扫描 @ComponentScan(excludeFilters = @ComponentScan.Filter(type = FilterType.ANNOTATION, value = {ExcludeComponent.class})) //添加了@ExcludeComponent注解的类将不会被ComponentScan扫描 public class ServiceFileclientApplication { public static void main(String[] args) { SpringApplication.run(ServiceFileclientApplication.class, args); } } ---- package com.ymu.servicefileclient.config; public @interface ExcludeComponent { } ------- /** * 该类为Feign的配置类 * 注意：该类不应该在主应用程序上下文的@CompantScan中 */ @ExcludeComponent @Configuration public class FeignConfiguration { /** * 用feign.Contract.Default替换SpringMvcContract契约 * * @return */ @Bean public Contract feignContract() { return new feign.Contract.Default(); } } 文件相关1.在jar包所在目录下创建文件或者文件夹 //运行jar所在文件目录 @Value(&quot;${user.dir}&quot;) private String userDir; //创建文件夹abc URI uri = URI.create(userDir); File file = new File(uri + &quot;/abc&quot;); if (!file.exists()) { file.mkdir(); } 2.系统用户根目录下创建文件 // 桌面路径 FileSystemView fsv = FileSystemView.getFileSystemView(); File com = fsv.getHomeDirectory(); // String url = com.getPath().replaceAll(&quot;\\\\\\\\&quot;, &quot;\\\\\\\\\\\\\\\\&quot;) + &quot;\\\\&quot;; String filePath = com.getPath(); String fileName = &quot;导出数据.pdf&quot;; String uri = filePath.concat(File.separator).concat(fileName); 3.获取类所在资源目录 this.getClass().getClassLoader().getResource(&quot;&quot;).getPath(); --------------------------------------x 近期在用springboot封装一些对外服务的API接口，在本机测试都很顺利，可是当我打包jar文件放到服务器上测试的时候发现了类似下面的异常信息： java.nio.file.NoSuchFileException: file:/app.jar!/BOOT-INF/classes!/xxx.properties 于是网上一番搜索，找到类似的解决方法： Properties prop = new Properties(); InputStream is = this.getClass().getResourceAsStream(filePath); 取消自动配置方式一去掉pom中相关的依赖包。 代码中配置1.使用了@EnableAutoConfiguration的时候 @EnableAutoConfiguration(exclude={DataSourceAutoConfiguration.class}) 2.使用了@SpringBootApplication的时候 @SpringBootApplication(exclude = {DataSourceAutoConfiguration.class}) 1 3.使用了@SpringCloudApplication的时候 @EnableAutoConfiguration(exclude={DataSourceAutoConfiguration.class}) @SpringCloudApplication 4.通过配置文件来设置 spring.autoconfigure.exclude=org.springframework.boot.autoconfigure.jdbc.DataSourceAutoConfiguration 1 spring boot tomcat临时文件夹的问题The temporary upload location [/tmp/tomcat.1337767218595042057.80/work/Tomcat/localhost/ROOT] is no线上的系统中不能上传文件了，出现如下错误： org.springframework.web.multipart.MultipartException: Could not parse multipart servlet request;nested exception is java.io.IOException: The temporary upload location [/tmp/tomcat.1337767218595042057.80/work/Tomcat/localhost/ROOT] is not valid 原因：在linux系统中，springboot应用服务再启动（java -jar 命令启动服务）的时候，会在操作系统的/tmp目录下生成一个tomcat*的文件目录，上传的文件先要转换成临时文件保存在这个文件夹下面。由于临时/tmp目录下的文件，在长时间（10天）没有使用的情况下，就会被系统机制自动删除掉。所以如果系统长时间无人问津的话，就可能导致上面这个问题。 临时解决方法：手动在/tmp下创建相应得文件夹或者重启系统 解决办法：在 yml配置文件 中添加： server.tomcat.basedir: /data/apps/temp 手动的将临时文件夹设置为自定义的文件夹，就不会被Linux删除了。 集成jooq后，添加aop切面，应用启动变慢的问题 问题描述： spring boot2项目中，jpa集成jooq，添加切面，然后启动程序，每次都卡在初始化jpa的地方，要等待一两分钟甚至更久才能启动应用。 aop表达式： @Before(&quot;execution(public * com.xrlj.servicesyscommon.service.impl..*.*(..)))&quot;) 启动会卡在这里： 2019-04-15 00:21:42.100 INFO 9072 --- [ restartedMain] log4jdbc.log4j2 : 2. Connection closed. {executed in 0ms} 2019-04-15 00:21:42.100 INFO 9072 --- [ restartedMain] log4jdbc.log4j2 : 2. Connection.close() returned 2019-04-15 00:21:42.122 INFO 9072 --- [ restartedMain] j.LocalContainerEntityManagerFactoryBean : Initialized JPA EntityManagerFactory for persistence unit &apos;myself_db&apos; 问题解决：把execution表达式，改成within表达式即可。 改成： @Before(&quot;within(com.xrlj.servicesyscommon.service.impl..*)&quot;) 即可。 参考：网上描述，说是集成了jooq后才会这样的。https://github.com/jOOQ/jOOQ/issues/5902","tags":[]},{"title":"spring-boot更改ContextPath方法","date":"2017-09-28T06:03:23.000Z","path":"2017/09/28/sboot-change-contextpath/","text":"在spring-boot项目中，启动后容器的默认context-path为/,如：http://localhost:8080/，那么如何改成http://localhost:8080/api的形式呢？有以下几种方式： 1. 在配置文件Properties &amp; Yaml添加配置1.1 更改properties/src/main/resources/application.properties server.port=8080 server.contextPath=/mkyong 1.2 更改yaml/src/main/resources/application.properties server: port: 8080 contextPath: /mkyong 2、 自定义容器设置EmbeddedServletContainerCustomizerCustomContainer.java package com.mkyong; import org.springframework.boot.context.embedded.ConfigurableEmbeddedServletContainer; import org.springframework.boot.context.embedded.EmbeddedServletContainerCustomizer; import org.springframework.stereotype.Component; @Component public class CustomContainer implements EmbeddedServletContainerCustomizer { @Override public void customize(ConfigurableEmbeddedServletContainer container) { container.setPort(8080); container.setContextPath(&quot;/mkyong&quot;); } } 3. 命令行方式java -jar -Dserver.contextPath=/mkyong spring-boot-example-1.0.jar","tags":[{"name":"change-contextpath-way","slug":"change-contextpath-way","permalink":"https://xinxiamu.github.io/tags/change-contextpath-way/"}]},{"title":"rest-api版本迭代管理实践","date":"2017-09-26T06:23:44.000Z","path":"2017/09/26/api-version/","text":"在API系统设计，特别是有android或者ios移动客户端的系统设计过程中，当业务发生比较大的变动的时候，就会出现一个问题：我们为了使客户端的新旧版本（客户端有的用户可能不会主动升级版本）能准确的访问api接口并得到准确的数据，我们就不得不在该api接口实现中写代码做兼容。这样的话，随着业务的不断调整，整个api接口实现将变得臃肿不堪，同时bug不断，导致不能适用各个版本客户端的请求。因此，对api接口做版本迭代，让接口实现变得简单、易于维护、减少bug就显得十分必要了。 通常，restful-api的版本迭代实现方式主要又两种： 在url中显示设置，如：https://api.example.com/v1/。 在http请求头中添加，如： 设置请求头： Content-Version: 1 请求: https://api.example.com 首先，建立spring-boot-web项目： 在请求头中设置1.创建注解类ApiVersion在controller中添加注解标志api版本 package com.ymu.demo.springboot2apiversion.version; import org.springframework.web.bind.annotation.Mapping; import java.lang.annotation.*; /** * * 接口版本标识注解 * */ @Target({ElementType.METHOD, ElementType.TYPE}) @Retention(RetentionPolicy.RUNTIME) @Documented @Mapping public @interface ApiVersion { int value(); } 2.创建处理类ApiVersionCondition继承RequestCondition，每次url请求都会首先进入该方法。 package com.ymu.demo.springboot2apiversion.version; import org.springframework.web.servlet.mvc.condition.RequestCondition; import javax.servlet.http.HttpServletRequest; import java.util.regex.Pattern; public class ApiVersionCondition implements RequestCondition&lt;ApiVersionCondition&gt; { private int apiVersion; public ApiVersionCondition(int apiVersion){ this.apiVersion = apiVersion; } public ApiVersionCondition combine(ApiVersionCondition other) { // 采用最后定义优先原则，则方法上的定义覆盖类上面的定义 return new ApiVersionCondition(other.getApiVersion()); } public ApiVersionCondition getMatchingCondition(HttpServletRequest request) { String path = request.getServletPath(); if (path == null) { return null; } String contentVersion = request.getHeader(&quot;Content-Version&quot;); //在http请求头中定义api版本，而不是在url中 if (null == contentVersion || &quot;&quot;.equals(contentVersion)) { throw new IllegalArgumentException(&quot;Content-Version非null非空&quot;); } if (!isInteger(contentVersion)) { throw new IllegalArgumentException(&quot;Content-Version必须为整数&quot;); } int version = Integer.valueOf(contentVersion).intValue(); if(version &gt;= this.apiVersion) { // 如果请求的版本号大于配置版本号， 则满足 return this; } return null; } public int compareTo(ApiVersionCondition other, HttpServletRequest request) { // 优先匹配最新的版本号 return other.getApiVersion() - this.apiVersion; } public int getApiVersion() { return apiVersion; } /** * 判断字符串是否为整数。 * @param str * @return */ private boolean isInteger(String str) { Pattern pattern = Pattern.compile(&quot;^[-\\\\+]?[\\\\d]*$&quot;); return pattern.matcher(str).matches(); } } 3.自定义url注册回调类CustomRequestMappingHandlerMappingurl注解回调句柄类。继承RequestMappingHandlerMapping。 package com.ymu.demo.springboot2apiversion.version; import org.springframework.core.annotation.AnnotationUtils; import org.springframework.web.servlet.mvc.condition.RequestCondition; import org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping; import java.lang.reflect.Method; public class CustomRequestMappingHandlerMapping extends RequestMappingHandlerMapping { /** * 类。 * @param handlerType * @return */ @Override protected RequestCondition&lt;ApiVersionCondition&gt; getCustomTypeCondition(Class&lt;?&gt; handlerType) { ApiVersion apiVersion = AnnotationUtils.findAnnotation(handlerType, ApiVersion.class); return createCondition(apiVersion); } /** * 方法 * @param method * @return */ @Override protected RequestCondition&lt;ApiVersionCondition&gt; getCustomMethodCondition(Method method) { ApiVersion apiVersion = AnnotationUtils.findAnnotation(method, ApiVersion.class); return createCondition(apiVersion); } private RequestCondition&lt;ApiVersionCondition&gt; createCondition(ApiVersion apiVersion) { return apiVersion == null ? null : new ApiVersionCondition(apiVersion.value()); } } 4.创建web配置类并编辑内容：WebConfig配置自定义类RequestMappingHandlerMapping。 package com.ymu.demo.springboot2apiversion; import com.ymu.demo.springboot2apiversion.version.CustomRequestMappingHandlerMapping; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.web.servlet.config.annotation.WebMvcConfigurationSupport; import org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping; @Configuration public class WebConfig extends WebMvcConfigurationSupport{ @Override @Bean public RequestMappingHandlerMapping requestMappingHandlerMapping() { RequestMappingHandlerMapping handlerMapping = new CustomRequestMappingHandlerMapping(); handlerMapping.setOrder(0); handlerMapping.setInterceptors(getInterceptors()); return handlerMapping; } } 5.创建演示类HelloController package com.ymu.demo.springboot2apiversion; import com.ymu.demo.springboot2apiversion.version.ApiVersion; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RequestMethod; import org.springframework.web.bind.annotation.RestController; import javax.servlet.http.HttpServletRequest; @RestController @RequestMapping public class HelloController { //---------------- api版本管理 demo start ------------------// @RequestMapping(value = &quot;/hello&quot;,method = RequestMethod.GET) public String hello0(HttpServletRequest request){ print(request); return &quot;hello&quot;; } @RequestMapping(value = &quot;/hello&quot;,method = RequestMethod.GET) @ApiVersion(1) public String hello1(HttpServletRequest request){ print(request); return &quot;hello:v1&quot;; } @RequestMapping(value = &quot;/hello&quot;,method = RequestMethod.GET) @ApiVersion(5) public String hello5(HttpServletRequest request){ print(request); return &quot;hello:v5&quot;; } @RequestMapping(value = &quot;/hello&quot;,method = RequestMethod.GET) @ApiVersion(2) public String hello2(HttpServletRequest request){ print(request); return &quot;hello:v2&quot;; } private void print(HttpServletRequest request) { System.out.println(&quot;version:&quot; + request.getHeader(&quot;Content-Version&quot;)); } } 6.演示： 在url中显示设置在url中显示设置基本和上面过程一样。只不过是要稍微调整下注册路径，在注册路径中添加版本号。 1.修改CustomRequestMappingHandlerMapping类。只需要重写方法： /** * 为所有注册路径添加&quot;/{version}&quot;匹配规则。目的，做api版本管理。 * 不用在每个类或方法的@RequestMapping中加。 * @param method * @param handlerType * @return */ @Override protected RequestMappingInfo getMappingForMethod(Method method, Class&lt;?&gt; handlerType) { RequestMappingInfo requestMappingInfo = super.getMappingForMethod(method, handlerType); if (requestMappingInfo != null) { PatternsRequestCondition pcOri = requestMappingInfo.getPatternsCondition(); Set&lt;String&gt; s = pcOri.getPatterns(); StringBuilder pathNew = new StringBuilder(&quot;&quot;); if (s != null &amp;&amp; !s.isEmpty()) { for (String str: s ) { if (!&quot;/error&quot;.equals(str)) { pathNew.append(&quot;/{version}&quot;); pathNew.append(str); } else { pathNew.append(str); } } } PatternsRequestCondition pcnNew = new PatternsRequestCondition(pathNew.toString()); RequestMappingInfo requestMappingInfoNew = new RequestMappingInfo(requestMappingInfo.getName(),pcnNew,requestMappingInfo.getMethodsCondition(),requestMappingInfo.getParamsCondition(),requestMappingInfo.getHeadersCondition(),requestMappingInfo.getConsumesCondition(),requestMappingInfo.getProducesCondition(),requestMappingInfo.getCustomCondition()); return requestMappingInfoNew; } return requestMappingInfo; } ----------------------------------------------------- 完整代码如下： package com.ymu.framework.spring.mvc.api; import org.springframework.core.annotation.AnnotationUtils; import org.springframework.web.servlet.mvc.condition.PatternsRequestCondition; import org.springframework.web.servlet.mvc.condition.RequestCondition; import org.springframework.web.servlet.mvc.method.RequestMappingInfo; import org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping; import java.lang.reflect.Method; import java.util.Set; public class CustomRequestMappingHandlerMapping extends RequestMappingHandlerMapping { /** * 为所有注册路径添加&quot;/{version}&quot;匹配规则。目的，做api版本管理。 * 不用在每个类或方法的@RequestMapping中加。 * @param method * @param handlerType * @return */ @Override protected RequestMappingInfo getMappingForMethod(Method method, Class&lt;?&gt; handlerType) { RequestMappingInfo requestMappingInfo = super.getMappingForMethod(method, handlerType); if (requestMappingInfo != null) { PatternsRequestCondition pcOri = requestMappingInfo.getPatternsCondition(); Set&lt;String&gt; s = pcOri.getPatterns(); StringBuilder pathNew = new StringBuilder(&quot;&quot;); if (s != null &amp;&amp; !s.isEmpty()) { for (String str: s ) { if (!&quot;/error&quot;.equals(str)) { pathNew.append(&quot;/{version}&quot;); pathNew.append(str); } else { pathNew.append(str); } } } PatternsRequestCondition pcnNew = new PatternsRequestCondition(pathNew.toString()); RequestMappingInfo requestMappingInfoNew = new RequestMappingInfo(requestMappingInfo.getName(),pcnNew,requestMappingInfo.getMethodsCondition(),requestMappingInfo.getParamsCondition(),requestMappingInfo.getHeadersCondition(),requestMappingInfo.getConsumesCondition(),requestMappingInfo.getProducesCondition(),requestMappingInfo.getCustomCondition()); return requestMappingInfoNew; } return requestMappingInfo; } @Override protected RequestCondition&lt;ApiVersionCondition&gt; getCustomTypeCondition(Class&lt;?&gt; handlerType) { ApiVersion apiVersion = AnnotationUtils.findAnnotation(handlerType, ApiVersion.class); return createCondition(apiVersion); } @Override protected RequestCondition&lt;ApiVersionCondition&gt; getCustomMethodCondition(Method method) { ApiVersion apiVersion = AnnotationUtils.findAnnotation(method, ApiVersion.class); return createCondition(apiVersion); } private RequestCondition&lt;ApiVersionCondition&gt; createCondition(ApiVersion apiVersion) { return apiVersion == null ? null : new ApiVersionCondition(apiVersion.value()); } } 2.修改类ApiVersionCondition。主要修改方法：getMatchingCondition public ApiVersionCondition getMatchingCondition(HttpServletRequest request) { // String pathInfo = request.getPathInfo();//这个方法获取是null，报错。 String path = request.getServletPath(); if (path == null) { return null; } Matcher m = VERSION_PREFIX_PATTERN.matcher(path);//匹配路径 if(m.find()){ Integer version = Integer.valueOf(m.group(1)); if(version &gt;= this.apiVersion) // 如果请求的版本号大于配置版本号， 则满足 return this; } return null; } ----------------------------------------------------------- 完整代码如下： package com.ymu.framework.spring.mvc.api; import java.util.regex.Matcher; import java.util.regex.Pattern; import javax.servlet.http.HttpServletRequest; import org.springframework.web.servlet.mvc.condition.RequestCondition; public class ApiVersionCondition implements RequestCondition&lt;ApiVersionCondition&gt; { // 路径中版本的前缀， 这里用 /v[1-9]/的形式 private final static Pattern VERSION_PREFIX_PATTERN = Pattern.compile(&quot;v(\\\\d+)/&quot;); private int apiVersion; public ApiVersionCondition(int apiVersion){ this.apiVersion = apiVersion; } public ApiVersionCondition combine(ApiVersionCondition other) { // 采用最后定义优先原则，则方法上的定义覆盖类上面的定义 return new ApiVersionCondition(other.getApiVersion()); } public ApiVersionCondition getMatchingCondition(HttpServletRequest request) { // String pathInfo = request.getPathInfo();//这个方法获取是null，报错。 String path = request.getServletPath(); if (path == null) { return null; } Matcher m = VERSION_PREFIX_PATTERN.matcher(path);//匹配路径 if(m.find()){ Integer version = Integer.valueOf(m.group(1)); if(version &gt;= this.apiVersion) // 如果请求的版本号大于配置版本号， 则满足 return this; } return null; } public int compareTo(ApiVersionCondition other, HttpServletRequest request) { // 优先匹配最新的版本号 return other.getApiVersion() - this.apiVersion; } public int getApiVersion() { return apiVersion; } } 3.演示：","tags":[{"name":"api-version-manage,spring-boot中API版本迭代管理","slug":"api-version-manage-spring-boot中API版本迭代管理","permalink":"https://xinxiamu.github.io/tags/api-version-manage-spring-boot中API版本迭代管理/"}]},{"title":"微服务实践思考","date":"2017-09-26T02:14:45.000Z","path":"2017/09/26/microservice-think/","text":"","tags":[{"name":"微服务实践总结","slug":"微服务实践总结","permalink":"https://xinxiamu.github.io/tags/微服务实践总结/"}]},{"title":"apidoc在spring-mvc中实践","date":"2017-09-24T15:01:49.000Z","path":"2017/09/24/apidoc-java/","text":"官网：http://apidocjs.com/","tags":[{"name":"apidoc","slug":"apidoc","permalink":"https://xinxiamu.github.io/tags/apidoc/"}]},{"title":"spring-cloud-feign在使用中遇到的一些问题","date":"2017-09-24T13:53:46.000Z","path":"2017/09/24/scloud-feign-anyquestion/","text":"1. feign的接口继承特性1.1 暴露的接口package service.sys.common.api; import com.ymu.spcselling.infrastructure.constants.SpcsConstants; import com.ymu.spcselling.infrastructure.idgenerator.ID; import org.springframework.validation.annotation.Validated; import org.springframework.web.bind.annotation.*; import service.sys.common.vo.req.VIdGenReq; /** * 分布式id生成服务。 */ @RequestMapping(SpcsConstants.API_VERSION + &quot;/id&quot;) public interface IdGenerateApi { /** * 生成分布式id * @param vIdGenReq 请求对象。body体 * @return 生成的系统全局唯一id * * @api {post} /v1/id/gen 生成分布式id * @apiVersion 1.0.0 * @apiName genId * @apiGroup ID * @apiPermission admin * * @apiDescription 通过数据中心id，机器id生成long型唯一id * * @apiParam {long} dataCenterId 数据中心id,0-31。 * @apiParam {long} workerId 机器id，0-31。 * * @apiParamExample {json} Request-Example: * Request Headers * Content-Type:application/json * body: * { * &quot;dataCenterId&quot;: 0, * &quot;workerId:&quot; 0 * } * * @apiExample 请求例子: * curl -i http://localhost/user/4711 * * @apiSuccess {long} id 生成的id * * @apiError NoAccessRight 认证不通过 * @apiError UserNotFound The &lt;code&gt;id&lt;/code&gt; of the User was not found. * * @apiErrorExample 响应例子: * HTTP/1.1 401 Not Authenticated * { * &quot;error&quot;: &quot;NoAccessRight&quot; * } * * @apiSampleRequest url * */ @PostMapping(&quot;/gen&quot;) long genId(@RequestBody @Validated VIdGenReq vIdGenReq); /** * * 解析分布式id * @param id * @return * * @api {post} /v1/id/expId 解析分布式id * @apiVersion 1.0.0 * @apiName expId * @apiGroup ID * @apiPermission admin * * @apiDescription 把id解析成ID对象 * * @apiParam {long} id 接口生成的id，必传。 * * @apiExample 请求例子: * http://localhost/v1/id/expId?id=352608540609069079 * * @apiSuccess {long} timeStamp 时间戳。41位的时间序列 * @apiSuccess {long} dataCenterId 数据中心id * @apiSuccess {long} workerId 节点机器id * @apiSuccess {long} sequence 序列号 * * @apiError NoAccessRight 认证不通过 * //@apiError UserNotFound The &lt;code&gt;id&lt;/code&gt; of the User was not found. * * @apiErrorExample 响应例子: * HTTP/1.1 401 Not Authenticated * { * &quot;error&quot;: &quot;NoAccessRight&quot; * } * * @apiSampleRequest http://localhost/v1/id/expId * */ @GetMapping(&quot;/expId&quot;) ID expId(@RequestParam(value = &quot;id&quot;) long id); } 1.2 接口的实现package service.sys.common.controller; import com.ymu.spcselling.infrastructure.base.AbstractBaseController; import com.ymu.spcselling.infrastructure.idgenerator.ID; import org.apache.logging.log4j.LogManager; import org.apache.logging.log4j.Logger; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.cloud.context.config.annotation.RefreshScope; import org.springframework.web.bind.WebDataBinder; import org.springframework.web.bind.annotation.RequestBody; import org.springframework.web.bind.annotation.RestController; import service.sys.common.api.IdGenerateApi; import service.sys.common.service.local.IdService; import service.sys.common.vo.req.VIdGenReq; import service.sys.common.vo.req.VIdGenReqValidator; @RefreshScope @RestController public class IdGenerateController extends AbstractBaseController implements IdGenerateApi { private static final Logger LOGGER = LogManager.getLogger(SendEmailController.class); @Override protected void initBinder(WebDataBinder binder) { binder.addValidators(new VIdGenReqValidator()); } @Autowired private IdService idService; @Override public long genId(@RequestBody VIdGenReq vIdGenReq) { long id = idService.genId(vIdGenReq.getDataCenterId(), vIdGenReq.getWorkerId()); LOGGER.debug(&quot;genId:&quot; + id); return id; } @Override public ID expId(long id) { ID ID = idService.expId(id); LOGGER.debug(&quot;ID=&quot;, ID.toString()); return ID; } } 注意：在gen()接口方法中，虽然加了mvn的参数注解@RequestBody @Validated，但是在其实现中也要加上，否则这些注解功能将失效。类似的，还有一些其他的注解也要加上。 常见的在实现中要加上的注解有： @RequestBody @Validated @RequestHeader @RequestParam","tags":[{"name":"feign使用常见问题","slug":"feign使用常见问题","permalink":"https://xinxiamu.github.io/tags/feign使用常见问题/"}]},{"title":"spring-cloud-zuul网关统一异常处理","date":"2017-09-23T09:48:05.000Z","path":"2017/09/23/scloud-zuul-exception/","text":"","tags":[{"name":"zuul-exception","slug":"zuul-exception","permalink":"https://xinxiamu.github.io/tags/zuul-exception/"}]},{"title":"Keepalived+LVS+Nginx负载均衡之高可用","date":"2017-09-23T01:48:19.000Z","path":"2017/09/23/Keepalived-LVS-Nginx/","text":"为什么要使用LVS+Nginx在用nginx+tomcat做负载均衡时，接收到客户端请求后，nginx会将请求负载转发到tomcat服务端，同时保持和客户端连接，当服务端处理完毕后nginx再将结果返回给客户端。那么就是说，客户端所有的流量都是要经过nginx的，这就造成了一个问题，系统架构中nginx出现了单机性能瓶颈。而LVS做负载的时候，LVS接到客户端请求,将请求负载转发出去，同时断开与客户端连接，服务端处理完毕直接将结果返回给客户端，不再经过LVS。所以，结合两者优缺点，在nginx前在加多一层LVS为nginx做负载均衡，避免nginx单机性能瓶颈，使系统高可用。同时，使用Keepalived对LVC做双热备，避免单点故障。 参考 官网 Keepalived介绍Keepalived是分布式部署系统解决系统高可用的软件，结合LVS（Linux Virtual Server）使用，其功能类似于heartbeat，解决单机宕机的问题。keepalived是以VRRP协议为实现基础的，VRRP全称Virtual Router Redundancy Protocol，即虚拟路由冗余协议。通过VRRP协议结合LVS，对组群服务器监控情况，若master出现宕机情况，则将VIP漂移到backup机上。实现了分布式系统高可用。可以理解为：keepalived是LVS的管理软件，根据监控情况，将宕机服务器从ipvsadm移除掉。 Keepalived+LVS+Nginx实现系统高可用1. 架构图 服务器 IP地址 说明 虚拟IP 192.168.1.120:80 - 主机 192.168.1.104:80 - 备机 192.168.1.103:80 - Web站点A 192.168.1.101:8081 不同端口 Web站点B 192.168.1.101:8082 不同端口 2. 安装LVS2.1 安装ipvsadm，实现系统支持LVSyum install ipvsadm 3. 安装Keepalivedyum install Keepalived将keepalived设置开机启动systemctl enable keepalived 3.1 配置keepalived","tags":[]},{"title":"redis一主多从集群配置","date":"2017-09-21T05:46:08.000Z","path":"2017/09/21/redis-cluster-centos/","text":"","tags":[{"name":"redis,主从,集群","slug":"redis-主从-集群","permalink":"https://xinxiamu.github.io/tags/redis-主从-集群/"}]},{"title":"分布式ID生成-snowflake算法","date":"2017-09-20T03:06:57.000Z","path":"2017/09/20/distributed-id-snowflake/","text":"应用场景snowflake是twitter开源的分布式ID生成算法，其核心思想是：一个long型的ID，使用其中41bit作为毫秒数，10bit作为机器编号，12bit作为毫秒内序列号。这个算法单机每秒内理论上最多可以生成1000*(2^12)，也就是400W的ID，完全能满足业务的需求。借鉴snowflake的思想，结合各公司的业务逻辑和并发量，可以实现自己的分布式ID生成算法。 举例，假设某公司ID生成器服务的需求如下：（1）单机高峰并发量小于1W，预计未来5年单机高峰并发量小于10W（2）有2个机房，预计未来5年机房数量小于4个（3）每个机房机器数小于100台（4）目前有5个业务线有ID生成需求，预计未来业务线数量小于10个（5）…分析过程如下：（1）高位取从2016年1月1日到现在的毫秒数（假设系统ID生成器服务在这个时间之后上线），假设系统至少运行10年，那至少需要10年365天24小时3600秒1000毫秒=320*10^9，差不多预留39bit给毫秒数（2）每秒的单机高峰并发量小于10W，即平均每毫秒的单机高峰并发量小于100，差不多预留7bit给每毫秒内序列号（3）5年内机房数小于4个，预留2bit给机房标识（4）每个机房小于100台机器，预留7bit给每个机房内的服务器标识（5）业务线小于10个，预留4bit给业务线标识 这样设计的64bit标识，可以保证： （1）每个业务线、每个机房、每个机器生成的ID都是不同的 （2）同一个机器，每个毫秒内生成的ID都是不同的 （3）同一个机器，同一个毫秒内，以序列号区区分保证生成的ID是不同的 （4）将毫秒数放在最高位，保证生成的ID是趋势递增的 缺点： （1）由于“没有一个全局时钟”，每台服务器分配的ID是绝对递增的，但从全局看，生成的ID只是趋势递增的（有些服务器的时间早，有些服务器的时间晚） 最后一个容易忽略的问题： 生成的ID，例如message-id/ order-id/ tiezi-id，在数据量大时往往需要分库分表，这些ID经常作为取模分库分表的依据，为了分库分表后数据均匀，ID生成往往有“取模随机性”的需求，所以我们通常把每秒内的序列号放在ID的最末位，保证生成的ID是随机的。 又如果，我们在跨毫秒时，序列号总是归0，会使得序列号为0的ID比较多，导致生成的ID取模后不均匀。解决方法是，序列号不是每次都归0，而是归一个0到9的随机数，这个地方。 package com.ymu.spcselling.infrastructure.idgenerator; import lombok.extern.slf4j.Slf4j; /** * &lt;p&gt; * Snowflake算法是带有时间戳的全局唯一ID生成算法。它有一套固定的ID格式，如下： * &lt;p&gt; * 41位的时间序列（精确到毫秒，41位的长度可以使用69年） * 10位的机器标识（10位的长度最多支持部署1024个节点） * 12位的Sequence序列号（12位的Sequence序列号支持每个节点每毫秒产生4096个ID序号） * &lt;p&gt; * 结构如下(每部分用-分开):&lt;br&gt; * 0 - 0000000000 0000000000 0000000000 0000000000 0 - 00000 - 00000 - 000000000000 &lt;br&gt; * 优点是：整体上按照时间自增排序，且整个分布式系统内不会产生ID碰撞(由数据中心ID和机器ID作区分) * Author:frankwoo(吴峻申) &lt;br&gt; * Date:2017/8/29 &lt;br&gt; * Time:下午6:32 &lt;br&gt; * Mail:frank_wjs@hotmail.com &lt;br&gt; */ @Slf4j public class SnowflakeIdWorker { //开始时间截 (从2015-01-01起) private static final long START_TIME = 1420041600000L; // 机器ID所占位数 private static final long ID_BITS = 5L; //数据中心ID所占位数 private static final long DATA_CENTER_ID_BITS = 5L; // 机器ID最大值31 (此移位算法可很快计算出n位二进制数所能表示的最大十进制数) private static final long MAX_ID = ~(-1L &lt;&lt; ID_BITS); // 数据中心ID最大值31 private static final long MAX_DATA_CENTER_ID = ~(-1L &lt;&lt; DATA_CENTER_ID_BITS); //Sequence所占位数 private static final long SEQUENCE_BITS = 12L; //机器ID偏移量12 private static final long ID_SHIFT_BITS = SEQUENCE_BITS; //数据中心ID偏移量12+5=17 private static final long DATA_CENTER_ID_SHIFT_BITS = SEQUENCE_BITS + ID_BITS; //时间戳的偏移量12+5+5=22 private static final long TIMESTAMP_LEFT_SHIFT_BITS = SEQUENCE_BITS + ID_BITS + DATA_CENTER_ID_BITS; // Sequence掩码4095 private static final long SEQUENCE_MASK = ~(-1L &lt;&lt; SEQUENCE_BITS); // 上一毫秒数 private static long lastTimestamp = -1L; //毫秒内Sequence(0~4095) private static long sequence = 0L; //机器ID(0-31) private final long workerId; //数据中心ID(0-31) private final long dataCenterId; /** * 构造 * * @param workerId 机器ID(0-31) * @param dataCenterId 数据中心ID(0-31) */ public SnowflakeIdWorker(long workerId, long dataCenterId) { if (workerId &gt; MAX_ID || workerId &lt; 0) { throw new IllegalArgumentException(String.format(&quot;worker Id can&apos;t be greater than %d or less than 0&quot;, MAX_ID)); } if (dataCenterId &gt; MAX_DATA_CENTER_ID || dataCenterId &lt; 0) { throw new IllegalArgumentException(String.format(&quot;datacenter Id can&apos;t be greater than %d or less than 0&quot;, MAX_DATA_CENTER_ID)); } this.workerId = workerId; this.dataCenterId = dataCenterId; log.info(String.format(&quot;worker starting. timestamp left shift %d, datacenter id bits %d, worker id bits %d, sequence bits %d, workerid %d&quot;, TIMESTAMP_LEFT_SHIFT_BITS, DATA_CENTER_ID_BITS, ID_BITS, SEQUENCE_BITS, workerId)); } /** * 生成ID（线程安全） * * @return id */ public synchronized long nextId() { long timestamp = timeGen(); //如果当前时间小于上一次ID生成的时间戳，说明系统时钟被修改过，回退在上一次ID生成时间之前应当抛出异常！！！ if (timestamp &lt; lastTimestamp) { log.error(String.format(&quot;clock is moving backwards. Rejecting requests until %d.&quot;, lastTimestamp)); throw new IllegalStateException(String.format(&quot;Clock moved backwards. Refusing to generate id for %d milliseconds&quot;, lastTimestamp - timestamp)); } //如果是同一时间生成的，则进行毫秒内sequence生成 if (lastTimestamp == timestamp) { sequence = (sequence + 1) &amp; SEQUENCE_MASK; //溢出处理 if (sequence == 0) {//阻塞到下一毫秒,获得新时间戳 timestamp = tilNextMillis(lastTimestamp); } } else {//时间戳改变，毫秒内sequence重置 sequence = 0L; } //上次生成ID时间截 lastTimestamp = timestamp; //移位并通过或运算组成64位ID return ((timestamp - START_TIME) &lt;&lt; TIMESTAMP_LEFT_SHIFT_BITS) | (dataCenterId &lt;&lt; DATA_CENTER_ID_SHIFT_BITS) | (workerId &lt;&lt; ID_SHIFT_BITS) | sequence; } /** * 阻塞到下一毫秒,获得新时间戳 * * @param lastTimestamp 上次生成ID时间截 * @return 当前时间戳 */ private long tilNextMillis(long lastTimestamp) { long timestamp = timeGen(); while (timestamp &lt;= lastTimestamp) { timestamp = timeGen(); } return timestamp; } /** * 获取以毫秒为单位的当前时间 * * @return 当前时间(毫秒) */ private long timeGen() { return System.currentTimeMillis(); } //==============================Test============================================= /** 测试 */ /*public static void main(String[] args) { SnowflakeIdWorker idWorker = new SnowflakeIdWorker(0, 0); for (int i = 0; i &lt; 1000; i++) { long id = idWorker.nextId(); System.out.println(Long.toBinaryString(id)); System.out.println(id); } }*/ }","tags":[{"name":"snowflake算法","slug":"snowflake算法","permalink":"https://xinxiamu.github.io/tags/snowflake算法/"}]}]